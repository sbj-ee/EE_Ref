% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
\documentclass[
  11pt,
]{report}
\usepackage{xcolor}
\usepackage[inner=1.25in,outer=0.85in,top=1in,bottom=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{STIX Two Text}
  \setmonofont[]{Menlo}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\newcounter{none} % for unnumbered tables
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
% STIX Two Text is a variable font; fontspec cannot auto-detect the bold
% weight, so we re-declare the main font with an explicit BoldFont.
\setmainfont{STIX Two Text}[BoldFont={STIX Two Text Bold}]

% Fallback font for math symbols not in STIX Two Text
\usepackage{newunicodechar}
\newfontfamily\mathsymfont{STIX Two Math}
\setmathfont{STIX Two Math}

% Math symbols must be deferred to \AtBeginDocument because pandoc's
% template loads unicode-math, which claims these characters for math mode.
% Without this wrapper, newunicodechar definitions get overridden.
\AtBeginDocument{%
  % Math operators and relations
  \newunicodechar{√}{\ensuremath{\sqrt{\,}}}%
  \newunicodechar{≈}{\ensuremath{\approx}}%
  \newunicodechar{≠}{\ensuremath{\neq}}%
  \newunicodechar{≤}{\ensuremath{\leq}}%
  \newunicodechar{≥}{\ensuremath{\geq}}%
  \newunicodechar{∞}{\ensuremath{\infty}}%
  \newunicodechar{∠}{\ensuremath{\angle}}%
  \newunicodechar{∂}{\ensuremath{\partial}}%
  \newunicodechar{∇}{\ensuremath{\nabla}}%
  \newunicodechar{∫}{{\mathsymfont\char"222B}}%
  \newunicodechar{∮}{{\mathsymfont\char"222E}}%
  \newunicodechar{→}{\ensuremath{\to}}%
  \newunicodechar{↑}{\ensuremath{\uparrow}}%
  \newunicodechar{↓}{\ensuremath{\downarrow}}%
  \newunicodechar{↔}{\ensuremath{\leftrightarrow}}%
  \newunicodechar{∝}{\ensuremath{\propto}}%
  \newunicodechar{≪}{\ensuremath{\ll}}%
  \newunicodechar{≫}{\ensuremath{\gg}}%
  \newunicodechar{⊕}{\ensuremath{\oplus}}%
  \newunicodechar{✓}{{\mathsymfont\char"2713}}%
  \newunicodechar{✗}{\textbf{×}}%
  % Floor and ceiling brackets
  \newunicodechar{⌈}{\ensuremath{\lceil}}%
  \newunicodechar{⌉}{\ensuremath{\rceil}}%
  \newunicodechar{⌊}{\ensuremath{\lfloor}}%
  \newunicodechar{⌋}{\ensuremath{\rfloor}}%
}

% Modifier letters used as superscripts/subscripts in text
\newunicodechar{ᴮ}{\textsuperscript{B}}
\newunicodechar{ᴹ}{\textsuperscript{M}}
\newunicodechar{ᴺ}{\textsuperscript{N}}
\newunicodechar{ᵏ}{\textsuperscript{k}}
\newunicodechar{ᵐ}{\textsuperscript{m}}
\newunicodechar{ₖ}{\textsubscript{k}}
\newunicodechar{ₙ}{\textsubscript{n}}
\newunicodechar{ᵣ}{\textsubscript{r}}

% Page headers and footers for bound book
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
% Even (left-hand) pages: page number on left, section title on right
\fancyhead[LE]{\thepage}
\fancyhead[RE]{\small\itshape\nouppercase{\leftmark}}
% Odd (right-hand) pages: section title on left, page number on right
\fancyhead[LO]{\small\itshape\nouppercase{\rightmark}}
\fancyhead[RO]{\thepage}
% Footer: centered book title
\fancyfoot[CE,CO]{\small\textit{Electrical Engineering Reference}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.2pt}
% Plain pages (chapter openings, TOC): page number centered in footer
\fancypagestyle{plain}{%
  \fancyhf{}%
  \fancyfoot[C]{\thepage}%
  \renewcommand{\headrulewidth}{0pt}%
  \renewcommand{\footrulewidth}{0pt}%
}

% Figure placement and captions
\usepackage{float}
\usepackage{caption}
\captionsetup{font=small, skip=8pt, justification=centering, labelformat=empty}

% Table formatting
\usepackage{booktabs}
\usepackage{longtable}
\renewcommand{\arraystretch}{1.3}

% Green-shaded example boxes
\usepackage[most]{tcolorbox}
\newtcolorbox{examplebox}{
  colback=green!5!white,
  colframe=green!40!black,
  boxrule=0.5pt,
  arc=2pt,
  left=6pt,
  right=6pt,
  top=6pt,
  bottom=6pt,
  before skip=12pt plus 4pt,
  after skip=12pt plus 4pt,
  breakable,
  enhanced,
  before upper={\setlength{\parindent}{0pt}},
}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Electrical Engineering Reference},
  pdfauthor={Stephen B. Johnson},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

\title{Electrical Engineering Reference}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Editio Unica}
\author{Stephen B. Johnson}
\date{}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=blue}
\setcounter{tocdepth}{2}
\tableofcontents
}
\chapter{Foreword}\label{foreword}

\section{The Electric Charge}\label{the-electric-charge}

At the foundation of every topic in this book --- every circuit, every
signal, every electromagnetic wave --- lies a single physical
phenomenon: the electric charge. It is one of the most fundamental
properties of matter, as intrinsic to certain subatomic particles as
mass itself, yet its origins remain one of the deepest mysteries in
physics. We do not fully understand \emph{why} charge exists or
\emph{why} it comes in precisely two types, positive and negative, that
attract and repel with a force that is 10³⁶ times stronger than gravity.
We simply observe that it does, and from this one property, the entire
discipline of electrical engineering unfolds.

Consider what electric charge actually gives us. A stationary charge
creates an electric field that reaches out through empty space, exerting
force on other charges without any physical contact --- action at a
distance that troubled Newton and fascinated Faraday. Set that charge in
motion, and it becomes a current, generating a magnetic field that wraps
around it in closed loops, perpendicular to its direction of travel.
Accelerate the charge, and it radiates electromagnetic waves that
propagate at the speed of light, carrying energy and information across
the universe. These three behaviors --- the electrostatic field, the
magnetic field, and electromagnetic radiation --- are not three separate
phenomena but three manifestations of the same underlying reality,
unified by Maxwell's equations into a single elegant framework.

What makes this especially remarkable is the precision and reliability
of electrical phenomena. The charge of an electron, 1.602 × 10⁻¹⁹
coulombs, is identical for every electron in the universe --- not
approximately identical, but exactly so, to the limits of our
measurement capability. This uniformity means that electrical systems
are inherently predictable and reproducible. A resistor obeys Ohm's Law
whether it is in a basement lab in Middleton, Wisconsin or on a
spacecraft approaching Mars. A photon emitted by a semiconductor
junction carries exactly the energy corresponding to the bandgap of the
material. This predictability is what makes engineering possible: we can
design, analyze, and build systems with confidence that the underlying
physics will behave exactly as the mathematics describes.

The flow of charge through a conductor --- something as simple as
electrons drifting through copper wire --- enables the entire modern
world. In a power system, vast numbers of electrons oscillate back and
forth sixty times per second, transferring gigawatts of energy from
generators to cities hundreds of miles away, with the electromagnetic
field doing the actual work of energy transport while the electrons
themselves barely move. In a semiconductor, carefully arranged regions
of excess and deficit charge create the PN junctions and transistor
channels that form the basis of all digital computation --- billions of
tiny switches on a chip the size of a fingernail, each one exploiting
the quantum mechanical behavior of charge carriers in crystalline
silicon. In an antenna, oscillating charges launch electromagnetic waves
into free space, carrying voice, data, and video to receivers on the
other side of the planet or on satellites in orbit.

Every chapter in this book explores a different aspect of how we
harness, control, measure, and understand the behavior of electric
charge. Power engineering moves charge in bulk to deliver energy.
Communications engineering encodes information onto oscillating charges
and fields. Semiconductor physics explains how charge behaves in
crystalline materials. Control systems regulate the flow of charge to
achieve desired outcomes. Circuit analysis provides the mathematical
tools to predict what charge will do in any network of components.
Signal processing extracts meaning from the time-varying patterns of
charge. Electromagnetics describes the fields that charge creates and
responds to. Each discipline is a different lens focused on the same
underlying phenomenon.

The fact that so much of our technological civilization rests on a
single elementary property of matter --- a property we can measure with
extraordinary precision but cannot fully explain --- should give any
engineer a sense of wonder. Electric charge is not just the starting
point of electrical engineering; it is the thread that connects every
topic in this book, from the 800 kV transmission lines that span
continents to the nanometer-scale transistors that process billions of
operations per second. Understanding this connection transforms
electrical engineering from a collection of specialized disciplines into
a coherent story about one of nature's most remarkable gifts.

\chapter{Introduction}\label{introduction}

Electrical engineering spans a broad range of disciplines --- from power
systems and communications to semiconductors, control theory, and signal
processing. While the foundational principles remain grounded in circuit
theory and electromagnetics, the field has expanded to encompass digital
logic, embedded systems, photonics, and beyond.

Power Engineering

Communications Engineering

Semiconductors

Control Systems

Embedded Systems

Digital Logic

Circuit Analysis

Signal Processing

Electromagnetics

Power Electronics

Instrumentation and Measurement

Electric Motors

Operational Amplifiers

National Electrical Code (NEC)

Networking

Antenna Design and Principles

Radar Systems

Optics

Engineering Economics

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Appendices}

Imaginary Numbers and Phasors

Arctangent and atan2

Decibels

Unit Prefixes and SI Units

Getting Started with Python and marimo

Matrix Operations

\chapter{List of Figures}\label{list-of-figures}

\section{Chapter 1: Power
Engineering}\label{chapter-1-power-engineering}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-1-1}{Figure 1.1: U.S. Electricity Generation by Source (2022)}
\item
  \hyperlink{fig-1-3-6}{Figure 1.3.6: Power Factor Correction Analysis}
\item
  \hyperlink{fig-1-5-1}{Figure 1.5.1: Harmonic Spectrum and THD}
\end{itemize}

\section{Chapter 2: Communications
Engineering}\label{chapter-2-communications-engineering}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-2-1-1}{Figure 2.1.1: AM Modulation Waveform and Spectrum}
\item
  \hyperlink{fig-2-3}{Figure 2.3: Digital Modulation Constellation Diagrams}
\item
  \hyperlink{fig-2-6-1}{Figure 2.6.1: Shannon Channel Capacity vs SNR}
\end{itemize}

\section{Chapter 3: Semiconductors}\label{chapter-3-semiconductors}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-3-1-1}{Figure 3.1.1: Energy Band Diagrams: Conductor vs Semiconductor vs Insulator}
\item
  \hyperlink{fig-3-3-1}{Figure 3.3.1: PN Junction I-V Characteristic}
\item
  \hyperlink{fig-3-5-2}{Figure 3.5.2: MOSFET I-V Characteristics}
\end{itemize}

\section{Chapter 4: Control Systems}\label{chapter-4-control-systems}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-4-5}{Figure 4.5: Step Response: Second-Order System}
\item
  \hyperlink{fig-4-7-2}{Figure 4.7.2: Root Locus Plot}
\item
  \hyperlink{fig-4-8}{Figure 4.8: Bode Plot: Second-Order System}
\end{itemize}

\section{Chapter 5: Embedded Systems}\label{chapter-5-embedded-systems}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-5-4-2}{Figure 5.4.2: SPI Mode 0 Timing Diagram}
\item
  \hyperlink{fig-5-7-1}{Figure 5.7.1: Sleep Mode Average Current and Battery Life vs Wake Interval}
\item
  \hyperlink{fig-5-7-2}{Figure 5.7.2: Low-Power Frequency Scaling: Optimized vs Unoptimized Current}
\end{itemize}

\section{Chapter 6: Digital Logic}\label{chapter-6-digital-logic}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-6-1}{Figure 6.1: Number System Conversion Table (Decimal, Binary, Hex, Octal)}
\item
  \hyperlink{fig-6-2}{Figure 6.2: Logic Gate Truth Tables}
\item
  \hyperlink{fig-6-5-3}{Figure 6.5.3: 3-Bit Binary Counter Timing Diagram}
\end{itemize}

\section{Chapter 7: Circuit Analysis}\label{chapter-7-circuit-analysis}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-7-7-1}{Figure 7.7.1: Series RL Impedance vs Frequency}
\item
  \hyperlink{fig-7-7-2}{Figure 7.7.2: Series RLC Resonance}
\item
  \hyperlink{fig-7-8-1}{Figure 7.8.1: RC Charging Curve}
\item
  \hyperlink{fig-7-8-2}{Figure 7.8.2: RL Circuit Transient Response}
\item
  \hyperlink{fig-7-8-3}{Figure 7.8.3: Underdamped RLC Step Response}
\end{itemize}

\section{Chapter 8: Signal
Processing}\label{chapter-8-signal-processing}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-8-1-5}{Figure 8.1.5: Sampling and Aliasing}
\item
  \hyperlink{fig-8-2-1}{Figure 8.2.1: Fourier Series Harmonics of a Square Wave}
\item
  \hyperlink{fig-8-2-2}{Figure 8.2.2: Rectangular Pulse and Sinc Spectrum}
\item
  \hyperlink{fig-8-2-3}{Figure 8.2.3: DFT Frequency Bins}
\item
  \hyperlink{fig-8-2-6}{Figure 8.2.6: Hilbert Transform Envelope Extraction}
\item
  \hyperlink{fig-8-4-4}{Figure 8.4.4: Bilinear Transform: Analog vs Digital Filter}
\item
  \hyperlink{fig-8-5-1}{Figure 8.5.1: FIR Lowpass Filter Response}
\item
  \hyperlink{fig-8-5-2}{Figure 8.5.2: IIR Lowpass Filter Response}
\item
  \hyperlink{fig-8-5-7}{Figure 8.5.7: Allpass Filter: Magnitude and Group Delay}
\item
  \hyperlink{fig-8-6-1}{Figure 8.6.1: White Noise Power Spectral Density}
\item
  \hyperlink{fig-8-6-6}{Figure 8.6.6: Wavelet Transform Multi-Level Decomposition}
\end{itemize}

\section{Chapter 9: Electromagnetics}\label{chapter-9-electromagnetics}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-9-2-5}{Figure 9.2.5: B-H Hysteresis Loop}
\item
  \hyperlink{fig-9-4-4}{Figure 9.4.4: Skin Depth vs Frequency}
\item
  \hyperlink{fig-9-5-5}{Figure 9.5.5: Microstrip Z₀ and εeff vs Trace Width Ratio (W/h)}
\item
  \hyperlink{fig-9-5-6}{Figure 9.5.6: TDR Lattice Diagram and Voltage Waveforms}
\item
  \hyperlink{fig-9-7-1}{Figure 9.7.1: Shielding Effectiveness vs Frequency}
\end{itemize}

\section{Chapter 10: Power
Electronics}\label{chapter-10-power-electronics}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-10-2-1}{Figure 10.2.1: Full-Wave Bridge Rectifier}
\item
  \hyperlink{fig-10-2-3}{Figure 10.2.3: Rectifier Harmonic Spectrum: 6-Pulse vs 12-Pulse}
\item
  \hyperlink{fig-10-3-1}{Figure 10.3.1: Buck Converter Inductor Current}
\item
  \hyperlink{fig-10-3-2}{Figure 10.3.2: Boost Converter Inductor Current}
\item
  \hyperlink{fig-10-4-1}{Figure 10.4.1: SPWM Inverter Output}
\item
  \hyperlink{fig-10-4-3}{Figure 10.4.3: Multilevel Inverter: 2-Level vs 3-Level NPC}
\item
  \hyperlink{fig-10-6-1}{Figure 10.6.1: MOSFET Power Losses vs Switching Frequency}
\item
  \hyperlink{fig-10-7-1}{Figure 10.7.1: Active PFC Current Shaping}
\item
  \hyperlink{fig-10-8-1}{Figure 10.8.1: 96s NMC Pack Voltage vs SOC}
\item
  \hyperlink{fig-10-8-2}{Figure 10.8.2: Passive Cell Balancing Convergence}
\item
  \hyperlink{fig-10-8-3}{Figure 10.8.3: SOC Estimation with Coulomb Counting Drift}
\item
  \hyperlink{fig-10-9-3}{Figure 10.9.3: BESS Frequency Regulation Droop Response}
\item
  \hyperlink{fig-10-9-4}{Figure 10.9.4: BESS Peak Shaving Load Profile}
\item
  \hyperlink{fig-10-9-5}{Figure 10.9.5: BESS Capacity Degradation and LCOS}
\item
  \hyperlink{fig-10-10-1}{Figure 10.10.1: CC/CV Charging Profile}
\item
  \hyperlink{fig-10-10-4}{Figure 10.10.4: Fast Charging Thermal Analysis}
\item
  \hyperlink{fig-10-10-5}{Figure 10.10.5: Wireless Charging Efficiency vs Coupling Coefficient}
\item
  \hyperlink{fig-10-11-1}{Figure 10.11.1: EDLC Energy Storage vs Voltage — Usable 75\% and Electrolyte Comparison}
\item
  \hyperlink{fig-10-11-2}{Figure 10.11.2: Ragone Plot — Specific Power vs Specific Energy for Energy Storage Technologies}
\item
  \hyperlink{fig-10-11-3}{Figure 10.11.3: Supercapacitor Constant-Current Discharge Voltage Profile}
\item
  \hyperlink{fig-10-11-4}{Figure 10.11.4: Series-Parallel Bank Design — Voltage, Capacitance, and Energy vs Series Cell Count}
\item
  \hyperlink{fig-10-11-5}{Figure 10.11.5: Regenerative Braking Cycle — Voltage, Current, and Power for a Light Rail Tram}
\item
  \hyperlink{fig-10-12-1}{Figure 10.12.1: PV Module I-V and P-V Curves — Effect of Irradiance at 25 °C}
\end{itemize}

\section{Chapter 11: Instrumentation and
Measurement}\label{chapter-11-instrumentation-and-measurement}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-11-1-1}{Figure 11.1.1: Accuracy vs Precision: Target Analogy}
\item
  \hyperlink{fig-11-1-5}{Figure 11.1.5: Wheatstone Bridge Response}
\item
  \hyperlink{fig-11-2-1}{Figure 11.2.1: Thermocouple Voltage vs Temperature}
\end{itemize}

\section{Chapter 12: Electric Motors}\label{chapter-12-electric-motors}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-12-3-4}{Figure 12.3.4: Stepper Motor Torque vs Speed}
\item
  \hyperlink{fig-12-4-5}{Figure 12.4.5: FOC Vector Diagram}
\item
  \hyperlink{fig-12-5-6}{Figure 12.5.6: Motor Insulation Life vs Temperature}
\end{itemize}

\section{Chapter 13: Operational
Amplifiers}\label{chapter-13-operational-amplifiers}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-13-2-3}{Figure 13.2.3: Op-Amp Integrator Step Response}
\item
  \hyperlink{fig-13-2-4}{Figure 13.2.4: Op-Amp Differentiator Response}
\item
  \hyperlink{fig-13-2-5}{Figure 13.2.5: Log Amplifier Transfer Curve}
\item
  \hyperlink{fig-13-5-2}{Figure 13.5.2: Sallen-Key Butterworth Bode Plot}
\item
  \hyperlink{fig-13-5-4}{Figure 13.5.4: MFB Bandpass Filter Frequency Response}
\item
  \hyperlink{fig-13-5-5}{Figure 13.5.5: Active Twin-T Notch Filter}
\item
  \hyperlink{fig-13-6-2}{Figure 13.6.2: Schmitt Trigger Hysteresis}
\item
  \hyperlink{fig-13-6-4}{Figure 13.6.4: Relaxation Oscillator Waveforms}
\item
  \hyperlink{fig-13-7-2}{Figure 13.7.2: Slew Rate Limiting}
\end{itemize}

\section{Chapter 15: Networking}\label{chapter-15-networking}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-15-3-5}{Figure 15.3.5: SMF Fiber Link Budget: Power Margin vs Distance}
\item
  \hyperlink{fig-15-5-1}{Figure 15.5.1: Ethernet Frame Efficiency vs Payload Size}
\item
  \hyperlink{fig-15-10-5}{Figure 15.10.5: QoS LLQ Bandwidth Allocation and Voice Queuing Delay}
\end{itemize}

\section{Chapter 16: Antenna Design and
Principles}\label{chapter-16-antenna-design-and-principles}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-16-5-3}{Figure 16.5.3: Phased Array Pattern}
\end{itemize}

\section{Chapter 17: Radar Systems}\label{chapter-17-radar-systems}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-17-2-2}{Figure 17.2.2: FMCW Beat Frequency vs Range}
\end{itemize}

\section{Chapter 18: Optics}\label{chapter-18-optics}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-18-2-4}{Figure 18.2.4: Dielectric Mirror Reflectivity}
\end{itemize}

\section{Chapter 19: Engineering
Economics}\label{chapter-19-engineering-economics}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-19-1-2}{Figure 19.1.2: Simple vs Compound vs Continuous Interest Growth}
\item
  \hyperlink{fig-19-8-2}{Figure 19.8.2: Depreciation Methods: Book Value Comparison}
\item
  \hyperlink{fig-19-13-2}{Figure 19.13.2: NPV Sensitivity Analysis}
\end{itemize}

\section{Appendix A: Imaginary Numbers and
Phasors}\label{appendix-a-imaginary-numbers-and-phasors}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-a-3-1}{Figure A.3.1: Complex Plane: Polar Form}
\item
  \hyperlink{fig-a-4-3}{Figure A.4.3: Phasor Addition}
\item
  \hyperlink{fig-a-4-4}{Figure A.4.4: Series RL Phasor Diagram}
\item
  \hyperlink{fig-a-5-3}{Figure A.5.3: Power Triangle}
\end{itemize}

\section{Appendix B: Arctangent and
atan2}\label{appendix-b-arctangent-and-atan2}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-b-1-2}{Figure B.1.2: Quadrant Ambiguity: arctan vs atan2}
\item
  \hyperlink{fig-b-2-1}{Figure B.2.1: atan2 in All Four Quadrants}
\item
  \hyperlink{fig-b-2-3}{Figure B.2.3: atan2 Special Cases: Axis Points}
\end{itemize}

\section{Appendix C: Decibels}\label{appendix-c-decibels}

\begin{itemize}
\tightlist
\item
  \hyperlink{fig-c-1-3}{Figure C.1.3: Decibel Scale: Power and Voltage Ratios}
\item
  \hyperlink{fig-c-3-1}{Figure C.3.1: Fiber Optic Link Budget}
\item
  \hyperlink{fig-c-4-1}{Figure C.4.1: Op-Amp Bode Plot}
\end{itemize}

\chapter{Chapter 1}\label{chapter-1}

\chapter{Power Engineering}\label{power-engineering}

Power engineering is the subfield of electrical engineering concerned
with the generation, transmission, distribution, and utilization of
electric power. It encompasses the design and operation of the entire
electrical grid, from large-scale generating stations that convert
primary energy sources into electricity, through high-voltage
transmission lines that transport power over long distances, to the
distribution networks that deliver electricity to homes, businesses, and
industrial facilities. Power engineers work with AC circuit analysis,
three-phase systems, transformers, protective relaying, and power
electronics to ensure reliable and efficient delivery of electrical
energy.

\section{1.1 Power Generation}\label{power-generation}

\textbf{Y2022 U.S. Electricity Net Generation}
(\href{https://tinyurl.com/29eh55e3}{source})

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Source & Million kWh \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Fossil Fuels} & \\
~~~~Coal & 897,999 \\
~~~~Petroleum & 19,173 \\
~~~~Natural Gas & 1,579,190 \\
~~~~Other Gases & 11,397 \\
\textbf{Nuclear Electric Power} & 779,645 \\
\textbf{Hydroelectric Pumped Storage} & −5,112 \\
\textbf{Renewable Energy} & \\
~~~~Conventional Hydroelectric & 251,585 \\
~~~~Biomass --- Wood & 36,463 \\
~~~~Biomass --- Waste & 17,790 \\
~~~~Geothermal & 15,975 \\
~~~~Solar & 115,258 \\
~~~~Wind & 378,197 \\
\end{longtable}
}

\begin{figure}[H]

\hypertarget{fig-1-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch01_energy_mix.png}

\caption{Figure 1.1: U.S. Electricity Generation by Source (2022)}

\end{figure}

\subsection{1.1.1 Fossil Fuel Plants}\label{fossil-fuel-plants}

Fossil fuel plants generate electricity by burning coal, natural gas, or
petroleum to produce steam that drives a turbine connected to a
generator. In a typical steam cycle (Rankine cycle), fuel is combusted
in a boiler to heat water into high-pressure steam, which expands
through a turbine to produce mechanical work, and is then condensed back
into water for reuse. Natural gas plants often use a combined-cycle
configuration, where exhaust gases from a gas turbine (Brayton cycle)
are used to generate steam for a secondary steam turbine, achieving
thermal efficiencies above 60\%. Coal plants, while less efficient at
roughly 33-40\%, remain significant baseload generators due to abundant
fuel reserves. The primary drawbacks of fossil fuel generation are
carbon dioxide emissions, particulate pollution, and dependence on
finite fuel supplies.

\begin{examplebox}

\textbf{Example 1.1.1:} A combined-cycle natural gas plant has a gas
turbine (Brayton cycle) with an efficiency of 38\% and a steam turbine
(Rankine cycle) that recovers 45\% of the waste heat from the gas
turbine exhaust. If the plant burns natural gas at a thermal input rate
of 500 MW, determine the total electrical power output and the overall
plant efficiency.

\textbf{Solution:}\\
Gas turbine output: P\textsubscript{GT} = 0.38 × 500 MW = 190 MW\\
Waste heat from gas turbine: Q\textsubscript{waste} = 500 − 190 = 310
MW\\
Steam turbine output: P\textsubscript{ST} = 0.45 × 310 MW = 139.5 MW\\
Total electrical output: P\textsubscript{total} = 190 + 139.5 = 329.5
MW\\
Overall efficiency: η = P\textsubscript{total} / Q\textsubscript{in} =
329.5 / 500 = 0.659 = \textbf{65.9\%}

\end{examplebox}

\subsection{1.1.2 Hydroelectric Plants}\label{hydroelectric-plants}

Hydroelectric plants convert the potential energy of water stored at
elevation into electricity by directing flow through hydraulic turbines
coupled to generators. The available power is proportional to both the
volumetric flow rate and the hydraulic head (the vertical distance
between the reservoir surface and the turbine), following P = ρgQh.
Conventional impoundment plants use a dam to create a reservoir, while
run-of-river installations divert a portion of a river's natural flow
with little or no storage. Pumped-storage hydroelectric facilities act
as large-scale energy storage: during periods of low demand, water is
pumped from a lower reservoir to an upper reservoir, then released
through turbines during peak demand, with round-trip efficiencies of
70--85\%. Turbine selection depends on head and flow conditions ---
Francis turbines are used for medium heads (30--600 m), Pelton turbines
for high heads (\textgreater300 m), and Kaplan turbines for low heads
(\textless60 m) with variable blade pitch for efficiency across a range
of flow rates. Hydroelectric plants achieve turbine-generator
efficiencies of 85--95\%, offer rapid ramping capability for grid
frequency regulation, and have operational lifetimes exceeding 50 years
with relatively low maintenance costs.

\begin{examplebox}

\textbf{Example 1.1.2:} A hydroelectric dam has a hydraulic head of 80
meters and a water flow rate of 25 m³/s. The turbine-generator set has
an overall efficiency of 88\%. Determine the electrical power output.
(Use ρ = 1000 kg/m³ for water and g = 9.81 m/s².)

\textbf{Solution:}\\
Available hydraulic power: P\textsubscript{hydraulic} = ρ × g × Q × h =
1000 × 9.81 × 25 × 80 = 19,620,000 W = 19.62 MW\\
Electrical output: P\textsubscript{elec} = η ×
P\textsubscript{hydraulic} = 0.88 × 19.62 MW = \textbf{17.27 MW}

\end{examplebox}

\subsection{1.1.3 Nuclear Plants}\label{nuclear-plants}

Nuclear power plants generate electricity through nuclear fission, in
which heavy atomic nuclei (typically uranium-235 or plutonium-239) are
split by neutron bombardment, releasing enormous amounts of thermal
energy. This heat is used to produce steam that drives a
turbine-generator set, similar to a conventional thermal plant. Nuclear
plants operate as baseload generators with capacity factors often
exceeding 90\%, and they produce no direct carbon dioxide emissions
during operation. Reactor designs include pressurized water reactors
(PWR), boiling water reactors (BWR), and newer Generation III+ and small
modular reactor (SMR) designs that incorporate passive safety systems.
The primary challenges of nuclear power are the management of
radioactive waste, high capital construction costs, and the long
regulatory approval timelines.

\begin{examplebox}

\textbf{Example 1.1.3:} A nuclear power plant has a rated thermal output
of 3400 MW(th) and an electrical output of 1150 MW(e). The plant
operates at a capacity factor of 92\% over a year (8760 hours).
Determine the plant's thermal efficiency and the annual electrical
energy generated.

\textbf{Solution:}\\
Thermal efficiency: η = P\textsubscript{elec} / P\textsubscript{thermal}
= 1150 / 3400 = 0.338 = \textbf{33.8\%}\\
Annual energy at full capacity: E\textsubscript{full} = 1150 MW × 8760 h
= 10,074,000 MWh\\
Annual energy at 92\% capacity factor: E\textsubscript{actual} = 0.92 ×
10,074,000 = 9,268,080 MWh = \textbf{9.27 × 10⁶ MWh}

\end{examplebox}

\subsection{1.1.4 Solar}\label{solar}

Solar power generation converts sunlight into electricity using one of
two primary technologies: photovoltaic (PV) cells and concentrated solar
power (CSP). PV cells use semiconductor materials (typically crystalline
silicon) to produce direct current through the photovoltaic effect,
which is then converted to alternating current by an inverter for grid
connection. CSP systems use mirrors or lenses to concentrate sunlight
onto a receiver, heating a working fluid to drive a conventional steam
turbine. Solar generation is intermittent and dependent on irradiance,
time of day, and weather conditions, making energy storage or
supplemental generation necessary for reliable supply. Utility-scale
solar installations typically achieve capacity factors of 20-30\%, with
ongoing cost reductions making solar one of the lowest-cost sources of
new electricity generation.

\begin{examplebox}

\textbf{Example 1.1.4:} A utility-scale solar PV farm has a rated DC
capacity of 50 MW. The inverter efficiency is 96\%, and the site
receives an average peak sun hours (PSH) equivalent of 5.2 hours/day.
Determine the average daily AC energy output and the capacity factor.

\textbf{Solution:}\\
Daily DC energy: E\textsubscript{DC} = 50 MW × 5.2 h = 260 MWh\\
Daily AC energy: E\textsubscript{AC} = 0.96 × 260 = \textbf{249.6 MWh}\\
Hours in a day at full rated output: 24 h\\
Capacity factor: CF = E\textsubscript{AC} / (50 MW × 24 h) = 249.6 /
1200 = 0.208 = \textbf{20.8\%}

\end{examplebox}

\subsection{1.1.5 Wind}\label{wind}

Wind turbines convert the kinetic energy of moving air into electrical
energy using aerodynamic blades mounted on a rotor that drives a
generator, either directly or through a gearbox. Modern utility-scale
horizontal-axis wind turbines have rated capacities ranging from 2 MW to
over 15 MW for offshore installations, with rotor diameters exceeding
200 meters. The power available from wind is proportional to the cube of
wind speed (P = 0.5 × ρ × A × v³), but practical extraction is limited
by the Betz limit of approximately 59.3\% of the total kinetic energy.
Wind generation is variable and non-dispatchable, requiring grid
balancing through forecasting, energy storage, or complementary
generation sources. Onshore wind farms typically achieve capacity
factors of 25-45\%, while offshore installations benefit from stronger
and more consistent winds.

\begin{examplebox}

\textbf{Example 1.1.5:} A wind turbine has a rotor diameter of 120 m and
operates in air with density ρ = 1.225 kg/m³. The wind speed is 12 m/s
and the turbine's power coefficient is C\textsubscript{p} = 0.42.
Determine the electrical power output.

\textbf{Solution:}\\
Rotor swept area: A = π × (D/2)² = π × (60)² = 11,309.7 m²\\
Available wind power: P\textsubscript{wind} = 0.5 × ρ × A × v³ = 0.5 ×
1.225 × 11,309.7 × (12)³\\
P\textsubscript{wind} = 0.5 × 1.225 × 11,309.7 × 1728 = 11,970,186.48 W
= 11.97 MW\\
Electrical output: P\textsubscript{elec} = C\textsubscript{p} ×
P\textsubscript{wind} = 0.42 × 11.97 = \textbf{5.03 MW}

\end{examplebox}

\subsection{1.1.6 Micro Grids}\label{micro-grids}

A microgrid is a localized energy system that can operate independently
from the main utility grid (islanded mode) or connected to it (grid-tied
mode). Microgrids typically integrate distributed energy resources such
as solar panels, wind turbines, diesel or natural gas generators, and
battery energy storage systems, all managed by a central controller. The
controller optimizes power flow, manages load balancing, and coordinates
the transition between grid-connected and islanded operation during
utility outages. Microgrids improve resilience for critical facilities
such as hospitals, military installations, and remote communities that
cannot tolerate extended power interruptions. They also enable
participation in demand response programs and can reduce energy costs by
optimizing the use of local generation and storage resources.

\begin{examplebox}

\textbf{Example 1.1.6:} A microgrid serves a hospital with a peak load
of 800 kW. The microgrid has a 500 kW solar array (currently producing
350 kW), a 400 kWh battery storage system (currently at 90\% state of
charge), and a 600 kW diesel generator. Determine (a) how much power the
battery or diesel generator must supply to meet the peak load, and (b)
how long the battery alone could sustain the deficit if the diesel
generator is unavailable (assume 90\% inverter efficiency and 10\%
minimum state of charge).

\textbf{Solution:}

(a) Deficit = Peak load − Solar output = 800 − 350 = 450 kW\\
The battery or diesel generator must supply \textbf{450 kW}.

(b) Usable battery energy: E\textsubscript{usable} =
(SOC\textsubscript{current} − SOC\textsubscript{min}) × Capacity = (0.90
− 0.10) × 400 = 320 kWh\\
AC energy delivered (accounting for inverter efficiency):
E\textsubscript{AC} = 0.90 × 320 = 288 kWh\\
Duration at 450 kW deficit: t = 288 / 450 = \textbf{0.64 hours
(approximately 38.4 minutes)}

\end{examplebox}

\subsection{1.1.7 Generator Step-Up (GSU)
Transformers}\label{generator-step-up-gsu-transformers}

The generator step-up transformer is the critical link between a power
plant's generator and the high-voltage transmission system. Generators
typically produce electricity at relatively low voltages (11 kV to 25
kV) to keep insulation requirements manageable within the machine, and
the GSU steps this up to transmission voltage (115 kV to 765 kV) for
efficient long-distance power transfer. GSU transformers are among the
largest and most expensive single pieces of equipment in a power plant,
with ratings from tens of MVA at small facilities to over 1000 MVA at
large nuclear stations. They are typically three-phase, oil-filled units
with delta-connected generator-side (low-voltage) windings and
wye-connected transmission-side (high-voltage) windings --- the delta
connection traps third-harmonic currents from the generator, while the
wye connection provides a neutral point for system grounding. GSU
transformers are designed for continuous operation at full load and must
withstand through-fault currents from the transmission system, with
impedances typically ranging from 8\% to 15\% on their own base. Because
of their size and long lead times for replacement (often 12 to 18
months), utilities maintain spare transformer programs and monitor GSU
health through dissolved gas analysis (DGA), thermal monitoring, and
periodic oil testing.

\begin{examplebox}

\textbf{Example 1.1.7:} A 600 MW natural gas combined-cycle plant has a
generator rated at 700 MVA, 22 kV, 0.85 power factor. The GSU
transformer is rated 700 MVA, 22 kV delta / 345 kV wye-grounded, with an
impedance of 10.5\%. Determine (a) the rated current on each side, (b)
the maximum symmetrical fault current on the 345 kV side due to a fault
at the GSU secondary terminals (assuming an infinite bus on the
generator side), and (c) the fault MVA.

\textbf{Solution:}

(a) Rated currents:\\
I\textsubscript{LV} = S / (√3 × V\textsubscript{LV}) = 700 × 10⁶ / (√3 ×
22,000) = \textbf{18,370.2 A}\\
I\textsubscript{HV} = S / (√3 × V\textsubscript{HV}) = 700 × 10⁶ / (√3 ×
345,000) = \textbf{1,171 A}

(b) Maximum symmetrical fault current at 345 kV terminals:\\
I\textsubscript{fault} = I\textsubscript{HV,rated} / Z\textsubscript{pu}
= 1,171 / 0.105 = \textbf{11,152 A ≈ 11.2 kA}

(c) Fault MVA:\\
S\textsubscript{fault} = S\textsubscript{rated} / Z\textsubscript{pu} =
700 / 0.105 = \textbf{6,667 MVA ≈ 6.7 GVA}

\end{examplebox}

\subsection{1.1.8 Auxiliary (Station Service)
Transformers}\label{auxiliary-station-service-transformers}

Auxiliary transformers, also called station service transformers or unit
auxiliary transformers, supply the internal electrical loads needed to
operate the power plant itself. These loads include boiler feed pumps,
circulating water pumps, forced-draft and induced-draft fans, coal
pulverizers, condensate pumps, control systems, lighting, and HVAC ---
collectively known as station service or house load, typically consuming
5\% to 10\% of the plant's gross generation. A generating station
usually has two types of auxiliary supply: the unit auxiliary
transformer (UAT), which taps off the generator bus between the
generator and the GSU and powers loads during normal operation, and the
startup/standby auxiliary transformer (SAT), which is fed from the
transmission system or a separate substation bus to provide power during
startup, shutdown, and emergency conditions when the generator is
offline. The UAT is typically rated at 5\% to 12\% of the generator MVA
and steps down from generator voltage (e.g., 22 kV) to medium-voltage
auxiliary buses (typically 4.16 kV or 6.9 kV), with further step-downs
to 480 V for smaller loads. Automatic transfer schemes (fast bus
transfer or residual voltage transfer) switch loads from the UAT to the
SAT upon a generator trip to maintain power to critical plant equipment
and prevent a cascading shutdown.

\begin{examplebox}

\textbf{Example 1.1.8:} A 500 MW coal-fired generating unit has a
generator rated at 588 MVA, 20 kV. Station service loads total 35 MW at
0.90 power factor lagging. The unit auxiliary transformer (UAT) steps
down from 20 kV to 4.16 kV. Determine (a) the station service as a
percentage of gross generation, (b) the required UAT MVA rating, and (c)
the UAT rated current on the 4.16 kV side.

\textbf{Solution:}

(a) Station service percentage:\\
Station service = P\textsubscript{aux} / P\textsubscript{gross} × 100 =
35 / 500 × 100 = \textbf{7.0\%}\\
Net plant output = 500 − 35 = \textbf{465 MW}

(b) Required UAT apparent power:\\
S\textsubscript{UAT} = P\textsubscript{aux} / PF = 35 / 0.90 = 38.9
MVA\\
With 15\% margin for future loads and motor starting:
S\textsubscript{rated} = 38.9 × 1.15 = \textbf{44.7 MVA} (select a
standard 45 MVA rating)

(c) UAT rated current at 4.16 kV:\\
I\textsubscript{4.16kV} = S\textsubscript{rated} / (√3 × V) = 45 × 10⁶ /
(√3 × 4,160) = \textbf{6,245 A}

\end{examplebox}

\section{1.2 Power Transmission}\label{power-transmission}

\subsection{1.2.1 Transmission Lines}\label{transmission-lines}

Transmission lines carry bulk electrical power from generating stations
to substations near load centers, operating at high voltages (69 kV to
765 kV and above) to minimize resistive losses over long distances. They
are characterized by four distributed parameters per unit length: series
resistance R (conductor ohmic loss), series inductance L (magnetic flux
linkage between conductors), shunt capacitance C (electric field between
conductors and ground), and shunt conductance G (leakage current through
insulators, usually negligible). Whether these parameters can be treated
as lumped elements or must be modeled as continuously distributed
depends on the electrical length of the line --- the ratio of the
physical length to the wavelength at the operating frequency
(approximately 5,000 km at 60 Hz). Lines shorter than about 80 km are
electrically short enough that shunt effects are negligible and a simple
series impedance model suffices, while medium lines (80-250 km) require
a lumped pi or T equivalent circuit that accounts for charging current,
and long lines (over 250 km) demand the full distributed-parameter
treatment using hyperbolic functions derived from the telegrapher's
equations. Two key parameters emerge from the distributed model: the
characteristic impedance Z\textsubscript{c} (also called surge
impedance), which is the ratio √(L/C) for a lossless line and typically
ranges from 250 to 400 Ω for overhead lines, and the propagation
constant γ = √(zy), which determines attenuation and phase shift per
unit length. The surge impedance loading (SIL) --- defined as
V\textsubscript{LL}²/Z\textsubscript{c} --- represents the power at
which the line's distributed capacitive reactive generation exactly
balances its inductive reactive absorption, producing a flat voltage
profile with unity power factor at both ends. At loads below SIL the
line generates net reactive power and the receiving-end voltage rises
(the Ferranti effect), while at loads above SIL the line absorbs
reactive power and voltage drops, requiring shunt compensation or series
capacitors to maintain acceptable voltage profiles.

\subsubsection{1.2.1.1 Short Transmission
Lines}\label{short-transmission-lines}

Short transmission lines are conductors that are less than 80 km in
length.

\begin{examplebox}

\textbf{Example 1.2.1.1:} A 60 km, 69 kV, single-phase short
transmission line has a series impedance of Z = (0.15 + j0.40) Ω/km. The
line delivers 10 MVA at 69 kV with a 0.85 lagging power factor at the
receiving end. Determine the sending-end voltage and the voltage
regulation.

\textbf{Solution:}\\
Total line impedance: Z\textsubscript{total} = 60 × (0.15 + j0.40) = 9.0
+ j24.0 Ω\\
Receiving-end voltage: V\textsubscript{R} = 69,000 V\\
Receiving-end current: I\textsubscript{R} = S / V\textsubscript{R} =
10,000,000 / 69,000 = 144.93 A\\
Power factor angle: θ = cos⁻¹(0.85) = 31.79°\\
I\textsubscript{R} in phasor form: I\textsubscript{R} = 144.93∠−31.79°
A\\
Sending-end voltage: V\textsubscript{S} = V\textsubscript{R} +
I\textsubscript{R} × Z\textsubscript{total}\\
I\textsubscript{R} × Z\textsubscript{total} = 144.93∠−31.79° ×
25.63∠69.44° = 3,714.6∠37.65°\\
I\textsubscript{R} × Z\textsubscript{total} = 3,714.6 × (cos 37.65° + j
sin 37.65°) = 2,941.2 + j2,268.4 V\\
V\textsubscript{S} = 69,000 + 2,940.4 + j2,268.4 = 71,940.4 + j2,268.4\\
\textbar V\textsubscript{S}\textbar{} = √(71,940.4² + 2,268.4²) =
71,976.2 V\\
Voltage regulation: VR\% = (\textbar V\textsubscript{S}\textbar{} −
\textbar V\textsubscript{R}\textbar) /
\textbar V\textsubscript{R}\textbar{} × 100 = (71,976.2 − 69,000) /
69,000 × 100 = \textbf{4.31\%}

\end{examplebox}

\subsubsection{1.2.1.2 Medium Transmission
Lines}\label{medium-transmission-lines}

Medium transmission lines range from 80 km to 250 km in length and
require consideration of the line's shunt capacitance in addition to
series resistance and inductance. The standard model for medium lines is
the nominal pi (or nominal T) circuit, where the total shunt capacitance
is split equally and placed at each end of the line (pi model) or
concentrated at the midpoint (T model). This lumped-parameter approach
provides reasonable accuracy for steady-state analysis at power
frequencies without the complexity of distributed-parameter models. The
ABCD (transmission) parameters for the nominal pi model include the
effect of charging current, which becomes significant at these lengths
and can cause the receiving-end voltage to rise above the sending-end
voltage under light load conditions (the Ferranti effect).

\begin{examplebox}

\textbf{Example 1.2.1.2:} A 200 km, 230 kV, three-phase medium
transmission line has the following per-phase parameters: z = 0.05 +
j0.45 Ω/km and y = j3.4 × 10⁻⁶ S/km. Using the nominal π model,
determine the ABCD parameters.

\textbf{Solution:}\\
Total series impedance: Z = z × l = (0.05 + j0.45) × 200 = 10 + j90 Ω =
90.55∠83.66° Ω\\
Total shunt admittance: Y = y × l = j3.4 × 10⁻⁶ × 200 = j6.8 × 10⁻⁴ S

Nominal π ABCD parameters:\\
A = D = 1 + (Y × Z) / 2\\
Y × Z / 2 = (j6.8 × 10⁻⁴)(10 + j90) / 2 = (j0.0068 + j²0.0612) / 2 =
(−0.0612 + j0.0068) / 2\\
Y × Z / 2 = −0.0306 + j0.0034\\
A = D = 1 − 0.0306 + j0.0034 = \textbf{0.9694 + j0.0034 = 0.9694∠0.20°}

B = Z = \textbf{10 + j90 = 90.55∠83.66° Ω}

C = Y × (1 + Y × Z / 4)\\
Y × Z / 4 = −0.0153 + j0.0017\\
C = j6.8 × 10⁻⁴ × (1 − 0.0153 + j0.0017) = j6.8 × 10⁻⁴ × (0.9847 +
j0.0017)\\
C = j6.696 × 10⁻⁴ − 1.156 × 10⁻⁶ = \textbf{−1.156 × 10⁻⁶ + j6.696 × 10⁻⁴
≈ 6.696 × 10⁻⁴∠90.1° S}

\end{examplebox}

\subsubsection{1.2.1.3 Long Transmission
Lines}\label{long-transmission-lines}

Long transmission lines exceed 250 km in length and require a
distributed-parameter model because lumped approximations introduce
unacceptable errors at these distances. The voltage and current at any
point along the line are governed by the telegrapher's equations, which
yield hyperbolic functions (sinh, cosh) in the exact ABCD parameter
expressions. Key characteristics of long lines include the propagation
constant (γ), which determines attenuation and phase shift per unit
length, and the characteristic (surge) impedance, which defines the
natural loading of the line. At surge impedance loading (SIL), the
reactive power generated by the line capacitance exactly equals the
reactive power absorbed by the line inductance, resulting in a flat
voltage profile. Long lines also exhibit pronounced wave propagation
effects, making them susceptible to traveling-wave surges from lightning
and switching events.

\begin{examplebox}

\textbf{Example 1.2.1.3:} A 400 km, 345 kV, three-phase long
transmission line has per-phase distributed parameters: z = 0.03 + j0.35
Ω/km and y = j4.4 × 10⁻⁶ S/km. Determine the characteristic impedance
(Z\textsubscript{c}) and propagation constant (γ), and find the surge
impedance loading (SIL).

\textbf{Solution:}\\
Characteristic impedance: Z\textsubscript{c} = √(z / y) = √((0.03 +
j0.35) / (j4.4 × 10⁻⁶))\\
z / y = (0.03 + j0.35) / (j4.4 × 10⁻⁶)\\
Multiply numerator and denominator by −j: = (0.03 + j0.35)(−j) / (4.4 ×
10⁻⁶)\\
= (−j0.03 + 0.35) / (4.4 × 10⁻⁶) = (0.35 − j0.03) / (4.4 × 10⁻⁶) =
79,545.5 − j6,818.2\\
\textbar z/y\textbar{} = √(79,545.5² + 6,818.2²) = 79,837.7\\
angle = tan⁻¹(−6818.2 / 79,545.5) = −4.90°\\
Z\textsubscript{c} = √(79,837.7)∠(−4.90°/2) = \textbf{282.6∠−2.45° Ω ≈
282.6 Ω} (nearly resistive)

Propagation constant: γ = √(z × y) = √((0.03 + j0.35)(j4.4 × 10⁻⁶))\\
z × y = (0.03 + j0.35)(j4.4 × 10⁻⁶) = j1.32 × 10⁻⁷ − 1.54 × 10⁻⁶\\
= −1.54 × 10⁻⁶ + j1.32 × 10⁻⁷ = 1.546 × 10⁻⁶∠175.1°\\
γ = √(1.546 × 10⁻⁶)∠(175.1°/2) = \textbf{1.243 × 10⁻³∠87.55° per km}\\
γ = α + jβ ≈ 5.31 × 10⁻⁵ + j1.242 × 10⁻³ per km

Surge impedance loading (line-to-line voltage):\\
SIL = V\textsubscript{LL}² / Z\textsubscript{c} = (345,000)² / 282.6 =
\textbf{421.1 MW}

\end{examplebox}

\subsection{1.2.2 Underground Transmission
Lines}\label{underground-transmission-lines}

Underground transmission lines use high-voltage insulated cables
installed in duct banks, tunnels, or direct-buried configurations to
transmit bulk power in areas where overhead lines are impractical or
prohibited --- primarily dense urban corridors, water crossings, airport
approach zones, and environmentally sensitive areas. Underground
transmission differs fundamentally from underground distribution
(§1.3.3) in voltage class (69 kV to 500 kV versus 5-35 kV), cable
construction, installation complexity, and the magnitude of special
engineering considerations required.

\textbf{Cable Construction and Types.} Modern underground transmission
cables are predominantly cross-linked polyethylene (XLPE) insulated,
which has largely replaced older fluid-filled cable technologies for new
installations. XLPE cables are solid-dielectric, maintenance-free, and
available at voltages up to 500 kV, with conductor sizes ranging from
500 kcmil to 5,000 kcmil in copper or aluminum. High-pressure
fluid-filled (HPFF) pipe-type cables --- three insulated conductors
pulled through a steel pipe pressurized with dielectric fluid --- remain
in service at 69-345 kV in many legacy installations, particularly in
the northeastern United States. Self-contained fluid-filled (SCFF)
cables use a hollow-core conductor with dielectric oil fed through the
center, maintaining positive oil pressure to prevent void formation in
the insulation. For the highest power transfers, gas-insulated lines
(GIL) use SF₆ or SF₆/N₂ gas mixtures within an aluminum enclosure to
achieve ratings up to 5,000 MVA at 500 kV, though at significantly
higher cost than cable systems.

\textbf{Installation Methods.} Duct bank installations consist of
concrete-encased PVC or fiberglass conduits, typically with manholes
spaced every 500-800 meters for cable pulling, splicing, and maintenance
access. Directional drilling (horizontal directional drilling, HDD)
allows cable installation beneath waterways, highways, and
environmentally sensitive areas without open trenching, with bore
lengths up to 2 km. Cable tunnels provide a walk-in environment for
installation and maintenance of multiple cable circuits, often used in
dense urban areas where duct bank capacity is exhausted. Direct burial
is less common for transmission cables but is used in some rural or
suburban settings where soil conditions permit.

\textbf{Special Considerations.} Underground transmission requires
careful attention to several factors that are either absent or less
critical for overhead lines:

\begin{itemize}
\item
  \textbf{Thermal management}: Cable ampacity is limited by the maximum
  allowable conductor temperature (typically 90°C for XLPE) and the
  ability of the surrounding soil to dissipate heat. Soil thermal
  resistivity (ρ\textsubscript{soil}, typically 60-120 °C·cm/W) is the
  dominant factor, and it increases dramatically as soil dries out from
  cable heating --- a phenomenon called thermal runaway. Mutual heating
  between cables in the same duct bank or trench reduces ampacity by
  10-30\% compared to a single isolated cable. Thermal analysis follows
  the Neher-McGrath method (IEEE Std 835) or IEC 60287, and may require
  special thermal backfill (typically Fluidized Thermal Backfill with ρ
  ≤ 50 °C·cm/W) to improve heat dissipation.
\item
  \textbf{Charging current}: Underground cables have a much higher
  capacitance per unit length than overhead lines (typically 20-60 times
  greater) because the conductor-to-ground spacing in a cable is
  measured in millimeters rather than meters. This produces a large
  capacitive charging current that flows even at no load:
  I\textsubscript{charging} = 2πfCV. At 230 kV on an XLPE cable with C =
  0.2 μF/km, the charging current is approximately 10 A/km per phase.
  This limits the practical AC cable length to roughly 30-80 km
  (depending on voltage) before the entire cable ampacity is consumed by
  charging current. Shunt reactors are installed to compensate the
  capacitive reactive power on longer cable circuits.
\item
  \textbf{Reactive compensation}: Because of the high charging current,
  underground cable circuits require shunt reactor compensation at
  intervals along the route --- typically at each end and at
  intermediate points for cables longer than 20-30 km. The reactive
  power generated by the cable capacitance can be 10--20 MVAR/km at the
  highest transmission voltages (345 kV and above), and 4--8 MVAR/km at
  230 kV, requiring large shunt reactors (50--200 MVAR each) that add
  significant cost and land requirements at reactor stations.
\item
  \textbf{Fault location and repair}: Locating faults on underground
  transmission cables is more difficult than on overhead lines,
  requiring specialized techniques such as time-domain reflectometry
  (TDR), thumping (applying high-voltage impulses to create an audible
  discharge at the fault), and acoustic/electromagnetic fault
  pinpointing. Repair times are measured in weeks rather than hours ---
  a single cable fault typically requires 2-4 weeks to excavate, cut out
  the damaged section, install a splice, test, and re-energize. This
  extended outage time is a major consideration in system planning and
  usually requires redundant cable circuits or backup overhead paths.
\item
  \textbf{Joints and terminations}: Cable joints (splices) are required
  at intervals of 500-1,000 meters (limited by cable manufacturing
  lengths, drum sizes, and pull tension limits) and are statistically
  the weakest point in a cable system, accounting for the majority of
  cable failures. Factory-molded prefabricated joints and cold-shrink
  technology have improved reliability, but each joint is a potential
  failure point. Cable terminations at the transition from underground
  to overhead (called transition stations or riser poles) require stress
  cones to manage the electric field concentration at the cable end.
\item
  \textbf{Cost}: Underground transmission typically costs 5-15 times
  more than equivalent overhead construction, with 345 kV urban duct
  bank installations running \$15-50 million per mile compared to \$1-5
  million per mile for overhead. The cost premium includes cable
  materials, civil works (trenching, duct banks, manholes), longer
  installation time, and the reactive compensation equipment. This cost
  difference means underground transmission is reserved for situations
  where overhead lines are truly not feasible.
\end{itemize}

\begin{examplebox}

\textbf{Example 1.2.2:} A 230 kV underground XLPE cable circuit is 25 km
long with three single-core cables (one per phase). Each cable has a
capacitance of 0.23 μF/km and an ampacity of 800 A (accounting for soil
conditions and mutual heating in the duct bank). Determine (a) the
charging current per phase, (b) the total three-phase reactive power
generated by the cable capacitance, (c) the remaining ampacity available
for load current, and (d) the maximum power transfer.

\textbf{Solution:}

(a) Charging current per phase:\\
I\textsubscript{charging} = 2πfCV\textsubscript{LN} = 2π × 60 × (0.23 ×
10⁻⁶ × 25) × (230,000/√3)\\
C\textsubscript{total} = 0.23 × 25 = 5.75 μF\\
I\textsubscript{charging} = 2π × 60 × 5.75 × 10⁻⁶ × 132,791 =
\textbf{288 A per phase}

(b) Three-phase reactive power:\\
Q\textsubscript{charging} = 3 × V\textsubscript{LN} ×
I\textsubscript{charging} = 3 × 132,791 × 288 = 114.7 × 10⁶ VAR =
\textbf{114.7 MVAR}\\
A shunt reactor of approximately 115 MVAR would be required to
compensate this charging current.

(c) Remaining ampacity for load current:\\
The cable current rating is 800 A. The charging and load currents are
roughly 90° apart (charging is capacitive), so:\\
I\textsubscript{load,max} = √(I\textsubscript{rated}² −
I\textsubscript{charging}²) = √(800² − 288²) = √(640,000 − 82,944) =
√557,056 = \textbf{746 A}

(d) Maximum power transfer:\\
S\textsubscript{max} = √3 × V\textsubscript{LL} ×
I\textsubscript{load,max} = √3 × 230,000 × 746 = 297 × 10⁶ VA =
\textbf{297 MVA}\\
The charging current reduces the usable capacity from 319 MVA (at 800 A)
to 297 MVA --- a 7\% reduction for this 25 km cable.\\
At 50 km, the charging current would double to 576 A, leaving only
√(800² − 576²) = 555 A for load, reducing capacity by 31\%.

\end{examplebox}

\section{1.3 Power Distribution}\label{power-distribution}

\subsection{1.3.1 Substations}\label{substations}

Substations are critical nodes in the electric power system where
voltage is transformed between transmission and distribution levels,
circuits are switched and protected, and power flow is monitored and
controlled. The primary function of most substations is voltage
transformation --- stepping down from transmission voltages (69-765 kV)
to distribution voltages (4-35 kV) --- but substations also serve as
switching points that allow operators to reconfigure the network for
maintenance, load balancing, or fault isolation. Substations are
classified by their role in the system: transmission substations
interconnect high-voltage lines and may include autotransformers for
voltage conversion between transmission levels, distribution substations
step voltage down to feeder levels for delivery to customers, and
switching substations provide interconnection and sectionalizing without
voltage transformation. Major equipment categories within a substation
include power transformers, circuit breakers, disconnect switches,
voltage regulators, instrument transformers (CTs and VTs), surge
arresters, capacitor banks, and the control house containing protective
relays, metering, SCADA equipment, and battery backup systems. The
physical arrangement of buses and breakers --- single bus, double bus,
main-and-transfer, ring bus, or breaker-and-a-half --- determines the
substation's reliability and operational flexibility, with
higher-reliability configurations used at critical transmission nodes
where loss of a single component must not interrupt service. Substation
grounding is essential for personnel safety and proper relay operation,
requiring a ground grid of buried copper conductors designed to limit
step and touch potentials below IEEE 80 thresholds during fault
conditions.

\subsubsection{1.3.1.1 Transformers}\label{transformers}

Transformers are static electromagnetic devices that transfer electrical
energy between two or more circuits through mutual induction, enabling
voltage step-up or step-down while maintaining approximately constant
power (V₁I₁ approximately equals V₂I₂). Power transformers in
substations are typically oil-filled for insulation and cooling, with
ratings ranging from a few MVA for distribution transformers to over
1000 MVA for large transmission-class units. The turns ratio (N₁/N₂)
determines the voltage transformation ratio, while the core is
constructed from laminated silicon steel to minimize eddy current and
hysteresis losses. Three-phase transformers can be configured in
delta-wye, wye-delta, wye-wye, or delta-delta connections, each
providing different phase shift and grounding characteristics.
Transformer nameplate data includes rated power (kVA or MVA), voltage
ratings, impedance percentage, cooling class (ONAN, ONAF, etc.), and tap
changer range.

\begin{examplebox}

\textbf{Example 1.3.1.1:} A three-phase, 50 MVA, 138 kV / 13.8 kV,
delta-wye transformer has a nameplate impedance of 8.5\%. Determine (a)
the turns ratio, (b) the rated current on each side, and (c) the maximum
symmetrical fault current on the secondary side assuming an infinite bus
on the primary.

\textbf{Solution:}

(a) Turns ratio: N₁/N₂ = V₁/V₂ = 138,000 / 13,800 = \textbf{10:1}

(b) Rated currents (three-phase):\\
Primary: I\textsubscript{primary} = S / (√3 × V\textsubscript{primary})
= 50,000,000 / (√3 × 138,000) = \textbf{209.2 A}\\
Secondary: I\textsubscript{secondary} = S / (√3 ×
V\textsubscript{secondary}) = 50,000,000 / (√3 × 13,800) =
\textbf{2,091.8 A}

(c) Maximum symmetrical fault current on secondary (infinite bus
assumption):\\
I\textsubscript{fault} = I\textsubscript{rated} / Z\textsubscript{pu} =
2,091.8 / 0.085 = \textbf{24,609 A ≈ 24.6 kA}

\end{examplebox}

\subsubsection{1.3.1.2 Autotransformers}\label{autotransformers}

An autotransformer uses a single winding with a tap point to provide
voltage transformation, rather than the two electrically isolated
windings of a conventional transformer. The portion of the winding
common to both the primary and secondary circuits carries only the
difference between the primary and secondary currents, which means the
winding can be physically smaller and lighter than an equivalent
two-winding transformer. The apparent power rating
(S\textsubscript{auto}) of the autotransformer is the full load it
delivers, but the actual power transferred through electromagnetic
coupling (S\textsubscript{transformed}) is only a fraction of the total:
S\textsubscript{transformed} = S\textsubscript{auto} × (1 − N₂/N₁) for a
step-down configuration. This makes autotransformers significantly more
efficient and economical when the voltage ratio is close to 1:1, such as
the 138/115 kV or 345/230 kV connections common in transmission systems.
The main disadvantage is the lack of galvanic isolation between primary
and secondary --- a fault on one side is directly coupled to the other
--- so autotransformers are not used where electrical isolation is
required. Common applications include transmission system voltage
conversion, voltage regulators (step type), motor starting (reduced
voltage), and laboratory variable-voltage supplies (Variacs).

\begin{examplebox}

\textbf{Example 1.3.1.2:} A single-phase, 100 MVA, 230/115 kV
autotransformer supplies a 115 kV load. Determine (a) the turns ratio,
(b) the rated load current on the 115 kV side, (c) the current in the
common (series) winding, and (d) the power advantage (ratio of
autotransformer rating to the equivalent two-winding transformer rating
that would handle the same transformed power).

\textbf{Solution:}

(a) Turns ratio: a = N₁/N₂ = V₁/V₂ = 230/115 = \textbf{2:1}

(b) Rated load current at 115 kV:\\
I\textsubscript{load} = S\textsubscript{auto} / V₂ = 100 × 10⁶ / 115,000
= \textbf{869.6 A}

(c) Current in the series (common) winding:\\
The series winding carries the difference between load current and
source current.\\
I\textsubscript{source} = S\textsubscript{auto} / V₁ = 100 × 10⁶ /
230,000 = 434.8 A\\
I\textsubscript{series} = I\textsubscript{load} −
I\textsubscript{source} = 869.6 − 434.8 = \textbf{434.8 A}

(d) Transformed power (power actually coupled magnetically):\\
S\textsubscript{transformed} = S\textsubscript{auto} × (1 − 1/a) = 100 ×
(1 − 1/2) = \textbf{50 MVA}\\
Power advantage = S\textsubscript{auto} / S\textsubscript{transformed} =
100 / 50 = \textbf{2.0}

A two-winding transformer rated at only 50 MVA can deliver 100 MVA as an
autotransformer at this 2:1 ratio. The closer the ratio is to 1:1, the
greater the advantage --- for example, at 230/200 kV the advantage would
be 230/(230 − 200) = 7.67.

\end{examplebox}

\subsubsection{1.3.1.3 Circuit Breakers}\label{circuit-breakers}

Circuit breakers are switching devices designed to interrupt fault
currents and isolate faulted sections of the power system to prevent
equipment damage and maintain system stability. They must be capable of
interrupting currents ranging from normal load current to maximum fault
current (which can exceed 50 kA in transmission substations) and then
withstanding the recovery voltage across their open contacts. Modern
high-voltage circuit breakers use SF₆ (sulfur hexafluoride) gas as the
arc-extinguishing medium due to its superior dielectric strength and
thermal properties, while medium-voltage breakers may use vacuum
interrupters. Circuit breakers are rated by their nominal voltage,
continuous current capacity, short-circuit interrupting capacity, and
interrupting time (typically 3-5 cycles at 60 Hz). Protective relays
monitor system conditions and send trip signals to circuit breakers when
abnormal conditions such as overcurrent, differential current, or
distance (impedance) faults are detected.

\begin{examplebox}

\textbf{Example 1.3.1.3:} A 145 kV substation bus has a rated
short-circuit current of 40 kA symmetrical. The circuit breaker must
interrupt the fault within 5 cycles at 60 Hz. Determine (a) the
interrupting time in milliseconds, and (b) the three-phase short-circuit
MVA that the breaker must be rated to handle.

\textbf{Solution:}

(a) Interrupting time: t = 5 cycles × (1/60 s/cycle) = 5/60 = 0.0833 s =
\textbf{83.3 ms}

(b) Short-circuit MVA:\\
S\textsubscript{fault} = √3 × V\textsubscript{LL} ×
I\textsubscript{fault} = √3 × 145,000 × 40,000 = 10,045,900,000 VA\\
S\textsubscript{fault} = \textbf{10,046 MVA ≈ 10.0 GVA}

\end{examplebox}

\subsubsection{1.3.1.4 Voltage Regulators}\label{voltage-regulators}

Voltage regulators maintain the distribution voltage within acceptable
limits (typically plus or minus 5\% of nominal per ANSI C84.1) as load
conditions vary throughout the day. The most common type in distribution
systems is the step voltage regulator, which is an autotransformer with
an automatic tap-changing mechanism that can adjust the output voltage
in steps of approximately 0.625\% over a range of plus or minus 10\%.
The regulator control circuit uses a voltage-sensing element, a line
drop compensator (to account for voltage drop between the regulator and
the load center), and a time-delay mechanism to prevent excessive tap
changes during transient fluctuations. Single-phase regulators are used
on distribution feeders, while three-phase regulators or load tap
changers (LTCs) on substation power transformers provide voltage
regulation at the substation level.

\begin{examplebox}

\textbf{Example 1.3.1.4:} A step voltage regulator on a 7.2 kV
(line-to-neutral) distribution feeder is set to maintain 7,200 V at the
load center. The line drop compensator settings are R = 3.0 V and X =
9.0 V (on a 120 V base). The current transformer ratio is 200:5. At peak
load, the feeder current is 150 A at a power factor of 0.90 lagging.
Determine the required regulator output voltage.

\textbf{Solution:}\\
CT ratio: 200:5 = 40:1\\
Secondary current: I\textsubscript{sec} = 150 / 40 = 3.75 A\\
Power factor angle: θ = cos⁻¹(0.90) = 25.84°\\
I\textsubscript{sec} in rectangular form: I\textsubscript{sec} =
3.75∠−25.84° = 3.375 − j1.635 A

Compensator voltage drop (on 120 V base):\\
V\textsubscript{drop} = I\textsubscript{sec} × (R + jX) = (3.375 −
j1.635)(3.0 + j9.0)\\
= 10.125 + j30.375 − j4.905 + 14.715\\
= 24.84 + j25.47 V\\
\textbar V\textsubscript{drop}\textbar{} = √(24.84² + 25.47²) = 35.6 V

Required regulator output on 120 V base: V\textsubscript{reg} = 120 +
35.6 = 155.6 V\\
Convert to primary: V\textsubscript{out} = (155.6 / 120) × 7,200 =
\textbf{9,336 V}

Since the regulator range is ±10\% of 7,200 V (6,480 to 7,920 V), the
compensator raises the set point so the regulator output compensates for
the line drop.\\
The regulator output voltage is set to approximately \textbf{7,200 +
(35.6/120 × 7,200) = 7,200 + 2,136 = 9,336 V}.

Note: In practice, each tap step is 0.625\% of 7,200 V = 45 V, so the
regulator would need approximately 2,136/45 ≈ 47.5 boost steps, far
exceeding the ±16 step maximum (maximum boost = 16 steps × 45 V = 720 V;
full raise-to-lower range = 1,440 V).\\
This indicates the line drop is too large for a single regulator and
would require a second regulator or conductor upgrade.\\
For a more typical 50 A load: V\textsubscript{drop} ≈ 11.9 V (on 120 V
base), and the regulator output would be 7,200 + 714 = \textbf{7,914 V},
which is within the ±10\% range at tap position +16.

\end{examplebox}

\subsubsection{1.3.1.5 Current Transformer
(CT)}\label{current-transformer-ct}

Current transformers are instrument transformers that produce a
secondary current proportional to the primary current flowing through
the power conductor, typically standardized at 5 A or 1 A secondary
output. CTs enable protective relays and metering equipment to measure
high currents (hundreds or thousands of amperes) safely at low,
standardized levels. They are specified by their ratio (e.g., 600:5),
accuracy class (e.g., 0.3 for metering, C400 for relaying), and burden
rating, which defines the maximum secondary impedance the CT can drive
while maintaining accuracy. The secondary circuit of a CT must never be
left open while primary current is flowing, as this would cause
dangerously high voltages on the secondary winding due to the loss of
the demagnetizing effect of secondary current. CTs are available in
bushing, window (toroidal), and bar-type configurations depending on the
installation requirements.

\begin{examplebox}

\textbf{Example 1.3.1.5:} A 600:5 CT with accuracy class C200 is
connected to a relay with an impedance of 2.0 Ω and lead wire resistance
of 1.5 Ω (total loop). The primary fault current is 9,000 A. Determine
(a) the secondary current, (b) the voltage the CT must develop across
the burden, and (c) whether the CT can maintain accuracy.

\textbf{Solution:}

(a) Secondary current: I\textsubscript{sec} = I\textsubscript{primary} /
CT ratio = 9,000 / (600/5) = 9,000 / 120 = \textbf{75 A}

(b) Total burden impedance: Z\textsubscript{burden} = 2.0 + 1.5 = 3.5
Ω\\
Voltage across burden: V\textsubscript{sec} = I\textsubscript{sec} ×
Z\textsubscript{burden} = 75 × 3.5 = \textbf{262.5 V}

(c) The CT accuracy class is C200, meaning it can maintain accuracy up
to 200 V across the burden at 20 times rated secondary current (20 × 5 =
100 A).\\
At 75 A (15 times rated), the required voltage is 262.5 V, which
\textbf{exceeds the 200 V rating}.\\
The CT will saturate, producing distorted output. A higher accuracy
class (e.g., C400) or lower burden is needed.

\end{examplebox}

\subsubsection{1.3.1.6 Voltage Transformer
(VT)}\label{voltage-transformer-vt}

Voltage transformers (also called potential transformers, or PTs) step
down high primary voltages to standardized low secondary voltages,
typically 120 V or 69.3 V, for use by metering and protective relaying
equipment. They operate on the same electromagnetic induction principle
as power transformers but are designed for high accuracy at very low
burden (power output), with accuracy classes such as 0.3 or 0.6 for
metering applications. VTs can be electromagnetic (wound-type) for
voltages up to about 138 kV, or capacitor voltage transformers (CVTs) at
higher voltages, where a capacitive voltage divider reduces the voltage
before a small electromagnetic transformer provides the final step-down.
The secondary winding of a VT is typically grounded on one terminal for
safety, and fuses are installed on both primary and secondary sides to
protect against faults. VT ratings include the voltage ratio, thermal
burden (maximum VA output), and accuracy class at specified burdens.

\begin{examplebox}

\textbf{Example 1.3.1.6:} A 14,400:120 V voltage transformer is
connected to three relays (each with a burden of 25 VA) and one meter
(burden of 50 VA). The VT has a thermal burden rating of 200 VA.
Determine (a) the total connected burden, (b) the secondary current
drawn, and (c) whether the VT is within its rating.

\textbf{Solution:}

(a) Total burden: S\textsubscript{total} = 3 × 25 + 50 = \textbf{125 VA}

(b) Secondary current: I\textsubscript{sec} = S\textsubscript{total} /
V\textsubscript{sec} = 125 / 120 = \textbf{1.042 A}

(c) The total burden of 125 VA is less than the thermal rating of 200
VA, so the VT is \textbf{within its rating} with a margin of 200 − 125 =
75 VA (37.5\% margin).

\end{examplebox}

\subsubsection{1.3.1.7 Switching}\label{switching}

Substation switching equipment includes disconnect switches, load break
switches, and bus sectionalizers that provide isolation, operational
flexibility, and maintenance access for substation components.
Disconnect switches (also called isolators) are used to provide a
visible air gap for safe maintenance but can only be operated under
no-load conditions since they have no arc-interrupting capability. Load
break switches can interrupt normal load currents but are not rated for
fault current interruption, making them suitable for routine switching
operations such as transferring load between buses or feeders. Bus
configurations such as single bus, main-and-transfer,
breaker-and-a-half, and ring bus define the arrangement of switches and
circuit breakers and determine the level of reliability and operational
flexibility of the substation. Proper switching procedures and
interlocking schemes are critical to prevent equipment damage and ensure
personnel safety during switching operations.

\begin{examplebox}

\textbf{Example 1.3.1.7:} A breaker-and-a-half substation bus
arrangement has two main buses and three bays, each bay containing two
breakers and one line connection between the breakers. If one breaker
fails and must be isolated for maintenance, determine how many circuits
(lines) lose their redundant protection and how many circuits are
completely de-energized.

\textbf{Solution:}\\
In a breaker-and-a-half scheme, each line is connected between two
circuit breakers in a bay. Each breaker is shared between two circuits
(one on each side).\\
When one breaker is taken out of service:\\
- The circuit connected to that bay still has its other breaker for
protection, so \textbf{zero circuits are de-energized}.\\
- The circuit in that bay operates with only one breaker instead of two,
meaning \textbf{one circuit loses its redundant breaker protection} (it
can still operate but cannot tolerate a second breaker failure).\\
- All other circuits remain fully protected with their two dedicated
breakers.

This demonstrates the high reliability of the breaker-and-a-half scheme:
\textbf{no circuits are lost} during a single breaker outage.

\end{examplebox}

\subsection{1.3.2 Poles}\label{poles}

Distribution poles are the most visible component of the overhead power
system, supporting conductors, transformers, and protective equipment
along the path from the substation to the end customer. Pole materials
include wood (the most common in North America, typically southern
yellow pine or Douglas fir), steel (used for higher loads, longer spans,
or harsh environments), concrete (spun-cast prestressed, common in
coastal and high-wind regions), and fiberglass composite (lightweight
and rot-resistant, gaining adoption in environmentally sensitive areas).
Standard wood poles in the United States are classified by the ANSI O5.1
standard according to height (typically 35 to 70 feet for distribution)
and strength class (Class 1 through Class 10, with Class 1 being the
strongest at approximately 4,500 lbs of horizontal load capacity at 2
feet from the top), and are pressure-treated with preservatives such as
pentachlorophenol, chromated copper arsenate (CCA), or copper
naphthenate to resist decay and insect damage. Poles must be engineered
to withstand three categories of mechanical loading: vertical loads from
conductor and equipment weight, transverse loads from wind pressure on
conductors and the pole itself (with ice accumulation in cold climates),
and longitudinal loads from unbalanced conductor tension at dead-end,
angle, and junction structures. The NESC defines three loading districts
--- Heavy, Medium, and Light --- each specifying different combinations
of ice thickness (0 to 0.5 inches radial), wind pressure (0 to 4 psf),
and temperature, which determine the minimum pole class required for a
given span and conductor configuration. Span lengths typically range
from 100 to 400 feet depending on pole class, conductor size, and
terrain, with longer spans requiring stronger poles and potentially
guying --- the use of down guys anchored to the ground or sidewalk guys
to counteract unbalanced loads at corners, dead-ends, and heavy
equipment locations. Pole-mounted equipment includes distribution
transformers, fuse cutouts, lightning arresters, reclosers,
sectionalizers, and capacitor banks, all of which must be installed at
proper clearance heights above ground and with adequate working space to
comply with the NESC and local utility standards.

\begin{examplebox}

\textbf{Example 1.3.2:} A 45-foot Class 4 wood distribution pole is to
be set in soil with a setting depth of 10\% of length plus 2 feet. The
pole supports a 167 kVA single-phase transformer (weight 1,200 lbs)
mounted at 25 feet above ground, and three 4/0 ACSR conductors. The
horizontal wind span is 300 feet, and the NESC Rule 250B wind loading is
4 psf on projected conductor area (diameter 0.563 inches). Determine (a)
the setting depth and (b) the total horizontal wind force on the
conductors.

\textbf{Solution:}

(a) Setting depth: d = 0.10 × 45 + 2 = 4.5 + 2 = \textbf{6.5 feet}\\
Height above ground: 45 − 6.5 = 38.5 feet

(b) Projected area of one conductor per foot: A\textsubscript{per\_ft} =
0.563 in / 12 = 0.0469 ft²/ft\\
Total conductor length (wind span): 300 ft\\
Projected area per conductor: A = 0.0469 × 300 = 14.08 ft²\\
Wind force per conductor: F = 4 psf × 14.08 = 56.3 lbs\\
Total horizontal wind force (3 conductors): F\textsubscript{total} = 3 ×
56.3 = \textbf{168.9 lbs}

\end{examplebox}

\subsection{1.3.3 Underground}\label{underground}

Underground distribution systems use insulated cables installed below
grade to deliver power in areas where overhead construction is
impractical, prohibited, or undesirable --- including dense urban
centers, new residential subdivisions with underground requirements,
airport approach zones, and areas with high aesthetic or environmental
sensitivity. The primary cable types used at distribution voltages (5-35
kV) are cross-linked polyethylene (XLPE) and ethylene propylene rubber
(EPR) insulated cables, which have largely replaced older
paper-insulated lead-covered (PILC) cables due to their superior
dielectric performance, moisture resistance, lower weight, and easier
splicing and termination. Installation methods include duct bank systems
(multiple PVC or HDPE conduits encased in concrete, common in urban
areas where future cable pulling and replacement is expected), direct
burial (cables with a rugged outer jacket laid in a trench with sand
bedding, lower initial cost but difficult to replace), and cable troughs
or tunnels in industrial and utility campus environments. Underground
systems offer significantly improved reliability against weather-related
outages --- eliminating exposure to wind, ice storms, falling trees,
lightning, and vehicle strikes --- but come with substantially higher
installation costs (typically 5 to 10 times that of equivalent overhead
construction) and present greater challenges when faults do occur. Fault
location in underground systems requires specialized techniques such as
time-domain reflectometry (TDR), thumper/surge generators, and acoustic
or electromagnetic fault pinpointing, and repair times are measured in
hours to days compared to minutes for many overhead faults. Cable
ampacity (current-carrying capacity) is heavily influenced by the
thermal environment --- soil thermal resistivity (ρ\textsubscript{soil},
typically 60-120 °C·cm/W), burial depth, spacing between cables or
ducts, grouping derating factors for multiple circuits, and ambient soil
temperature --- requiring thermal analysis per the Neher-McGrath method
(NEC 310.60) or IEC 60287. Pad-mounted transformers, switching cabinets,
and junction pedestals provide the above-ground interface between the
underground system and customer service, designed with tamper-resistant
enclosures and visible disconnect points for safe operation in publicly
accessible locations.

\begin{examplebox}

\textbf{Example 1.3.3:} A single-conductor 15 kV, 500 kcmil XLPE
underground cable is direct-buried at a depth of 36 inches in soil with
thermal resistivity ρ\textsubscript{soil} = 90 °C·cm/W. The cable has a
conductor resistance of 0.0277 Ω/1000 ft at 90°C, an insulation thermal
resistance of 45.2 °C·cm/W, and the maximum conductor temperature is
90°C with an ambient soil temperature of 25°C. Using a simplified
Neher-McGrath approach, estimate the cable ampacity. Assume the total
effective thermal resistance from conductor to ambient is
R\textsubscript{thermal} = 5.8 °C/W per foot.

\textbf{Solution:}\\
Allowable temperature rise: ΔT = T\textsubscript{max} −
T\textsubscript{ambient} = 90 − 25 = 65°C\\
Heat dissipation per foot: W = ΔT / R\textsubscript{thermal} = 65 / 5.8
= 11.21 W/ft\\
Since heat is primarily I²R loss:\\
W = I² × R\textsubscript{conductor} = I² × (0.0277 / 1000) Ω/ft = I² ×
2.77 × 10⁻⁵ Ω/ft\\
I² = 11.21 / 2.77 × 10⁻⁵ = 404,693\\
I = √404,693 = \textbf{636 A}

\end{examplebox}

\subsection{1.3.4 Three-Phase
Connections}\label{three-phase-connections}

Three-phase power systems use two fundamental winding configurations ---
wye (Y, also called star) and delta (Δ) --- to connect generators,
transformers, motors, and loads. The choice between wye and delta
affects the relationship between line and phase voltages, line and phase
currents, neutral availability, and fault behavior, making it one of the
most important decisions in power system design.

\subsubsection{1.3.4.1 Wye (Star) Connection}\label{wye-star-connection}

In a wye connection, one terminal of each of the three phase windings is
connected to a common neutral point, while the other terminal of each
winding connects to the respective line conductor. The line-to-line
voltage is √3 times the phase (line-to-neutral) voltage:
V\textsubscript{LL} = √3 × V\textsubscript{LN}, and the line current
equals the phase current: I\textsubscript{L} = I\textsubscript{phase}.
The neutral point can be grounded to establish a voltage reference,
provide a return path for unbalanced currents, and limit overvoltages
during ground faults --- this is why wye connections are standard on the
secondary side of distribution transformers (e.g., 208Y/120 V or
480Y/277 V), where the neutral provides both the safety ground reference
and a fourth conductor for single-phase loads. In a balanced wye system,
the neutral carries zero current; under unbalanced loading, the neutral
carries the vector sum of the three phase currents. Wye connections are
also preferred for high-voltage transmission because each winding is
insulated only to the line-to-neutral voltage, reducing insulation cost.

\begin{examplebox}

\textbf{Example 1.3.4.1:} A three-phase, 480Y/277 V wye-connected system
supplies a balanced load of 150 kW at 0.90 power factor lagging.
Determine (a) the line-to-neutral voltage, (b) the line current, and (c)
the neutral current.

\textbf{Solution:}

(a) Line-to-neutral voltage:\\
V\textsubscript{LN} = V\textsubscript{LL} / √3 = 480 / 1.732 =
\textbf{277 V}

(b) Line current (balanced three-phase):\\
S = P / PF = 150 / 0.90 = 166.7 kVA\\
I\textsubscript{L} = S / (√3 × V\textsubscript{LL}) = 166,700 / (1.732 ×
480) = \textbf{200.6 A}

(c) Neutral current:\\
For a balanced load, the three phase currents are equal in magnitude and
displaced by 120°. Their vector sum is zero:\\
I\textsubscript{N} = I\textsubscript{A} + I\textsubscript{B} +
I\textsubscript{C} = \textbf{0 A}

\end{examplebox}

\subsubsection{1.3.4.2 Delta (Δ)
Connection}\label{delta-ux3b4-connection}

In a delta connection, the three phase windings are connected end-to-end
in a closed loop, forming a triangle. Each line conductor connects to
the junction of two windings. The line-to-line voltage equals the phase
voltage: V\textsubscript{LL} = V\textsubscript{phase}, and the line
current is √3 times the phase current: I\textsubscript{L} = √3 ×
I\textsubscript{phase}. Delta connections have no neutral point, so they
cannot supply line-to-neutral loads directly and cannot be solidly
grounded (though corner grounding or resistance grounding through a
grounding transformer is possible). Delta-connected transformer windings
trap triplen harmonic currents (3rd, 9th, 15th, etc.) that circulate
within the closed delta loop rather than propagating into the power
system, which is why the primary winding of distribution transformers is
often delta-connected. Delta connections also provide a path for
zero-sequence currents during ground faults on the wye side of a
delta-wye transformer, enabling ground fault detection. Motors are
commonly delta-connected at 480 V to avoid the need for a neutral
conductor.

\begin{examplebox}

\textbf{Example 1.3.4.2:} A three-phase, 480 V delta-connected motor
draws 80 A line current at 0.85 power factor lagging. Determine (a) the
phase voltage across each motor winding, (b) the current through each
winding, and (c) the three-phase power consumed.

\textbf{Solution:}

(a) Phase voltage (delta: line voltage equals phase voltage):\\
V\textsubscript{phase} = V\textsubscript{LL} = \textbf{480 V}

(b) Phase current:\\
I\textsubscript{phase} = I\textsubscript{L} / √3 = 80 / 1.732 =
\textbf{46.2 A}

(c) Three-phase power:\\
P = √3 × V\textsubscript{LL} × I\textsubscript{L} × PF = 1.732 × 480 ×
80 × 0.85 = \textbf{56,533 W ≈ 56.5 kW}

\end{examplebox}

\subsubsection{1.3.4.3 Delta-Wye
Transformations}\label{delta-wye-transformations}

Many power system configurations require converting between delta and
wye equivalent circuits for analysis, particularly when combining
delta-connected sources with wye-connected loads or vice versa. The
transformation formulas relate impedances in a delta configuration
(Z\textsubscript{AB}, Z\textsubscript{BC}, Z\textsubscript{CA}) to
equivalent wye impedances (Z\textsubscript{A}, Z\textsubscript{B},
Z\textsubscript{C}) and vice versa. For balanced systems where all
impedances are equal, the conversion simplifies to Z\textsubscript{Y} =
Z\textsubscript{Δ} / 3 (delta to wye) and Z\textsubscript{Δ} = 3 ×
Z\textsubscript{Y} (wye to delta). For unbalanced systems, the
delta-to-wye conversion is Z\textsubscript{A} = (Z\textsubscript{AB} ×
Z\textsubscript{CA}) / (Z\textsubscript{AB} + Z\textsubscript{BC} +
Z\textsubscript{CA}), with similar expressions for Z\textsubscript{B}
and Z\textsubscript{C} by cyclic rotation. Transformer connections use
specific delta-wye combinations (Dy1, Dy11, Yd1, etc.) that introduce
30° phase shifts between primary and secondary voltages, which must be
matched when paralleling transformers.

\begin{examplebox}

\textbf{Example 1.3.4.3:} A balanced delta-connected load has
Z\textsubscript{Δ} = 30 + j15 Ω per phase and is connected to a 240 V
three-phase source. Determine (a) the equivalent wye impedance per
phase, (b) the line current using the wye equivalent, and (c) verify the
result using delta phase currents.

\textbf{Solution:}

(a) Equivalent wye impedance (balanced system):\\
Z\textsubscript{Y} = Z\textsubscript{Δ} / 3 = (30 + j15) / 3 =
\textbf{10 + j5 Ω}\\
\textbar Z\textsubscript{Y}\textbar{} = √(10² + 5²) = 11.18 Ω

(b) Line current using wye equivalent:\\
V\textsubscript{LN} = V\textsubscript{LL} / √3 = 240 / 1.732 = 138.6 V\\
I\textsubscript{L} = V\textsubscript{LN} /
\textbar Z\textsubscript{Y}\textbar{} = 138.6 / 11.18 = \textbf{12.40 A}

(c) Verification using delta phase currents:\\
\textbar Z\textsubscript{Δ}\textbar{} = √(30² + 15²) = 33.54 Ω\\
I\textsubscript{phase,Δ} = V\textsubscript{LL} /
\textbar Z\textsubscript{Δ}\textbar{} = 240 / 33.54 = 7.16 A\\
I\textsubscript{L} = √3 × I\textsubscript{phase,Δ} = 1.732 × 7.16 =
\textbf{12.40 A} ✓

\end{examplebox}

\subsection{1.3.5 AC Analysis}\label{ac-analysis}

The analysis of AC distribution circuits requires mathematical tools
that can represent both the magnitude and phase angle of sinusoidal
voltages and currents. Since power system quantities are sinusoidal at a
fixed frequency (60 Hz in North America, 50 Hz in most other regions),
steady-state analysis is greatly simplified by representing these
time-varying quantities as complex numbers known as phasors, enabling
the use of algebraic rather than differential equation methods.

\subsubsection{1.3.5.1 Complex Numbers and
Phasors}\label{complex-numbers-and-phasors}

Complex numbers provide a compact mathematical representation of AC
quantities by encoding both magnitude and phase angle in a single
expression of the form Z = a + jb, where a is the real (resistive)
component and b is the imaginary (reactive) component, with j
representing the square root of negative one. The rectangular form (a +
jb) is convenient for addition and subtraction of impedances in series,
while the polar form (\textbar Z\textbar{} at angle θ) is preferred for
multiplication and division, which arise in series-parallel circuit
analysis and power calculations. A phasor is a complex number that
represents the amplitude and phase of a sinusoidal waveform relative to
a reference, obtained by applying the Euler relation: V =
V\textsubscript{m} × e\textsuperscript{jθ} = V\textsubscript{m} at angle
θ, where V\textsubscript{m} is the peak value and θ is the phase angle.
In power engineering, phasors are conventionally expressed as RMS
(root-mean-square) values rather than peak values, since RMS values
directly relate to average power delivery (P = V\textsubscript{rms} ×
I\textsubscript{rms} × cos(θ)). Impedance, expressed as Z = R + jX
(where X is reactance), relates phasor voltage and current through Ohm's
law (V = I × Z), enabling systematic analysis of AC circuits using
techniques such as Kirchhoff's laws, mesh analysis, and nodal analysis
in the phasor domain.

\begin{examplebox}

\textbf{Example 1.3.5.1:} A series RLC circuit has R = 10 Ω, L = 50 mH,
and C = 100 μF, connected to a 120 V\textsubscript{rms}, 60 Hz source.
Determine the impedance, current, and power factor.

\textbf{Solution:}\\
Inductive reactance: X\textsubscript{L} = 2πfL = 2π × 60 × 0.050 = 18.85
Ω\\
Capacitive reactance: X\textsubscript{C} = 1 / (2πfC) = 1 / (2π × 60 ×
100 × 10⁻⁶) = 26.53 Ω\\
Net reactance: X = X\textsubscript{L} − X\textsubscript{C} = 18.85 −
26.53 = −7.68 Ω (capacitive)\\
Impedance: Z = R + jX = 10 − j7.68 Ω\\
\textbar Z\textbar{} = √(10² + 7.68²) = √(100 + 58.98) = √158.98 = 12.61
Ω\\
Phase angle: θ = tan⁻¹(−7.68 / 10) = −37.52°\\
Z = \textbf{12.61∠−37.52° Ω}

Current: I = V / Z = 120∠0° / 12.61∠−37.52° = \textbf{9.52∠37.52° A}
(current leads voltage)

Power factor: pf = cos(37.52°) = \textbf{0.793 leading}

\end{examplebox}

\subsection{1.3.6 Power Factor
Correction}\label{power-factor-correction}

Power factor correction (PFC) techniques are employed to improve the
power factor of electrical systems, particularly in transmission lines.
Power factor is a measure of how effectively electrical power is being
utilized, and it is defined as the cosine of the phase angle between
voltage and current in an AC circuit. A low power factor can lead to
inefficient energy usage, increased losses, and reduced system capacity.

Common power factor correction techniques include capacitor banks,
synchronous condensers, Static VAR Compensators (SVCs), Static
Synchronous Compensators (STATCOMs), and phase advancers. Capacitor
banks --- the most widely deployed method --- connect capacitors in
parallel with the load to supply leading reactive power and offset the
lagging reactive component. Synchronous condensers are rotating machines
(synchronous generators without a prime mover) whose field excitation
can be adjusted to either absorb or supply reactive power. SVCs use
thyristors, reactors, and capacitors to provide rapid, continuous
reactive compensation with millisecond response to load changes.
STATCOMs, based on voltage-source converters, offer faster and more
precise reactive power injection or absorption than SVCs and support
voltage stability during disturbances. Phase advancers are applied to
large induction motors, injecting leading reactive current into the
rotor circuit to reduce the lagging reactive demand seen at the stator
terminals. Together, these techniques minimize reactive power flow,
reduce I²R losses, improve voltage profiles, and increase the effective
capacity of generation and transmission infrastructure.

\begin{examplebox}

\textbf{Example 1.3.6:} An industrial facility draws 500 kW of real
power at a power factor of 0.72 lagging from a 480 V, 60 Hz, three-phase
supply. The utility requires the power factor to be corrected to 0.95
lagging. Determine the required capacitor bank size in kVAR and the
capacitance per phase for a delta-connected capacitor bank.

\textbf{Solution:}\\
Original reactive power:\\
θ₁ = cos⁻¹(0.72) = 43.95°\\
Q₁ = P × tan(θ₁) = 500 × tan(43.95°) = 500 × 0.9639 = 481.9 kVAR

Target reactive power:\\
θ₂ = cos⁻¹(0.95) = 18.19°\\
Q₂ = P × tan(θ₂) = 500 × tan(18.19°) = 500 × 0.3287 = 164.4 kVAR

Required capacitor bank: Q\textsubscript{cap} = Q₁ − Q₂ = 481.9 − 164.4
= \textbf{317.5 kVAR}

For a delta-connected bank, each capacitor sees line-to-line voltage:\\
Q per phase: Q\textsubscript{phase} = 317.5 / 3 = 105.8 kVAR\\
Capacitive reactance per phase: X\textsubscript{C} =
V\textsubscript{LL}² / Q\textsubscript{phase} = (480)² / 105,800 = 2.177
Ω\\
Capacitance per phase: C = 1 / (2πfX\textsubscript{C}) = 1 / (2π × 60 ×
2.177) = \textbf{1,219 μF per phase}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-1-3-6}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch01_power_factor.png}

\caption{Figure 1.3.6: Power Factor Correction Analysis}

\end{figure}

\section{1.4 Power System Protection}\label{power-system-protection}

Power system protection is the branch of power engineering concerned
with detecting abnormal conditions (faults, overloads, equipment
failures) and isolating the affected portion of the system as quickly as
possible to prevent equipment damage, maintain system stability, and
ensure personnel safety. A protection system consists of instrument
transformers (CTs and VTs) that sense system quantities, protective
relays that make trip decisions based on measured currents, voltages,
impedances, or differential quantities, and circuit breakers that
physically interrupt the fault current. The three fundamental
requirements of a protection system are dependability (it must operate
when required), security (it must not operate when not required), and
speed (it must clear faults before they cause cascading damage).

\subsection{1.4.1 Protective Relays}\label{protective-relays}

Protective relays are the decision-making elements of a protection
system. They continuously monitor electrical quantities provided by
instrument transformers and issue trip signals to circuit breakers when
abnormal conditions are detected. Modern digital relays (also called
numerical or microprocessor-based relays) use sampled current and
voltage waveforms processed by algorithms that implement multiple
protection functions in a single device, along with oscillography, event
recording, and communication capabilities.

The major relay types and their applications are:

\begin{itemize}
\tightlist
\item
  \textbf{Overcurrent relays (50/51)}: Operate when current exceeds a
  pickup threshold. Time-overcurrent relays (51) have an inverse
  time-current characteristic where trip time decreases as fault current
  increases. Instantaneous overcurrent relays (50) trip without
  intentional delay for high-magnitude faults.
\item
  \textbf{Distance relays (21)}: Measure the apparent impedance (V/I)
  seen from the relay location. Since impedance is proportional to line
  length, distance relays can determine whether a fault is within a
  protected zone. They are the primary protection for transmission
  lines, typically with three zones of increasing reach and time delay.
\item
  \textbf{Differential relays (87)}: Compare currents entering and
  leaving a protected element (transformer, bus, generator). Under
  normal conditions, the currents balance (Kirchhoff's current law);
  during an internal fault, the differential current exceeds a threshold
  and the relay operates. Differential protection is the primary
  protection for transformers, generators, and busbars because it
  provides fast, selective protection with a clearly defined protection
  zone.
\item
  \textbf{Directional relays (67)}: Determine the direction of power or
  fault current flow using the phase angle between voltage and current.
  They are used to provide selectivity in looped or networked systems
  where fault current can flow in either direction.
\end{itemize}

\begin{examplebox}

\textbf{Example 1.4.1:} A time-overcurrent relay (51) protecting a
distribution feeder has a pickup current of 600 A and uses the IEEE Very
Inverse characteristic: t = (19.61 / (M\textsuperscript{2} − 1) + 0.491)
× TDS, where M = I\textsubscript{fault}/I\textsubscript{pickup} and TDS
is the time dial setting. With TDS = 2.0, determine the relay operating
time for fault currents of (a) 3,000 A and (b) 6,000 A.

\textbf{Solution:}

(a) M = 3,000/600 = 5.0.\\
t = (19.61/(25 − 1) + 0.491) × 2.0 = (19.61/24 + 0.491) × 2.0 = (0.817 +
0.491) × 2.0 = \textbf{2.62 s}

(b) M = 6,000/600 = 10.0.\\
t = (19.61/(100 − 1) + 0.491) × 2.0 = (19.61/99 + 0.491) × 2.0 = (0.198
+ 0.491) × 2.0 = \textbf{1.38 s}

The inverse characteristic ensures faster tripping for higher fault
currents --- doubling the fault current from 3,000 A to 6,000 A nearly
halved the operating time.

\end{examplebox}

\subsection{1.4.2 Fault Analysis}\label{fault-analysis}

Fault analysis determines the magnitude and distribution of currents
during short-circuit conditions, which is essential for sizing
protective equipment and setting relay parameters. The three types of
symmetrical component analysis --- positive, negative, and zero sequence
--- are used to analyze unbalanced faults. The four common fault types,
in order of severity, are:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Fault Type & Frequency & Severity & Analysis Method \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Single line-to-ground (SLG) & 70-80\% & Least & All three sequences \\
Line-to-line (LL) & 15-20\% & Moderate & Positive + negative \\
Double line-to-ground (DLG) & 5-10\% & High & All three sequences \\
Three-phase (3Φ) & \textless{} 5\% & Highest & Positive sequence only \\
\end{longtable}
}

The per-unit system simplifies fault calculations by normalizing all
quantities to chosen base values. In the per-unit system, the fault
current is I\textsubscript{fault} = V\textsubscript{pre-fault} /
Z\textsubscript{total}, where Z\textsubscript{total} includes the source
impedance, transformer impedance, and line impedance in the fault path.
The symmetrical fault current (AC component) determines the interrupting
rating of circuit breakers, while the asymmetrical fault current
(including DC offset) determines the momentary or close-and-latch
rating.

\begin{examplebox}

\textbf{Example 1.4.2:} A 13.8 kV distribution bus is supplied through a
transformer with Z = 8\% on a 25 MVA base. The source impedance on the
same base is 2\%. Determine (a) the three-phase fault current at the bus
in per-unit and amperes, (b) the fault MVA, and (c) the required circuit
breaker interrupting rating.

\textbf{Solution:}\\
Base current: I\textsubscript{base} = S\textsubscript{base} / (√3 ×
V\textsubscript{base}) = 25 × 10⁶ / (√3 × 13,800) = 1,046 A.

(a) Total impedance: Z\textsubscript{total} = Z\textsubscript{source} +
Z\textsubscript{transformer} = 0.02 + 0.08 = 0.10 pu.\\
I\textsubscript{fault} = V/Z = 1.0/0.10 = 10.0 pu = 10.0 × 1,046 =
\textbf{10,460 A}

(b) Fault MVA = S\textsubscript{base}/Z\textsubscript{total} = 25/0.10 =
\textbf{250 MVA}

(c) The asymmetrical fault current includes a DC offset factor.\\
For typical X/R = 15, the asymmetry factor is approximately 1.6:
I\textsubscript{asym} = 1.6 × 10,460 = 16,736 A.\\
The breaker must be rated for at least \textbf{250 MVA} interrupting
capacity and a close-and-latch rating of at least \textbf{16.7 kA}.

\end{examplebox}

\subsection{1.4.3 Protection
Coordination}\label{protection-coordination}

Protection coordination (also called selectivity) ensures that the
protective device closest to a fault operates first, while upstream
devices provide backup protection with sufficient time delay. Proper
coordination minimizes the extent of the system affected by a fault ---
only the faulted section is de-energized while the rest of the system
continues to operate. The coordination time interval (CTI) between
successive devices is typically 0.2-0.4 seconds for relay-to-relay
coordination and 0.1-0.2 seconds for fuse-to-fuse coordination.

Coordination studies plot the time-current characteristics of all
protective devices on a single log-log graph (the coordination curve)
and verify that they do not overlap. For overcurrent devices, the
upstream device must have a longer operating time than the downstream
device at all fault current levels within the coordination range.
Fuse-fuse coordination requires that the upstream fuse's minimum melting
time exceeds the downstream fuse's total clearing time by a factor of at
least 1.5. Modern coordination studies use software tools that model
relay characteristics, fuse curves, and breaker trip curves to automate
the verification process.

\begin{examplebox}

\textbf{Example 1.4.3:} Two time-overcurrent relays protect series
sections of a distribution feeder. Relay B (downstream) has TDS = 1.5
and pickup = 400 A. Relay A (upstream) must coordinate with Relay B with
a CTI of 0.3 s. Both use IEEE Moderately Inverse characteristics: t =
(0.0515 / (M\textsuperscript{0.02} − 1) + 0.114) × TDS. For a maximum
fault current of 4,000 A seen by both relays, determine the required TDS
for Relay A (pickup = 600 A).

\textbf{Solution:}\\
Relay B operating time at 4,000 A: M\textsubscript{B} = 4,000/400 =
10.\\
t\textsubscript{B} = (0.0515/(10\textsuperscript{0.02} − 1) + 0.114) ×
1.5 = (0.0515/(1.0471 − 1) + 0.114) × 1.5\\
t\textsubscript{B} = (0.0515/0.0471 + 0.114) × 1.5 = (1.093 + 0.114) ×
1.5 = \textbf{1.81 s}

Required Relay A time: t\textsubscript{A} = t\textsubscript{B} + CTI =
1.81 + 0.3 = 2.11 s.

Relay A at 4,000 A: M\textsubscript{A} = 4,000/600 = 6.667.\\
2.11 = (0.0515/(6.667\textsuperscript{0.02} − 1) + 0.114) ×
TDS\textsubscript{A}\\
6.667\textsuperscript{0.02} = e\textsuperscript{0.02 × ln(6.667)} =
e\textsuperscript{0.02 × 1.897} = e\textsuperscript{0.03794} = 1.0387.\\
2.11 = (0.0515/0.0387 + 0.114) × TDS\textsubscript{A} = (1.331 + 0.114)
× TDS\textsubscript{A} = 1.445 × TDS\textsubscript{A}.\\
TDS\textsubscript{A} = 2.11/1.445 = \textbf{1.46} (round up to TDS =
\textbf{1.5} for standard settings).

\end{examplebox}

\subsection{1.4.4 Symmetrical Components}\label{symmetrical-components}

Symmetrical components, developed by Charles Fortescue in 1918,
decompose any set of unbalanced three-phase phasors into three balanced
sets: positive sequence (V₁, normal rotation a-b-c), negative sequence
(V₂, reverse rotation a-c-b), and zero sequence (V₀, all three phasors
in phase). The transformation is {[}V₀; V₁; V₂{]} = (1/3) × {[}1, 1, 1;
1, a, a²; 1, a², a{]} × {[}V\textsubscript{a}; V\textsubscript{b};
V\textsubscript{c}{]}, where a = 1∠120° and a² = 1∠240°. Each sequence
component sees a different impedance: the positive-sequence impedance Z₁
equals the normal balanced impedance, the negative-sequence impedance Z₂
≈ Z₁ for transformers and transmission lines (but differs for rotating
machines), and the zero-sequence impedance Z₀ depends heavily on the
grounding configuration and transformer winding connections (delta
windings block zero-sequence current).

Symmetrical components simplify unbalanced fault calculations by
converting a coupled three-phase problem into three independent
single-phase sequence networks. A balanced three-phase fault involves
only the positive-sequence network. A single-line-to-ground (SLG) fault
connects all three sequence networks in series: I\textsubscript{fault} =
3V₁/(Z₁ + Z₂ + Z₀). A line-to-line fault connects the positive and
negative networks in parallel: I\textsubscript{fault} = √3 × V₁/(Z₁ +
Z₂). These formulations make it possible to analyze unbalanced
conditions using sequence impedance data from equipment nameplates and
test reports.

\begin{examplebox}

\textbf{Example 1.4.4:} A 100 MVA, 13.8 kV generator has Z₁ = j0.15 pu,
Z₂ = j0.15 pu, and Z₀ = j0.05 pu on the machine base. The generator
neutral is grounded through an impedance Z\textsubscript{g} = j0.10 pu.
The pre-fault voltage is 1.0 pu. Calculate the fault current for a
single-line-to-ground fault on phase A.

\textbf{Solution:}\\
For an SLG fault, the sequence currents are equal: I₀ = I₁ = I₂ = V₁/(Z₁
+ Z₂ + Z₀ + 3Z\textsubscript{g}).

Total impedance: Z₁ + Z₂ + Z₀ + 3Z\textsubscript{g} = j0.15 + j0.15 +
j0.05 + j0.30 = j0.65 pu.

Sequence currents: I₀ = I₁ = I₂ = 1.0/j0.65 = −j1.538 pu.

Phase A fault current: I\textsubscript{a} = I₀ + I₁ + I₂ = 3 × (−j1.538)
= −j4.615 pu.

Base current: I\textsubscript{base} = S\textsubscript{base}/(√3 ×
V\textsubscript{base}).\\
For S\textsubscript{base} = 100 MVA: I\textsubscript{base} = 100 ×
10⁶/(√3 × 13,800) = 4,184 A.

Fault current magnitude: I\textsubscript{fault} = 4.615 × 4,184 =
\textbf{19,309 A}.\\
Phases B and C carry zero current (I\textsubscript{b} =
I\textsubscript{c} = 0), confirming the single-line-to-ground fault
condition.

\end{examplebox}

\section{1.5 Power Quality}\label{power-quality}

Power quality refers to the characteristics of the voltage and current
waveforms delivered to end users and their conformance to established
standards. Poor power quality can cause equipment malfunctions,
overheating, reduced efficiency, and premature failure. The major power
quality phenomena include harmonics (waveform distortion), voltage sags
and swells (short-duration magnitude variations), transients (fast
voltage spikes), flicker (systematic voltage variations), and frequency
variations. IEEE Standard 519-2022 establishes limits for harmonic
distortion, while IEEE Standard 1159 defines and categorizes power
quality events.

\subsection{1.5.1 Harmonics}\label{harmonics}

Harmonics are sinusoidal voltages or currents at integer multiples of
the fundamental power system frequency (60 Hz in North America, 50 Hz in
most other regions). Nonlinear loads such as variable frequency drives
(VFDs), rectifiers, switching power supplies, and LED drivers draw
non-sinusoidal currents that contain harmonics. The most significant
harmonics in three-phase systems are the 5th (300 Hz), 7th (420 Hz),
11th (660 Hz), and 13th (780 Hz), because triplen harmonics (3rd, 9th,
15th) are trapped by delta transformer windings and do not propagate
into the utility system in balanced three-phase circuits.

Total Harmonic Distortion (THD) quantifies the overall distortion level:
THD = √(Σ V\textsubscript{h}²) / V₁ × 100\%, where V\textsubscript{h} is
the magnitude of the h-th harmonic and V₁ is the fundamental. IEEE 519
limits voltage THD to 5\% at the point of common coupling (PCC) for
systems below 69 kV, with no individual harmonic exceeding 3\%. Current
distortion limits depend on the ratio of short-circuit current to load
current (I\textsubscript{SC}/I\textsubscript{L}), with larger ratios
permitting higher distortion because the system is stiffer and less
affected.

\begin{examplebox}

\textbf{Example 1.5.1:} A 6-pulse VFD produces the following harmonic
current spectrum (as a percentage of fundamental): 5th = 20\%, 7th =
14\%, 11th = 9\%, 13th = 7.7\%, 17th = 5.9\%, 19th = 5.3\%. The VFD
draws 150 A fundamental on a system where I\textsubscript{SC} = 10,000
A. Determine (a) the current THD, (b) the total demand distortion (TDD),
and (c) whether the installation meets IEEE 519 limits (for
I\textsubscript{SC}/I\textsubscript{L} \textgreater{} 50, the TDD limit
is 12\%).

\textbf{Solution:}

(a) THD = √(20² + 14² + 9² + 7.7² + 5.9² + 5.3²) = √(400 + 196 + 81 +
59.3 + 34.8 + 28.1) = √799.2 = \textbf{28.3\%}

(b) TDD = THD × (I\textsubscript{fundamental} / I\textsubscript{L}).\\
For this example, I\textsubscript{L} = maximum demand load current = 150
A.\\
I\textsubscript{SC}/I\textsubscript{L} = 10,000/150 = 66.7
(\textgreater{} 50).\\
TDD = √(Σ I\textsubscript{h}² / I\textsubscript{L}²) × 100\%.\\
Since fundamental = load current here, TDD = THD = \textbf{28.3\%}

(c) IEEE 519 limit for I\textsubscript{SC}/I\textsubscript{L}
\textgreater{} 50: TDD ≤ 12\%, individual harmonics: 5th-7th ≤ 15\%,
11th-13th ≤ 7\%.\\
The 5th harmonic (20\%) exceeds the 15\% individual limit, and TDD
(28.3\%) far exceeds 12\%.\\
The VFD \textbf{does not comply} --- harmonic mitigation such as a
12-pulse drive, active filter, or passive LC filters would be required.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-1-5-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch01_harmonics_thd.png}

\caption{Figure 1.5.1: Harmonic Spectrum and THD}

\end{figure}

\subsection{1.5.2 Voltage Sags and
Swells}\label{voltage-sags-and-swells}

A voltage sag (or dip) is a temporary reduction in RMS voltage to
between 10\% and 90\% of nominal for a duration of 0.5 cycles to 1
minute. Voltage sags are the most common power quality event affecting
industrial facilities and are primarily caused by faults on adjacent
feeders, motor starting, and transformer energization. A voltage swell
is a temporary increase in RMS voltage to between 110\% and 180\% of
nominal for the same duration range, typically caused by single
line-to-ground faults (which raise the voltage on the unfaulted phases)
or load rejection events.

The CBEMA/ITIC curve (now ITI curve from the Information Technology
Industry Council) defines the voltage magnitude and duration envelope
within which electronic equipment should operate without malfunction.
Equipment is expected to ride through sags to 80\% of nominal for up to
10 seconds, to 70\% for up to 0.5 seconds, and to nearly 0\% for up to 1
cycle (about 16.7 ms at 60 Hz). Mitigation strategies include
uninterruptible power supplies (UPS), dynamic voltage restorers (DVR),
and automatic transfer switches (ATS) that transfer critical loads to an
alternate source within a few cycles.

\begin{examplebox}

\textbf{Example 1.5.2:} A 480 V bus experiences a voltage sag to 65\% of
nominal lasting 200 ms caused by a fault on an adjacent feeder. A
sensitive CNC machine requires a minimum of 80\% voltage. Determine (a)
the sag magnitude in volts, (b) whether the machine will trip, (c) the
energy a DVR must inject to maintain 100\% voltage if the load draws 100
kVA, and (d) whether the event falls within the ITIC ``prohibited'' or
``no damage'' region.

\textbf{Solution:}

(a) Sag voltage: 0.65 × 480 = \textbf{312 V} (the voltage drops from 480
V to 312 V).

(b) The machine requires ≥ 80\% (384 V). Since 312 V \textless{} 384 V,
the machine \textbf{will trip}.

(c) The DVR must supply the difference: V\textsubscript{DVR} = 480 − 312
= 168 V (35\% of nominal).\\
DVR apparent power: S\textsubscript{DVR} =
(V\textsubscript{DVR}/V\textsubscript{nominal}) × S\textsubscript{load}
= 0.35 × 100 = 35 kVA.\\
Energy: E = S\textsubscript{DVR} × t = 35 × 0.2 = \textbf{7.0 kJ}
(assuming unity power factor).

(d) On the ITIC curve, 65\% voltage for 200 ms falls \textbf{below the
lower curve} (outside the acceptable region), confirming equipment is
expected to malfunction. A UPS or DVR is needed to protect the CNC
machine.

\end{examplebox}

\subsection{1.5.3 Power Quality
Monitoring}\label{power-quality-monitoring}

Power quality monitoring uses specialized instruments to record and
analyze voltage, current, and frequency disturbances over time. A power
quality analyzer (PQA) captures RMS variations, transients, harmonics,
flicker, and power factor with time-stamping, enabling engineers to
correlate events with their causes. Monitoring locations are typically
selected at the point of common coupling (PCC) with the utility, at the
main distribution panel, and at critical or sensitive loads.

IEEE 1159.3 defines the Power Quality Data Interchange Format (PQDIF), a
standard file format for exchanging power quality data between different
instruments and analysis software. Key measurements include RMS voltage
trending (cycle-by-cycle or half-cycle), harmonic spectrum (magnitude
and phase of each harmonic up to the 50th), transient capture
(high-speed sampling at 1-10 MHz for recording fast voltage spikes), and
statistical analysis (SARFI indices that count the number of sags and
swells exceeding various thresholds over a period).

\begin{examplebox}

\textbf{Example 1.5.3:} A manufacturing plant installs a power quality
monitor at the 13.8 kV service entrance. Over a 30-day monitoring
period, the following events are recorded: 42 voltage sags (15 to
70-80\%, 20 to 80-90\%, 7 to 50-70\%), 3 voltage swells to 110-120\%,
and average voltage THD of 3.2\%. Determine (a) the SARFI-80 index (sags
below 80\%), (b) the average sag frequency per week, (c) whether the
voltage THD meets IEEE 519 limits, and (d) the expected annual cost if
each sag below 70\% causes a production disruption costing \$15,000.

\textbf{Solution:}

(a) SARFI-80 counts events where the retained voltage drops below 80\%
of nominal. The 70-80\% category (15 events) falls below the 80\%
threshold by definition, as does the 50-70\% category (7 events). The
80-90\% sags (20 events) do not qualify.\\
SARFI-80 = 15 + 7 = \textbf{22 events} over 30 days.

(b) Total sags: 42 in 30 days = 42/4.286 = \textbf{9.8 sags per week}.

(c) Voltage THD = 3.2\% \textless{} 5\% limit for systems \textless{} 69
kV: \textbf{compliant} with IEEE 519.

(d) Sags below 70\%: 7 in 30 days → annualized: 7 × (365/30) =
85.2/year.\\
Annual cost: 85.2 × \$15,000 = \textbf{\$1,278,000/year} --- easily
justifying investment in a UPS or DVR system.

\end{examplebox}

\subsection{1.5.4 Arc Flash Analysis}\label{arc-flash-analysis}

An arc flash occurs when an electric current passes through ionized air
between conductors or from a conductor to ground, creating a plasma arc
with temperatures exceeding 20,000°C. The intense thermal energy,
pressure blast, and molten metal ejection pose severe hazards to workers
performing energized electrical work. NFPA 70E requires arc flash hazard
analysis for all electrical equipment likely to be serviced while
energized, and IEEE Standard 1584-2018 provides the empirical equations
for calculating incident energy based on system parameters.

The IEEE 1584 simplified method estimates incident energy as E = 4.184 ×
C\textsubscript{f} × E\textsubscript{n} × (t/0.2) ×
(610\textsuperscript{x}/D\textsuperscript{x}), where C\textsubscript{f}
is a calculation factor (1.0 for voltages above 1 kV, 1.5 for voltages
at or below 1 kV), E\textsubscript{n} is the normalized incident energy,
t is the arc duration in seconds, D is the working distance in mm, and x
is the distance exponent. The arc duration depends primarily on the
clearing time of the upstream protective device --- reducing clearing
time is the single most effective arc flash mitigation strategy. Other
mitigation methods include zone-selective interlocking (which
accelerates upstream relay tripping), arc flash detection relays (which
sense the arc light and trip in \textless{} 5 ms), current-limiting
fuses, remote racking of breakers, and increasing the working distance.
PPE categories range from Category 1 (4 cal/cm²) through Category 4 (40
cal/cm²), with incident energies above 40 cal/cm² considered too
dangerous for energized work.

\begin{examplebox}

\textbf{Example 1.5.4:} A 480 V switchgear has a bolted fault current of
35 kA. The protective relay clears the fault in 0.25 seconds (15
cycles). The working distance is 610 mm (24 inches). Using the IEEE 1584
simplified method with E\textsubscript{n} = 3.5 J/cm² (for the given
system configuration), C\textsubscript{f} = 1.5, and distance exponent x
= 1.641, determine (a) the incident energy and (b) the required PPE
category.

\textbf{Solution:}

(a) E = 4.184 × C\textsubscript{f} × E\textsubscript{n} × (t/0.2) ×
(610\textsuperscript{x}/D\textsuperscript{x})\\
E = 4.184 × 1.5 × 3.5 × (0.25/0.2) ×
(610\textsuperscript{1.641}/610\textsuperscript{1.641})\\
E = 4.184 × 1.5 × 3.5 × 1.25 × 1.0 = \textbf{27.5 J/cm²} = \textbf{6.57
cal/cm²}

(b) PPE categories: Cat 1 ≤ 4 cal/cm², Cat 2 ≤ 8 cal/cm², Cat 3 ≤ 25
cal/cm², Cat 4 ≤ 40 cal/cm².\\
At 6.57 cal/cm², the required PPE is \textbf{Category 2} (arc-rated
clothing with minimum rating of 8 cal/cm²).\\
If the relay clearing time were reduced to 0.1 s (5 cycles) using an arc
flash relay, the incident energy would drop to 6.57 × (0.1/0.25) = 2.63
cal/cm² --- reducing the requirement to Category 1.

\end{examplebox}

\section{1.6 HVDC Transmission}\label{hvdc-transmission}

High-Voltage Direct Current (HVDC) transmission converts AC power to DC
for long-distance transmission and then converts it back to AC at the
receiving end. HVDC is preferred over AC for submarine cables (where AC
capacitive charging current limits cable lengths to approximately 50-80
km), very long overhead lines (where HVDC becomes economical above
approximately 600-800 km due to lower line losses and no reactive power
requirements), and asynchronous interconnections between power systems
operating at different frequencies or with incompatible AC
characteristics.

\subsection{1.6.1 HVDC Fundamentals}\label{hvdc-fundamentals}

An HVDC link consists of a rectifier station (converting AC to DC), a DC
transmission line or cable, and an inverter station (converting DC back
to AC). The two basic configurations are monopolar (one conductor with
ground or sea return) and bipolar (two conductors at
±V\textsubscript{dc} with a metallic or ground return, which provides
redundancy since each pole can operate independently). Typical HVDC
voltage levels range from ±250 kV to ±800 kV, with the highest voltage
systems (±1,100 kV in China) transmitting up to 12 GW over distances
exceeding 3,000 km.

The advantages of HVDC over AC for long-distance transmission include:
no reactive power flow (the DC line has no capacitance or inductance
effects at DC), lower losses (only resistive losses in two conductors
versus three for AC), no skin effect at DC (the full conductor
cross-section carries current), independent control of power flow
(magnitude and direction), and the ability to connect asynchronous
systems. The disadvantages include the high cost of converter stations
(typically \$100-200 million each), the generation of harmonics by the
converters (requiring large AC and DC filters), and the difficulty of
creating multi-terminal DC networks (tapping power off a DC line is more
complex than AC).

\begin{examplebox}

\textbf{Example 1.6.1:} A bipolar HVDC link operates at ±500 kV and
transmits 3,000 MW over a distance of 1,500 km. Each conductor has a
resistance of 0.012 Ω/km. Determine (a) the DC current per pole, (b) the
total I²R losses, (c) the loss percentage, and (d) the equivalent AC
loss for comparison (assuming 3 conductors at 500 kV AC with the same
resistance per conductor).

\textbf{Solution:}

(a) Each pole carries half the power: P\textsubscript{pole} = 3,000/2 =
1,500 MW.\\
I\textsubscript{dc} = P\textsubscript{pole} / V\textsubscript{dc} =
1,500 × 10⁶ / (500 × 10³) = \textbf{3,000 A per pole}

(b) Resistance per conductor: R = 0.012 × 1,500 = 18 Ω.\\
Losses per pole: P\textsubscript{loss} = I²R = 3,000² × 18 = 162 MW.\\
Total losses (two poles): P\textsubscript{total loss} = 2 × 162 =
\textbf{324 MW}

(c) Loss percentage: 324/3,000 × 100 = \textbf{10.8\%} (high due to the
long distance, but DC has no reactive losses)

(d) For equivalent AC at 500 kV (three-phase), line current:
I\textsubscript{AC} = 3,000 × 10⁶ / (√3 × 500 × 10³) = 3,464 A.\\
AC losses: 3 × I² × R = 3 × 3,464² × 18 = 3 × 216.0 × 10⁶ = 648 MW =
21.6\%.\\
The HVDC link losses (10.8\%) are approximately \textbf{half} the
equivalent AC losses (21.6\%), demonstrating the advantage of HVDC for
long-distance transmission.

\end{examplebox}

\subsection{1.6.2 Converter Technologies}\label{converter-technologies}

The two main converter technologies for HVDC are Line-Commutated
Converters (LCC) and Voltage Source Converters (VSC). LCC-HVDC uses
thyristor valves in a 6-pulse or 12-pulse bridge configuration, where
the thyristors are turned on by gate signals but rely on the AC system
voltage to turn off (commutate). LCC is a mature technology capable of
very high power ratings (up to 12 GW) and voltages (±1,100 kV), but it
requires a strong AC system for commutation, consumes reactive power
(approximately 50-60\% of active power), and can only control the DC
current magnitude and direction, not independently control active and
reactive power.

VSC-HVDC uses insulated-gate bipolar transistors (IGBTs) in a modular
multilevel converter (MMC) topology, where each IGBT can be turned on
and off by gate signals, providing full four-quadrant control of active
and reactive power. VSC can operate with weak AC systems or even create
an AC voltage grid (black start capability), making it ideal for
offshore wind farm connections and island power supply. VSC-HVDC ratings
have grown rapidly, with current projects reaching ±525 kV and 2,000 MW.
The MMC topology uses hundreds of submodules per arm to synthesize a
nearly perfect sinusoidal voltage, virtually eliminating the need for
harmonic filters.

\begin{examplebox}

\textbf{Example 1.6.2:} A 12-pulse LCC-HVDC rectifier station operates
at a firing angle α = 15° with a commutation overlap angle μ = 20°. The
no-load DC voltage (for a 6-pulse bridge) is V\textsubscript{d0} = 3√2 ×
V\textsubscript{LL} / π = 350 kV. Determine (a) the actual DC voltage
per 6-pulse bridge accounting for firing angle and commutation, (b) the
total DC voltage for the 12-pulse configuration, and (c) the reactive
power consumed by the converter.

\textbf{Solution:}

(a) DC voltage per bridge with firing angle and overlap:\\
V\textsubscript{d} = V\textsubscript{d0} × (cos(α) + cos(α + μ))/2 = 350
× (cos(15°) + cos(35°))/2\\
V\textsubscript{d} = 350 × (0.9659 + 0.8192)/2 = 350 × 0.8926 =
\textbf{312.4 kV per bridge}

(b) A 12-pulse configuration has two 6-pulse bridges in series:\\
V\textsubscript{dc} = 2 × 312.4 = \textbf{624.8 kV}

(c) The power factor of an LCC rectifier is approximately:\\
cos(φ) ≈ (cos(α) + cos(α + μ))/2 = 0.8926.\\
φ = cos⁻¹(0.8926) = 26.8°.\\
If P\textsubscript{dc} = 2,000 MW: Q = P × tan(φ) = 2,000 × tan(26.8°) =
2,000 × 0.505 = \textbf{1,010 MVAR}

The converter consumes over 1,000 MVAR of reactive power, which must be
supplied by capacitor banks and harmonic filters at the converter
station.

\end{examplebox}

\section{1.7 Load Flow Analysis}\label{load-flow-analysis}

Load flow (or power flow) analysis determines the steady-state operating
condition of a power system --- the voltage magnitude and angle at every
bus, and the real and reactive power flowing through every transmission
line and transformer. This is the most fundamental power system
calculation, performed routinely for system planning, operational
studies, and contingency analysis. The results identify overloaded
lines, buses with voltage violations, and the reactive power support
needed to maintain acceptable voltage profiles.

Each bus in the network is characterized by four quantities: voltage
magnitude \textbar V\textbar, voltage angle δ, real power injection P,
and reactive power injection Q. Of these four, two are specified and two
are unknowns. A slack bus (one per system) has fixed
\textbar V\textbar{} and δ (typically δ = 0° as the reference), a PV bus
(generator) has specified P and \textbar V\textbar, and a PQ bus (load)
has specified P and Q. The power balance equations at each bus are
P\textsubscript{i} =
Σ\textbar V\textsubscript{i}\textbar\textbar V\textsubscript{k}\textbar(G\textsubscript{ik}
cos(δ\textsubscript{i} − δ\textsubscript{k}) + B\textsubscript{ik}
sin(δ\textsubscript{i} − δ\textsubscript{k})) and Q\textsubscript{i} =
Σ\textbar V\textsubscript{i}\textbar\textbar V\textsubscript{k}\textbar(G\textsubscript{ik}
sin(δ\textsubscript{i} − δ\textsubscript{k}) − B\textsubscript{ik}
cos(δ\textsubscript{i} − δ\textsubscript{k})), where G\textsubscript{ik}
+ jB\textsubscript{ik} are elements of the bus admittance matrix
Y\textsubscript{bus}. These nonlinear equations are solved iteratively
using the Newton-Raphson method (quadratic convergence, typically 3--5
iterations) or the Gauss-Seidel method (simpler but slower convergence).

\begin{examplebox}

\textbf{Example 1.7:} A 2-bus system has Bus 1 (slack, V₁ = 1.0∠0° pu)
connected to Bus 2 (PQ load, P₂ = −1.0 pu, Q₂ = −0.5 pu) through a
transmission line with admittance y₁₂ = 5 − j15 pu. Using the
Gauss-Seidel method with an initial guess of V₂ = 1.0∠0° pu, perform two
iterations to find V₂.

\textbf{Solution:}\\
Y\textsubscript{bus} for a 2-bus system: Y₁₁ = Y₂₂ = y₁₂ = 5 − j15, Y₁₂
= Y₂₁ = −y₁₂ = −5 + j15.

Gauss-Seidel update: V₂\textsuperscript{(k+1)} = (1/Y₂₂) × ((P₂ −
jQ₂)/V₂\textsuperscript{(k)*} − Y₂₁V₁).

\textbf{Iteration 1} (V₂⁽⁰⁾ = 1.0∠0°):\\
(P₂ − jQ₂)/V₂⁽⁰⁾* = (−1.0 + j0.5)/1.0 = −1.0 + j0.5.\\
−Y₂₁V₁ = (5 − j15)(1.0) = 5 − j15.\\
Sum = (−1.0 + j0.5) + (5 − j15) = 4.0 − j14.5.\\
V₂⁽¹⁾ = (4.0 − j14.5)/(5 − j15) = (4.0 − j14.5)(5 + j15)/((5)² + (15)²)
= (20 + j60 − j72.5 + 217.5)/250 = (237.5 − j12.5)/250 = \textbf{0.950 −
j0.050 = 0.9513∠−3.01° pu}.

\textbf{Iteration 2} (V₂⁽¹⁾ = 0.950 − j0.050):\\
V₂⁽¹⁾* = 0.950 + j0.050.\\
(P₂ − jQ₂)/V₂⁽¹⁾* = (−1.0 + j0.5)/(0.950 + j0.050) = (−1.0 + j0.5)(0.950
− j0.050)/(0.9025 + 0.0025) = (−0.950 + j0.050 + j0.475 + 0.025)/0.9050
= (−0.925 + j0.525)/0.9050 = −1.022 + j0.580.\\
Sum = (−1.022 + j0.580) + (5 − j15) = 3.978 − j14.42.\\
V₂⁽²⁾ = (3.978 − j14.42)/(5 − j15) = (3.978 − j14.42)(5 + j15)/250 =
(19.89 + j59.67 − j72.1 + 216.3)/250 = (236.19 − j12.43)/250 =
\textbf{0.9448 − j0.0497 = 0.9461∠−3.01° pu}.

The voltage at Bus 2 converges toward approximately 0.946∠−3.0° pu,
showing a 5.4\% voltage drop due to the load.\\
Continued iterations (or Newton-Raphson) would refine this result.\\
The line power flow from Bus 1 to Bus 2 can then be calculated as S₁₂ =
V₁(V₁ − V₂)* × y₁₂*.

\end{examplebox}

\section{1.8 SCADA Systems}\label{scada-systems}

Supervisory Control and Data Acquisition (SCADA) systems provide
centralized monitoring and control of geographically distributed power
system assets --- generators, substations, transmission lines, and
distribution feeders. A SCADA system continuously collects real-time
measurements (bus voltages, line currents, power flows, breaker states,
transformer tap positions, and equipment temperatures) from Remote
Terminal Units (RTUs) and Intelligent Electronic Devices (IEDs) located
at field sites, transmits them to a central master station, and presents
them to operators through a Human-Machine Interface (HMI). Operators can
issue supervisory commands --- opening or closing circuit breakers,
adjusting transformer taps, changing generator setpoints --- that are
relayed back to field devices. Modern SCADA systems integrate with
Energy Management Systems (EMS) to perform state estimation, automatic
generation control (AGC), economic dispatch, and contingency analysis in
real time.

\subsection{1.8.1 SCADA Architecture}\label{scada-architecture}

A typical SCADA architecture consists of four layers: field
instrumentation (CTs, VTs, transducers, and sensors), RTUs or substation
automation controllers that digitize and aggregate field measurements, a
communications network linking remote sites to the control center, and
the master station with SCADA servers, databases, and HMI displays.
Communication protocols include DNP3 (Distributed Network Protocol),
widely used in North American utilities for serial and TCP/IP-based
polling of RTUs; IEC 60870-5-101/104, the international equivalent used
extensively outside North America; and IEC 61850, a substation
automation standard that uses GOOSE (Generic Object Oriented Substation
Event) messaging for high-speed peer-to-peer communication between IEDs
within a substation. The scan rate --- the interval at which the master
polls all RTUs --- is typically 2--10 seconds for SCADA systems, while
IEC 61850 GOOSE messages achieve latencies under 4 ms for
protection-critical signals. Redundancy is achieved through dual master
stations in hot-standby configuration, redundant communication paths
(fiber, microwave, cellular backup), and dual RTU processors.

\begin{examplebox}

\textbf{Example 1.8.1:} A utility SCADA system monitors 120 substations,
each with an RTU reporting 80 analog measurements (voltage, current,
power) and 60 digital status points (breaker positions, alarms). The
master station polls all RTUs using DNP3 over TCP/IP with a scan cycle
of 4 seconds. Each analog measurement requires 4 bytes and each digital
point requires 1 bit. Determine the total number of data points, the
minimum data throughput required, and the average polling rate per RTU.

\textbf{Solution:}\\
Analog points: 120 × 80 = 9,600 analog measurements\\
Digital points: 120 × 60 = 7,200 status points\\
Total data points: 9,600 + 7,200 = \textbf{16,800 points}

Data per scan cycle:\\
Analog data: 9,600 × 4 bytes = 38,400 bytes\\
Digital data: 7,200 × 1 bit = 7,200 bits = 900 bytes\\
Total payload: 38,400 + 900 = 39,300 bytes per scan\\
With DNP3 framing overhead (\textasciitilde20\%): 39,300 × 1.2 = 47,160
bytes per scan

Minimum throughput: 47,160 bytes / 4 s = 11,790 bytes/s = \textbf{94.3
kbps}\\
Average polling rate: 120 RTUs / 4 s = \textbf{30 RTUs/s} (one RTU
polled every 33.3 ms)

\end{examplebox}

\subsection{1.8.2 SCADA Cybersecurity}\label{scada-cybersecurity}

Power system SCADA networks are critical infrastructure targets, and
cybersecurity has become a fundamental design requirement. The NERC CIP
(North American Electric Reliability Corporation Critical Infrastructure
Protection) standards mandate security controls for bulk electric system
cyber assets, including electronic security perimeters (ESP), access
management, security patching, incident response, and configuration
change management. Defense-in-depth strategies include network
segmentation using firewalls and demilitarized zones (DMZ) between the
corporate IT network and the operational technology (OT) SCADA network,
encrypted communications using TLS or VPN tunnels for DNP3 Secure
Authentication, role-based access control (RBAC) for HMI operator
consoles, and intrusion detection systems (IDS) tuned to recognize
anomalous SCADA traffic patterns such as unauthorized control commands
or abnormal polling frequencies. Air-gapping --- physically isolating
the SCADA network from the internet --- was once standard practice but
is increasingly impractical as utilities adopt cloud-based analytics,
remote access for maintenance, and wide-area monitoring; instead,
managed security interfaces with strict firewall rules, application
whitelisting, and continuous monitoring have become the norm.

\begin{examplebox}

\textbf{Example 1.8.2:} A utility's SCADA cybersecurity audit reveals
that the control center firewall processes an average of 2,500
authorized DNP3 sessions per hour. The intrusion detection system (IDS)
has a false positive rate of 0.2\% and a detection rate (true positive
rate) of 98.5\% for malicious traffic. During a 24-hour monitoring
period, 12 actual intrusion attempts occur among the total traffic.
Determine the expected number of detected intrusions, missed intrusions,
and false alarms over 24 hours.

\textbf{Solution:}\\
Total authorized sessions in 24 hours: 2,500 × 24 = 60,000 sessions\\
Actual intrusion attempts: 12

Detected intrusions (true positives): 0.985 × 12 = \textbf{11.82 ≈ 12
detected}\\
Missed intrusions (false negatives): 12 − 11.82 = \textbf{0.18 ≈ 0
missed}

Legitimate sessions: 60,000 − 12 = 59,988\\
False alarms (false positives): 0.002 × 59,988 = \textbf{119.98 ≈ 120
false alarms}

Precision: 12 / (12 + 120) = 12 / 132 = \textbf{9.1\%}\\
The low precision illustrates the base-rate problem in cybersecurity:
even with a low false positive rate, the rarity of actual attacks means
most alerts are false alarms, requiring analyst triage to distinguish
real threats.

\end{examplebox}

\chapter{Chapter 2}\label{chapter-2}

\chapter{Communications Engineering}\label{communications-engineering}

Communications engineering is the branch of electrical engineering
focused on the transmission, reception, and processing of
information-bearing signals across a variety of media including wired,
wireless, and optical channels. The discipline spans analog techniques
such as amplitude and frequency modulation to modern digital methods
including sampling, quantization, error correction, and data
compression. At its core, communications engineering applies signal
processing theory to reliably move information from a source to a
destination while managing constraints such as bandwidth, noise,
interference, and power.

\section{2.1 Analog Signal Processing}\label{analog-signal-processing}

Analog signals are continuous time signals. They represent physical
quantities such as voltage, current, or pressure as smoothly varying
waveforms without discrete steps. Analog signal processing operates on
these continuous waveforms using circuits composed of resistors,
capacitors, inductors, and operational amplifiers to perform operations
such as amplification, filtering, modulation, and demodulation. Because
analog systems work directly with continuous signals, they can be
simpler to implement for certain tasks, but they are susceptible to
noise accumulation at each processing stage, which limits the distance
and fidelity of analog communication links.

\subsection{2.1.1 AM Radio}\label{am-radio}

Amplitude Modulation (AM) is one of the earliest and most fundamental
modulation techniques in communications engineering. In AM, the
amplitude of a high-frequency carrier signal is varied in proportion to
the instantaneous value of the baseband message signal, while the
carrier frequency remains constant. Mathematically, the AM signal can be
expressed as s(t) = {[}A\textsubscript{c} + m(t){]} ×
cos(2πf\textsubscript{c}t), where A\textsubscript{c} is the carrier
amplitude, m(t) is the message signal, and f\textsubscript{c} is the
carrier frequency. The modulation index m, defined as the ratio of the
peak message amplitude to the carrier amplitude, must be kept at or
below 1.0 to avoid envelope distortion and overmodulation --- when m
\textgreater{} 1, the carrier envelope crosses zero, introducing severe
distortion that a simple envelope detector cannot recover. The
modulation process is fundamentally a multiplication of the carrier by
(1 + m(t)/A\textsubscript{c}), which in the frequency domain shifts the
baseband message spectrum to be centered on the carrier frequency,
creating an upper sideband (USB) and a lower sideband (LSB) symmetric
about f\textsubscript{c}. Because both sidebands carry identical
information, the total occupied bandwidth equals twice the highest
frequency component of the message signal.

Commercial AM broadcast radio operates in the medium frequency (MF) band
from 540 kHz to 1700 kHz, with each station allocated a 10 kHz channel
bandwidth, limiting the audio baseband to 5 kHz. Demodulation can be
accomplished with a simple envelope detector consisting of a diode and
an RC low-pass filter, which is one reason AM radio receivers were
historically inexpensive and widely accessible --- the crystal radio,
requiring no external power source, is the simplest possible AM
receiver. However, standard AM (also called Double Sideband Full
Carrier, DSB-FC) is not power-efficient because a significant portion of
the transmitted power resides in the carrier, which carries no
information; at 100\% modulation, only one-third of the total power is
in the sidebands. Double Sideband Suppressed Carrier (DSB-SC) eliminates
the carrier entirely, putting all transmitted power into the
information-bearing sidebands, but requires coherent (synchronous)
demodulation with a locally generated carrier reference. Single Sideband
(SSB) goes further by transmitting only one sideband, halving the
bandwidth and further improving power efficiency --- SSB is the standard
for HF (shortwave) radio, amateur radio, and military communications
where spectrum and power are at a premium. Despite its inefficiency,
conventional DSB-FC AM remains in active use for commercial broadcast
(AM radio), aviation voice communications (where the simple envelope
detector ensures reliability), and as a building block for understanding
more advanced modulation schemes.

\begin{examplebox}

\textbf{Example 2.1.1:} An AM broadcast transmitter has a carrier power
of 50 kW and is modulated by a single-tone audio signal with a
modulation index of m = 0.75. Determine (a) the total transmitted power,
(b) the power in each sideband, and (c) the efficiency (percentage of
total power carrying information).

\textbf{Solution:}

(a) Total transmitted power for a single-tone AM signal:\\
P\textsubscript{total} = P\textsubscript{c} × (1 + m²/2) = 50 × (1 +
0.75²/2) = 50 × (1 + 0.2813) = 50 × 1.2813 = \textbf{64.06 kW}

(b) Power in both sidebands combined: P\textsubscript{sb} =
P\textsubscript{c} × m²/2 = 50 × 0.5625/2 = 50 × 0.2813 = 14.06 kW\\
Power in each sideband: P\textsubscript{each} = 14.06 / 2 = \textbf{7.03
kW}

(c) Efficiency (only sideband power carries information):\\
η = P\textsubscript{sb} / P\textsubscript{total} = 14.06 / 64.06 =
0.2195 = \textbf{21.95\%}

This demonstrates why standard AM is inefficient: at m = 0.75, nearly
78\% of the transmitted power is in the carrier, which carries no
information.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-2-1-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch02_am_modulation.png}

\caption{Figure 2.1.1: AM Modulation Waveform and Spectrum}

\end{figure}

\subsection{2.1.2 FM Radio}\label{fm-radio}

Frequency Modulation (FM) encodes information by varying the
instantaneous frequency of a carrier signal in proportion to the message
signal, while keeping the amplitude constant. The FM signal is expressed
as s(t) = A\textsubscript{c} × cos(2πf\textsubscript{c}t +
2πk\textsubscript{f} ∫m(τ)dτ), where k\textsubscript{f} is the frequency
sensitivity in Hz/V and m(t) is the message signal. The maximum
frequency deviation Δf = k\textsubscript{f} × max\textbar m(t)\textbar{}
determines how far the instantaneous frequency swings from the carrier.
The modulation index β = Δf / f\textsubscript{m}, where
f\textsubscript{m} is the highest message frequency, governs the
spectral characteristics of the FM signal.

Carson's rule approximates the bandwidth of an FM signal as B ≈ 2(Δf +
f\textsubscript{m}) = 2f\textsubscript{m}(β + 1). Commercial FM
broadcast radio operates in the VHF band from 88 to 108 MHz with a
maximum frequency deviation of ±75 kHz and audio bandwidth of 15 kHz,
giving β = 5 and a Carson bandwidth of approximately 180 kHz --- each
station is allocated a 200 kHz channel. FM provides superior noise
performance compared to AM because amplitude variations caused by noise
can be removed by a limiter before demodulation. The improvement is
quantified by the FM noise advantage: for wideband FM with β
\textgreater\textgreater{} 1, the output SNR exceeds the input
carrier-to-noise ratio by a factor of 3β²(β + 1), which is the basis for
trading bandwidth for noise performance. Pre-emphasis and de-emphasis
filters further improve high-frequency SNR by boosting high frequencies
before transmission and attenuating them at the receiver.

\begin{examplebox}

\textbf{Example 2.1.2:} An FM broadcast station transmits with a maximum
frequency deviation of Δf = 75 kHz and audio bandwidth of
f\textsubscript{m} = 15 kHz. Determine (a) the modulation index, (b) the
Carson's rule bandwidth, (c) the number of significant sidebands from
the Bessel function table (for β = 5, there are 8 significant sideband
pairs), and (d) the exact bandwidth based on significant sidebands.

\textbf{Solution:}

(a) Modulation index: β = Δf / f\textsubscript{m} = 75,000 / 15,000 =
\textbf{5}

(b) Carson's rule bandwidth: B = 2(Δf + f\textsubscript{m}) = 2(75,000 +
15,000) = \textbf{180 kHz}

(c) For β = 5, the Bessel function table shows 8 significant sideband
pairs (J₀ through J₈ have magnitudes \textgreater{} 0.01).

(d) Exact bandwidth from significant sidebands: B\textsubscript{exact} =
2 × 8 × f\textsubscript{m} = 2 × 8 × 15 = \textbf{240 kHz}

Carson's rule underestimates the bandwidth (180 kHz vs.~240 kHz) but
captures approximately 98\% of the signal power, which is why FM
broadcast channels are spaced at 200 kHz --- a practical compromise
between Carson's rule and the exact sideband extent.

\end{examplebox}

\section{2.2 Digital Signal Processing}\label{digital-signal-processing}

A digital signal is created by sampling a continuous signal and
representing the samples as discrete values which can be used
computationally. The process involves two key steps: sampling, which
converts the continuous-time signal into a discrete-time sequence, and
quantization, which maps each sample to a finite set of discrete
amplitude levels. Digital signal processing (DSP) then manipulates these
discrete numerical sequences using algorithms implemented in software or
dedicated hardware such as DSP microprocessors and FPGAs. The primary
advantages of digital processing over analog include repeatable
precision, immunity to noise accumulation during processing stages, the
ability to implement adaptive and non-linear algorithms, and
straightforward storage and retrieval of signal data.

\subsection{2.2.1 Fourier Analysis}\label{fourier-analysis}

The Fourier series coefficients represent the frequencies present in a
signal. Any periodic signal can be decomposed into a sum of sinusoidal
components at harmonically related frequencies using the Fourier series,
where each coefficient specifies the amplitude and phase of the
corresponding harmonic. For aperiodic signals, the Fourier Transform
extends this concept by representing the signal as a continuous spectrum
of frequencies rather than discrete harmonics. In the digital domain,
the Discrete Fourier Transform (DFT) operates on finite-length sampled
sequences, and the Fast Fourier Transform (FFT) algorithm computes the
DFT efficiently in O(N log N) operations rather than the O(N²) required
by direct computation. Fourier analysis is foundational in
communications engineering for tasks such as spectral analysis, filter
design, modulation and demodulation, and characterizing the frequency
response of channels and systems.

\begin{examplebox}

\textbf{Example 2.2.1:} A periodic square wave signal has a fundamental
frequency of 1 kHz, amplitude of 5 V (peak-to-peak), and 50\% duty
cycle. Determine the Fourier series coefficients for the first three
non-zero harmonic components, and calculate the RMS voltage of the
signal truncated to these three harmonics.

\textbf{Solution:}\\
A square wave with amplitude A (±A/2) and 50\% duty cycle has the
Fourier series:\\
x(t) = (2A/π) × {[}sin(2πf₁t) + (1/3)sin(2π·3f₁t) + (1/5)sin(2π·5f₁t) +
\ldots{]}

With peak-to-peak = 5 V, the amplitude A/2 = 2.5 V, so A = 5 V, and 2A/π
= 10/π = 3.183 V.

First three non-zero harmonics (only odd harmonics are present):\\
1st harmonic (1 kHz): a₁ = 2A/π = 10/π = \textbf{3.183 V peak}\\
3rd harmonic (3 kHz): a₃ = 2A/(3π) = 10/(3π) = \textbf{1.061 V peak}\\
5th harmonic (5 kHz): a₅ = 2A/(5π) = 10/(5π) = \textbf{0.637 V peak}

RMS voltage of the truncated signal (sum of sinusoidal RMS values):\\
V\textsubscript{rms} = √(a₁²/2 + a₃²/2 + a₅²/2) = √(3.183²/2 + 1.061²/2
+ 0.637²/2)\\
V\textsubscript{rms} = √(5.066 + 0.563 + 0.203) = √5.832 = \textbf{2.415
V}

For comparison, the true RMS of the square wave is 2.5 V, so the
three-harmonic approximation captures (2.415/2.5)² = 93.3\% of the total
power.

\end{examplebox}

\subsection{2.2.2 Nyquist Sampling}\label{nyquist-sampling}

The Nyquist sampling rate is greater than 2 times the maximum signal
frequency. More precisely, the Nyquist-Shannon sampling theorem states
that a band-limited continuous signal with no frequency content above
f\textsubscript{max} can be perfectly reconstructed from its samples if
the sampling rate f\textsubscript{s} is greater than 2 ×
f\textsubscript{max}. This minimum rate of 2 × f\textsubscript{max} is
called the Nyquist rate. If the signal is sampled below this rate,
aliasing occurs, where higher-frequency components are misrepresented as
lower frequencies in the sampled data, causing irreversible distortion.
In practice, anti-aliasing low-pass filters are applied before the
analog-to-digital converter to attenuate frequency components above
f\textsubscript{s}/2, and systems typically sample at rates somewhat
above the Nyquist rate to provide a guard band that relaxes the filter
design requirements.

\begin{examplebox}

\textbf{Example 2.2.2:} An audio signal contains frequency components
from 20 Hz to 18 kHz. It is to be digitized with a sampling rate of 44.1
kHz (CD-quality audio). Determine (a) the Nyquist rate, (b) whether
aliasing will occur, and (c) the frequency at which a 20 kHz component
would appear in the sampled data.

\textbf{Solution:}

(a) Nyquist rate: f\textsubscript{Nyquist} = 2 × f\textsubscript{max} =
2 × 18,000 = \textbf{36 kHz}

(b) The sampling rate of 44.1 kHz exceeds the Nyquist rate of 36 kHz, so
\textbf{no aliasing will occur} for the 18 kHz signal content. The guard
band is 44,100/2 − 18,000 = 4,050 Hz.

(c) If an out-of-band component at 20 kHz is present (not filtered by
the anti-aliasing filter):\\
Check against the Nyquist limit: 20,000 Hz \textless{}
f\textsubscript{s}/2 = 22,050 Hz, so the 20 kHz component is
\textbf{below the Nyquist frequency and does not alias} --- it appears
at 20 kHz in the sampled spectrum. However, if a 25 kHz component were
present:\\
f\textsubscript{alias} = f\textsubscript{s} − 25,000 = 44,100 − 25,000 =
\textbf{19,100 Hz} --- this would alias and corrupt the audio band,
which is why anti-aliasing filters are essential.

\end{examplebox}

\subsection{2.2.3 Quantization and
Encoding}\label{quantization-and-encoding}

Quantization is the process of mapping continuous-amplitude samples to a
finite set of discrete levels. After sampling converts a continuous-time
signal to a discrete-time sequence, quantization assigns each sample to
the nearest available level from a set of 2\textsuperscript{N} levels,
where N is the number of bits per sample. The spacing between adjacent
levels is the step size Δ = (V\textsubscript{max} −
V\textsubscript{min}) / 2\textsuperscript{N} for uniform quantization,
and the resulting quantization error for each sample is bounded by ±Δ/2.
This error behaves as additive white noise with a
signal-to-quantization-noise ratio (SQNR) of approximately 6.02N + 1.76
dB for a full-scale sinusoidal input, meaning each additional bit
improves the SQNR by about 6 dB.

Non-uniform quantization allocates finer step sizes to small signal
amplitudes and coarser steps to large amplitudes, improving the
effective dynamic range for signals like speech that spend most of their
time at low levels. The two standard companding laws are μ-law (used in
North America and Japan, with μ = 255) and A-law (used in Europe, with A
= 87.6), both of which are implemented in PCM telephone systems using
8-bit samples at 8 kHz for a bit rate of 64 kbps per voice channel.
After quantization, each sample is encoded into a binary codeword for
transmission or storage, a process called pulse code modulation (PCM).

\begin{examplebox}

\textbf{Example 2.2.3:} A 16-bit audio ADC has an input range of ±1 V (2
V full-scale). Determine (a) the quantization step size, (b) the maximum
quantization error, (c) the SQNR for a full-scale sinusoidal input, and
(d) the dynamic range in dB.

\textbf{Solution:}

(a) Step size: Δ = 2 V / 2¹⁶ = 2 / 65,536 = \textbf{30.52 μV}

(b) Maximum quantization error: ±Δ/2 = ±15.26 μV = \textbf{±15.26 μV}

(c) SQNR = 6.02N + 1.76 = 6.02(16) + 1.76 = 96.32 + 1.76 = \textbf{98.08
dB}

(d) Dynamic range = 20 log₁₀(2\textsuperscript{N}) = 20 log₁₀(65,536) =
20 × 4.816 = \textbf{96.33 dB}

The 98 dB SQNR explains why 16-bit audio (CD quality) provides excellent
fidelity --- the quantization noise floor is nearly 100 dB below a
full-scale signal.

\end{examplebox}

\section{2.3 Digital Modulation}\label{digital-modulation}

Digital modulation maps discrete data (bits or symbols) onto analog
carrier waveforms for transmission over bandpass channels. Unlike analog
modulation where the message is a continuous waveform, digital
modulation transmits information as a sequence of symbols, each
representing one or more bits. The key performance metrics for digital
modulation schemes are bandwidth efficiency (bits/s/Hz), power
efficiency (the E\textsubscript{b}/N₀ required to achieve a target bit
error rate), and implementation complexity. The choice of modulation
scheme involves a trade-off between these factors, with higher-order
schemes achieving greater bandwidth efficiency at the cost of increased
power requirements and sensitivity to noise.

\begin{figure}[H]

\hypertarget{fig-2-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch02_constellation.png}

\caption{Figure 2.3: Digital Modulation Constellation Diagrams}

\end{figure}

\subsection{2.3.1 Amplitude Shift Keying
(ASK)}\label{amplitude-shift-keying-ask}

Amplitude Shift Keying (ASK) varies the amplitude of a carrier to
represent digital data. In binary ASK (also called on-off keying, OOK),
a binary 1 is transmitted as the carrier at full amplitude and a binary
0 as zero amplitude (or a reduced amplitude). The transmitted signal is
s(t) = A\textsubscript{k} × cos(2πf\textsubscript{c}t) during the k-th
symbol interval, where A\textsubscript{k} takes on one of M discrete
amplitude levels for M-ASK. Binary ASK has a bandwidth efficiency of 1
bit/s/Hz and requires the simplest transmitter and receiver, but it is
the least power-efficient of the basic digital modulation schemes
because the amplitude variations make it highly susceptible to noise and
fading. ASK finds application in low-cost, low-data-rate systems such as
RFID tags and infrared remote controls.

\begin{examplebox}

\textbf{Example 2.3.1:} A binary ASK system transmits at 9,600 bps using
a carrier at 100 kHz with raised-cosine pulse shaping having a roll-off
factor of α = 0.35. Determine (a) the required bandwidth, (b) the
bandwidth efficiency, and (c) the minimum E\textsubscript{b}/N₀ for a
BER of 10⁻⁵ using coherent detection.

\textbf{Solution:}

(a) Bandwidth with raised-cosine shaping: B = R\textsubscript{b}(1 + α)
= 9,600 × (1 + 0.35) = 9,600 × 1.35 = \textbf{12,960 Hz}

(b) Bandwidth efficiency: η = R\textsubscript{b} / B = 9,600 / 12,960 =
\textbf{0.74 bits/s/Hz}

(c) For coherent binary ASK, BER = Q(√(E\textsubscript{b}/N₀)).\\
For BER = 10⁻⁵, the Q-function argument is 4.265, so
E\textsubscript{b}/N₀ = 4.265² = 18.19 = \textbf{12.60 dB}.\\
Binary ASK requires about 3 dB more E\textsubscript{b}/N₀ than BPSK for
the same BER.

\end{examplebox}

\subsection{2.3.2 Frequency Shift Keying
(FSK)}\label{frequency-shift-keying-fsk}

Frequency Shift Keying (FSK) encodes digital data by switching the
carrier frequency between two or more discrete values. In binary FSK
(BFSK), a binary 1 is transmitted at frequency f₁ and a binary 0 at
frequency f₂, with the tone spacing Δf = \textbar f₁ − f₂\textbar{}
determining the modulation characteristics. When Δf =
R\textsubscript{b}/2 (where R\textsubscript{b} is the bit rate), the two
tones are orthogonal over each bit period, yielding minimum shift keying
(MSK), which achieves the minimum bandwidth for orthogonal FSK. The
constant-envelope property of FSK makes it robust against nonlinear
amplifier distortion and amplitude fading, which is why it is widely
used in wireless and industrial applications.

Gaussian MSK (GMSK) passes the data through a Gaussian low-pass filter
before frequency modulation, producing smoother phase transitions and
significantly reduced spectral sidelobes compared to standard MSK. GMSK
with a bandwidth-time product BT = 0.3 is used in the GSM cellular
standard, achieving 99\% power containment within a bandwidth of
approximately 0.57 × R\textsubscript{b}. Non-coherent detection of FSK
is straightforward using envelope detectors or discriminators, making
FSK receivers simpler than PSK receivers at the cost of a 1-3 dB power
penalty.

\begin{examplebox}

\textbf{Example 2.3.2:} A binary FSK system uses frequencies f₁ = 1,200
Hz (mark) and f₂ = 2,200 Hz (space) at a data rate of 300 bps (similar
to the Bell 103 modem). Determine (a) the frequency deviation, (b) the
modulation index h = Δf / R\textsubscript{b}, (c) the Carson's rule
bandwidth, and (d) whether the tones are orthogonal.

\textbf{Solution:}

(a) Frequency deviation: Δf = \textbar f₁ − f₂\textbar{} = \textbar1,200
− 2,200\textbar{} = \textbf{1,000 Hz}

(b) Modulation index: h = Δf / R\textsubscript{b} = 1,000 / 300 =
\textbf{3.33}

(c) Carson's rule bandwidth: B = 2(Δf + R\textsubscript{b}) = 2(1,000 +
300) = \textbf{2,600 Hz}

(d) For orthogonal FSK, the minimum tone spacing is R\textsubscript{b}/2
= 150 Hz for coherent detection or R\textsubscript{b} = 300 Hz for
non-coherent detection.\\
Since Δf = 1,000 Hz exceeds both thresholds, the tones are
\textbf{orthogonal} for both coherent and non-coherent detection.\\
The wide spacing (h = 3.33) is spectrally inefficient but provides
robust performance at low SNR.

\end{examplebox}

\subsection{2.3.3 Phase Shift Keying
(PSK)}\label{phase-shift-keying-psk}

Phase Shift Keying (PSK) maps digital data to discrete phase values of
the carrier signal. In Binary PSK (BPSK), the carrier phase is 0° for a
binary 1 and 180° for a binary 0, providing a phase separation of 180°
between the two symbols. BPSK achieves the best power efficiency among
binary modulation schemes, requiring an E\textsubscript{b}/N₀ of only
9.6 dB for a BER of 10⁻⁵ with coherent detection. Quadrature PSK (QPSK)
doubles the bandwidth efficiency to 2 bits/s/Hz by using four phase
states (0°, 90°, 180°, 270°), where each symbol carries 2 bits.
Remarkably, QPSK achieves the same BER performance as BPSK per bit
because the 3 dB increase in symbol energy exactly compensates for the
reduced phase spacing.

Higher-order PSK (8-PSK, 16-PSK) further increases bandwidth efficiency
but with diminishing returns and rapidly increasing power requirements.
As the number of phase states M increases, the angular spacing between
adjacent symbols shrinks to 2π/M, making the constellation increasingly
sensitive to phase noise and requiring higher SNR to maintain the same
BER. For M ≥ 8, hybrid amplitude-phase constellations (QAM) become more
power-efficient than pure PSK. Differential PSK (DPSK) encodes data in
the phase change between successive symbols rather than absolute phase,
simplifying demodulation by eliminating the need for a coherent carrier
reference at a cost of approximately 1-2 dB in power efficiency.

\begin{examplebox}

\textbf{Example 2.3.3:} A QPSK satellite link transmits at a symbol rate
of 10 Msymbols/s with raised-cosine pulse shaping (α = 0.25). Determine
(a) the bit rate, (b) the occupied bandwidth, (c) the bandwidth
efficiency, and (d) the required E\textsubscript{b}/N₀ for BER = 10⁻⁶.

\textbf{Solution:}

(a) QPSK carries 2 bits/symbol: R\textsubscript{b} = 2 ×
R\textsubscript{s} = 2 × 10 × 10⁶ = \textbf{20 Mbps}

(b) Occupied bandwidth: B = R\textsubscript{s}(1 + α) = 10 × 10⁶ × (1 +
0.25) = \textbf{12.5 MHz}

(c) Bandwidth efficiency: η = R\textsubscript{b} / B = 20 / 12.5 =
\textbf{1.6 bits/s/Hz}

(d) For QPSK, BER = Q(√(2E\textsubscript{b}/N₀)).\\
For BER = 10⁻⁶, Q⁻¹(10⁻⁶) = 4.753, so 2E\textsubscript{b}/N₀ = 4.753² =
22.59, giving E\textsubscript{b}/N₀ = 11.30 = \textbf{10.53 dB}.\\
This is the same E\textsubscript{b}/N₀ required by BPSK, confirming that
QPSK doubles the data rate without a power penalty.

\end{examplebox}

\subsection{2.3.4 Quadrature Amplitude Modulation
(QAM)}\label{quadrature-amplitude-modulation-qam}

Quadrature Amplitude Modulation (QAM) combines amplitude and phase
modulation by independently modulating two orthogonal carriers (in-phase
I and quadrature Q) to create a two-dimensional signal constellation.
Each symbol in an M-QAM constellation carries log₂(M) bits by occupying
a unique point in the I-Q plane. Common orders include 16-QAM (4
bits/symbol), 64-QAM (6 bits/symbol), 256-QAM (8 bits/symbol), and
1024-QAM (10 bits/symbol). For square QAM constellations (M = 4, 16, 64,
256, \ldots), the constellation points form a regular grid, and the
minimum Euclidean distance between adjacent symbols determines the error
rate performance.

QAM achieves higher bandwidth efficiency than PSK for the same number of
constellation points because the rectangular grid arrangement provides
better minimum distance between symbols than equally-spaced phase-only
constellations. The approximate BER for square M-QAM with Gray coding is
BER ≈ (4/log₂(M)) × (1 − 1/√M) × Q(√(3 log₂(M) ×
E\textsubscript{b}/(N₀(M−1)))). QAM is the dominant modulation scheme in
modern broadband communications: cable modems (DOCSIS) use up to
4096-QAM, Wi-Fi 6 (802.11ax) uses up to 1024-QAM, and 5G NR uses up to
256-QAM. The trade-off is that higher-order QAM requires significantly
better SNR --- moving from 64-QAM to 256-QAM gains 33\% more bits per
symbol but requires approximately 5 dB more E\textsubscript{b}/N₀.

\begin{examplebox}

\textbf{Example 2.3.4:} A 64-QAM digital cable TV channel has a symbol
rate of 5.057 Msymbols/s (the DOCSIS standard 6 MHz channel). Determine
(a) the number of bits per symbol, (b) the raw bit rate, (c) the
bandwidth efficiency, and (d) the minimum E\textsubscript{b}/N₀ for a
BER of 10⁻⁶.

\textbf{Solution:}

(a) Bits per symbol: log₂(64) = \textbf{6 bits/symbol}

(b) Raw bit rate: R\textsubscript{b} = 6 × 5.057 × 10⁶ = \textbf{30.34
Mbps}

(c) Bandwidth efficiency: η = R\textsubscript{b} / B = 30.34 / 6 =
\textbf{5.06 bits/s/Hz}

(d) For 64-QAM, the required E\textsubscript{b}/N₀ for BER = 10⁻⁶:\\
Using the approximation: BER ≈ (4/6)(1 − 1/8) ×
Q(√(3×6×E\textsubscript{b}/(N₀×63)))\\
Setting BER = 10⁻⁶: Q(√(18E\textsubscript{b}/(63N₀))) ≈ 10⁻⁶ / 0.583 =
1.71 × 10⁻⁶\\
Q⁻¹(1.71 × 10⁻⁶) ≈ 4.64, so 18E\textsubscript{b}/(63N₀) = 21.53, giving
E\textsubscript{b}/N₀ = 75.35 = \textbf{18.77 dB}

\end{examplebox}

\subsection{2.3.5 Constellation Diagrams and BER
Performance}\label{constellation-diagrams-and-ber-performance}

A constellation diagram is a graphical representation of a digital
modulation scheme in the in-phase (I) and quadrature (Q) signal space,
where each point represents a unique symbol. Decision regions divide the
I-Q plane into zones --- the receiver maps each received signal point to
the nearest constellation point, and errors occur when noise displaces a
point across a decision boundary. Gray coding assigns bit patterns to
adjacent constellation points so that they differ by only one bit,
ensuring that the most likely symbol errors (to nearest neighbors) cause
only a single bit error rather than multiple bit errors.

The bit error rate performance of different modulation schemes reflects
the fundamental trade-off between bandwidth efficiency and power
efficiency. BPSK and QPSK achieve the same BER per bit (BER =
Q(√(2E\textsubscript{b}/N₀))), requiring E\textsubscript{b}/N₀ ≈ 9.6 dB
for BER = 10⁻⁵, but QPSK carries twice the data rate in the same
bandwidth. Higher-order schemes require progressively more power: 16-QAM
needs approximately 13.4 dB, 64-QAM needs approximately 17.8 dB, and
256-QAM needs approximately 22.5 dB for the same BER = 10⁻⁵. This means
each step up in constellation size gains spectral efficiency at the cost
of requiring a cleaner channel with higher SNR.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4250}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Modulation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Bits/Symbol
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Bandwidth Efficiency
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
E\textsubscript{b}/N₀ for BER = 10⁻⁵
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
BPSK & 1 & 1 bit/s/Hz & 9.6 dB \\
QPSK & 2 & 2 bits/s/Hz & 9.6 dB \\
16-QAM & 4 & 4 bits/s/Hz & 13.4 dB \\
64-QAM & 6 & 6 bits/s/Hz & 17.8 dB \\
256-QAM & 8 & 8 bits/s/Hz & 22.5 dB \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 2.3.5:} A wireless communication system operates with
E\textsubscript{b}/N₀ = 12 dB and requires a BER no worse than 10⁻⁵.
Determine (a) the BER achieved by BPSK, (b) the BER achieved by QPSK,
(c) the BER achieved by 16-QAM, and (d) the recommended modulation
scheme.

\textbf{Solution:}\\
E\textsubscript{b}/N₀ = 12 dB = 10\textsuperscript{12/10} = 15.85
(linear).

(a) BPSK: BER = Q(√(2 × 15.85)) = Q(5.63) = \textbf{9.0 × 10⁻⁹} --- well
below the 10⁻⁵ requirement.

(b) QPSK: Same BER as BPSK per bit: BER = Q(√(2 × 15.85)) = \textbf{9.0
× 10⁻⁹} --- also meets the requirement with double the data rate.

(c) 16-QAM: BER ≈ (3/4) × Q(√(4/5 × 15.85)) = (3/4) × Q(√(12.68)) =
(3/4) × Q(3.56) = 0.75 × 1.85 × 10⁻⁴ = \textbf{1.39 × 10⁻⁴} --- exceeds
the 10⁻⁵ requirement.

(d) \textbf{QPSK is recommended.}\\
It provides 2 bits/s/Hz bandwidth efficiency while meeting the BER
target with 2.4 dB of margin.\\
BPSK also meets the target but wastes half the available spectral
efficiency.\\
16-QAM fails the BER requirement by nearly an order of magnitude at this
E\textsubscript{b}/N₀.

\end{examplebox}

\subsection{2.3.6 MIMO and Spatial
Multiplexing}\label{mimo-and-spatial-multiplexing}

Multiple-Input Multiple-Output (MIMO) systems use multiple antennas at
both the transmitter and receiver to exploit the spatial dimension of
the wireless channel, dramatically increasing capacity without
additional bandwidth or power. The fundamental insight is that in a rich
scattering environment (typical of indoor and urban settings), different
transmit-receive antenna pairs experience statistically independent
fading paths, creating parallel spatial channels through which
independent data streams can be simultaneously transmitted. The
theoretical capacity of an N\textsubscript{t} × N\textsubscript{r} MIMO
system in a rich scattering environment is C = Σ log₂(1 +
SNR\textsubscript{i}/N\textsubscript{t}) over min(N\textsubscript{t},
N\textsubscript{r}) spatial channels, scaling approximately linearly
with min(N\textsubscript{t}, N\textsubscript{r}) --- a revolutionary
result compared to the logarithmic scaling of SISO (single antenna)
systems.

MIMO operates in three primary modes. \textbf{Spatial multiplexing}
transmits independent data streams on each antenna, maximizing
throughput --- this is the mode used in Wi-Fi 802.11n (up to 4 streams),
802.11ac/ax (up to 8 streams), and LTE (up to 8 layers).
\textbf{Transmit diversity} sends the same data from multiple antennas
with different space-time coding (e.g., Alamouti code for 2 antennas),
improving reliability without increasing data rate --- used in cell-edge
scenarios and safety-critical links. \textbf{Beamforming} uses channel
state information (CSI) to coherently combine signals at the receiver,
increasing the effective SNR by the array gain factor --- used in 5G NR
with massive MIMO arrays (§16.5.2). The number of independent spatial
streams is limited by the rank of the channel matrix H (an
N\textsubscript{r} × N\textsubscript{t} matrix), which depends on the
scattering environment: line-of-sight channels have rank 1 (no
multiplexing gain), while rich multipath environments approach full
rank. Singular value decomposition (SVD) of H reveals the available
parallel channels and their quality.

\begin{examplebox}

\textbf{Example 2.3.6:} A 4×4 MIMO Wi-Fi system (802.11ac) operates at 5
GHz with 80 MHz bandwidth and 256-QAM modulation (8 bits/symbol) with
5/6 coding rate. The channel supports 4 independent spatial streams.
Determine (a) the data rate per spatial stream, (b) the total aggregate
data rate, (c) the capacity gain compared to a SISO (1×1) system, and
(d) the minimum required SNR per stream for BER = 10⁻⁵ with 256-QAM.

\textbf{Solution:}

(a) For 802.11ac with 80 MHz: 234 data subcarriers, OFDM symbol duration
= 3.6 μs (3.2 μs useful + 0.4 μs GI).\\
Rate per stream = 234 × 8 × (5/6) / 3.6 × 10⁻⁶ = 1,560 / 3.6 × 10⁻⁶ =
433.3 × 10⁶ = \textbf{433.3 Mbps} per stream (the standard specifies
433.3 Mbps for MCS 9, short GI).

(b) Total data rate = 4 × 433.3 = \textbf{1,733 Mbps} (1.73 Gbps).\\
This matches the 802.11ac Wave 2 maximum for 80 MHz, 4 spatial streams.

(c) A SISO system with the same bandwidth and modulation achieves 433.3
Mbps.\\
The MIMO gain is \textbf{4×} --- a linear scaling with the number of
spatial streams, consistent with the theoretical prediction for
full-rank channels.

(d) For 256-QAM at BER = 10⁻⁵, the required E\textsubscript{b}/N₀ ≈ 22.5
dB.\\
Per-stream SNR = E\textsubscript{b}/N₀ + 10 log₁₀(bits/symbol) − 10
log₁₀(coding gain) ≈ 22.5 + 9.0 − 0.8 = \textbf{30.7 dB}.\\
This high SNR requirement limits 256-QAM operation to short-range,
high-SNR scenarios --- at greater distances, the system adaptively falls
back to lower-order modulation (64-QAM, 16-QAM).

\end{examplebox}

\section{2.4 Channel Coding and Error
Correction}\label{channel-coding-and-error-correction}

Channel coding adds structured redundancy to transmitted data so that
the receiver can detect and correct errors introduced by noise,
interference, and fading in the communication channel. Shannon's channel
coding theorem proves that error-free communication is theoretically
possible at any rate below the channel capacity, provided sufficiently
long and sophisticated codes are used. In practice, channel codes are
classified into block codes (which process data in fixed-length blocks)
and convolutional codes (which process data as a continuous stream). The
key metric for any code is its coding gain --- the reduction in required
E\textsubscript{b}/N₀ to achieve a given BER compared to uncoded
transmission.

\subsection{2.4.1 Error Detection}\label{error-detection}

Error detection codes add check bits that allow the receiver to
determine whether errors have occurred during transmission, without
necessarily correcting them. The simplest scheme is single parity, where
one bit is appended to each data word such that the total number of 1s
is even (even parity) or odd (odd parity). Single parity detects all odd
numbers of bit errors but misses even numbers of errors, giving an
undetected error probability that drops rapidly as the number of errors
increases for random error channels.

The Cyclic Redundancy Check (CRC) is a far more powerful error detection
code based on polynomial division in GF(2). The transmitter divides the
data polynomial by a generator polynomial and appends the remainder as
the CRC check value. Standard CRC polynomials include CRC-8 (8-bit),
CRC-16 (16-bit), and CRC-32 (32-bit, used in Ethernet and ZIP). A CRC of
degree r detects all burst errors of length ≤ r, all odd numbers of
errors (if the generator has an even number of terms), and all
double-bit errors (if the generator is a primitive polynomial). The
CRC-32 used in Ethernet provides a Hamming distance of 4 for frames up
to 12,144 bits, guaranteeing detection of all 1, 2, and 3-bit errors
within a frame.

\begin{examplebox}

\textbf{Example 2.4.1:} An Ethernet frame carries 1,500 bytes of payload
data protected by a CRC-32 checksum. If the raw bit error rate of the
channel is 10⁻⁸, determine (a) the probability that a frame contains at
least one bit error, (b) the probability of an undetected error
(assuming the CRC-32 misses errors with probability 2⁻³²), and (c) the
expected time between undetected errors at 1 Gbps.

\textbf{Solution:}

(a) Total bits per frame (including headers): approximately 1,538 bytes
× 8 = 12,304 bits.\\
P(one or more errors) = 1 − (1 − 10⁻⁸)¹²'³⁰⁴ ≈ 12,304 × 10⁻⁸ =
\textbf{1.23 × 10⁻⁴} (about 1 in 8,127 frames)

(b) The CRC-32 fails to detect an error pattern with probability
approximately 2⁻³² = 2.33 × 10⁻¹⁰.\\
P(undetected error per frame) = P(error) × P(CRC miss) = 1.23 × 10⁻⁴ ×
2.33 × 10⁻¹⁰ = \textbf{2.87 × 10⁻¹⁴}

(c) At 1 Gbps with 12,304-bit frames: frame rate = 10⁹/12,304 ≈ 81,274
frames/s.\\
Mean time between undetected errors = 1 / (81,274 × 2.87 × 10⁻¹⁴) = 4.29
× 10⁸ s ≈ \textbf{13.6 years}

\end{examplebox}

\subsection{2.4.2 Forward Error Correction
(FEC)}\label{forward-error-correction-fec}

Forward Error Correction (FEC) codes enable the receiver to both detect
and correct errors without requesting retransmission, which is essential
for one-way links (broadcast, deep space) and delay-sensitive
applications. A block code (n, k) encodes k data bits into an n-bit
codeword by adding n − k parity bits, with code rate R\textsubscript{c}
= k/n.~The error-correcting capability depends on the minimum Hamming
distance d\textsubscript{min} of the code: it can correct up to t =
⌊(d\textsubscript{min} − 1)/2⌋ errors. Hamming codes are the simplest
FEC with d\textsubscript{min} = 3 and t = 1; the (7,4) Hamming code
encodes 4 data bits into 7 bits with a code rate of 0.571.

Reed-Solomon (RS) codes operate on multi-bit symbols rather than
individual bits, making them especially effective against burst errors.
An RS(n, k) code over GF(2\textsuperscript{m}) uses m-bit symbols and
can correct up to t = (n − k)/2 symbol errors regardless of how many
bits within each symbol are corrupted. RS(255, 223) with 8-bit symbols
is widely used in deep-space communications (CCSDS/NASA standard),
satellite data links, and some optical storage systems. (CDs use CIRC
with RS(32,28)/RS(28,24) inner/outer codes; DVDs use RS-PC with
different parameters.) Convolutional codes process data as a continuous
stream through a shift register of constraint length K, producing output
bits based on the current input and K − 1 previous inputs. Turbo codes
(parallel concatenated convolutional codes) and Low-Density Parity-Check
(LDPC) codes approach within fractions of a dB of the Shannon limit and
are used in 4G/5G cellular, DVB-S2 satellite TV, and Wi-Fi 6.

\begin{examplebox}

\textbf{Example 2.4.2:} A deep-space communication link uses a rate-1/2
convolutional code with constraint length K = 7 (the NASA standard)
concatenated with an RS(255, 223) outer code. For a channel BER of 10⁻²,
determine (a) the inner code BER after Viterbi decoding (approximately
10⁻⁴ at this input BER), (b) the symbol error rate into the RS decoder,
(c) the number of correctable symbol errors per RS block, and (d) the
overall output BER.

\textbf{Solution:}

(a) The rate-1/2, K=7 convolutional code with Viterbi decoding achieves
approximately BER\textsubscript{inner} ≈ \textbf{10⁻⁴} at an input BER
of 10⁻² (a coding gain of about 5.5 dB).

(b) RS(255, 223) uses 8-bit symbols. The probability of a symbol error
given a bit error rate of 10⁻⁴:\\
P\textsubscript{symbol error} = 1 − (1 − 10⁻⁴)⁸ ≈ 8 × 10⁻⁴ = \textbf{8 ×
10⁻⁴}

(c) RS(255, 223) has t = (255 − 223)/2 = \textbf{16 correctable symbol
errors} per 255-symbol block.

(d) The probability of block failure (more than 16 errors in 255
symbols) is negligibly small at a symbol error rate of 8 × 10⁻⁴.\\
Using the binomial distribution, the expected number of symbol errors
per block is 255 × 8 × 10⁻⁴ = 0.204, far below the correction capacity
of 16.\\
The output BER is effectively \textbf{\textless{} 10⁻¹²}, demonstrating
the power of concatenated coding.

\end{examplebox}

\subsection{2.4.3 Interleaving and Burst Error
Protection}\label{interleaving-and-burst-error-protection}

Interleaving is a technique that rearranges the order of transmitted
symbols so that burst errors (which corrupt consecutive bits) are spread
across multiple codewords after de-interleaving at the receiver. Most
FEC codes are designed to correct random errors, but real channels often
produce bursty errors due to fading, impulse noise, or scratches on
optical discs. A block interleaver writes data into a matrix row-by-row
and reads it out column-by-column, so that a burst error affecting L
consecutive bits is distributed across L different codewords, with at
most one error per codeword if the interleaving depth D ≥ L.

Convolutional interleavers are more memory-efficient than block
interleavers and introduce less latency, making them preferred in
streaming applications. The combination of interleaving with FEC is
fundamental to virtually every modern digital communication system. For
example, the CD audio system uses Cross-Interleaved Reed-Solomon Coding
(CIRC), which combines two levels of RS coding with convolutional
interleaving to correct burst errors up to 4,000 consecutive bits
(approximately 2.5 mm of track) and conceal bursts up to 13,300 bits.

\begin{examplebox}

\textbf{Example 2.4.3:} A communication system uses a (15, 11) Hamming
code that can correct single-bit errors per codeword. The channel
produces burst errors of length up to 5 bits. Design a block interleaver
to protect against these bursts and determine (a) the interleaving
depth, (b) the interleaver matrix dimensions, and (c) the total latency
in bits.

\textbf{Solution:}

(a) To spread a burst of L = 5 bits across separate codewords, the
interleaving depth must be D ≥ L = \textbf{5 rows}.

(b) The interleaver matrix has D rows × n columns, where n = 15
(codeword length): \textbf{5 × 15 matrix} (75 bits total).

(c) The interleaver must fill the entire matrix before reading it out,
so the latency = D × n = 5 × 15 = \textbf{75 bits}.\\
At both transmitter and receiver, the total end-to-end interleaving
latency is 2 × 75 = 150 bits.\\
A burst of 5 consecutive bits in the interleaved stream maps to 5
separate codewords after de-interleaving, placing at most 1 error per
codeword --- within the correction capability of the Hamming code.

\end{examplebox}

\section{2.5 Multiplexing}\label{multiplexing}

Multiplexing combines multiple independent signals or data streams onto
a single shared transmission medium, allowing efficient use of expensive
infrastructure such as fiber optic cables, radio spectrum, and satellite
transponders. The fundamental resource being shared differs by
technique: frequency, time, or code. Each multiplexing method is
characterized by how it partitions the available channel capacity among
users and how it handles contention and interference between users
sharing the medium.

\subsection{2.5.1 Frequency Division Multiplexing
(FDM)}\label{frequency-division-multiplexing-fdm}

Frequency Division Multiplexing (FDM) assigns each signal a unique
frequency band within the total available bandwidth, with guard bands
between adjacent channels to prevent spectral overlap. Each user
transmits continuously within its allocated band, and the receiver uses
bandpass filters to separate the individual channels. Traditional analog
FDM was the backbone of the telephone network, where 12 voice channels
(each 4 kHz wide with 300 Hz guard bands) were combined into a 48 kHz
group, 5 groups into a supergroup (240 kHz), and so on up to master
groups carrying 3,600 channels.

Orthogonal Frequency Division Multiplexing (OFDM) is a modern digital
variant that uses closely-spaced orthogonal subcarriers, eliminating the
need for guard bands between channels. In OFDM, data is distributed
across N narrowband subcarriers using the Inverse FFT, and the symbol
duration is N times longer than the subcarrier spacing, which provides
inherent robustness against multipath fading. OFDM is used in Wi-Fi
(802.11a/g/n/ac/ax), 4G LTE, 5G NR, DVB-T digital television, and DOCSIS
3.1 cable systems.

\begin{examplebox}

\textbf{Example 2.5.1:} An OFDM system (similar to 802.11a Wi-Fi) uses a
20 MHz channel bandwidth with 64 subcarriers, of which 48 carry data, 4
are pilot tones, and 12 are null (guard and DC). The subcarrier spacing
is 312.5 kHz and the guard interval (cyclic prefix) is 0.8 μs. Determine
(a) the useful symbol duration, (b) the total symbol duration, (c) the
raw data rate using 64-QAM (6 bits/subcarrier), and (d) the spectral
efficiency.

\textbf{Solution:}

(a) Useful symbol duration: T\textsubscript{symbol} = 1 / Δf = 1 /
312,500 = \textbf{3.2 μs}

(b) Total symbol duration: T\textsubscript{total} =
T\textsubscript{symbol} + T\textsubscript{guard} = 3.2 + 0.8 =
\textbf{4.0 μs}

(c) Raw data rate: R\textsubscript{b} = (48 data subcarriers × 6
bits/subcarrier) / 4.0 μs = 288 / 4.0 × 10⁻⁶ = \textbf{72 Mbps}

(d) Spectral efficiency: η = R\textsubscript{b} / B = 72 / 20 =
\textbf{3.6 bits/s/Hz}

\end{examplebox}

\subsection{2.5.2 Time Division Multiplexing
(TDM)}\label{time-division-multiplexing-tdm}

Time Division Multiplexing (TDM) assigns each signal a recurring time
slot within a repeating frame, so that multiple users take turns
transmitting in rapid succession over a single shared channel. Unlike
FDM, where each user occupies a narrow frequency band continuously, TDM
gives each user the full channel bandwidth but only for a brief,
periodically recurring interval --- the switching between time slots
happens so rapidly that each channel appears to have a continuous,
dedicated connection. Synchronous TDM assigns fixed time slots to each
channel in every frame regardless of whether that channel has data to
send, which simplifies framing and synchronization but wastes capacity
when channels are idle. Statistical TDM (also called asynchronous TDM or
statistical multiplexing) addresses this inefficiency by dynamically
allocating time slots only to channels that have data ready, requiring
address headers on each slot to identify the source but achieving
significantly higher utilization --- typically 2 to 4 times the
throughput of synchronous TDM for bursty traffic such as data
networking. Frame synchronization is critical in synchronous TDM: the
receiver must identify the start of each frame to correctly demultiplex
the interleaved channels, which is accomplished through dedicated
framing bits or synchronization patterns embedded in the frame
structure.

The T-carrier hierarchy, developed by Bell Labs in the 1960s, is the
foundational TDM system in North American telecommunications. A DS-0
channel carries one digitized voice call at 64 kbps (8-bit samples at 8
kHz). A DS-1 (T1) frame multiplexes 24 DS-0 channels plus one framing
bit into 193 bits per frame, transmitted at 8,000 frames/s for a line
rate of 1.544 Mbps. Higher levels aggregate T1s: DS-2 combines 4 DS-1s
(6.312 Mbps), and DS-3 (T3) combines 28 DS-1s for 44.736 Mbps --- the
standard rate for interconnecting telephone switches and early internet
backbone links. The European E-carrier hierarchy uses a similar
structure but with 32 time slots per frame (30 voice channels plus
signaling and synchronization), giving the E1 a rate of 2.048 Mbps. The
SONET (Synchronous Optical Network) and SDH (Synchronous Digital
Hierarchy) standards extended TDM into the optical domain with
synchronous framing, built-in overhead for operations and management,
and standardized rates from OC-1/STM-0 (51.84 Mbps) through OC-3 (155.52
Mbps), OC-48 (2.488 Gbps), OC-192 (9.953 Gbps), and OC-768 (39.813
Gbps). While Ethernet and IP-based packet switching have largely
replaced TDM for data transport, TDM principles persist in cellular
systems (GSM uses TDM within each FDMA channel), passive optical
networks (GPON uses upstream TDM), and synchronization-critical
applications.

\begin{examplebox}

\textbf{Example 2.5.2:} A SONET OC-48 link carries 48 STS-1 signals.
Each STS-1 frame is 810 bytes (90 columns × 9 rows) transmitted at 8,000
frames/s. Determine (a) the STS-1 line rate, (b) the OC-48 line rate,
(c) the payload capacity of one STS-1 (overhead is 27 bytes per frame),
and (d) the maximum number of DS-1 signals that one OC-48 can carry.

\textbf{Solution:}

(a) STS-1 line rate: 810 bytes × 8 bits × 8,000 frames/s = \textbf{51.84
Mbps}

(b) OC-48 line rate: 48 × 51.84 = \textbf{2,488.32 Mbps} (approximately
2.5 Gbps)

(c) STS-1 payload: (810 − 27) bytes × 8 bits × 8,000 = 783 × 8 × 8,000 =
\textbf{50.112 Mbps}

(d) Each DS-1 occupies one VT1.5 (1.728 Mbps container capacity,
carrying a 1.544 Mbps DS-1 signal).\\
An STS-1 SPE carries 28 VT1.5s.\\
An OC-48 carries 48 STS-1s: 48 × 28 = \textbf{1,344 DS-1 signals}.

\end{examplebox}

\subsection{2.5.3 Code Division Multiple Access
(CDMA)}\label{code-division-multiple-access-cdma}

Code Division Multiple Access (CDMA) allows multiple users to share the
same frequency band and time slots simultaneously by assigning each user
a unique pseudo-random spreading code. Each user's data is multiplied by
its assigned code (a wideband pseudo-noise sequence), spreading the
narrowband data signal across a much wider bandwidth. At the receiver,
correlation with the same code despreads the desired signal while all
other users' signals (spread with different codes) remain wideband and
appear as noise. The processing gain G\textsubscript{p} = W/R, where W
is the spread bandwidth and R is the data rate, quantifies the
interference rejection capability of the system.

The two main types of spreading codes are Walsh codes (perfectly
orthogonal, used for downlink synchronous channels) and PN sequences
(pseudo-orthogonal, used for uplink asynchronous channels). CDMA offers
soft capacity limits, graceful degradation under overload, inherent
frequency diversity, and resistance to narrowband interference ---
making it the basis for IS-95 and CDMA2000 (2G/3G cellular) and the
underlying access method for GPS satellite navigation. The near-far
problem, where a strong nearby transmitter overwhelms a weak distant
one, requires precise power control (typically 800 adjustments per
second in IS-95) to ensure all users arrive at the base station at
approximately equal power levels.

\begin{examplebox}

\textbf{Example 2.5.3:} A CDMA2000 system operates in a 1.25 MHz band
with a data rate of 9.6 kbps per voice user. Determine (a) the
processing gain, (b) the processing gain in dB, (c) the maximum number
of users per sector if the required E\textsubscript{b}/N₀ is 7 dB and
voice activity factor is 0.4, and (d) the total sector capacity if
3-sector cells are used.

\textbf{Solution:}

(a) Processing gain: G\textsubscript{p} = W / R = 1,250,000 / 9,600 =
\textbf{130.2}

(b) Processing gain in dB: 10 log₁₀(130.2) = \textbf{21.15 dB}

(c) For a single cell/sector, the approximate capacity is:\\
N ≈ 1 + (G\textsubscript{p} / (E\textsubscript{b}/N₀)) × (1/v), where v
= voice activity factor = 0.4.\\
E\textsubscript{b}/N₀ = 10\textsuperscript{7/10} = 5.01.\\
N ≈ 1 + (130.2 / 5.01) × (1/0.4) = 1 + 26.0 × 2.5 = 1 + 65.0 =
\textbf{66 users per sector}

(d) With 3 sectors per cell and a 3-sector reuse factor of about 2.55×
(due to directional antennas): Total ≈ 66 × 2.55 ≈ \textbf{168 users per
cell}.

\end{examplebox}

\subsection{2.5.4 OFDMA and SC-FDMA}\label{ofdma-and-sc-fdma}

Orthogonal Frequency Division Multiple Access (OFDMA) extends OFDM from
a single-user modulation technique to a multi-user access scheme by
dynamically allocating subsets of subcarriers to different users based
on their channel conditions and traffic demands. In each OFDM symbol
interval, the base station assigns groups of contiguous or distributed
subcarriers (called resource blocks in LTE or resource units in Wi-Fi 6)
to individual users, enabling simultaneous transmission to multiple
users within a single OFDM symbol. This fine-grained frequency-domain
scheduling exploits frequency-selective fading: by assigning each user
the subcarriers where their channel is strongest, OFDMA achieves
multi-user diversity gain and significantly higher aggregate throughput
than systems that allocate the entire bandwidth to one user at a time.

LTE downlink uses OFDMA with 15 kHz subcarrier spacing and resource
blocks of 12 subcarriers × 7 OFDM symbols (0.5 ms slot). A 20 MHz LTE
channel has 100 resource blocks (1,200 subcarriers), dynamically
distributed among users each millisecond. 5G NR extends this with
flexible numerology: subcarrier spacings of 15, 30, 60, 120, or 240 kHz
scale the OFDM parameters for different frequency bands and latency
requirements. Wi-Fi 6 (802.11ax) introduced OFDMA to Wi-Fi for the first
time, using resource units as small as 26 subcarriers (2 MHz) in a 20
MHz channel, enabling simultaneous uplink and downlink transmissions to
up to 9 users per 20 MHz channel.

Single Carrier Frequency Division Multiple Access (SC-FDMA) --- used for
the LTE uplink --- applies a DFT precoding stage before the OFDM
modulation, effectively converting the multicarrier OFDM signal into a
single-carrier waveform in the frequency domain. The key advantage is a
lower peak-to-average power ratio (PAPR) compared to OFDMA --- typically
2--4 dB lower --- which allows the mobile device's power amplifier to
operate more efficiently, extending battery life and reducing heat. The
trade-off is reduced scheduling flexibility (each user must occupy
contiguous subcarriers) and slightly more complex equalization at the
receiver.

\begin{examplebox}

\textbf{Example 2.5.4:} An LTE base station has a 10 MHz downlink
channel using OFDMA with 15 kHz subcarrier spacing. The usable bandwidth
contains 600 subcarriers grouped into 50 resource blocks (RBs) of 12
subcarriers each. Three users are scheduled: User A (high-throughput,
good channel) gets 30 RBs with 64-QAM, 3/4 coding; User B (moderate)
gets 15 RBs with 16-QAM, 1/2 coding; User C (cell-edge) gets 5 RBs with
QPSK, 1/3 coding. Determine (a) the subcarrier count per user, (b) the
data rate per user (14 OFDM symbols per 1 ms subframe, using 11 for
data), and (c) the total cell throughput.

\textbf{Solution:}

(a) User A: 30 × 12 = 360 subcarriers.\\
User B: 15 × 12 = 180 subcarriers.\\
User C: 5 × 12 = 60 subcarriers.\\
Total: 600 subcarriers (all allocated).

(b) Bits per subcarrier per OFDM symbol:\\
User A = 6 × 3/4 = 4.5 bits; User B = 4 × 1/2 = 2.0 bits; User C = 2 ×
1/3 = 0.667 bits.\\
Data rate = subcarriers × bits × data symbols / subframe time:\\
User A: 360 × 4.5 × 11 / 1 × 10⁻³ = 17,820 / 10⁻³ = \textbf{17.82
Mbps}\\
User B: 180 × 2.0 × 11 / 10⁻³ = 3,960 / 10⁻³ = \textbf{3.96 Mbps}\\
User C: 60 × 0.667 × 11 / 10⁻³ = 440 / 10⁻³ = \textbf{0.44 Mbps}

(c) Total cell throughput: 17.82 + 3.96 + 0.44 = \textbf{22.22 Mbps}.\\
This illustrates how OFDMA flexibly partitions resources: User A with a
strong channel gets high-order modulation and most resources, while the
cell-edge User C receives robust low-rate service using a small
allocation, all sharing the same 10 MHz channel simultaneously.

\end{examplebox}

\section{2.6 Information Theory}\label{information-theory}

Information theory, founded by Claude Shannon in 1948, establishes the
fundamental limits on reliable communication and data compression. It
provides the theoretical framework for understanding how much data can
be transmitted through a noisy channel and how efficiently a source can
be represented. Information theory underpins the design of every modern
communication system by establishing bounds that real codes and systems
approach but can never exceed.

\subsection{2.6.1 Shannon's Channel
Capacity}\label{shannons-channel-capacity}

Shannon's channel capacity theorem states that every communication
channel has a maximum rate C (in bits per second) at which information
can be transmitted with arbitrarily low error probability. For an
additive white Gaussian noise (AWGN) channel with bandwidth B and
signal-to-noise ratio SNR, the capacity is C = B × log₂(1 + SNR). This
deceptively simple formula reveals the fundamental trade-off: capacity
increases linearly with bandwidth but only logarithmically with power
(SNR). Doubling the bandwidth approximately doubles the capacity, while
doubling the transmit power provides only about 1 bit/s/Hz improvement.

The channel capacity represents an existence theorem --- it proves that
codes exist that can achieve rates up to C with vanishingly small error
rates, but it does not prescribe how to construct them. For decades,
practical codes operated 3-10 dB from the Shannon limit. Modern turbo
codes (1993) and LDPC codes approach within 0.1 dB of the Shannon limit,
nearly closing the gap between theory and practice. The spectral
efficiency limit C/B = log₂(1 + SNR) establishes an upper bound on
bandwidth efficiency for any modulation and coding scheme.

\begin{examplebox}

\textbf{Example 2.6.1:} A communication channel has a bandwidth of 4 kHz
(standard telephone line) and an SNR of 30 dB. Determine (a) the Shannon
capacity, (b) the maximum spectral efficiency, (c) the number of
signaling levels needed per symbol to approach capacity (assuming
Nyquist signaling at 2B symbols/s), and (d) compare to the actual V.34
modem rate of 33.6 kbps.

\textbf{Solution:}

(a) SNR in linear: 10\textsuperscript{30/10} = 1,000.\\
Capacity: C = 4,000 × log₂(1 + 1,000) = 4,000 × log₂(1,001) = 4,000 ×
9.968 = \textbf{39.87 kbps}

(b) Maximum spectral efficiency: C/B = log₂(1,001) = \textbf{9.97
bits/s/Hz}

(c) At Nyquist symbol rate of 2B = 8,000 symbols/s: bits per symbol
needed = 39,870 / 8,000 = 4.98, requiring M = 2⁵ = 32 total
constellation points, equivalent to roughly \textbf{32-QAM} (between
16-QAM and 64-QAM).

(d) The V.34 modem achieves 33.6 kbps, which is 33.6/39.87 =
\textbf{84.3\%} of the Shannon limit --- a testament to the
sophisticated trellis-coded modulation used in V.34.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-2-6-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch02_shannon_capacity.png}

\caption{Figure 2.6.1: Shannon Channel Capacity vs SNR}

\end{figure}

\subsection{2.6.2 Entropy and Source
Coding}\label{entropy-and-source-coding}

Entropy H(X) measures the average information content (in bits) per
symbol emitted by a discrete source. For a source with M symbols having
probabilities p₁, p₂, \ldots, p\textsubscript{M}, the entropy is H(X) =
−Σ p\textsubscript{i} × log₂(p\textsubscript{i}). Entropy is maximized
at log₂(M) bits/symbol when all symbols are equally likely, and it
decreases as the source becomes more predictable (some symbols more
probable than others). Shannon's source coding theorem establishes that
the entropy H(X) is the minimum average number of bits needed to
represent each source symbol without loss --- no lossless compression
scheme can achieve an average code length below H(X).

Huffman coding constructs an optimal prefix-free code by assigning
shorter codewords to more frequent symbols. It achieves an average code
length within 1 bit of the entropy. Arithmetic coding can approach the
entropy even more closely by encoding entire sequences rather than
individual symbols. In practice, modern lossless compression algorithms
(LZ77/LZ78, DEFLATE used in ZIP/gzip) exploit both statistical
redundancy and structural patterns, routinely compressing English text
to about 1-2 bits per character compared to the 8 bits of ASCII. Lossy
source coding (e.g., JPEG, MP3, AAC) permits controlled distortion to
achieve much higher compression ratios, governed by rate-distortion
theory.

\begin{examplebox}

\textbf{Example 2.6.2:} A binary source emits 0s and 1s with
probabilities P(0) = 0.9 and P(1) = 0.1. Determine (a) the entropy of
the source, (b) the maximum lossless compression ratio compared to
fixed-length coding, (c) the average Huffman code length (using the
trivial assignment: 0→``0'', 1→``1''), and (d) the compression
achievable by run-length encoding with an average run of 10 zeros
between each 1.

\textbf{Solution:}

(a) Entropy: H(X) = −0.9 × log₂(0.9) − 0.1 × log₂(0.1)\\
H(X) = −0.9 × (−0.152) − 0.1 × (−3.322) = 0.137 + 0.332 = \textbf{0.469
bits/symbol}

(b) Fixed-length coding uses 1 bit/symbol. Compression ratio: 1 / 0.469
= \textbf{2.13:1} (maximum theoretical)

(c) For a binary source with unequal probabilities, the trivial Huffman
code assigns 1 bit to each symbol, so the average length = 1 bit/symbol
--- no compression.\\
To exploit the redundancy, we need to code blocks of symbols: for blocks
of n = 4, there are 16 possible 4-bit blocks with varying probabilities,
and Huffman coding of these blocks achieves closer to H(X) = 0.469
bits/source-symbol.

(d) With an average run length of 10 zeros between 1s, we can encode
each run using ⌈log₂(max run)⌉ bits. For runs averaging 10 symbols, we
encode approximately 11 source symbols (10 zeros + one 1) using about 4
bits (for the run length), giving \textbf{0.36 bits/symbol} ---
approaching the entropy limit.

\end{examplebox}

\section{2.7 Noise in Communication
Systems}\label{noise-in-communication-systems}

Noise is the fundamental limiting factor in all communication systems,
establishing a floor below which signals cannot be reliably detected.
Understanding noise sources and their propagation through receiver
chains is essential for designing systems that achieve the required
signal quality. The two key concepts are noise power (how much noise a
component or channel introduces) and noise figure (how much a device
degrades the signal-to-noise ratio).

\subsection{2.7.1 Thermal Noise and Noise
Power}\label{thermal-noise-and-noise-power}

Thermal noise (Johnson-Nyquist noise) is generated by the random motion
of charge carriers in any resistive component at a temperature above
absolute zero. The available noise power from a resistor at temperature
T over a bandwidth B is N = kTB, where k = 1.381 × 10⁻²³ J/K is
Boltzmann's constant. At the standard reference temperature T₀ = 290 K
(approximately 17°C), the noise power spectral density is N₀ = kT₀ =
4.00 × 10⁻²¹ W/Hz = −174 dBm/Hz. This value is a fundamental constant of
communications engineering --- every receiver operating at room
temperature faces at least −174 dBm/Hz of thermal noise.

The open-circuit RMS noise voltage across a resistor R is
V\textsubscript{n} = √(4kTRB), which shows that noise voltage increases
with both resistance and bandwidth. When this resistor drives a matched
load (maximum power transfer), the delivered noise power is kTB
regardless of the resistance value --- a remarkable result that means
thermal noise power depends only on temperature and bandwidth. In
practice, the total noise in a receiver includes contributions from
antenna noise (sky temperature), component thermal noise, and active
device noise, all of which are combined using equivalent noise
temperature concepts.

\begin{examplebox}

\textbf{Example 2.7.1:} A 50 Ω receiver front-end has a bandwidth of 10
MHz and operates at T = 290 K. Determine (a) the thermal noise power in
watts and dBm, (b) the RMS noise voltage across the 50 Ω input, and (c)
the minimum detectable signal if the receiver requires SNR = 10 dB.

\textbf{Solution:}

(a) Noise power: N = kTB = 1.381 × 10⁻²³ × 290 × 10 × 10⁶ = \textbf{4.00
× 10⁻¹⁴ W}\\
In dBm: N = 10 log₁₀(4.00 × 10⁻¹⁴ / 10⁻³) = 10 log₁₀(4.00 × 10⁻¹¹) = 10
× (−10.40) = \textbf{−104.0 dBm}\\
This matches the quick calculation: −174 dBm/Hz + 10 log₁₀(10⁷) = −174 +
70 = −104 dBm.

(b) RMS noise voltage: V\textsubscript{n} = √(4kTRB) = √(4 × 1.381 ×
10⁻²³ × 290 × 50 × 10⁷) = √(8.01 × 10⁻¹²) = \textbf{2.83 μV}

(c) Minimum detectable signal = N + SNR\textsubscript{required} = −104.0
+ 10 = \textbf{−94.0 dBm} (or 0.40 pW).\\
Any signal weaker than this will not achieve the required 10 dB SNR.

\end{examplebox}

\subsection{2.7.2 Noise Figure and Cascaded
Systems}\label{noise-figure-and-cascaded-systems}

The noise figure (NF) of a device quantifies how much it degrades the
signal-to-noise ratio, defined as F = SNR\textsubscript{in} /
SNR\textsubscript{out} (linear ratio) or NF = 10 log₁₀(F) in dB. An
ideal noiseless device has F = 1 (NF = 0 dB), while real amplifiers
typically have NF between 0.5 dB (cryogenic LNAs) and 10 dB (mixers).
The noise figure can also be expressed through the equivalent noise
temperature: T\textsubscript{e} = T₀(F − 1), which represents the
temperature of a matched resistor at the input that would produce the
same amount of added noise as the device itself.

For a cascade of stages, the Friis formula gives the overall noise
figure: F\textsubscript{total} = F₁ + (F₂ − 1)/G₁ + (F₃ − 1)/(G₁G₂) +
\ldots, where F\textsubscript{n} and G\textsubscript{n} are the noise
figure and available gain of the n-th stage. This formula reveals a
critical design principle: the first stage dominates the system noise
performance because subsequent stages' noise contributions are divided
by the cumulative gain of all preceding stages. This is why a low-noise
amplifier (LNA) with high gain is placed at the very front of a receiver
chain --- its noise figure becomes essentially the system noise figure,
and its gain suppresses the noise contributions of the noisier stages
that follow.

\begin{examplebox}

\textbf{Example 2.7.2:} A satellite receiver front-end consists of an
LNA (NF = 1.5 dB, gain = 20 dB) followed by a cable (loss = 3 dB) and a
mixer (NF = 8 dB). Determine (a) the linear noise figures and gains, (b)
the overall system noise figure, (c) the system noise temperature, and
(d) the system noise figure if the cable and LNA are swapped (cable
first).

\textbf{Solution:}

(a) Converting from dB to linear:\\
LNA: F₁ = 10\textsuperscript{1.5/10} = 1.413, G₁ =
10\textsuperscript{20/10} = 100\\
Cable: F₂ = 10\textsuperscript{3/10} = 2.0, G₂ =
10\textsuperscript{−3/10} = 0.5 (a 3 dB loss has NF = 3 dB and gain = −3
dB)\\
Mixer: F₃ = 10\textsuperscript{8/10} = 6.31

(b) Friis formula: F\textsubscript{total} = 1.413 + (2.0 − 1)/100 +
(6.31 − 1)/(100 × 0.5)\\
F\textsubscript{total} = 1.413 + 0.010 + 0.106 = 1.529\\
NF\textsubscript{total} = 10 log₁₀(1.529) = \textbf{1.84 dB}

(c) System noise temperature: T\textsubscript{e} = 290 × (1.529 − 1) =
290 × 0.529 = \textbf{153.4 K}

(d) If the cable is placed before the LNA: F\textsubscript{total} = 2.0
+ (1.413 − 1)/0.5 + (6.31 − 1)/(0.5 × 100) = 2.0 + 0.826 + 0.106 =
2.932, giving NF = 10 log₁₀(2.932) = \textbf{4.67 dB}.\\
Moving the lossy cable ahead of the LNA nearly triples the system noise
figure (1.84 → 4.67 dB), demonstrating why the LNA must be the first
element in the chain.

\end{examplebox}

\subsection{2.7.3 Satellite Link Budget and
G/T}\label{satellite-link-budget-and-gt}

Satellite communication links require specialized link budget analysis
because of the extreme path distances (36,000 km for geostationary
orbit), limited satellite power, and the need to share transponder
capacity among many users. The satellite link has two segments: the
uplink (earth station to satellite) and the downlink (satellite to earth
station), each with its own power budget, path loss, and noise
characteristics. The key figure of merit for a satellite receive system
is the G/T ratio --- the receive antenna gain divided by the system
noise temperature, expressed in dB/K --- which quantifies the receiver's
sensitivity independent of bandwidth.

The carrier-to-noise ratio for a satellite link is: C/N = EIRP + G/T −
L\textsubscript{path} − k − 10 log₁₀(B), where EIRP is the effective
isotropic radiated power of the transmitter (dBW), G/T is the receiver
figure of merit (dB/K), L\textsubscript{path} is the free-space path
loss (dB), k = −228.6 dBW/(K·Hz) is Boltzmann's constant, and B is the
noise bandwidth (Hz). For a complete link through a bent-pipe
transponder (which amplifies and retransmits without demodulation), the
overall C/N is: 1/(C/N)\textsubscript{total} = 1/(C/N)\textsubscript{up}
+ 1/(C/N)\textsubscript{down} + 1/(C/N)\textsubscript{intermod}. Rain
attenuation is a critical factor at Ku-band and Ka-band, with typical
rain margins of 3--6 dB at Ku-band and 6--12 dB at Ka-band for
99.5--99.9\% link availability. The link availability target determines
the rain attenuation statistics used, derived from ITU-R rain zone data
for the earth station location.

\begin{examplebox}

\textbf{Example 2.7.3:} A Ku-band satellite TV downlink operates at 12.5
GHz from a geostationary satellite at 36,000 km range. The satellite
transponder has EIRP = 52 dBW. The home receiver uses a 60 cm offset
dish with 65\% aperture efficiency and a system noise temperature of 150
K (including LNB noise). Determine (a) the receive antenna gain, (b) the
G/T of the receiver, (c) the free-space path loss, (d) the C/N for a 27
MHz transponder bandwidth, and (e) the rain margin available if the
minimum C/N for DVB-S2 QPSK 3/4 is 5.5 dB.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 12.5 × 10⁹ = 0.024 m.\\
G\textsubscript{rx} = η(πD/λ)² = 0.65 × (π × 0.6/0.024)² = 0.65 ×
(78.54)² = 0.65 × 6,168 = 4,009\\
G\textsubscript{rx}(dBi) = 10 log₁₀(4,009) = \textbf{36.0 dBi}

(b) G/T = G\textsubscript{rx} − 10 log₁₀(T\textsubscript{sys}) = 36.0 −
10 log₁₀(150) = 36.0 − 21.8 = \textbf{14.2 dB/K}

(c) FSPL = 20 log₁₀(4πd/λ) = 20 log₁₀(4π × 3.6 × 10⁷/0.024) = 20
log₁₀(1.885 × 10¹⁰) = 20 × 10.275 = \textbf{205.5 dB}

(d) C/N = EIRP + G/T − FSPL − k − 10 log₁₀(B)\\
C/N = 52 + 14.2 − 205.5 − (−228.6) − 10 log₁₀(27 × 10⁶)\\
C/N = 52 + 14.2 − 205.5 + 228.6 − 74.3 = \textbf{15.0 dB}

(e) Rain margin = C/N − C/N\textsubscript{required} = 15.0 − 5.5 =
\textbf{9.5 dB}.\\
This generous margin accommodates heavy rain events at Ku-band (typical
rain attenuation of 3--6 dB for 99.7\% availability in temperate
climates), ensuring reliable satellite TV reception in most weather
conditions.\\
During extreme downpours exceeding 9.5 dB of rain attenuation, the
receiver would lose lock temporarily --- the well-known ``rain fade''
effect.

\end{examplebox}

\section{2.8 Link Budget Analysis}\label{link-budget-analysis}

A link budget is a systematic accounting of all gains and losses in a
communication link from transmitter to receiver, used to determine
whether the received signal meets the minimum required level for
reliable communication. Link budgets are essential for designing any
communication system --- wireless, satellite, fiber optic, or wired ---
and they directly connect the noise and modulation concepts from earlier
sections into a complete system-level analysis.

\subsection{2.8.1 Link Budget
Fundamentals}\label{link-budget-fundamentals}

The fundamental link budget equation expresses the received power as:
P\textsubscript{rx} = P\textsubscript{tx} + G\textsubscript{tx} −
L\textsubscript{path} + G\textsubscript{rx} − L\textsubscript{misc} (all
in dB), where P\textsubscript{tx} is the transmit power,
G\textsubscript{tx} and G\textsubscript{rx} are the transmit and receive
antenna gains, L\textsubscript{path} is the path loss, and
L\textsubscript{misc} accounts for additional losses such as cable
losses, atmospheric absorption, and fading margins. For free-space
propagation (no obstructions or reflections), the path loss is given by
the Friis transmission equation: FSPL = 20 log₁₀(4πd/λ) dB, where d is
the distance and λ = c/f is the wavelength. At 1 GHz and 1 km, the
free-space path loss is approximately 92.4 dB, and it increases by 6 dB
for every doubling of distance or frequency.

The system margin is the difference between the actual received power
and the receiver sensitivity (the minimum power for acceptable
performance): margin = P\textsubscript{rx} −
P\textsubscript{sensitivity}. Receiver sensitivity depends on the noise
floor (kTB), the receiver noise figure, and the required SNR (or
E\textsubscript{b}/N₀) for the chosen modulation and coding scheme. A
positive margin indicates a working link; a negative margin means the
link will fail. Practical designs include a fade margin (typically
10--30 dB depending on reliability requirements) to account for
statistical variations in path loss due to multipath fading, rain
attenuation, or other time-varying impairments.

\begin{examplebox}

\textbf{Example 2.8.1:} A 2.4 GHz Wi-Fi access point transmits at
P\textsubscript{tx} = 20 dBm with an antenna gain of G\textsubscript{tx}
= 3 dBi. The client device has an antenna gain of G\textsubscript{rx} =
0 dBi and a receiver sensitivity of −70 dBm for the 54 Mbps data rate
(64-QAM, 3/4 coding). Determine (a) the free-space path loss at 100 m,
(b) the received power, (c) the link margin, and (d) the maximum range
with a 10 dB fade margin.

\textbf{Solution:}

(a) Free-space path loss at 2.4 GHz, 100 m:\\
λ = c/f = 3 × 10⁸ / 2.4 × 10⁹ = 0.125 m\\
FSPL = 20 log₁₀(4π × 100 / 0.125) = 20 log₁₀(10,053) = 20 × 4.002 =
\textbf{80.0 dB}

(b) Received power: P\textsubscript{rx} = 20 + 3 − 80.0 + 0 − 0 =
\textbf{−57.0 dBm}

(c) Link margin: margin = P\textsubscript{rx} −
P\textsubscript{sensitivity} = −57.0 − (−70) = \textbf{13.0 dB}

(d) With a 10 dB fade margin, the allowable path loss =
P\textsubscript{tx} + G\textsubscript{tx} + G\textsubscript{rx} −
P\textsubscript{sensitivity} − fade margin = 20 + 3 + 0 − (−70) − 10 =
83.0 dB.\\
Since FSPL = 80.0 dB at 100 m, the additional 3 dB allows
10\textsuperscript{3/20} = 1.41× more distance: d\textsubscript{max} =
100 × 1.41 = \textbf{141 m}.\\
In practice, indoor environments add 10--20 dB of wall and obstruction
losses, reducing the effective range to 30--50 m at the 54 Mbps rate.

\end{examplebox}

\chapter{Chapter 3}\label{chapter-3}

\chapter{Semiconductors}\label{semiconductors}

Semiconductors are materials with electrical conductivity between that
of a conductor and an insulator, and they form the foundation of nearly
all modern electronic devices. By introducing controlled impurities
(doping) into semiconductor crystals, engineers create regions of excess
electrons (N-type) and excess holes (P-type) that enable the
construction of diodes, transistors, and integrated circuits. The
ability to precisely control current flow through semiconductor
junctions has made possible everything from simple rectifiers and
voltage regulators to microprocessors containing billions of
transistors.

\section{3.1 Semiconductor
Fundamentals}\label{semiconductor-fundamentals}

\subsection{3.1.1 Energy Bands and
Bandgap}\label{energy-bands-and-bandgap}

In a crystalline solid, the discrete energy levels of individual atoms
merge into continuous energy bands due to the close proximity of atoms
in the lattice. The two most important bands are the valence band (the
highest energy band that is fully occupied by electrons at absolute
zero) and the conduction band (the next higher band, which is empty at
absolute zero). The energy gap between them --- the bandgap
(E\textsubscript{g}) --- determines whether a material is a conductor
(no gap or overlapping bands), a semiconductor (small gap, 0.5-3.5 eV),
or an insulator (large gap, \textgreater{} 4 eV). At temperatures above
absolute zero, thermal energy promotes some electrons from the valence
band into the conduction band, creating mobile electrons in the
conduction band and mobile holes (vacant electron states) in the valence
band. The intrinsic carrier concentration n\textsubscript{i} depends
exponentially on bandgap and temperature: n\textsubscript{i} =
√(N\textsubscript{C} × N\textsubscript{V}) ×
e\textsuperscript{−Eg/(2kT)}, where N\textsubscript{C} and
N\textsubscript{V} are the effective density of states in the conduction
and valence bands, k is Boltzmann's constant (8.617 × 10⁻⁵ eV/K), and T
is absolute temperature.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Material
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Bandgap E\textsubscript{g} (eV)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
n\textsubscript{i} at 300 K (cm⁻³)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Germanium (Ge) & 0.66 & 2.4 × 10¹³ & Indirect \\
Silicon (Si) & 1.12 & 1.5 × 10¹⁰ & Indirect \\
Gallium Arsenide (GaAs) & 1.42 & 1.8 × 10⁶ & Direct \\
Silicon Carbide (SiC) & 3.26 & \textasciitilde10⁻⁹ & Indirect \\
Gallium Nitride (GaN) & 3.40 & \textasciitilde10⁻¹⁰ & Direct \\
\end{longtable}
}

\begin{figure}[H]

\hypertarget{fig-3-1-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch03_energy_bands.png}

\caption{Figure 3.1.1: Energy Band Diagrams: Conductor vs Semiconductor vs Insulator}

\end{figure}

\begin{examplebox}

\textbf{Example 3.1.1:} The intrinsic carrier concentration of a
semiconductor can be approximated as n\textsubscript{i} ≈ B ×
T\textsuperscript{3/2} × e\textsuperscript{−Eg/(2kT)}, where B is a
material constant. For silicon (E\textsubscript{g} = 1.12 eV) at 300 K,
n\textsubscript{i} = 1.5 × 10¹⁰ cm⁻³. Estimate n\textsubscript{i} for
silicon at 400 K (elevated operating temperature).

\textbf{Solution:}\\
Taking the ratio at two temperatures (B cancels):\\
n\textsubscript{i}(T₂)/n\textsubscript{i}(T₁) =
(T₂/T₁)\textsuperscript{3/2} × e\textsuperscript{−Eg/(2k) × (1/T₂ −
1/T₁)}\\
(T₂/T₁)\textsuperscript{3/2} = (400/300)\textsuperscript{3/2} =
(1.333)\textsuperscript{3/2} = 1.540\\
Exponent: −E\textsubscript{g}/(2k) × (1/T₂ − 1/T₁) = −1.12/(2 × 8.617 ×
10⁻⁵) × (1/400 − 1/300)\\
= −6,499 × (0.00250 − 0.00333) = −6,499 × (−8.33 × 10⁻⁴) = 5.416\\
e\textsuperscript{5.416} = 224.9\\
n\textsubscript{i}(400 K) = 1.5 × 10¹⁰ × 1.540 × 224.9 = \textbf{5.20 ×
10¹² cm⁻³}

The intrinsic carrier concentration increases by a factor of
\textasciitilde346 for a 100 K temperature rise, illustrating why
semiconductor device characteristics are strongly temperature dependent.

\end{examplebox}

\subsection{3.1.2 Doping (N-Type and
P-Type)}\label{doping-n-type-and-p-type}

Doping introduces controlled impurity atoms into the semiconductor
crystal to dramatically increase the concentration of one carrier type.
N-type doping uses donor atoms from Group V of the periodic table
(phosphorus, arsenic, antimony for silicon) --- each donor has five
valence electrons, four of which bond with neighboring silicon atoms
while the fifth is loosely bound and easily ionized into the conduction
band. P-type doping uses acceptor atoms from Group III (boron, gallium,
indium for silicon) --- each acceptor has only three valence electrons,
creating a hole in the bonding structure that acts as a mobile positive
charge carrier. At room temperature, virtually all dopant atoms are
ionized, so the majority carrier concentration equals the doping
concentration: n ≈ N\textsubscript{D} for N-type and p ≈
N\textsubscript{A} for P-type. The minority carrier concentration is
determined by the mass action law: n × p = n\textsubscript{i}², which
holds in thermal equilibrium regardless of doping.

\begin{examplebox}

\textbf{Example 3.1.2:} A silicon wafer is doped with phosphorus at
N\textsubscript{D} = 2 × 10¹⁶ cm⁻³. The electron mobility in this
material is μ\textsubscript{n} = 1,250 cm²/(V·s). Determine (a) the
majority and minority carrier concentrations, (b) the resistivity, and
(c) the conductivity. Use n\textsubscript{i} = 1.5 × 10¹⁰ cm⁻³ and q =
1.602 × 10⁻¹⁹ C.

\textbf{Solution:}

(a) Majority carriers (electrons): n ≈ N\textsubscript{D} = \textbf{2 ×
10¹⁶ cm⁻³}\\
Minority carriers (holes): p = n\textsubscript{i}² / n = (1.5 × 10¹⁰)² /
(2 × 10¹⁶) = 2.25 × 10²⁰ / 2 × 10¹⁶ = \textbf{1.125 × 10⁴ cm⁻³}

(b) Conductivity (dominated by majority carriers):\\
σ = q × n × μ\textsubscript{n} = 1.602 × 10⁻¹⁹ × 2 × 10¹⁶ × 1,250 =
\textbf{4.006 (Ω·cm)⁻¹}

Resistivity: ρ = 1/σ = 1/4.006 = \textbf{0.250 Ω·cm}

\end{examplebox}

\subsection{3.1.3 Drift and Diffusion}\label{drift-and-diffusion}

Current flow in semiconductors occurs by two mechanisms: drift and
diffusion. Drift current results from the motion of charge carriers
under the influence of an electric field --- carriers accelerate in the
field direction, collide with lattice atoms, and establish an average
drift velocity v\textsubscript{d} = μ × E, where μ is the carrier
mobility. The drift current density is J\textsubscript{drift} = q × (n ×
μ\textsubscript{n} + p × μ\textsubscript{p}) × E, where the electron and
hole components add because electrons move opposite to the field but
carry negative charge. Diffusion current results from carrier
concentration gradients --- carriers naturally move from regions of high
concentration to regions of low concentration, similar to gas diffusion.
The diffusion current density is J\textsubscript{diff} = q ×
D\textsubscript{n} × (dn/dx) − q × D\textsubscript{p} × (dp/dx), where D
is the diffusion coefficient related to mobility by the Einstein
relation: D = (kT/q) × μ. At room temperature, kT/q = 0.02585 V (the
thermal voltage V\textsubscript{T}).

\begin{examplebox}

\textbf{Example 3.1.3:} A silicon bar doped at N\textsubscript{D} = 10¹⁶
cm⁻³ is 2 mm long with 5 V applied across it. The electron mobility is
μ\textsubscript{n} = 1,300 cm²/(V·s). Determine (a) the electric field,
(b) the electron drift velocity, (c) the drift current density, and (d)
the electron diffusion coefficient.

\textbf{Solution:}

(a) Electric field: E = V/L = 5/0.2 = \textbf{25 V/cm}

(b) Drift velocity: v\textsubscript{d} = μ\textsubscript{n} × E = 1,300
× 25 = \textbf{32,500 cm/s = 325 m/s}

(c) Drift current density (N-type, electrons dominate):\\
J\textsubscript{drift} = q × n × μ\textsubscript{n} × E = 1.602 × 10⁻¹⁹
× 10¹⁶ × 1,300 × 25\\
= 1.602 × 10⁻¹⁹ × 3.25 × 10²⁰ = \textbf{52.1 A/cm²}

(d) Diffusion coefficient (Einstein relation):\\
D\textsubscript{n} = V\textsubscript{T} × μ\textsubscript{n} = 0.02585 ×
1,300 = \textbf{33.6 cm²/s}

\end{examplebox}

\section{3.2 Semiconductor Materials}\label{semiconductor-materials}

The choice of semiconductor material determines the fundamental
performance limits of a device --- its operating frequency, breakdown
voltage, thermal tolerance, and optical properties. Silicon dominates
electronics due to its abundance, mature processing technology, and
excellent native oxide, while III-V and wide-bandgap compounds such as
GaAs, GaN, and SiC are chosen where silicon's electron mobility or
bandgap is insufficient for the application.

\subsection{3.2.1 Silicon (Si)}\label{silicon-si}

Silicon (Si) is a Group IV element with atomic number 14, four valence
electrons, and a diamond cubic crystal structure in which each atom
forms covalent bonds with four nearest neighbors in a tetrahedral
arrangement. With an indirect bandgap of 1.12 eV at 300 K, silicon
occupies an ideal middle ground --- wide enough to keep intrinsic
leakage low (n\textsubscript{i} ≈ 1.5 × 10¹⁰ cm⁻³ at room temperature)
yet narrow enough for practical doping and device operation at standard
voltages. Silicon is the second most abundant element in the Earth's
crust after oxygen, and its native oxide SiO₂ is a high-quality
electrical insulator that can be thermally grown with an atomically
sharp Si/SiO₂ interface --- this fortuitous property enabled the MOSFET
and the entire CMOS revolution, as no other semiconductor forms such an
excellent natural gate dielectric. Doping silicon with Group V donors
(phosphorus, arsenic, antimony) creates N-type material, while Group III
acceptors (boron, gallium, indium) create P-type material, with doping
concentrations spanning from 10¹⁴ to 10²¹ cm⁻³ for different device
regions. Silicon's electron mobility of approximately 1,350 cm²/(V·s)
and hole mobility of 480 cm²/(V·s) are modest compared to III-V
compounds, but its unmatched manufacturability, mechanical strength, and
the mature ecosystem of fabrication processes make it the foundation of
CMOS logic, power devices (MOSFETs, IGBTs, thyristors), photovoltaic
solar cells, and MEMS sensors --- accounting for over 95\% of all
semiconductor devices produced worldwide.

\begin{examplebox}

\textbf{Example 3.2.1:} Intrinsic silicon at T = 300 K has an intrinsic
carrier concentration of n\textsubscript{i} = 1.5 × 10¹⁰ cm⁻³. If the
silicon is doped with phosphorus (donor) at a concentration of
N\textsubscript{D} = 5 × 10¹⁶ cm⁻³, determine the electron and hole
concentrations, and the position of the Fermi level relative to the
intrinsic Fermi level (use kT = 0.02585 eV at 300 K).

\textbf{Solution:}\\
Since N\textsubscript{D} \textgreater\textgreater{} n\textsubscript{i},
the electron concentration is approximately:\\
n ≈ N\textsubscript{D} = \textbf{5 × 10¹⁶ cm⁻³}

Hole concentration (from mass action law n × p = n\textsubscript{i}²):\\
p = n\textsubscript{i}² / n = (1.5 × 10¹⁰)² / (5 × 10¹⁶) = 2.25 × 10²⁰ /
5 × 10¹⁶ = \textbf{4.5 × 10³ cm⁻³}

Fermi level position relative to intrinsic level:\\
E\textsubscript{F} − E\textsubscript{i} = kT × ln(n /
n\textsubscript{i}) = 0.02585 × ln(5 × 10¹⁶ / 1.5 × 10¹⁰)\\
= 0.02585 × ln(3.33 × 10⁶) = 0.02585 × 15.02 = \textbf{0.388 eV above
E\textsubscript{i}}

\end{examplebox}

\subsection{3.2.2 Gallium Arsenide (GaAs)}\label{gallium-arsenide-gaas}

Gallium Arsenide (GaAs) is a III-V compound semiconductor with a direct
bandgap of 1.42 eV at 300 K --- the direct gap means electrons can
transition between the conduction and valence bands by emitting or
absorbing a photon without requiring a phonon (lattice vibration) for
momentum conservation, making GaAs far superior to silicon for light
emission and optical detection. GaAs has an electron mobility of
approximately 8,500 cm²/(V·s) at low doping levels, roughly 6 times
higher than silicon, which translates directly into faster transit times
and higher operating frequencies for transistors. The combination of
high mobility and semi-insulating substrate capability (resistivity
\textgreater{} 10⁷ Ω·cm, achieved through chromium doping or the native
EL2 deep-level defect) makes GaAs the material of choice for monolithic
microwave integrated circuits (MMICs) operating from 1 GHz to over 100
GHz, including low-noise amplifiers, power amplifiers, and mixers for
radar, satellite, and cellular base station applications. In
optoelectronics, the 1.42 eV bandgap corresponds to emission at 870 nm
(near-infrared), and the AlGaAs/GaAs material system enables laser
diodes, LEDs, and high-efficiency multi-junction solar cells that
achieve conversion efficiencies above 45\% under concentrated sunlight
--- making GaAs the standard for space solar panels despite its higher
cost. The principal limitations of GaAs are its higher material cost
(gallium is far less abundant than silicon, and crystal growth from the
melt requires high-pressure arsenic overpressure), its mechanical
fragility compared to silicon, the absence of a high-quality native
oxide (preventing straightforward MOS device fabrication), and lower
thermal conductivity (0.46 W/(cm·K) vs 1.5 W/(cm·K) for silicon), which
constrains power dissipation. These trade-offs confine GaAs to
applications where its speed and optical properties justify the cost
premium, while silicon dominates mainstream digital and power
electronics.

\begin{examplebox}

\textbf{Example 3.2.2:} A GaAs MESFET operates with an electron mobility
of μ\textsubscript{n} = 8,500 cm²/(V·s), compared to silicon's
μ\textsubscript{n} = 1,350 cm²/(V·s). Both devices have a channel length
of L = 0.5 μm. Estimate the transit time for electrons through the
channel in each material at an electric field of E = 5 kV/cm, and
determine the maximum operating frequency estimate (f\textsubscript{T} ≈
1 / (2π × τ\textsubscript{transit})).

\textbf{Solution:}\\
Electron drift velocity: v\textsubscript{d} = μ\textsubscript{n} × E

GaAs: v\textsubscript{d} = 8,500 × 5,000 = 4.25 × 10⁷ cm/s\\
Transit time: τ = L / v\textsubscript{d} = 0.5 × 10⁻⁴ / 4.25 × 10⁷ =
1.176 × 10⁻¹² s = 1.18 ps\\
f\textsubscript{T} = 1 / (2π × 1.176 × 10⁻¹²) = \textbf{135.2 GHz}

Silicon: v\textsubscript{d} = 1,350 × 5,000 = 6.75 × 10⁶ cm/s\\
Transit time: τ = 0.5 × 10⁻⁴ / 6.75 × 10⁶ = 7.407 × 10⁻¹² s = 7.41 ps\\
f\textsubscript{T} = 1 / (2π × 7.407 × 10⁻¹²) = \textbf{21.5 GHz}

The GaAs device has a \textbf{6.3× higher} estimated operating frequency
than silicon, demonstrating why GaAs is preferred for high-frequency RF
applications.

\end{examplebox}

\subsection{3.2.3 Gallium Nitride (GaN)}\label{gallium-nitride-gan}

Gallium Nitride is a wide bandgap semiconductor with a bandgap of
approximately 3.4 eV, compared to 1.12 eV for silicon. This wide bandgap
allows GaN devices to operate at higher voltages, temperatures, and
switching frequencies with lower losses. GaN is widely used in power
electronics (high-efficiency power converters and chargers), RF
amplifiers (5G base stations, radar, and satellite communications), and
optoelectronics (blue and white LEDs, laser diodes). Its high electron
mobility, achieved through AlGaN/GaN heterostructures forming a
two-dimensional electron gas (2DEG), makes it particularly well-suited
for high-frequency High Electron Mobility Transistors (HEMTs).

\begin{examplebox}

\textbf{Example 3.2.3:} A GaN power transistor switching converter
operates at 500 kHz with a drain-source voltage of 400 V and a load
current of 10 A. The GaN device has switching losses characterized by
t\textsubscript{rise} = 5 ns and t\textsubscript{fall} = 8 ns. An
equivalent silicon MOSFET has t\textsubscript{rise} = 30 ns and
t\textsubscript{fall} = 45 ns. Compare the switching power losses for
both devices.

\textbf{Solution:}\\
Switching energy per cycle: E\textsubscript{sw} = 0.5 ×
V\textsubscript{DS} × I\textsubscript{D} × (t\textsubscript{rise} +
t\textsubscript{fall})

GaN: E\textsubscript{sw} = 0.5 × 400 × 10 × (5 × 10⁻⁹ + 8 × 10⁻⁹) =
2,000 × 13 × 10⁻⁹ = 26 μJ\\
Switching power loss: P\textsubscript{sw} = E\textsubscript{sw} ×
f\textsubscript{sw} = 26 × 10⁻⁶ × 500,000 = \textbf{13.0 W}

Silicon: E\textsubscript{sw} = 0.5 × 400 × 10 × (30 × 10⁻⁹ + 45 × 10⁻⁹)
= 2,000 × 75 × 10⁻⁹ = 150 μJ\\
Switching power loss: P\textsubscript{sw} = 150 × 10⁻⁶ × 500,000 =
\textbf{75.0 W}

The GaN device reduces switching losses by a factor of 75.0 / 13.0 =
\textbf{5.8×}, demonstrating why GaN enables efficient high-frequency
power conversion.

\end{examplebox}

\section{3.3 PN Junction}\label{pn-junction}

When P-type and N-type semiconductor regions are brought into contact, a
PN junction is formed --- the fundamental building block of diodes,
BJTs, MOSFETs, solar cells, and LEDs. The diffusion of majority carriers
across the junction creates a charge-depleted region with an internal
electric field that opposes further diffusion, establishing an
equilibrium condition.

\subsection{3.3.1 Depletion Region and Built-In
Potential}\label{depletion-region-and-built-in-potential}

At the PN junction, electrons from the N-side diffuse into the P-side
and holes from the P-side diffuse into the N-side, leaving behind fixed
ionized donor atoms (positive) on the N-side and fixed ionized acceptor
atoms (negative) on the P-side. This region of immobile charges, called
the depletion region (or space charge region), creates an internal
electric field directed from N to P that opposes further diffusion. The
resulting built-in potential (also called contact potential or junction
potential) is V\textsubscript{bi} = (kT/q) × ln(N\textsubscript{A} ×
N\textsubscript{D} / n\textsubscript{i}²). The depletion width depends
on doping concentrations and any externally applied voltage: W =
√(2ε\textsubscript{s}/q × (1/N\textsubscript{A} + 1/N\textsubscript{D})
× (V\textsubscript{bi} − V\textsubscript{A})), where ε\textsubscript{s}
is the semiconductor permittivity and V\textsubscript{A} is the applied
voltage (positive for forward bias, negative for reverse bias).

\begin{examplebox}

\textbf{Example 3.3.1:} A silicon PN junction has N\textsubscript{A} = 5
× 10¹⁷ cm⁻³ and N\textsubscript{D} = 2 × 10¹⁶ cm⁻³. At T = 300 K,
determine (a) the built-in potential and (b) the depletion width at zero
bias. Use n\textsubscript{i} = 1.5 × 10¹⁰ cm⁻³, ε\textsubscript{Si} =
11.7 × 8.854 × 10⁻¹⁴ F/cm = 1.036 × 10⁻¹² F/cm.

\textbf{Solution:}

(a) Built-in potential:\\
V\textsubscript{bi} = V\textsubscript{T} × ln(N\textsubscript{A} ×
N\textsubscript{D} / n\textsubscript{i}²) = 0.02585 × ln(5 × 10¹⁷ × 2 ×
10¹⁶ / (1.5 × 10¹⁰)²)\\
= 0.02585 × ln(10³⁴ / 2.25 × 10²⁰) = 0.02585 × ln(4.44 × 10¹³) = 0.02585
× 31.42\\
= \textbf{0.812 V}

(b) Depletion width at V\textsubscript{A} = 0:\\
W = √(2 × 1.036 × 10⁻¹² / 1.602 × 10⁻¹⁹ × (1/5 × 10¹⁷ + 1/2 × 10¹⁶) ×
0.812)\\
1/N\textsubscript{A} + 1/N\textsubscript{D} = 2 × 10⁻¹⁸ + 5 × 10⁻¹⁷ =
5.2 × 10⁻¹⁷ cm³\\
W = √(2 × 1.036 × 10⁻¹² × 5.2 × 10⁻¹⁷ × 0.812 / 1.602 × 10⁻¹⁹)\\
= √(8.748 × 10⁻²⁹ / 1.602 × 10⁻¹⁹) = √(5.461 × 10⁻¹⁰) = \textbf{2.34 ×
10⁻⁵ cm = 0.234 μm}

The depletion region extends mostly into the lightly doped N-side:
x\textsubscript{N} ≈ W × N\textsubscript{A}/(N\textsubscript{A} +
N\textsubscript{D}) = 0.234 × 0.962 = 0.225 μm on the N-side versus only
0.009 μm on the P-side.

\end{examplebox}

\subsection{3.3.2 Forward and Reverse
Bias}\label{forward-and-reverse-bias}

When a positive voltage is applied to the P-side relative to the N-side
(forward bias), the external field opposes the internal field, reducing
the depletion width and the potential barrier. This allows majority
carriers to cross the junction, producing an exponentially increasing
current described by the Shockley diode equation: I = I\textsubscript{S}
× (e\textsuperscript{V/(nVT)} − 1), where I\textsubscript{S} is the
reverse saturation current (typically 10⁻¹² to 10⁻¹⁵ A for silicon), n
is the ideality factor (1 for an ideal junction, 1-2 in practice), and
V\textsubscript{T} = kT/q ≈ 25.85 mV at 300 K. When a negative voltage
is applied (reverse bias), the depletion region widens and only a very
small leakage current (approximately I\textsubscript{S}) flows. If the
reverse voltage exceeds the breakdown voltage, the junction enters
avalanche or Zener breakdown and current increases rapidly.

\begin{figure}[H]

\hypertarget{fig-3-3-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch03_pn_junction.png}

\caption{Figure 3.3.1: PN Junction I-V Characteristic}

\end{figure}

\begin{examplebox}

\textbf{Example 3.3.2:} A silicon diode has a reverse saturation current
I\textsubscript{S} = 2 × 10⁻¹⁴ A and an ideality factor n = 1.0 at T =
300 K. Determine the forward current at (a) V = 0.60 V and (b) V = 0.70
V, and (c) calculate the ratio of currents to illustrate the exponential
nature of the I-V characteristic.

\textbf{Solution:}\\
V\textsubscript{T} = 0.02585 V at 300 K.

(a) At V = 0.60 V:\\
I = I\textsubscript{S} × (e\textsuperscript{V/VT} − 1) = 2 × 10⁻¹⁴ ×
(e\textsuperscript{0.60/0.02585} − 1)\\
= 2 × 10⁻¹⁴ × (e\textsuperscript{23.21} − 1) = 2 × 10⁻¹⁴ × 1.207 × 10¹⁰
= \textbf{0.241 mA}

(b) At V = 0.70 V:\\
I = 2 × 10⁻¹⁴ × (e\textsuperscript{0.70/0.02585} − 1) = 2 × 10⁻¹⁴ ×
(e\textsuperscript{27.08} − 1)\\
= 2 × 10⁻¹⁴ × 5.760 × 10¹¹ = \textbf{11.52 mA}

(c) Current ratio: 11.52/0.241 = \textbf{47.8×} --- a mere 100 mV
increase in forward voltage produces a \textasciitilde48× increase in
current, demonstrating the steep exponential characteristic.

\end{examplebox}

\subsection{3.3.3 Junction Capacitance}\label{junction-capacitance}

A PN junction exhibits two types of capacitance. The depletion
(junction) capacitance C\textsubscript{j} arises from the charge stored
in the depletion region and dominates under reverse bias:
C\textsubscript{j} = C\textsubscript{j0} / (1 −
V\textsubscript{A}/V\textsubscript{bi})\textsuperscript{m}, where
C\textsubscript{j0} is the zero-bias capacitance, V\textsubscript{A} is
the applied voltage (negative for reverse bias), and m is the grading
coefficient (0.5 for an abrupt junction, 0.33 for a linearly graded
junction). The diffusion capacitance C\textsubscript{d} arises from
minority carrier charge stored near the junction during forward bias and
is proportional to the forward current: C\textsubscript{d} =
τ\textsubscript{T} × I / V\textsubscript{T}, where τ\textsubscript{T} is
the transit time. Varactor (variable capacitance) diodes are
specifically designed to exploit the voltage-dependent depletion
capacitance for use in voltage-controlled oscillators (VCOs), tuning
circuits, and frequency multipliers.

\begin{examplebox}

\textbf{Example 3.3.3:} A varactor diode has C\textsubscript{j0} = 20
pF, V\textsubscript{bi} = 0.75 V, and m = 0.5 (abrupt junction). It is
used in an LC tank circuit with L = 100 nH. Determine (a) the junction
capacitance at reverse bias voltages of 1 V, 5 V, and 15 V, and (b) the
corresponding resonant frequencies.

\textbf{Solution:}

(a) C\textsubscript{j} = C\textsubscript{j0} / (1 +
V\textsubscript{R}/V\textsubscript{bi})\textsuperscript{0.5} (using
V\textsubscript{R} = \textbar V\textsubscript{A}\textbar{} for reverse
bias):

At V\textsubscript{R} = 1 V: C\textsubscript{j} = 20 / (1 +
1/0.75)\textsuperscript{0.5} = 20 / (2.333)\textsuperscript{0.5} = 20 /
1.528 = \textbf{13.09 pF}\\
At V\textsubscript{R} = 5 V: C\textsubscript{j} = 20 / (1 +
5/0.75)\textsuperscript{0.5} = 20 / (7.667)\textsuperscript{0.5} = 20 /
2.769 = \textbf{7.22 pF}\\
At V\textsubscript{R} = 15 V: C\textsubscript{j} = 20 / (1 +
15/0.75)\textsuperscript{0.5} = 20 / (21.0)\textsuperscript{0.5} = 20 /
4.583 = \textbf{4.36 pF}

(b) Resonant frequency: f₀ = 1 / (2π√(LC))

At 1 V: f₀ = 1 / (2π√(100 × 10⁻⁹ × 13.09 × 10⁻¹²)) = 1 / (2π × 1.144 ×
10⁻⁹) = \textbf{139.2 MHz}\\
At 5 V: f₀ = 1 / (2π√(100 × 10⁻⁹ × 7.22 × 10⁻¹²)) = 1 / (2π × 8.50 ×
10⁻¹⁰) = \textbf{187.3 MHz}\\
At 15 V: f₀ = 1 / (2π√(100 × 10⁻⁹ × 4.36 × 10⁻¹²)) = 1 / (2π × 6.604 ×
10⁻¹⁰) = \textbf{241.1 MHz}

The varactor provides a \textbf{1.73:1 frequency tuning range}
(241.1/139.2) with a 1-15 V control voltage sweep.

\end{examplebox}

\section{3.4 Diodes}\label{diodes}

A diode is a two-terminal device based on a PN junction that allows
current to flow easily in one direction (forward bias) and blocks
current in the other direction (reverse bias). A silicon diode will
``turn on'' when a forward voltage of approximately 0.6 V to 0.7 V is
applied and become conductive. Under normal conditions, only a very
small leakage current flows when reverse voltage is applied. However,
with a sufficiently large reverse voltage, the diode reaches its
breakdown voltage and begins conducting in reverse. Zener diodes are
specifically designed to operate in this breakdown region and are used
as voltage references and regulators.

\subsection{3.4.1 Rectifier Diodes}\label{rectifier-diodes}

Standard rectifier diodes are the most common type and are used to
convert AC to DC in power supplies. Schottky diodes use a
metal-semiconductor junction instead of a P-N junction, providing a
lower forward voltage drop (\textasciitilde0.2 V to 0.3 V) and faster
switching, making them ideal for high-frequency rectification and
clamping circuits. Signal diodes (such as the 1N4148) are optimized for
small-signal applications including switching, clipping, and logic
circuits. Light Emitting Diodes (LEDs) emit photons when forward biased
and are used in indicators, displays, and illumination. Photodiodes
operate in reverse bias and generate current proportional to incident
light, serving as optical detectors in communications and sensing
applications.

\begin{examplebox}

\textbf{Example 3.4.1:} A full-wave bridge rectifier uses four silicon
diodes (V\textsubscript{f} = 0.7 V each) and is supplied by a 12.6
V\textsubscript{rms} AC transformer secondary. The rectifier drives a
100 Ω load through a 1,000 μF filter capacitor at 60 Hz. Determine (a)
the peak output voltage, (b) the DC load current, and (c) the
peak-to-peak ripple voltage.

\textbf{Solution:}

(a) Peak transformer voltage: V\textsubscript{peak} = 12.6 × √2 = 17.82
V\\
Two diodes conduct at any time in a bridge rectifier:\\
Peak output voltage: V\textsubscript{out\_peak} = 17.82 − 2 × 0.7 =
\textbf{16.42 V}

(b) DC load current (approximately): I\textsubscript{DC} =
V\textsubscript{out\_peak} / R\textsubscript{L} = 16.42 / 100 =
\textbf{164.2 mA}

(c) Ripple voltage (full-wave, f\textsubscript{ripple} = 2 × 60 = 120
Hz):\\
V\textsubscript{ripple} = I\textsubscript{DC} / (f\textsubscript{ripple}
× C) = 0.1642 / (120 × 0.001) = \textbf{1.37 V peak-to-peak}

\end{examplebox}

\subsection{3.4.2 Zener Diodes}\label{zener-diodes}

Zener diodes are designed to operate in the reverse-biased breakdown
region, providing a stable voltage reference. Below about 5 V, the
breakdown mechanism is the Zener effect (quantum tunneling through a
thin depletion region in heavily doped junctions); above about 7 V,
avalanche breakdown (impact ionization) dominates. Diodes between 5-7 V
use a combination of both mechanisms. Zener diodes are characterized by
their Zener voltage (V\textsubscript{Z}), dynamic resistance
(r\textsubscript{z}), power dissipation rating, and temperature
coefficient --- notably, Zener breakdown has a negative temperature
coefficient while avalanche breakdown has a positive one, and 5.1 V
Zener diodes are popular because the two effects nearly cancel,
providing excellent temperature stability.

\begin{examplebox}

\textbf{Example 3.4.2:} A 5.1 V Zener diode (with dynamic resistance
r\textsubscript{z} = 10 Ω and maximum power dissipation
P\textsubscript{max} = 1 W) is used as a voltage regulator. The
unregulated input voltage varies from 9 V to 15 V, and the load
resistance is R\textsubscript{L} = 510 Ω. A series resistor
R\textsubscript{S} is needed. Determine (a) the value of
R\textsubscript{S} to keep the Zener in regulation over the full input
range, and (b) the maximum Zener current and power dissipation.

\textbf{Solution:}

(a) Load current: I\textsubscript{L} = V\textsubscript{Z} /
R\textsubscript{L} = 5.1 / 510 = 10 mA\\
Minimum Zener current for regulation (practical minimum):
I\textsubscript{Z\_min} ≈ 5 mA\\
At minimum input voltage (9 V), R\textsubscript{S} must allow
I\textsubscript{Z\_min} + I\textsubscript{L} to flow:\\
R\textsubscript{S} = (V\textsubscript{in\_min} − V\textsubscript{Z}) /
(I\textsubscript{Z\_min} + I\textsubscript{L}) = (9 − 5.1) / (0.005 +
0.010) = 3.9 / 0.015 = \textbf{260 Ω} (use 270 Ω standard value)

(b) At maximum input voltage (15 V) with R\textsubscript{S} = 270 Ω:\\
Total current: I\textsubscript{total} = (V\textsubscript{in\_max} −
V\textsubscript{Z}) / R\textsubscript{S} = (15 − 5.1) / 270 = 9.9 / 270
= 36.67 mA\\
Zener current: I\textsubscript{Z\_max} = I\textsubscript{total} −
I\textsubscript{L} = 36.67 − 10 = \textbf{26.67 mA}\\
Power dissipation: P\textsubscript{Z} = V\textsubscript{Z} ×
I\textsubscript{Z\_max} = 5.1 × 0.02667 = \textbf{0.136 W} (well within
the 1 W rating)

\end{examplebox}

\subsection{3.4.3 Schottky Diodes}\label{schottky-diodes}

Schottky diodes use a metal-semiconductor junction (typically a metal
such as platinum, chromium, or molybdenum deposited on N-type silicon)
rather than a PN junction. Because there is no minority carrier
injection across the junction, Schottky diodes have no reverse recovery
time --- they switch from conducting to blocking almost instantaneously.
The forward voltage drop is significantly lower than silicon PN diodes
(0.15-0.45 V versus 0.6-0.7 V), reducing conduction losses in power
applications. These characteristics make Schottky diodes the preferred
choice for high-frequency switching power supplies, output rectification
in DC-DC converters, freewheeling diodes for inductive loads, and
reverse polarity protection. The main limitations are lower reverse
voltage ratings (typically ≤ 200 V, though SiC Schottky diodes reach
1,200 V) and higher reverse leakage current compared to PN junction
diodes, which increases with temperature.

\begin{examplebox}

\textbf{Example 3.4.3:} A 5 V, 20 A output DC-DC converter uses output
rectifier diodes that each carry an average current of 10 A. Compare the
power loss using (a) a silicon PN rectifier diode with
V\textsubscript{f} = 0.85 V and t\textsubscript{rr} = 35 ns, versus (b)
a Schottky rectifier with V\textsubscript{f} = 0.35 V and negligible
recovery time. The converter switching frequency is 300 kHz with a
reverse voltage of 20 V and a di/dt during recovery of 200 A/μs.

\textbf{Solution:}

(a) Silicon PN rectifier:\\
Conduction loss: P\textsubscript{cond} = V\textsubscript{f} ×
I\textsubscript{avg} = 0.85 × 10 = 8.5 W\\
Reverse recovery loss: P\textsubscript{rr} ≈ 0.5 × V\textsubscript{R} ×
I\textsubscript{rr} × t\textsubscript{rr} × f\textsubscript{sw}\\
I\textsubscript{rr} ≈ di/dt × t\textsubscript{rr} = 200 × 10⁶ × 35 ×
10⁻⁹ = 7.0 A\\
P\textsubscript{rr} = 0.5 × 20 × 7.0 × 35 × 10⁻⁹ × 300,000 = 0.735 W\\
Total: P\textsubscript{Si} = 8.5 + 0.735 = \textbf{9.24 W per diode}

(b) Schottky rectifier:\\
Conduction loss: P\textsubscript{cond} = 0.35 × 10 = 3.5 W\\
Recovery loss: ≈ 0 W (no minority carrier storage)\\
Total: P\textsubscript{Schottky} = \textbf{3.5 W per diode}

The Schottky diode reduces rectifier losses by 9.24 − 3.5 = \textbf{5.74
W per diode (62\% reduction)}, saving 11.5 W total for the two
rectifiers.\\
This improves converter efficiency by 11.5/(5 × 20) × 100 = \textbf{11.5
percentage points}.

\end{examplebox}

\subsection{3.4.4 Light-Emitting Diodes
(LEDs)}\label{light-emitting-diodes-leds}

Light-emitting diodes emit photons when electrons recombine with holes
across a forward-biased PN junction in a direct-bandgap semiconductor.
The wavelength (color) of the emitted light is determined by the bandgap
energy of the semiconductor material: λ = hc/E\textsubscript{g}, where h
is Planck's constant (6.626 × 10⁻³⁴ J·s), c is the speed of light (3 ×
10⁸ m/s), and E\textsubscript{g} is the bandgap in joules. Common LED
materials include GaAs (infrared, \textasciitilde870 nm), AlGaInP
(red-yellow, 570-650 nm), InGaN (green-blue, 450-530 nm), and GaN
(violet-UV, 365-405 nm). White LEDs are typically produced by coating a
blue InGaN LED with a yellow phosphor (YAG:Ce), with the combination of
blue LED emission and yellow phosphor fluorescence perceived as white
light. LED efficiency is characterized by wall-plug efficiency (optical
power out / electrical power in, typically 30-50\% for modern high-power
LEDs) and luminous efficacy (lumens per watt, up to 200 lm/W for white
LEDs).

\begin{examplebox}

\textbf{Example 3.4.4:} A white LED luminaire uses 24 high-power LEDs,
each rated at 1 W electrical input with a luminous efficacy of 160 lm/W.
Each LED operates at V\textsubscript{f} = 3.0 V and I\textsubscript{f} =
333 mA. Determine (a) the total luminous output in lumens, (b) the total
electrical power, and (c) the equivalent incandescent wattage (assuming
15 lm/W for incandescent bulbs).

\textbf{Solution:}

(a) Luminous output per LED: Φ = 160 lm/W × 1 W = 160 lumens\\
Total: Φ\textsubscript{total} = 24 × 160 = \textbf{3,840 lumens}

(b) Electrical power per LED: P = V\textsubscript{f} ×
I\textsubscript{f} = 3.0 × 0.333 = 1.0 W\\
Total: P\textsubscript{total} = 24 × 1.0 = \textbf{24 W}

(c) Equivalent incandescent: P\textsubscript{incand} = 3,840 / 15 =
\textbf{256 W}\\
The LED luminaire produces the same light as a 256 W incandescent bulb
while consuming only 24 W --- a \textbf{10.7× reduction} in electrical
power.

\end{examplebox}

\section{3.5 Transistors}\label{transistors}

Transistors are the active building blocks of all modern electronic
circuits, performing amplification and switching functions by using a
small input signal or current to control a much larger output current.
The two dominant transistor families are the Bipolar Junction Transistor
(BJT), a current-controlled device, and the Metal-Oxide-Semiconductor
Field-Effect Transistor (MOSFET), a voltage-controlled device. Power
transistors such as IGBTs and power MOSFETs extend these principles to
high-voltage, high-current switching applications.

\subsection{3.5.1 Bipolar Junction Transistor
(BJT)}\label{bipolar-junction-transistor-bjt}

The Bipolar Junction Transistor is a current-controlled three-terminal
device (Base, Collector, Emitter) that comes in two polarities: NPN and
PNP. In an NPN transistor, a small current flowing into the Base
terminal controls a larger current flowing from Collector to Emitter; in
a PNP transistor, the current directions are reversed, with current
flowing from Emitter to Collector controlled by current flowing out of
the Base. The ratio of collector current to base current is the current
gain (β or h\textsubscript{FE}), typically ranging from 20 to several
hundred. BJTs operate in three regions: cutoff (off), active (linear
amplification), and saturation (fully on), making them useful for both
amplification and switching applications.

\begin{examplebox}

\textbf{Example 3.5.1:} An NPN BJT common-emitter amplifier has β = 150,
V\textsubscript{CC} = 12 V, R\textsubscript{C} = 2.2 kΩ, and
R\textsubscript{E} = 470 Ω. The base bias network sets
I\textsubscript{B} = 40 μA. Assuming V\textsubscript{BE} = 0.7 V,
determine (a) I\textsubscript{C}, (b) V\textsubscript{CE}, and (c) the
voltage gain A\textsubscript{v} if the AC input signal is applied to the
base and the output is taken at the collector (bypass capacitor across
R\textsubscript{E} for AC).

\textbf{Solution:}

(a) Collector current: I\textsubscript{C} = β × I\textsubscript{B} = 150
× 40 × 10⁻⁶ = \textbf{6.0 mA}

(b) Applying KVL around the collector-emitter loop:\\
V\textsubscript{CE} = V\textsubscript{CC} − I\textsubscript{C} ×
(R\textsubscript{C} + R\textsubscript{E}) = 12 − 0.006 × (2,200 + 470)\\
V\textsubscript{CE} = 12 − 0.006 × 2,670 = 12 − 16.02 = −4.02 V

Since V\textsubscript{CE} is negative, the transistor is in
\textbf{saturation} (not active mode).\\
In saturation, V\textsubscript{CE\_sat} ≈ 0.2 V.\\
Recalculating: I\textsubscript{C\_sat} = (V\textsubscript{CC} −
V\textsubscript{CE\_sat}) / (R\textsubscript{C} + R\textsubscript{E}) =
(12 − 0.2) / 2,670 = \textbf{4.42 mA}

(c) Since the transistor is saturated under the given bias, gain is not
defined at this operating point. For the purpose of calculating gain,
re-bias the circuit to the edge of saturation using I\textsubscript{C} =
4.42 mA from part (b):\\
Transconductance: g\textsubscript{m} = I\textsubscript{C} /
V\textsubscript{T} = 0.00442 / 0.02585 = 171.0 mA/V\\
With R\textsubscript{E} bypassed: A\textsubscript{v} =
−g\textsubscript{m} × R\textsubscript{C} = −171.0 × 10⁻³ × 2,200 =
\textbf{−376.2} (inverting)\\
\textbar A\textsubscript{v}\textbar{} in dB = 20 × log₁₀(376.2) =
\textbf{51.5 dB}

\end{examplebox}

\subsection{3.5.2 MOSFET}\label{mosfet}

The Metal-Oxide-Semiconductor Field-Effect Transistor is a
voltage-controlled three-terminal device (Gate, Drain, Source) where a
voltage applied to the Gate controls the current flowing between Drain
and Source through an electric field. MOSFETs are the most common type
of FET and come in enhancement-mode (normally off, requiring a gate
voltage to conduct) and depletion-mode (normally on) variants, in both
N-channel and P-channel configurations. JFETs (Junction FETs) use a
reverse-biased P-N junction as the gate and are depletion-mode devices,
often used in low-noise analog front-end circuits. FETs offer extremely
high input impedance at the gate, draw virtually no gate current in
steady state, and are the fundamental building block of CMOS logic,
which dominates modern digital integrated circuits.

\begin{examplebox}

\textbf{Example 3.5.2:} An N-channel enhancement-mode MOSFET has a
threshold voltage V\textsubscript{th} = 2.0 V and a process
transconductance parameter k\textsubscript{n} = 0.5 mA/V². The device
operates with V\textsubscript{GS} = 5 V and V\textsubscript{DS} = 8 V.
Determine (a) the operating region, (b) the drain current
I\textsubscript{D}, and (c) the small-signal transconductance
g\textsubscript{m}.

\textbf{Solution:}

(a) Check operating region:\\
V\textsubscript{GS} − V\textsubscript{th} = 5 − 2 = 3 V\\
V\textsubscript{DS} = 8 V \textgreater{} V\textsubscript{GS} −
V\textsubscript{th} = 3 V, so the MOSFET is in \textbf{saturation}
(pinch-off region).

(b) Drain current in saturation (ignoring channel-length modulation):\\
I\textsubscript{D} = (k\textsubscript{n} / 2) × (V\textsubscript{GS} −
V\textsubscript{th})² = (0.5 × 10⁻³ / 2) × (3)² = 0.25 × 10⁻³ × 9 =
\textbf{2.25 mA}

(c) Small-signal transconductance:\\
g\textsubscript{m} = k\textsubscript{n} × (V\textsubscript{GS} −
V\textsubscript{th}) = 0.5 × 10⁻³ × 3 = \textbf{1.5 mA/V}\\
Alternatively: g\textsubscript{m} = 2 × I\textsubscript{D} /
(V\textsubscript{GS} − V\textsubscript{th}) = 2 × 2.25 / 3 = \textbf{1.5
mA/V}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-3-5-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch03_mosfet.png}

\caption{Figure 3.5.2: MOSFET I-V Characteristics}

\end{figure}

\subsection{3.5.3 Power MOSFETs}\label{power-mosfets}

Power MOSFETs are designed for high-current, high-voltage switching
applications and differ significantly from signal-level MOSFETs in both
structure and specifications. They use a vertical device structure
(VDMOS or trench MOSFET) where current flows vertically through the
silicon die, allowing higher current ratings in a compact package. The
key parameter is R\textsubscript{DS(on)} --- the on-state drain-source
resistance --- which determines conduction losses: P\textsubscript{cond}
= I\textsubscript{D}² × R\textsubscript{DS(on)}. R\textsubscript{DS(on)}
has a positive temperature coefficient, which provides natural current
sharing when MOSFETs are paralleled but means losses increase at
elevated temperatures. Switching losses depend on gate charge
(Q\textsubscript{g}), which determines how quickly the gate driver can
turn the device on and off: lower Q\textsubscript{g} enables faster
switching and lower losses at high frequencies. Power MOSFETs also have
an intrinsic body diode (a parasitic PN junction between the body and
drain) that conducts when V\textsubscript{DS} goes negative, which is
both useful (as a freewheeling diode in half-bridge circuits) and
potentially problematic (slow body diode recovery can cause
shoot-through losses). The Safe Operating Area (SOA) defines the maximum
simultaneous voltage and current the device can withstand without
damage.

\begin{examplebox}

\textbf{Example 3.5.3:} A power MOSFET in a 48 V to 12 V synchronous
buck converter operates at f\textsubscript{sw} = 250 kHz with a load
current of 20 A. The high-side MOSFET has R\textsubscript{DS(on)} = 8
mΩ, Q\textsubscript{g} = 45 nC, and switching times
t\textsubscript{rise} = 15 ns, t\textsubscript{fall} = 20 ns. The duty
cycle is D = V\textsubscript{out}/V\textsubscript{in} = 12/48 = 0.25.
Determine (a) the conduction loss, (b) the switching loss, (c) the gate
drive loss (V\textsubscript{GS} = 10 V), and (d) the total power
dissipation.

\textbf{Solution:}

(a) Conduction loss (high-side conducts for D × T\textsubscript{sw}):\\
I\textsubscript{RMS} = I\textsubscript{load} × √D = 20 × √0.25 = 20 ×
0.5 = 10 A\\
P\textsubscript{cond} = I\textsubscript{RMS}² × R\textsubscript{DS(on)}
= 100 × 0.008 = \textbf{0.80 W}

(b) Switching loss (transitions occur at V\textsubscript{in} and
I\textsubscript{load}):\\
P\textsubscript{sw} = 0.5 × V\textsubscript{in} × I\textsubscript{load}
× (t\textsubscript{rise} + t\textsubscript{fall}) ×
f\textsubscript{sw}\\
= 0.5 × 48 × 20 × (15 + 20) × 10⁻⁹ × 250,000\\
= 480 × 35 × 10⁻⁹ × 250,000 = \textbf{4.20 W}

(c) Gate drive loss:\\
P\textsubscript{gate} = Q\textsubscript{g} × V\textsubscript{GS} ×
f\textsubscript{sw} = 45 × 10⁻⁹ × 10 × 250,000 = \textbf{0.11 W}

(d) Total power dissipation:\\
P\textsubscript{total} = 0.80 + 4.20 + 0.11 = \textbf{5.11 W}

Switching losses dominate (82\% of total), which is typical for
high-voltage converters.\\
Reducing switching losses requires either lower frequency (increases
inductor size) or a MOSFET with lower Q\textsubscript{g} (which
typically has higher R\textsubscript{DS(on)} --- the classic
R\textsubscript{DS(on)} × Q\textsubscript{g} figure of merit trade-off).

\end{examplebox}

\section{3.6 Voltage Regulators}\label{voltage-regulators-1}

Voltage regulators maintain a stable DC output voltage despite
variations in input voltage or load current. Linear regulators (such as
the LM7805 and LDO types) operate by dissipating excess voltage as heat
across a series pass element, offering low noise and simplicity but with
efficiency limited to the ratio of output to input voltage. Switching
regulators (buck, boost, and buck-boost topologies) use an inductor,
switch, and diode to convert voltage levels with efficiencies typically
exceeding 85-95\%, but introduce switching noise that must be filtered.
The choice between linear and switching regulators involves trade-offs
between efficiency, noise, cost, board space, and thermal management
requirements.

\subsection{3.6.1 Linear Regulators}\label{linear-regulators}

Fixed three-terminal linear regulators such as the LM78xx series
(positive output) and LM79xx series (negative output) are the simplest
voltage regulation solution --- the LM7805 provides a fixed 5 V output,
the LM7812 provides 12 V, and so on. These regulators require a minimum
input-to-output voltage difference (dropout voltage) of approximately 2
V to maintain regulation. Low-Dropout regulators (LDOs) reduce this
requirement to as little as 100-300 mV by using a PMOS or PNP pass
transistor instead of the NPN Darlington configuration used in the 78xx
series. LDOs are essential in battery-powered devices where every
millivolt of headroom matters, and in noise-sensitive analog circuits
where switching regulator ripple is unacceptable. Key LDO specifications
include dropout voltage, output noise (typically 10-100
μV\textsubscript{rms}), power supply rejection ratio (PSRR, 40-80 dB),
quiescent current (10 μA to 5 mA), and load/line transient response.

\begin{examplebox}

\textbf{Example 3.6.1:} A linear regulator powers a 3.3 V, 500 mA
microcontroller circuit from a 5.0 V USB supply. Compare (a) an
LM1117-3.3 LDO (dropout voltage = 1.2 V at 500 mA) and (b) a standard
LM317 configured for 3.3 V (dropout voltage = 2.0 V). For each,
determine the power dissipation, efficiency, and whether a heat sink is
required (assume a maximum junction temperature of 125°C, ambient
temperature of 40°C, and thermal resistance θ\textsubscript{JA} = 50°C/W
for SOT-223 package).

\textbf{Solution:}

(a) LM1117-3.3 LDO:\\
Input-output differential: ΔV = 5.0 − 3.3 = 1.7 V (\textgreater{} 1.2 V
dropout, so it regulates)\\
Power dissipation: P\textsubscript{D} = ΔV × I\textsubscript{out} = 1.7
× 0.5 = \textbf{0.85 W}\\
Efficiency: η = V\textsubscript{out}/V\textsubscript{in} = 3.3/5.0 =
\textbf{66.0\%}\\
Junction temperature: T\textsubscript{J} = T\textsubscript{A} +
P\textsubscript{D} × θ\textsubscript{JA} = 40 + 0.85 × 50 =
\textbf{82.5°C} (no heat sink needed)

(b) LM317 (adjustable, set to 3.3 V):\\
Required minimum input: V\textsubscript{in\_min} = 3.3 + 2.0 = 5.3 V\\
At V\textsubscript{in} = 5.0 V, the differential is only 1.7 V
\textless{} 2.0 V dropout --- the LM317 \textbf{cannot regulate} at this
input voltage.\\
It would require V\textsubscript{in} ≥ 5.3 V.\\
If supplied from a 7.0 V source instead: P\textsubscript{D} = (7.0 −
3.3) × 0.5 = \textbf{1.85 W}\\
Efficiency: η = 3.3/7.0 = \textbf{47.1\%}\\
T\textsubscript{J} = 40 + 1.85 × 50 = 132.5°C --- \textbf{exceeds 125°C
limit}, a heat sink is required.

This demonstrates why LDOs are preferred when the input-output
differential is small.

\end{examplebox}

\subsection{3.6.2 TI TL431 Programmable
Reference}\label{ti-tl431-programmable-reference}

The Texas Instruments TL431 is a programmable precision shunt voltage
regulator capable of operating over a range of approximately 2.5 V to 36
V. It functions as a voltage-controlled current sink: two external
resistors form a voltage divider that sets the output voltage by feeding
a fraction of it back to the TL431's reference input, and the device
adjusts its sink current to maintain that set voltage at its cathode.
The TL431 is widely used in the feedback network of isolated switch-mode
power supplies (SMPS), where it works with an optocoupler to regulate
the output voltage across the isolation boundary. It also serves as a
precision voltage reference, overvoltage clamp, and constant-current
source in a variety of power management and signal conditioning
circuits.

\begin{examplebox}

\textbf{Example 3.6.2:} A TL431 is used to regulate the output of a
power supply to 12.0 V. The TL431 internal reference voltage is
V\textsubscript{ref} = 2.495 V. The feedback network consists of two
resistors forming a voltage divider from the output to the TL431
reference pin. If R₂ (lower resistor, from reference pin to ground) is
chosen as 10 kΩ, determine the required value of R₁ (upper resistor,
from output to reference pin), and calculate the cathode current if a
100 Ω series resistor connects a 15 V supply to the cathode (anode
grounded).

\textbf{Solution:}\\
At regulation, the voltage at the reference pin equals
V\textsubscript{ref}:\\
V\textsubscript{ref} = V\textsubscript{out} × R₂ / (R₁ + R₂)\\
Solving for R₁:\\
R₁ = R₂ × (V\textsubscript{out} / V\textsubscript{ref} − 1) = 10,000 ×
(12.0 / 2.495 − 1) = 10,000 × (4.81 − 1) = 10,000 × 3.81\\
R₁ = \textbf{38.1 kΩ} (use 38.3 kΩ or a 36 kΩ + 2.2 kΩ series
combination for 38.2 kΩ)

Verify: V\textsubscript{out} = V\textsubscript{ref} × (R₁ + R₂) / R₂ =
2.495 × (38,200 + 10,000) / 10,000 = 2.495 × 4.82 = 12.03 V (close to
12.0 V)

Cathode current (TL431 acts as a shunt regulator sinking current to
maintain 12.0 V):\\
The divider current: I\textsubscript{divider} = V\textsubscript{out} /
(R₁ + R₂) = 12.0 / (38,200 + 10,000) = 12.0 / 48,200 = 0.249 mA\\
This is the reference pin bias current.\\
The cathode current depends on the external circuit driving the
cathode.\\
If a series resistor R\textsubscript{series} = 100 Ω is placed between a
15 V supply and the cathode:\\
I\textsubscript{K} = (V\textsubscript{supply} − V\textsubscript{out}) /
R\textsubscript{series} = (15 − 12) / 100 = \textbf{30 mA}

\end{examplebox}

\section{3.7 Semiconductor Fabrication}\label{semiconductor-fabrication}

Semiconductor fabrication transforms raw silicon into integrated
circuits through hundreds of precisely controlled process steps
performed in cleanroom environments. A modern fab (fabrication facility)
costs \$10--20 billion to build and operates at Class 1 cleanliness
(fewer than 1 particle per cubic foot larger than 0.5 μm). The
fabrication process involves repeated cycles of deposition, patterning,
etching, and doping to build up the transistor structures and
interconnect layers that form a complete IC. Understanding these
processes is essential for device engineers who design within
manufacturing constraints and for process engineers who optimize yield
and performance at each technology node.

\subsection{3.7.1 Crystal Growth and Wafer
Preparation}\label{crystal-growth-and-wafer-preparation}

The starting material for most semiconductor devices is a single-crystal
silicon ingot grown by the Czochralski (CZ) method: a seed crystal is
dipped into a crucible of molten silicon (at 1,414°C) and slowly pulled
upward while rotating, forming a cylindrical ingot of single-crystal
silicon up to 300 mm in diameter and 2 meters long. The pull rate and
rotation speed control the crystal diameter and defect density. For
ultra-high-purity applications (power devices, radiation detectors), the
float-zone (FZ) method passes a molten zone along a polycrystalline rod,
achieving resistivities above 10,000 Ω·cm by eliminating crucible
contamination. The ingot is sliced into wafers 0.775 mm thick (for 300
mm diameter), polished to sub-nanometer surface roughness, and cleaned.
Wafer crystal orientation --- (100) for CMOS (lower surface state
density) or (111) for bipolar --- affects device performance through
surface carrier mobility and oxidation rates.

\begin{examplebox}

\textbf{Example 3.7.1:} A 300 mm diameter silicon wafer is used to
fabricate ICs with die dimensions of 15 mm × 15 mm. Estimate the maximum
number of dies per wafer, accounting for edge exclusion of 3 mm.

\textbf{Solution:}\\
Usable wafer area: π × (D/2 − edge)² = π × (150 − 3)² = π × 147² =
\textbf{67,890 mm²}.

Die area: 15 × 15 = 225 mm².

Approximate dies: 67,890/225 = 301.7 ≈ 302.

Edge loss correction (dies crossing wafer boundary): subtract
approximately π × D/(die diagonal).\\
Die diagonal = √(15² + 15²) = 21.2 mm.\\
Edge dies lost ≈ π × 294/21.2 ≈ 43.6.

Estimated good dies: 302 − 44 = \textbf{\textasciitilde258 dies per
wafer}.\\
At a yield of 90\%, approximately 232 functional dies would be produced.

\end{examplebox}

\subsection{3.7.2 Lithography and
Patterning}\label{lithography-and-patterning}

Lithography transfers circuit patterns from a photomask onto the wafer
surface using light-sensitive photoresist. The process involves coating
the wafer with photoresist, exposing it through a photomask (or reticle)
using a stepper or scanner, and developing the exposed resist to create
the pattern. The minimum feature size is governed by the Rayleigh
criterion: CD\textsubscript{min} = k₁ × λ/NA, where λ is the exposure
wavelength, NA is the numerical aperture of the projection lens, and k₁
is a process-dependent factor (theoretical minimum 0.25, practical range
0.3--0.4).

Deep ultraviolet (DUV) lithography at 193 nm with immersion (water
between lens and wafer, NA ≈ 1.35) has been the workhorse from 65 nm
down to 7 nm nodes, using multi-patterning techniques (double and
quadruple patterning) to print features smaller than the single-exposure
resolution limit. Extreme ultraviolet (EUV) lithography at 13.5 nm uses
reflective optics (no lens materials are transparent at this wavelength)
and tin-droplet plasma light sources generating over 250 watts of EUV
power. EUV enables single-exposure patterning at 7 nm and below,
eliminating the cost and complexity of multi-patterning, and is
essential for 5 nm, 3 nm, and 2 nm nodes. High-NA EUV (NA = 0.55 vs
standard 0.33) extends EUV to sub-2 nm features.

\begin{examplebox}

\textbf{Example 3.7.2:} Compare the minimum feature size achievable with
DUV immersion lithography (λ = 193 nm, NA = 1.35, k₁ = 0.30) versus
standard EUV lithography (λ = 13.5 nm, NA = 0.33, k₁ = 0.30).

\textbf{Solution:}\\
DUV: CD\textsubscript{min} = 0.30 × 193/1.35 = \textbf{42.9 nm} (single
exposure).\\
To reach 7 nm node features (\textasciitilde30 nm metal pitch),
multi-patterning with 2--4 exposures per layer is required.

EUV: CD\textsubscript{min} = 0.30 × 13.5/0.33 = \textbf{12.3 nm} (single
exposure).\\
This resolves 7 nm and 5 nm features directly, and high-NA EUV (NA =
0.55) would achieve 0.30 × 13.5/0.55 = \textbf{7.4 nm}, enabling 2 nm
node patterning.

\end{examplebox}

\subsection{3.7.3 Doping and Ion
Implantation}\label{doping-and-ion-implantation}

Ion implantation is the primary method for introducing dopant atoms into
silicon with precise control of dose (atoms/cm²) and depth profile.
Dopant ions (boron for P-type, phosphorus or arsenic for N-type) are
accelerated to energies of 1 keV to 3 MeV and directed into the wafer
surface. The implanted ions follow an approximately Gaussian depth
distribution with a projected range R\textsubscript{p} and standard
deviation ΔR\textsubscript{p}, both determined by the ion species and
acceleration energy. Higher energy yields deeper implants; higher dose
increases the peak concentration. After implantation, the crystal
lattice is damaged by the ion collisions, so a thermal anneal (typically
rapid thermal annealing at 900--1,100°C for 1--30 seconds) is required
to repair the lattice and electrically activate the dopant atoms.

Thermal diffusion, the older doping method, uses a high-temperature
furnace (900--1,200°C) to drive dopant atoms from a surface source into
the bulk. The diffusion profile follows Fick's second law, producing a
complementary error function (erfc) profile for
constant-surface-concentration diffusion or a Gaussian profile for
limited-source diffusion. The junction depth x\textsubscript{j} where
the diffused dopant concentration equals the background doping is
approximately x\textsubscript{j} ≈ 2√(Dt), where D is the diffusion
coefficient (cm²/s) and t is the diffusion time.

\begin{examplebox}

\textbf{Example 3.7.3:} Phosphorus is diffused into a P-type silicon
substrate (N\textsubscript{A} = 10¹⁶ cm⁻³) at 1,000°C for 30 minutes.
The diffusion coefficient of phosphorus in silicon at 1,000°C is D = 2.5
× 10⁻¹⁴ cm²/s. The surface concentration is N\textsubscript{s} = 10²⁰
cm⁻³. Estimate the junction depth.

\textbf{Solution:}\\
Diffusion length: √(Dt) = √(2.5 × 10⁻¹⁴ × 1,800) = √(4.5 × 10⁻¹¹) = 6.71
× 10⁻⁶ cm = 0.0671 μm.

For a complementary error function profile, the junction occurs where
N(x\textsubscript{j}) = N\textsubscript{A}:\\
N\textsubscript{s} × erfc(x\textsubscript{j}/(2√(Dt))) =
N\textsubscript{A}.\\
erfc(x\textsubscript{j}/(2 × 0.0671 μm)) = 10¹⁶/10²⁰ = 10⁻⁴.

From erfc tables: erfc(2.75) ≈ 10⁻⁴, so x\textsubscript{j}/(2 × 0.0671)
= 2.75.\\
x\textsubscript{j} = 2.75 × 0.1342 = \textbf{0.369 μm}.\\
This shallow junction is typical of source/drain implants in submicron
CMOS processes.

\end{examplebox}

\subsection{3.7.4 Etching and Deposition}\label{etching-and-deposition}

Etching selectively removes material to transfer lithographic patterns
into underlying films. Wet etching uses chemical solutions (e.g.,
buffered HF for SiO₂, KOH for silicon) and is isotropic (etches equally
in all directions), limiting its use to features larger than
\textasciitilde1 μm. Dry etching --- primarily reactive ion etching
(RIE) --- uses plasma-generated reactive species in a vacuum chamber to
achieve anisotropic (directional) etching with nearly vertical
sidewalls, essential for sub-100 nm features. Etch selectivity (the
ratio of etch rates between the target material and the underlying layer
or photoresist) must be high enough to stop precisely at the intended
depth.

Thin-film deposition builds up the layers of an IC. Chemical vapor
deposition (CVD) uses gas-phase chemical reactions to deposit films:
LPCVD (low-pressure) for polysilicon and silicon nitride, PECVD
(plasma-enhanced) for SiO₂ and SiN\textsubscript{x} at lower
temperatures compatible with metal layers. Physical vapor deposition
(PVD/sputtering) deposits metal films (aluminum, titanium, tantalum) by
bombarding a target with argon ions. Atomic layer deposition (ALD)
deposits films one atomic layer at a time with self-limiting surface
reactions, achieving angstrom-level thickness control essential for
high-k gate dielectrics (HfO₂) and ultrathin barrier layers at advanced
nodes.

\begin{examplebox}

\textbf{Example 3.7.4:} An RIE process etches SiO₂ at a rate of 200
nm/min and the underlying silicon at 10 nm/min. A 500 nm SiO₂ film must
be completely removed. Calculate (a) the etch time, (b) the selectivity
ratio, and (c) the silicon loss if a 20\% overetch is applied.

\textbf{Solution:}

(a) Etch time: 500/200 = \textbf{2.5 minutes}.

(b) Selectivity: SiO₂ rate / Si rate = 200/10 = \textbf{20:1}.

(c) With 20\% overetch: additional time = 0.20 × 2.5 = 0.5 min.\\
Silicon loss = 10 × 0.5 = \textbf{5 nm}.\\
This is acceptable for most processes but would be significant for
ultra-thin body SOI devices where the silicon layer may be only 5--10 nm
thick.

\end{examplebox}

\subsection{3.7.5 CMOS Process
Integration}\label{cmos-process-integration}

A CMOS (Complementary Metal-Oxide-Semiconductor) process fabricates both
NMOS and PMOS transistors on the same substrate, enabling logic gates
that consume near-zero static power. The twin-well process begins with a
lightly doped substrate and forms separate N-wells (for PMOS) and
P-wells (for NMOS) through ion implantation and diffusion. Shallow
trench isolation (STI) fills etched trenches with SiO₂ to electrically
isolate adjacent transistors. The gate stack --- traditionally
polysilicon on SiO₂ --- has been replaced at 45 nm and below by
high-k/metal gate (HKMG), using HfO₂ (k ≈ 25 vs 3.9 for SiO₂) and metal
gates (TiN, TaN) to reduce gate leakage while maintaining high
capacitance.

The front-end-of-line (FEOL) builds the transistors: gate patterning,
source/drain implantation with halo and extension implants, silicide
formation (NiSi) for low-resistance contacts. The back-end-of-line
(BEOL) connects transistors with multiple metal interconnect layers
(10--15 layers at advanced nodes), using copper dual-damascene
processing with low-k dielectrics (k ≈ 2.5--3.0) to minimize RC delay.
Design rules specify minimum metal width, spacing, via sizes, and
density requirements that ensure manufacturability and yield.

\begin{examplebox}

\textbf{Example 3.7.5:} A 7 nm CMOS process has a gate pitch of 54 nm, a
minimum metal pitch of 36 nm, and 13 BEOL metal layers. The gate
capacitance is 1.2 fF/μm and the total interconnect capacitance for a
typical logic gate output is 3.5 fF. With a supply voltage of 0.75 V and
an NMOS drive current of 1.1 mA/μm, estimate the gate switching delay.

\textbf{Solution:}\\
Gate delay ≈ C\textsubscript{total} × V\textsubscript{DD} /
I\textsubscript{drive}.

For a minimum-size inverter with W\textsubscript{n} = 0.054 μm (one gate
pitch):\\
C\textsubscript{gate} = 1.2 × 0.054 = 0.065 fF. C\textsubscript{total} =
C\textsubscript{gate} + C\textsubscript{interconnect} = 0.065 + 3.5 =
3.565 fF.

I\textsubscript{drive} = 1.1 × 0.054 = 0.0594 mA = 59.4 μA.

Gate delay = 3.565 × 10⁻¹⁵ × 0.75 / (59.4 × 10⁻⁶) = \textbf{45 ps}.\\
At advanced nodes, interconnect capacitance dominates (98\% of total),
making BEOL optimization critical for performance.

\end{examplebox}

\subsection{3.7.6 Advanced Nodes and Future
Directions}\label{advanced-nodes-and-future-directions}

As planar MOSFETs scaled below 20 nm, short-channel effects
(drain-induced barrier lowering, subthreshold leakage) became
unmanageable with conventional gate structures. The industry
transitioned to three-dimensional transistor architectures that improve
electrostatic control of the channel:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Architecture
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Nodes
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Gate Contact
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Limitation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Planar MOSFET & \textgreater22 nm & Top only & Simple, low cost & High
leakage below 22 nm \\
FinFET (tri-gate) & 22--5 nm & Three sides of fin & 3× leakage reduction
vs planar & Fin width quantization limits flexibility \\
GAA Nanosheet & 3--2 nm & All four sides of sheet & Adjustable channel
width per sheet & Complex process, stacked sheet stress \\
CFET (complementary FET) & \textless2 nm & Stacked NMOS over PMOS &
\textasciitilde30\% area reduction vs GAA & Extreme process
complexity \\
\end{longtable}
}

FinFETs, introduced by Intel at 22 nm in 2012, wrap the gate around
three sides of a tall, narrow silicon fin, dramatically reducing leakage
current and improving drive current at low supply voltages.
Gate-all-around (GAA) nanosheet transistors, adopted at 3 nm by Samsung
and at 2 nm by TSMC, stack multiple horizontal silicon nanosheets with
the gate surrounding all four sides, providing better electrostatic
control and the flexibility to adjust drive strength by varying
nanosheet width.

Beyond transistor architecture, advanced packaging is reshaping IC
design. Chiplets decompose a large monolithic die into smaller
functional tiles (compute, I/O, memory) fabricated at different process
nodes and assembled using 2.5D (silicon interposer) or 3D (direct die
stacking with hybrid bonding) integration. Through-silicon vias (TSVs)
and micro-bumps provide vertical interconnects, while the Universal
Chiplet Interconnect Express (UCIe) standard enables multi-vendor
chiplet interoperability. High Bandwidth Memory (HBM) stacks DRAM dies
using TSVs to achieve bandwidths exceeding 1 TB/s. Backside power
delivery networks (BSPDN) route power through the back of the wafer,
freeing the front-side BEOL for signal routing and reducing IR drop by
30--50\%.

\begin{examplebox}

\textbf{Example 3.7.6:} A 7 nm FinFET process achieves a transistor
density of 91 million transistors per mm². A 3 nm GAA nanosheet process
achieves 292 million transistors per mm². A processor design requires 12
billion transistors. Calculate the die area at each node and the
percentage area reduction from 7 nm to 3 nm.

\textbf{Solution:}\\
7 nm die area: 12 × 10⁹ / (91 × 10⁶) = \textbf{131.9 mm²}.

3 nm die area: 12 × 10⁹ / (292 × 10⁶) = \textbf{41.1 mm²}.

Area reduction: (131.9 − 41.1)/131.9 × 100 = \textbf{68.8\%}.\\
Alternatively, the same 131.9 mm² die at 3 nm could hold 131.9 × 292 ×
10⁶ = 38.5 billion transistors --- enabling significantly more compute
capability or allowing a smaller, cheaper die for equivalent
functionality.

\end{examplebox}

\chapter{Chapter 4}\label{chapter-4}

\chapter{Control Systems}\label{control-systems}

Control systems engineering deals with the analysis and design of
systems that regulate the behavior of dynamic processes to achieve
desired performance objectives. A control system takes a reference input
(the desired output), compares it to the actual output, and applies
corrective action to minimize the difference. Control theory provides
the mathematical tools --- including transfer functions, frequency
response, and state-space methods --- to model system dynamics, assess
stability, and design controllers that meet specifications for accuracy,
speed of response, and robustness to disturbances.

\section{4.1 Open Loop}\label{open-loop}

An open-loop control system operates without feedback from the output to
the input, meaning the controller has no knowledge of the actual system
response. The input command is applied directly to the actuator, and the
output is entirely dependent on the accuracy of the system model and the
absence of disturbances. Because there is no mechanism to detect or
correct errors, open-loop systems are inherently sensitive to parameter
variations, external disturbances, and modeling inaccuracies. These
systems are simpler and less expensive to implement, making them
suitable for applications where the relationship between input and
output is well characterized and disturbances are minimal, such as a
toaster or a washing machine timer. The transfer function of an
open-loop system is simply the forward path transfer function G(s), and
the output C(s) = G(s) × R(s), where R(s) is the reference input.

\begin{examplebox}

\textbf{Example 4.1:} An open-loop motor speed controller has a forward
path transfer function G(s) = 50 / (s + 10). A unit step input R(s) =
1/s is applied. Find the steady-state output speed.

\textbf{Solution:}\\
The output is C(s) = G(s) × R(s) = 50 / {[}s(s + 10){]}.\\
Using partial fractions: C(s) = 5/s - 5/(s + 10).\\
Taking the inverse Laplace transform: c(t) = 5 - 5e\^{}(-10t).\\
As t approaches infinity, the exponential term decays to zero, so the
steady-state output = 5.\\
If unity gain (output = reference) were desired, the error would be 1 −
5 = −4 --- the system over-drives by a factor of 5 with no mechanism to
detect or correct the discrepancy, illustrating the fundamental
limitation of open-loop control.

\end{examplebox}

\section{4.2 Closed Loop}\label{closed-loop}

A closed-loop control system, also known as a feedback control system,
continuously measures the output and compares it to the desired
reference input to generate an error signal. This error signal is then
processed by the controller to adjust the actuator input, driving the
output toward the desired value and reducing the effect of disturbances
and parameter variations. The canonical form of a closed-loop system
with unity feedback has a transfer function of G(s) / (1 + G(s)H(s)),
where G(s) is the forward path transfer function and H(s) is the
feedback path transfer function. Closed-loop systems offer superior
performance in terms of accuracy, stability, and disturbance rejection
compared to open-loop systems, at the cost of increased complexity and
the potential for instability if not properly designed. Stability
analysis techniques such as Routh-Hurwitz criteria, root locus plots,
and Bode plots are essential tools for designing closed-loop systems
that meet transient and steady-state performance specifications.

\begin{examplebox}

\textbf{Example 4.2:} A unity feedback closed-loop system (H(s) = 1) has
a forward path transfer function G(s) = 100 / {[}s(s + 5){]}. Determine
the closed-loop transfer function and the steady-state error to a unit
step input.

\textbf{Solution:}\\
The closed-loop transfer function is T(s) = G(s) / {[}1 + G(s)H(s){]} =
{[}100 / s(s + 5){]} / {[}1 + 100 / s(s + 5){]} = 100 / (s² + 5s +
100).\\
For a unit step input R(s) = 1/s, the steady-state error is
e\textsubscript{ss} = 1 / (1 + K\textsubscript{p}), where the position
error constant K\textsubscript{p} = lim(s-\textgreater0) G(s) =
lim(s-\textgreater0) 100 / {[}s(s + 5){]} = infinity.\\
Therefore e\textsubscript{ss} = 1 / (1 + infinity) = 0.\\
The closed-loop system with a Type 1 open-loop transfer function has
zero steady-state error to a step input, demonstrating the superior
accuracy of feedback control.

\end{examplebox}

\section{4.3 Control Signals}\label{control-signals}

Control signals are standardized test inputs used to characterize and
analyze the dynamic behavior of control systems. By applying known input
signals and observing the system response, engineers can evaluate
performance metrics such as rise time, settling time, overshoot, and
steady-state error. The following are the most common control signals
used in control system analysis.

\subsection{4.3.1 Step Input}\label{step-input}

The unit step function u(t) transitions instantaneously from zero to a
constant value at time t = 0. Its Laplace transform is 1/s. The step
input is the most widely used test signal because it simultaneously
excites the transient and steady-state behavior of a system. The step
response reveals key performance characteristics including rise time,
peak overshoot, settling time, and steady-state error. In practice, many
real-world disturbances resemble sudden changes, making the step
response a practical measure of how a system handles abrupt input
changes.

\begin{examplebox}

\textbf{Example 4.3.1:} A first-order system has the transfer function
G(s) = 20 / (s + 4). Determine the steady-state value and the time
constant from the unit step response.

\textbf{Solution:}\\
For a unit step input R(s) = 1/s, the output is C(s) = 20 / {[}s(s +
4){]}.\\
Using partial fractions: C(s) = 5/s - 5/(s + 4).\\
The time-domain response is c(t) = 5(1 - e\^{}(-4t)).\\
The time constant τ = 1/4 = 0.25 s (the system reaches 63.2\% of its
final value in 0.25 s).\\
The steady-state value is c(infinity) = 5.\\
The settling time (to within 2\%) is approximately 4τ = 1.0 s.

\end{examplebox}

\subsection{4.3.2 Ramp Input}\label{ramp-input}

The ramp function r(t) = t × u(t) increases linearly with time, and its
Laplace transform is 1/s². A ramp input tests the ability of a system to
track a continuously changing reference, which is important in
applications such as antenna tracking systems or CNC machine tool
positioning. The steady-state error to a ramp input is characterized by
the velocity error constant K\textsubscript{v}, where a higher
K\textsubscript{v} indicates better tracking performance. A Type 0
system (no free integrators in the open-loop transfer function) will
have an unbounded steady-state error to a ramp input, while a Type 1
system will exhibit a finite constant error.

\begin{examplebox}

\textbf{Example 4.3.2:} A unity feedback system has an open-loop
transfer function G(s) = 200 / {[}s(s + 10)(s + 20){]}. Determine the
steady-state error for a unit ramp input r(t) = t.

\textbf{Solution:}\\
This is a Type 1 system (one free integrator in G(s)).\\
The velocity error constant is K\textsubscript{v} = lim(s-\textgreater0)
s * G(s) = lim(s-\textgreater0) s * 200 / {[}s(s + 10)(s + 20){]} = 200
/ (10 * 20) = 1.\\
The steady-state error to a ramp input is e\textsubscript{ss} = 1 /
K\textsubscript{v} = 1 / 1 = 1.\\
The system tracks the ramp with a constant position lag of 1 unit behind
the reference.

\end{examplebox}

\subsection{4.3.3 Impulse Input}\label{impulse-input}

The unit impulse function δ(t) is an idealized signal of infinite
amplitude and infinitesimal duration with unit area, and its Laplace
transform is simply 1. The impulse response is mathematically
significant because it is the inverse Laplace transform of the system
transfer function itself, meaning the impulse response completely
characterizes a linear time-invariant (LTI) system. Any output of an LTI
system can be obtained by convolving the impulse response with the input
signal. While a true impulse cannot be generated physically, it can be
approximated by a short-duration, high-amplitude pulse.

\begin{examplebox}

\textbf{Example 4.3.3:} A system has the transfer function G(s) = 10 /
(s² + 3s + 2). Find the impulse response g(t).

\textbf{Solution:}\\
Factor the denominator: G(s) = 10 / {[}(s + 1)(s + 2){]}.\\
Using partial fractions: G(s) = 10/(s + 1) - 10/(s + 2).\\
Since the impulse response is the inverse Laplace transform of G(s)
itself (because R(s) = 1 for an impulse), g(t) = 10e\^{}(-t) -
10e\^{}(-2t) for t \textgreater= 0.\\
At t = 0, g(0) = 10 - 10 = 0.\\
The peak occurs when dg/dt = -10e\^{}(-t) + 20e\^{}(-2t) = 0, giving
e\^{}(t) = 2, so t = ln(2) = 0.693 s.\\
The peak value is g(0.693) = 10(0.5) - 10(0.25) = 2.5.

\end{examplebox}

\subsection{4.3.4 Sinusoidal Input}\label{sinusoidal-input}

A sinusoidal input of the form A × sin(ω × t) is used for frequency
response analysis, which is fundamental to control system design using
Bode plots, Nyquist plots, and Nichols charts. When a sinusoidal input
is applied to a stable LTI system, the steady-state output is also
sinusoidal at the same frequency but with a different amplitude and
phase shift determined by the system transfer function evaluated at s =
j*ω. The frequency response reveals the system bandwidth, resonant
peaks, gain margin, and phase margin, all of which are critical
parameters for assessing relative stability and designing compensators.
Frequency domain methods are particularly valuable because they allow
engineers to design controllers using experimentally measured data
without requiring an explicit mathematical model of the plant.

\begin{examplebox}

\textbf{Example 4.3.4:} A stable system has the transfer function G(s) =
5 / (s + 2). A sinusoidal input r(t) = 3 sin(4t) is applied. Find the
steady-state output.

\textbf{Solution:}\\
Evaluate G(s) at s = jω where ω = 4 rad/s: G(j4) = 5 / (j4 + 2) = 5 / (2
+ j4).\\
The magnitude is \textbar G(j4)\textbar{} = 5 / sqrt(2² + 4²) = 5 /
sqrt(20) = 5 / (2sqrt(5)) = sqrt(5)/2 = 1.118.\\
The phase angle is φ = -arctan(4/2) = -arctan(2) = -63.43 degrees.\\
The steady-state output is y\textsubscript{ss}(t) = 3 * 1.118 * sin(4t -
63.43 degrees) = 3.354 sin(4t - 63.43 degrees).\\
The output has the same frequency as the input but with an amplitude
scaled by \textbar G(j4)\textbar{} and a phase lag of 63.43 degrees.

\end{examplebox}

\section{4.4 Transfer Functions and Block
Diagrams}\label{transfer-functions-and-block-diagrams}

Transfer functions and block diagrams are the primary tools for modeling
and analyzing linear time-invariant (LTI) control systems. A transfer
function expresses the input-output relationship of a system in the
Laplace domain as a ratio of polynomials, while block diagrams provide a
graphical representation of signal flow through interconnected
subsystems. Together, they enable systematic analysis and design of
complex control systems by breaking them into manageable components.

\subsection{4.4.1 Transfer Function
Representation}\label{transfer-function-representation}

The transfer function H(s) of an LTI system is defined as the ratio of
the Laplace transform of the output Y(s) to the Laplace transform of the
input X(s), assuming zero initial conditions: H(s) = Y(s)/X(s) =
(b\textsubscript{m}s\textsuperscript{m} +
b\textsubscript{m−1}s\textsuperscript{m−1} + \ldots{} + b₀) /
(a\textsubscript{n}s\textsuperscript{n} +
a\textsubscript{n−1}s\textsuperscript{n−1} + \ldots{} + a₀). The roots
of the numerator polynomial are called zeros and the roots of the
denominator polynomial are called poles. The poles determine the
stability and natural response modes of the system: poles in the left
half of the s-plane produce decaying responses (stable), poles on the
imaginary axis produce sustained oscillations (marginally stable), and
poles in the right half produce growing responses (unstable).

The order of a system is the highest power of s in the denominator,
which equals the number of energy storage elements in the physical
system. First-order systems have one pole and are characterized by their
time constant τ and DC gain K. Second-order systems have two poles and
are characterized by natural frequency ω\textsubscript{n} and damping
ratio ζ, which together determine the transient behavior --- overdamped
(ζ \textgreater{} 1), critically damped (ζ = 1), underdamped (0
\textless{} ζ \textless{} 1), or undamped (ζ = 0).

\begin{examplebox}

\textbf{Example 4.4.1:} A system has the transfer function H(s) = 50(s +
3) / (s² + 8s + 25). Determine (a) the poles and zeros, (b) the natural
frequency and damping ratio, (c) the DC gain, and (d) whether the system
is stable.

\textbf{Solution:}

(a) Zero: s + 3 = 0 → s = −3 (one zero at s = −3).\\
Poles: s² + 8s + 25 = 0 → s = (−8 ± √(64 − 100))/2 = (−8 ± j6)/2 =
\textbf{−4 ± j3} (complex conjugate poles).

(b) Standard form: s² + 2ζω\textsubscript{n}s + ω\textsubscript{n}² = s²
+ 8s + 25.\\
ω\textsubscript{n} = √25 = \textbf{5 rad/s}, 2ζω\textsubscript{n} = 8,
so ζ = 8/(2×5) = \textbf{0.8} (underdamped).

(c) DC gain: H(0) = 50(3)/25 = \textbf{6}

(d) Both poles are at s = −4 ± j3, which have negative real parts (left
half-plane). The system is \textbf{stable}.

\end{examplebox}

\subsection{4.4.2 Block Diagram Algebra}\label{block-diagram-algebra}

Block diagrams represent control systems as interconnected blocks, where
each block contains a transfer function and arrows indicate signal flow
direction. The three fundamental interconnections are series (cascade),
parallel, and feedback. In a series connection, the overall transfer
function is the product of individual transfer functions: H(s) = H₁(s) ×
H₂(s). In a parallel connection, the outputs are summed: H(s) = H₁(s) +
H₂(s). In a negative feedback configuration, the closed-loop transfer
function is H(s) = G(s) / (1 + G(s)H(s)), where G(s) is the forward path
and H(s) is the feedback path.

Block diagram reduction simplifies complex diagrams to a single
equivalent transfer function using systematic rules: moving summing
junctions and pickoff points, eliminating feedback loops, and combining
series/parallel blocks. The reduction process preserves the overall
input-output relationship while progressively simplifying the diagram.
For systems with multiple inputs and outputs, superposition applies ---
each input is considered independently while setting all other inputs to
zero, and the total output is the sum of individual contributions.

\begin{examplebox}

\textbf{Example 4.4.2:} A control system has a forward path with two
series blocks G₁(s) = 10/(s + 2) and G₂(s) = 1/(s + 5), a unity feedback
path H(s) = 1, and a disturbance D(s) entering between G₁ and G₂.
Determine (a) the closed-loop transfer function Y(s)/R(s), (b) the
disturbance transfer function Y(s)/D(s), and (c) the steady-state
response to a unit step disturbance.

\textbf{Solution:}

(a) Forward path: G(s) = G₁(s) × G₂(s) = 10 / {[}(s + 2)(s + 5){]}.\\
Closed-loop: Y(s)/R(s) = G(s) / (1 + G(s)) = 10 / {[}(s + 2)(s + 5) +
10{]} = \textbf{10 / (s² + 7s + 20)}

(b) For disturbance D entering between G₁ and G₂:\\
Y(s)/D(s) = G₂(s) / (1 + G₁(s)G₂(s)) = (s + 2) / {[}(s + 2)(s + 5) +
10{]} = \textbf{(s + 2) / (s² + 7s + 20)}

(c) Steady-state response to unit step disturbance: y\textsubscript{ss}
= lim(s→0) s × {[}Y(s)/D(s){]} × (1/s) = (0 + 2)/(0 + 0 + 20) =
\textbf{0.1}. The feedback reduces the disturbance effect from what
would be G₂(0) = 0.2 in open-loop to 0.1 --- a factor of 2 attenuation.

\end{examplebox}

\subsection{4.4.3 Signal Flow Graphs}\label{signal-flow-graphs}

Signal flow graphs (SFGs) provide an alternative to block diagrams for
representing system interconnections, using nodes for signals and
directed branches for transfer functions. Mason's gain formula computes
the overall transfer function directly from the graph without sequential
reduction: T(s) = (1/Δ) × Σ P\textsubscript{k}Δ\textsubscript{k}, where
P\textsubscript{k} is the gain of the k-th forward path, Δ = 1 − (sum of
individual loop gains) + (sum of products of non-touching loop gains
taken two at a time) − \ldots, and Δ\textsubscript{k} is the cofactor
for the k-th forward path (Δ evaluated with all loops touching that path
removed).

SFGs are particularly useful when there are multiple forward paths and
multiple feedback loops, where block diagram reduction would require
many steps. The key terminology includes: a forward path is any path
from input to output that does not pass through any node more than once,
and a loop is a closed path that starts and ends at the same node.

\begin{examplebox}

\textbf{Example 4.4.3:} A system has the signal flow graph with: input R
to node X₁ with gain 1, X₁ to X₂ with gain G₁ = 5, X₂ to output Y with
gain G₂ = 2, X₂ to X₁ with gain H₁ = −0.5 (feedback loop 1), and Y to X₁
with gain H₂ = −0.1 (feedback loop 2). Apply Mason's gain formula to
find Y/R.

\textbf{Solution:}\\
Forward path: P₁ = 1 × G₁ × G₂ = 1 × 5 × 2 = 10.

Loop gains:\\
L₁ = G₁ × H₁ = 5 × (−0.5) = −2.5 (loop: X₁ → X₂ → X₁)\\
L₂ = G₁ × G₂ × H₂ = 5 × 2 × (−0.1) = −1.0 (loop: X₁ → X₂ → Y → X₁)

Non-touching loops: L₁ and L₂ share nodes X₁ and X₂, so they are
touching. No non-touching pairs.

Graph determinant: Δ = 1 − (L₁ + L₂) = 1 − (−2.5 − 1.0) = 1 + 3.5 = 4.5.

Cofactor: Δ₁ = 1 (all loops touch the forward path).

\textbf{Y/R = P₁Δ₁/Δ = 10 × 1 / 4.5 = 2.22}

\end{examplebox}

\section{4.5 Time-Domain Performance}\label{time-domain-performance}

Time-domain performance specifications define how a control system
responds to standard test inputs, particularly the unit step. These
specifications provide quantitative criteria for evaluating and
comparing controller designs and are directly related to the system's
pole locations in the s-plane.

\begin{figure}[H]

\hypertarget{fig-4-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch04_step_response.png}

\caption{Figure 4.5: Step Response: Second-Order System}

\end{figure}

\subsection{4.5.1 First-Order System
Response}\label{first-order-system-response}

A first-order system has the standard form transfer function G(s) = K /
(τs + 1), where K is the DC gain and τ is the time constant. The unit
step response is c(t) = K(1 − e\textsuperscript{−t/τ}), which rises
monotonically toward the final value K without overshoot. The time
constant τ is the time to reach 63.2\% of the final value, and the
system reaches 95\% at 3τ, 98\% at 4τ, and 99.3\% at 5τ. The rise time
(10\% to 90\%) is t\textsubscript{r} = 2.2τ, and the 2\% settling time
is t\textsubscript{s} = 4τ.

First-order systems appear in many practical applications: thermal
systems (heating/cooling), RC circuits, first-order chemical reactions,
and liquid level systems. The frequency response of a first-order system
has a single break frequency at ω = 1/τ, beyond which the magnitude
rolls off at −20 dB/decade.

\begin{examplebox}

\textbf{Example 4.5.1:} A temperature control system has a transfer
function G(s) = 80 / (25s + 1), where the input is heater power
(0-100\%) and the output is temperature in °C. Determine (a) the
steady-state temperature for 50\% heater input, (b) the time constant,
(c) the time to reach 95\% of final temperature, and (d) the 10-90\%
rise time.

\textbf{Solution:}

(a) DC gain K = 80, so for 50\% input: T\textsubscript{ss} = 80 × 0.5 =
\textbf{40°C}

(b) Time constant: τ = \textbf{25 seconds}

(c) Time to 95\%: t = 3τ = 3 × 25 = \textbf{75 seconds}

(d) Rise time: t\textsubscript{r} = 2.2τ = 2.2 × 25 = \textbf{55
seconds}

\end{examplebox}

\subsection{4.5.2 Second-Order System
Response}\label{second-order-system-response}

The standard second-order system has transfer function G(s) =
ω\textsubscript{n}² / (s² + 2ζω\textsubscript{n}s +
ω\textsubscript{n}²), where ω\textsubscript{n} is the undamped natural
frequency and ζ is the damping ratio. The damping ratio determines the
character of the step response: for ζ \textless{} 1 (underdamped), the
system oscillates with decaying amplitude, with the damped frequency
ω\textsubscript{d} = ω\textsubscript{n}√(1 − ζ²). The key performance
specifications are:

\begin{itemize}
\tightlist
\item
  \textbf{Rise time}: t\textsubscript{r} ≈ (1.8 − 0.2ζ) /
  ω\textsubscript{n} for underdamped systems (approximate)
\item
  \textbf{Peak time}: t\textsubscript{p} = π / ω\textsubscript{d} = π /
  (ω\textsubscript{n}√(1 − ζ²))
\item
  \textbf{Percent overshoot}: \%OS = 100 ×
  e\textsuperscript{−ζπ/√(1−ζ²)}
\item
  \textbf{Settling time} (2\%): t\textsubscript{s} ≈ 4 /
  (ζω\textsubscript{n})
\end{itemize}

These specifications create competing demands: reducing overshoot
requires increasing ζ, but this also increases rise time. The poles of
the second-order system are at s = −ζω\textsubscript{n} ±
jω\textsubscript{n}√(1 − ζ²), and lines of constant ζ are radial lines
from the origin, while lines of constant ω\textsubscript{n} are circles
centered at the origin.

\begin{examplebox}

\textbf{Example 4.5.2:} A servo motor position control system has a
closed-loop transfer function G(s) = 900 / (s² + 24s + 900). Determine
(a) ω\textsubscript{n} and ζ, (b) the percent overshoot, (c) the peak
time, (d) the 2\% settling time, and (e) the pole locations.

\textbf{Solution:}

(a) Comparing with ω\textsubscript{n}² = 900 and 2ζω\textsubscript{n} =
24:\\
ω\textsubscript{n} = 30 rad/s, ζ = 24/(2×30) = \textbf{0.4}
(underdamped).

(b) \%OS = 100 × e\textsuperscript{−0.4π/√(1−0.16)} = 100 ×
e\textsuperscript{−0.4π/0.9165} = 100 × e\textsuperscript{−1.371} = 100
× 0.254 = \textbf{25.4\%}

(c) ω\textsubscript{d} = 30√(1 − 0.16) = 30 × 0.9165 = 27.49 rad/s.\\
t\textsubscript{p} = π/ω\textsubscript{d} = π/27.49 = \textbf{0.114 s}

(d) t\textsubscript{s} = 4/(ζω\textsubscript{n}) = 4/(0.4 × 30) = 4/12 =
\textbf{0.333 s}

(e) Poles: s = −12 ± j27.49 = \textbf{−12 ± j27.5}

\end{examplebox}

\subsection{4.5.3 Steady-State Error}\label{steady-state-error}

Steady-state error is the difference between the desired reference input
and the actual output as time approaches infinity. For unity feedback
systems, the steady-state error depends on the system type number (the
number of free integrators in the open-loop transfer function) and the
type of input signal. The error constants --- position constant
K\textsubscript{p}, velocity constant K\textsubscript{v}, and
acceleration constant K\textsubscript{a} --- quantify the steady-state
tracking capability:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
System Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Step Error (1/1+K\textsubscript{p})
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ramp Error (1/K\textsubscript{v})
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Parabola Error (1/K\textsubscript{a})
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Type 0 & 1/(1+K\textsubscript{p}) & ∞ & ∞ \\
Type 1 & 0 & 1/K\textsubscript{v} & ∞ \\
Type 2 & 0 & 0 & 1/K\textsubscript{a} \\
\end{longtable}
}

where K\textsubscript{p} = lim(s→0) G(s), K\textsubscript{v} = lim(s→0)
sG(s), and K\textsubscript{a} = lim(s→0) s²G(s).

\begin{examplebox}

\textbf{Example 4.5.3:} A unity feedback system has G(s) = 500(s + 2) /
{[}s²(s + 10)(s + 25){]}. Determine (a) the system type, (b) the
appropriate error constant, and (c) the steady-state error for an input
r(t) = 3t² (a parabolic input with magnitude 3).

\textbf{Solution:}

(a) G(s) has two free integrators (s² in the denominator), so this is a
\textbf{Type 2} system.

(b) For a Type 2 system, the relevant error constant for a parabolic
input is:\\
K\textsubscript{a} = lim(s→0) s²G(s) = lim(s→0) s² ×
500(s+2)/{[}s²(s+10)(s+25){]} = 500(2)/(10×25) = \textbf{4}

(c) For a parabolic input r(t) = (A/2)t², where A = 6 (since r(t) = 3t²
= (6/2)t²):\\
e\textsubscript{ss} = A/K\textsubscript{a} = 6/4 = \textbf{1.5}

\end{examplebox}

\section{4.6 PID Control}\label{pid-control}

The Proportional-Integral-Derivative (PID) controller is the most widely
used controller in industrial process control, found in over 90\% of
control loops. The PID controller computes a control signal u(t) based
on the error e(t) = r(t) − y(t) as: u(t) = K\textsubscript{p}e(t) +
K\textsubscript{i}∫e(τ)dτ + K\textsubscript{d}(de/dt), where
K\textsubscript{p} is the proportional gain, K\textsubscript{i} is the
integral gain, and K\textsubscript{d} is the derivative gain. In the
Laplace domain, the PID transfer function is G\textsubscript{c}(s) =
K\textsubscript{p} + K\textsubscript{i}/s + K\textsubscript{d}s.

\subsection{4.6.1 Proportional Control}\label{proportional-control}

Proportional control generates a corrective action directly proportional
to the error signal: u(t) = K\textsubscript{p} × e(t). Increasing
K\textsubscript{p} reduces steady-state error and speeds up the
response, but excessively high gain leads to oscillations and eventual
instability. For a Type 0 system with proportional control, the
steady-state error to a step input is e\textsubscript{ss} = 1/(1 +
K\textsubscript{p}G(0)), which can be made small but never zero.
Proportional control alone cannot eliminate steady-state error to a step
input in a Type 0 system, which is a fundamental limitation that
motivates the addition of integral action.

\begin{examplebox}

\textbf{Example 4.6.1:} A proportional controller with gain
K\textsubscript{p} controls a plant G(s) = 1/(s + 4) in a unity feedback
configuration. Determine (a) the closed-loop transfer function, (b) the
steady-state error to a unit step for K\textsubscript{p} = 20, and (c)
the value of K\textsubscript{p} that yields a 2\% settling time of 0.5
s.

\textbf{Solution:}

(a) Closed-loop: T(s) = K\textsubscript{p}G(s) / (1 +
K\textsubscript{p}G(s)) = K\textsubscript{p} / (s + 4 +
K\textsubscript{p}) = \textbf{K\textsubscript{p} / (s + 4 +
K\textsubscript{p})}

(b) Position error constant: K\textsubscript{pos} = lim(s→0)
K\textsubscript{p}G(s) = lim(s→0) K\textsubscript{p}/(s+4) = 20/4 = 5.\\
e\textsubscript{ss} = 1/(1 + K\textsubscript{pos}) = 1/(1 + 5) =
\textbf{0.167} (16.7\% error)

(c) This is first-order with pole at s = −(4 + K\textsubscript{p}). Time
constant τ = 1/(4 + K\textsubscript{p}).\\
Settling time: t\textsubscript{s} = 4τ = 4/(4 + K\textsubscript{p}) =
0.5 s → 4 + K\textsubscript{p} = 8 → K\textsubscript{p} = \textbf{4}

\end{examplebox}

\subsection{4.6.2 Integral Control}\label{integral-control}

Integral control adds a term proportional to the accumulated error over
time: u\textsubscript{i}(t) = K\textsubscript{i}∫e(τ)dτ. The integral
action introduces a pole at s = 0 (a free integrator) in the controller,
which increases the system type by one. This guarantees zero
steady-state error for step inputs in systems that would otherwise have
finite error with proportional control alone. However, the additional
phase lag (−90° at all frequencies) from the integrator reduces the
phase margin and can destabilize the system if K\textsubscript{i} is too
large.

Integral windup is a practical problem that occurs when the actuator
saturates (reaches its physical limits) while the integral term
continues to accumulate error. When the error eventually changes sign,
the large accumulated integral must unwind before the controller can
respond appropriately, causing excessive overshoot. Anti-windup
strategies include clamping the integrator, conditionally disabling
integration during saturation, and back-calculation methods.

\begin{examplebox}

\textbf{Example 4.6.2:} A PI controller (K\textsubscript{p} = 5,
K\textsubscript{i} = 10) controls a plant G(s) = 2/(s + 1) with unity
feedback. Determine (a) the open-loop transfer function, (b) the system
type, (c) the steady-state error to a unit ramp, and (d) the closed-loop
poles.

\textbf{Solution:}

(a) Controller: G\textsubscript{c}(s) = K\textsubscript{p} +
K\textsubscript{i}/s = (5s + 10)/s.\\
Open-loop: G\textsubscript{OL}(s) = G\textsubscript{c}(s) × G(s) = 2(5s
+ 10) / {[}s(s + 1){]} = \textbf{(10s + 20) / {[}s(s + 1){]}}

(b) One free integrator in the open-loop → \textbf{Type 1} system
(proportional-only was Type 0).

(c) K\textsubscript{v} = lim(s→0) s × (10s + 20)/{[}s(s + 1){]} = 20/1 =
20.\\
e\textsubscript{ss} = 1/K\textsubscript{v} = 1/20 = \textbf{0.05} (5\%
position lag for a ramp).

(d) Closed-loop characteristic equation: s(s + 1) + 10s + 20 = s² + 11s
+ 20 = 0.\\
s = (−11 ± √(121 − 80))/2 = (−11 ± √41)/2 = (−11 ± 6.40)/2 =
\textbf{−2.30 and −8.70} (both stable, overdamped).

\end{examplebox}

\subsection{4.6.3 Derivative Control}\label{derivative-control}

Derivative control adds a term proportional to the rate of change of the
error: u\textsubscript{d}(t) = K\textsubscript{d} × de/dt. Derivative
action anticipates future error by responding to its rate of change,
providing a damping effect that reduces overshoot and improves transient
response. In the frequency domain, the derivative term introduces a zero
at s = 0, adding positive phase shift that can improve the phase margin.
However, derivative control amplifies high-frequency noise, so a
first-order low-pass filter is typically applied: the practical
derivative term becomes K\textsubscript{d}s / (τ\textsubscript{f}s + 1),
where τ\textsubscript{f} is a small filter time constant (typically
τ\textsubscript{f} = K\textsubscript{d}/(8 to 20 × K\textsubscript{p})).

Derivative control is never used alone because it provides no corrective
action for constant errors. It is always combined with proportional
control (PD) or proportional-integral control (PID). The effect of
derivative action is often described as ``applying the brakes'' --- it
opposes rapid changes in the error, slowing the approach to the setpoint
and reducing overshoot.

\begin{examplebox}

\textbf{Example 4.6.3:} A PD controller (K\textsubscript{p} = 50,
K\textsubscript{d} = 5) controls a plant G(s) = 1/(s² + 2s). Determine
(a) the closed-loop transfer function, (b) the natural frequency and
damping ratio, (c) the percent overshoot, and (d) compare to
proportional-only control (K\textsubscript{d} = 0).

\textbf{Solution:}

(a) PD controller: G\textsubscript{c}(s) = 50 + 5s.\\
Closed-loop: T(s) = (5s + 50)/(s² + 2s + 5s + 50) = \textbf{(5s +
50)/(s² + 7s + 50)}

(b) ω\textsubscript{n} = √50 = 7.07 rad/s, 2ζω\textsubscript{n} = 7, ζ =
7/(2 × 7.07) = \textbf{0.495}

(c) \%OS = 100 × e\textsuperscript{−0.495π/√(1−0.245)} = 100 ×
e\textsuperscript{−0.495π/0.869} = 100 × e\textsuperscript{−1.789} =
\textbf{16.7\%}

(d) With K\textsubscript{d} = 0 (P-only): T(s) = 50/(s² + 2s + 50), ζ =
2/(2 × 7.07) = 0.141.\\
\%OS = 100 × e\textsuperscript{−0.141π/0.990} = 100 ×
e\textsuperscript{−0.447} = 64.0\%.\\
The derivative action reduced overshoot from \textbf{64.0\% to 16.7\%}
by increasing the damping ratio from 0.141 to 0.495.

\end{examplebox}

\subsection{4.6.4 PID Tuning}\label{pid-tuning}

PID tuning determines the values of K\textsubscript{p},
K\textsubscript{i}, and K\textsubscript{d} that achieve satisfactory
closed-loop performance. The Ziegler-Nichols method is the most
well-known empirical tuning approach, available in two forms. The first
method (step response) applies a step input to the open-loop plant and
measures the reaction curve parameters: the dead time L and the time
constant T from the maximum slope tangent line. The second method
(ultimate gain) increases K\textsubscript{p} with K\textsubscript{i} =
K\textsubscript{d} = 0 until sustained oscillations occur at the
ultimate gain K\textsubscript{u} with period P\textsubscript{u}.

Ziegler-Nichols ultimate gain tuning rules:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Controller
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
K\textsubscript{p}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
K\textsubscript{i}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
K\textsubscript{d}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
P & 0.5 K\textsubscript{u} & --- & --- \\
PI & 0.45 K\textsubscript{u} & 0.54
K\textsubscript{u}/P\textsubscript{u} & --- \\
PID & 0.6 K\textsubscript{u} & 1.2 K\textsubscript{u}/P\textsubscript{u}
& 0.075 K\textsubscript{u}P\textsubscript{u} \\
\end{longtable}
}

These rules typically produce a response with 25\% overshoot and are
used as a starting point for further manual refinement. Other tuning
methods include Cohen-Coon, internal model control (IMC), and
software-based optimization using performance criteria such as ITAE
(Integral of Time-weighted Absolute Error).

\begin{examplebox}

\textbf{Example 4.6.4:} A temperature control loop has an ultimate gain
of K\textsubscript{u} = 8.5 and an ultimate period of P\textsubscript{u}
= 12 s. Using the Ziegler-Nichols ultimate gain method, determine the
PID parameters and the resulting controller transfer function.

\textbf{Solution:}\\
K\textsubscript{p} = 0.6 × K\textsubscript{u} = 0.6 × 8.5 =
\textbf{5.1}\\
K\textsubscript{i} = 1.2 × K\textsubscript{u} / P\textsubscript{u} = 1.2
× 8.5 / 12 = \textbf{0.85 s⁻¹}\\
K\textsubscript{d} = 0.075 × K\textsubscript{u} × P\textsubscript{u} =
0.075 × 8.5 × 12 = \textbf{7.65 s}

Controller transfer function:\\
G\textsubscript{c}(s) = 5.1 + 0.85/s + 7.65s = \textbf{(7.65s² + 5.1s +
0.85) / s}

The integral time T\textsubscript{i} =
K\textsubscript{p}/K\textsubscript{i} = 5.1/0.85 = 6.0 s and derivative
time T\textsubscript{d} = K\textsubscript{d}/K\textsubscript{p} =
7.65/5.1 = 1.5 s, consistent with the alternative Ziegler-Nichols form:
T\textsubscript{i} = P\textsubscript{u}/2 = 6.0 s and T\textsubscript{d}
= P\textsubscript{u}/8 = 1.5 s.

\end{examplebox}

\section{4.7 Stability Analysis}\label{stability-analysis}

Stability is the most fundamental requirement of any control system ---
an unstable system produces unbounded outputs and is useless or
dangerous. A linear time-invariant system is stable if all poles of its
closed-loop transfer function lie in the open left half of the s-plane
(negative real parts). Stability analysis methods determine whether a
system is stable and how much margin exists before instability, without
necessarily computing the exact pole locations.

\subsection{4.7.1 Routh-Hurwitz
Criterion}\label{routh-hurwitz-criterion}

The Routh-Hurwitz criterion determines the number of closed-loop poles
in the right half-plane (RHP) by examining the coefficients of the
characteristic polynomial without solving for the roots. For a
characteristic equation a\textsubscript{n}s\textsuperscript{n} +
a\textsubscript{n−1}s\textsuperscript{n−1} + \ldots{} + a₁s + a₀ = 0,
the Routh array is constructed as a triangular table. A necessary
condition for stability is that all coefficients have the same sign. The
sufficient condition is that all entries in the first column of the
Routh array are positive --- the number of sign changes in the first
column equals the number of RHP poles.

Special cases arise when a first-column element is zero (replace with a
small positive ε and proceed) or when an entire row is zero (indicating
symmetric roots about the origin, such as a pair of purely imaginary
poles). The Routh criterion is especially useful for determining the
range of a parameter (such as controller gain K) for which the system
remains stable.

\begin{examplebox}

\textbf{Example 4.7.1:} A unity feedback system has the open-loop
transfer function G(s) = K / {[}s(s + 2)(s + 5){]}. Determine the range
of K for stability using the Routh-Hurwitz criterion.

\textbf{Solution:}\\
Closed-loop characteristic equation: s³ + 7s² + 10s + K = 0.

Routh array:\\
\textbar{} s³ \textbar{} 1 \textbar{} 10 \textbar{}\\
\textbar{} s² \textbar{} 7 \textbar{} K \textbar{}\\
\textbar{} s¹ \textbar{} (70 − K)/7 \textbar{} 0 \textbar{}\\
\textbar{} s⁰ \textbar{} K \textbar{} \textbar{}

For stability, all first-column entries must be positive:\\
- s³: 1 \textgreater{} 0 ✓\\
- s²: 7 \textgreater{} 0 ✓\\
- s¹: (70 − K)/7 \textgreater{} 0 → K \textless{} 70\\
- s⁰: K \textgreater{} 0

Range of K for stability: \textbf{0 \textless{} K \textless{} 70}. At K
= 70, the s¹ row becomes zero, indicating purely imaginary poles
(sustained oscillation at the boundary of stability).

\end{examplebox}

\subsection{4.7.2 Root Locus}\label{root-locus}

The root locus is a graphical method that shows how the closed-loop
poles of a system move in the s-plane as a parameter (typically the loop
gain K) varies from 0 to infinity. For a system with open-loop transfer
function KG(s)H(s), the closed-loop poles satisfy 1 + KG(s)H(s) = 0, and
the root locus is the set of all points s where the angle of G(s)H(s)
equals ±180°(2k+1). Key construction rules include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The root locus starts at the open-loop poles (K = 0) and ends at the
  open-loop zeros (K → ∞)
\item
  The number of branches equals the number of open-loop poles
\item
  Branches on the real axis lie to the left of an odd number of real
  poles and zeros
\item
  Asymptotes approach angles of (2k+1) × 180°/(n−m) at the centroid
  σ\textsubscript{a} = (Σpoles − Σzeros)/(n−m)
\item
  Breakaway/break-in points occur where dK/ds = 0
\end{enumerate}

The root locus reveals how gain affects stability (does the locus cross
the imaginary axis?), transient response (do the poles move toward
higher or lower damping?), and the presence of conditionally stable
regions.

\begin{examplebox}

\textbf{Example 4.7.2:} Plot the root locus for G(s)H(s) = 1/{[}s(s +
3)(s + 5){]} and determine (a) the asymptote angles and centroid, (b)
the breakaway point, and (c) the imaginary axis crossing (gain and
frequency at which the system becomes unstable).

\textbf{Solution:}\\
Open-loop poles: 0, −3, −5 (n = 3 poles, m = 0 zeros).

(a) Asymptote angles: (2k+1) × 180°/3 = \textbf{60°, 180°, 300°}\\
Centroid: σ\textsubscript{a} = (0 − 3 − 5)/3 = \textbf{−2.67}

(b) Characteristic equation: K = −s(s+3)(s+5) = −(s³ + 8s² + 15s).\\
dK/ds = −(3s² + 16s + 15) = 0 → s = (−16 ± √(256−180))/6 = (−16 ±
8.72)/6.\\
Breakaway point (on locus, between 0 and −3): s = (−16 + 8.72)/6 =
\textbf{−1.21}

(c) Applying the Routh--Hurwitz criterion to the characteristic equation
s³ + 8s² + 15s + K = 0:\\
Routh s¹ row: (8×15 − K)/8 = (120 − K)/8 = 0 → K = \textbf{120}.\\
Auxiliary equation at K = 120: 8s² + 120 = 0 → s = ±j√15 =
\textbf{±j3.87 rad/s}.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-4-7-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch04_root_locus.png}

\caption{Figure 4.7.2: Root Locus Plot}

\end{figure}

\section{4.8 Frequency Response Design}\label{frequency-response-design}

Frequency response methods analyze and design control systems using the
system's response to sinusoidal inputs across a range of frequencies.
These methods are powerful because they can be applied using
experimentally measured data (no mathematical model required), they
provide direct insight into bandwidth, stability margins, and noise
rejection, and they form the basis for designing lead, lag, and lead-lag
compensators.

\begin{figure}[H]

\hypertarget{fig-4-8}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch04_bode_plot.png}

\caption{Figure 4.8: Bode Plot: Second-Order System}

\end{figure}

\subsection{4.8.1 Bode Plots}\label{bode-plots}

Bode plots consist of two graphs: magnitude (in dB) versus frequency
(log scale) and phase (in degrees) versus frequency (log scale). They
are constructed by factoring the transfer function into standard forms
and using straight-line approximations. The basic building blocks are: a
constant gain K (flat line at 20 log₁₀\textbar K\textbar{} dB), a pole
at the origin (−20 dB/decade slope, −90° phase), a zero at the origin
(+20 dB/decade, +90°), a real pole at s = −a (−20 dB/decade above ω = a,
−45°/decade phase centered at ω = a), and a real zero (mirror image of a
pole). Complex conjugate poles produce a resonant peak near
ω\textsubscript{n} with height dependent on ζ.

The bandwidth ω\textsubscript{BW} (the frequency where the magnitude
drops to −3 dB from its DC value) is directly related to the speed of
the closed-loop response: roughly ω\textsubscript{BW} ≈
4/(t\textsubscript{s}ζ) for second-order systems. Larger bandwidth means
faster response but also greater susceptibility to high-frequency noise.

\begin{examplebox}

\textbf{Example 4.8.1:} Construct the Bode magnitude and phase
asymptotic plots for G(s) = 100(s + 10) / {[}s(s + 100){]} and determine
(a) the gain crossover frequency, (b) the DC slope, and (c) the
high-frequency slope.

\textbf{Solution:}\\
Rewrite in standard form: G(s) = 100 × 10 × (s/10 + 1) / {[}s × 100 ×
(s/100 + 1){]} = 10(s/10 + 1) / {[}s(s/100 + 1){]}.

DC gain factor: 10 → 20 dB. Corner frequencies: ω₁ = 10 rad/s (zero), ω₂
= 100 rad/s (pole).

(a) Magnitude at frequency ω: \textbar G(jω)\textbar{} = 10/ω for ω
\textless{} 10 (slope −20 dB/dec). At ω = 10: gain = 10/10 = 1 = 0 dB.
The zero at ω = 10 flattens the slope to 0 dB/dec. At ω = 100, the pole
resumes −20 dB/dec. Gain crossover (0 dB): occurs at \textbf{ω = 10
rad/s} where the magnitude first crosses 0 dB.

(b) DC slope: −20 dB/decade (due to the 1/s pole at origin).

(c) High-frequency slope (ω \textgreater\textgreater{} 100): \textbf{−20
dB/decade} (one pole at origin + one zero + one pole = net −20 dB/dec).

\end{examplebox}

\subsection{4.8.2 Gain and Phase Margins}\label{gain-and-phase-margins}

Gain margin (GM) and phase margin (PM) are quantitative measures of how
close a stable system is to instability. The gain margin is the amount
of additional gain (in dB) needed at the phase crossover frequency
(where the phase equals −180°) to make the system unstable. The phase
margin is the amount of additional phase lag (in degrees) needed at the
gain crossover frequency (where the magnitude equals 0 dB) to reach
−180°. Adequate stability margins typically require GM ≥ 6 dB and PM ≥
30-60°.

For second-order systems, the phase margin is directly related to the
damping ratio: PM ≈ 100ζ for ζ \textless{} 0.7, or more precisely ζ ≈
PM/100 for PM \textless{} 70°. This provides a direct connection between
frequency-domain specifications and time-domain performance. A system
with a phase margin of 45° will have a damping ratio of approximately
0.45 and about 20\% overshoot.

\begin{examplebox}

\textbf{Example 4.8.2:} A unity feedback system has G(s) = 50 / {[}s(s +
2)(s + 10){]}. Determine (a) the gain crossover frequency, (b) the phase
margin, (c) the phase crossover frequency, and (d) the gain margin.

\textbf{Solution:}

(a) At gain crossover, \textbar G(jω)\textbar{} = 1:\\
50 / {[}ω × √(ω² + 4) × √(ω² + 100){]} = 1.\\
Simplify: 2,500 = ω²(ω² + 4)(ω² + 100). Trial: ω = 2: 4 × 8 × 104 =
3,328 (too high). ω = 2.2: 4.84 × 8.84 × 104.84 = 4,487 (too high). ω =
1.8: 3.24 × 7.24 × 103.24 = 2,422 (close). By interpolation,
ω\textsubscript{gc} ≈ \textbf{1.82 rad/s}.

(b) Phase at ω\textsubscript{gc}: ∠G(j1.82) = −90° − arctan(1.82/2) −
arctan(1.82/10) = −90° − 42.3° − 10.3° = −142.6°.\\
PM = 180° − 142.6° = \textbf{37.4°} (adequate but modest).

(c) Phase crossover (∠G = −180°): −90° − arctan(ω/2) − arctan(ω/10) =
−180°.\\
arctan(ω/2) + arctan(ω/10) = 90°. This occurs when (ω/2)(ω/10) = 1 → ω²
= 20 → ω\textsubscript{pc} = \textbf{4.47 rad/s}.

(d) \textbar G(j4.47)\textbar{} = 50/(4.47 × √(20+4) × √(20+100)) =
50/(4.47 × 4.90 × 10.95) = 50/239.8 = 0.2085 = −13.6 dB.\\
GM = \textbf{13.6 dB} (comfortable margin).

\end{examplebox}

\subsection{4.8.3 Nyquist Criterion}\label{nyquist-criterion}

The Nyquist stability criterion uses the open-loop frequency response
G(jω)H(jω) plotted as a polar curve (the Nyquist plot) to determine
closed-loop stability. The criterion states: the number of closed-loop
RHP poles Z equals the number of open-loop RHP poles P plus the number
of clockwise encirclements N of the critical point (−1, 0): Z = P + N.
For a stable open-loop system (P = 0), the closed-loop system is stable
if and only if the Nyquist plot does not encircle the (−1, 0) point.

The Nyquist criterion is more general than the Routh-Hurwitz criterion
because it handles time delays (which introduce infinite-order
characteristic equations), open-loop unstable systems, and systems
defined only by measured frequency response data. The distance from the
Nyquist curve to the (−1, 0) point relates to the gain and phase
margins, and the inverse of this minimum distance is the sensitivity
peak M\textsubscript{s}, which should typically be kept below 2 (6 dB).

\begin{examplebox}

\textbf{Example 4.8.3:} An open-loop stable system has G(jω)H(jω) that
passes through the real axis at −0.4 when ω = 5 rad/s. The Nyquist plot
makes zero clockwise encirclements of (−1, 0). Determine (a) whether the
closed-loop system is stable, (b) the gain margin, and (c) the maximum
additional gain before instability.

\textbf{Solution:}

(a) P = 0 (open-loop stable), N = 0 (no encirclements).\\
Z = P + N = 0. The closed-loop system is \textbf{stable} (no RHP poles).

(b) The Nyquist plot crosses the negative real axis at −0.4. The gain
margin is the factor by which the gain could be increased before the
plot passes through (−1, 0):\\
GM = 1/0.4 = 2.5 = 20 log₁₀(2.5) = \textbf{7.96 dB}

(c) The system becomes unstable when the gain is multiplied by 2.5, so
the maximum additional gain is a factor of \textbf{2.5} (or 7.96 dB
above the current gain).

\end{examplebox}

\subsection{4.8.4 Lead-Lag Compensation}\label{lead-lag-compensation}

A lead compensator has the transfer function G\textsubscript{c}(s) =
K\textsubscript{c}(s + z)/(s + p) where p \textgreater{} z, placing the
zero closer to the origin than the pole. The lead network contributes
positive phase shift near the geometric mean frequency
ω\textsubscript{m} = √(zp), which increases the phase margin and
improves transient response. The maximum phase lead is
φ\textsubscript{max} = arcsin((p − z)/(p + z)), and the attenuation
factor α = z/p \textless{} 1 determines the amount of phase boost
available (smaller α gives more phase lead but requires more gain
compensation).

A lag compensator uses the same form but with z \textgreater{} p,
placing the pole closer to the origin. The lag network boosts
low-frequency gain to reduce steady-state error without significantly
affecting the phase margin at the crossover frequency, provided the lag
corner frequencies are placed well below the gain crossover. A lead-lag
compensator combines both networks to simultaneously improve transient
response (via lead) and steady-state accuracy (via lag). The design
procedure typically involves: (1) set K\textsubscript{c} to meet the
steady-state error requirement, (2) determine the additional phase lead
needed at the desired crossover frequency, (3) compute α = (1 − sin
φ\textsubscript{max})/(1 + sin φ\textsubscript{max}), and (4) place the
compensator zero and pole symmetrically around the crossover frequency.

\begin{examplebox}

\textbf{Example 4.8.4:} A unity feedback system has G(s) = 20 / {[}s(s +
2){]}. The current phase margin is insufficient. Design a lead
compensator to achieve a phase margin of 45° at a gain crossover
frequency of ω\textsubscript{gc} = 5 rad/s.

\textbf{Solution:}\\
Current phase at ω = 5: ∠G(j5) = −90° − arctan(5/2) = −90° − 68.2° =
−158.2°. Current PM = 180° − 158.2° = 21.8°.

Additional phase needed: 45° − 21.8° + 5° (safety margin) = 28.2°.

Compute α: α = (1 − sin 28.2°)/(1 + sin 28.2°) = (1 − 0.4726)/(1 +
0.4726) = 0.527/1.473 = \textbf{0.358}.

Compensator zero and pole: z = ω\textsubscript{gc}√α = 5 × 0.598 = 2.99
rad/s, p = ω\textsubscript{gc}/√α = 5/0.598 = 8.36 rad/s.

Gain adjustment: \textbar G(j5)\textbar{} = 20/(5 × √(29)) = 20/26.93 =
0.743. The lead compensator attenuation at ω\textsubscript{gc} is √α =
0.598, so K\textsubscript{c} = 1/(0.743 × 0.598) = \textbf{2.25}.

Lead compensator: G\textsubscript{c}(s) = 2.25(s + 2.99)/(s + 8.36).
Verification: new PM ≈ 21.8° + 28.2° = \textbf{50°} (exceeds 45° target
due to the 5° safety margin).

\end{examplebox}

\section{4.9 State-Space
Representation}\label{state-space-representation}

State-space representation describes a system using a set of first-order
differential equations rather than a single higher-order transfer
function. This formulation handles multiple-input multiple-output (MIMO)
systems naturally, accommodates initial conditions, and provides a
framework for modern control design methods including optimal control,
adaptive control, and robust control.

\subsection{4.9.1 State-Space Model}\label{state-space-model}

The state-space model consists of two matrix equations: the state
equation ẋ(t) = Ax(t) + Bu(t) and the output equation y(t) = Cx(t) +
Du(t), where x is the n×1 state vector, u is the m×1 input vector, y is
the p×1 output vector, A is the n×n system matrix, B is the n×m input
matrix, C is the p×n output matrix, and D is the p×m feedthrough matrix.
The state variables represent the minimum set of variables that
completely describe the system's internal condition --- typically
quantities associated with energy storage elements (inductor currents,
capacitor voltages, position, velocity).

The transfer function can be recovered from the state-space model as
H(s) = C(sI − A)⁻¹B + D. The eigenvalues of the A matrix are the system
poles, and the system is stable if all eigenvalues have negative real
parts. A key advantage of the state-space approach is that internal
system behavior (not visible at the output) can be analyzed through the
state variables, enabling detection and control of internal
instabilities that transfer-function methods might miss.

\begin{examplebox}

\textbf{Example 4.9.1:} An RLC circuit has the state-space model with
states x₁ = capacitor voltage and x₂ = inductor current, where L = 0.5
H, C = 0.1 F, R = 3 Ω, input u = source voltage, and output y =
capacitor voltage. Write the state-space matrices and determine the
eigenvalues.

\textbf{Solution:}\\
From the circuit equations: L(dx₂/dt) = u − Rx₂ − x₁ and C(dx₁/dt) = x₂.

State equation:\\
ẋ₁ = (1/C)x₂ = 10x₂\\
ẋ₂ = (−1/L)x₁ − (R/L)x₂ + (1/L)u = −2x₁ − 6x₂ + 2u

\textbf{A} = {[}0, 10; −2, −6{]}, \textbf{B} = {[}0; 2{]}, \textbf{C} =
{[}1, 0{]}, \textbf{D} = {[}0{]}

Eigenvalues: det(sI − A) = s(s + 6) + 20 = s² + 6s + 20 = 0.\\
s = (−6 ± √(36 − 80))/2 = (−6 ± j6.63)/2 = \textbf{−3 ± j3.32}

Both eigenvalues have negative real parts → system is \textbf{stable}.
The natural frequency is ω\textsubscript{n} = √20 = 4.47 rad/s and
damping ratio ζ = 3/4.47 = 0.671.

\end{examplebox}

\subsection{4.9.2 Controllability and
Observability}\label{controllability-and-observability}

Controllability determines whether it is possible to drive the system
from any initial state to any desired final state in finite time using
the available inputs. A system is controllable if and only if the
controllability matrix C\textsubscript{M} = {[}B, AB, A²B, \ldots,
A\textsuperscript{n−1}B{]} has full rank (rank n). If a system is not
fully controllable, some state variables cannot be influenced by the
input, and the system's behavior in those modes is dictated entirely by
initial conditions.

Observability determines whether the system's internal states can be
uniquely determined from measurements of the output over a finite time
interval. A system is observable if and only if the observability matrix
O\textsubscript{M} = {[}C; CA; CA²; \ldots; CA\textsuperscript{n−1}{]}
has full rank. A system that is both controllable and observable can be
fully controlled and monitored using feedback, and it has a minimal
realization (the transfer function representation captures all system
dynamics).

\begin{examplebox}

\textbf{Example 4.9.2:} For the RLC circuit from §4.9.1 with A = {[}0,
10; −2, −6{]}, B = {[}0; 2{]}, C = {[}1, 0{]}, determine whether the
system is (a) controllable and (b) observable.

\textbf{Solution:}

(a) Controllability matrix: C\textsubscript{M} = {[}B, AB{]} = {[}{[}0;
2{]}, {[}10×2; −2×0 + (−6)×2{]}{]} = {[}{[}0, 20{]}; {[}2, −12{]}{]}.\\
det(C\textsubscript{M}) = 0×(−12) − 20×2 = −40 ≠ 0. Rank = 2 = n →
\textbf{fully controllable}.

(b) Observability matrix: O\textsubscript{M} = {[}C; CA{]} = {[}{[}1,
0{]}; {[}1×0 + 0×(−2), 1×10 + 0×(−6){]}{]} = {[}{[}1, 0{]}; {[}0,
10{]}{]}.\\
det(O\textsubscript{M}) = 1×10 − 0×0 = 10 ≠ 0. Rank = 2 = n →
\textbf{fully observable}.

Since the system is both controllable and observable, state feedback and
observer-based control designs can be applied.

\end{examplebox}

\subsection{4.9.3 State Feedback Control}\label{state-feedback-control}

State feedback control uses the full state vector to compute the control
input: u(t) = −Kx(t) + r(t), where K is the 1×n feedback gain vector and
r(t) is the reference input. The closed-loop system matrix becomes
A\textsubscript{CL} = A − BK, and the eigenvalues of A\textsubscript{CL}
are the closed-loop poles. If the system is controllable, the gain
vector K can be chosen to place the closed-loop poles at any desired
locations --- this is the pole placement theorem. The Ackermann formula
provides a direct computation: K = {[}0 0 \ldots{} 1{]} ×
C\textsubscript{M}⁻¹ × φ(A), where φ(A) is the desired characteristic
polynomial evaluated at the A matrix.

In practice, not all states are directly measurable, so a state observer
(or estimator) reconstructs the unmeasured states from the output
measurements. The Luenberger observer has the form: x̂̇ = Ax̂ + Bu + L(y −
Cx̂), where L is the observer gain vector chosen so that the estimation
error decays quickly. The separation principle guarantees that the
controller and observer can be designed independently --- the combined
system's poles are the union of the controller poles and observer poles.

\begin{examplebox}

\textbf{Example 4.9.3:} For the RLC circuit with A = {[}0, 10; −2, −6{]}
and B = {[}0; 2{]}, design a state feedback controller to place the
closed-loop poles at s = −5 ± j5 (ζ = 0.707, ω\textsubscript{n} = 7.07
rad/s).

\textbf{Solution:}\\
Desired characteristic polynomial: (s + 5 − j5)(s + 5 + j5) = s² + 10s +
50.

Current characteristic polynomial: s² + 6s + 20.

A\textsubscript{CL} = A − BK where K = {[}k₁, k₂{]}:\\
A − BK = {[}0, 10; −2−2k₁, −6−2k₂{]}.

Characteristic equation: s² + (6 + 2k₂)s + (20 + 20k₁) = s² + 10s + 50.

Matching coefficients:\\
6 + 2k₂ = 10 → k₂ = \textbf{2}\\
20 + 20k₁ = 50 → k₁ = \textbf{1.5}

K = {[}1.5, 2{]}. The control law u(t) = −1.5x₁(t) − 2x₂(t) + r(t)
places the closed-loop poles at s = −5 ± j5, achieving ζ = 0.707
(approximately 4.3\% overshoot) and ω\textsubscript{n} = 7.07 rad/s.

\end{examplebox}

\subsection{4.9.4 Observer Design}\label{observer-design}

When not all state variables are directly measurable, a Luenberger
observer reconstructs the full state vector from the available output
measurements. The observer has the form x̂̇(t) = Ax̂(t) + Bu(t) + L(y(t) −
Cx̂(t)), where x̂ is the estimated state vector and L is the n×1 observer
gain vector. The estimation error e(t) = x(t) − x̂(t) evolves as ė(t) =
(A − LC)e(t), so the observer poles are the eigenvalues of (A − LC). For
the estimation error to decay quickly, the observer poles are typically
placed 3--5 times faster than the controller poles. The system must be
observable (§4.9.2) for arbitrary observer pole placement to be
possible. The separation principle guarantees that the controller gain K
and observer gain L can be designed independently --- the closed-loop
system with observer-based feedback has poles at the union of the
controller poles (eigenvalues of A − BK) and the observer poles
(eigenvalues of A − LC).

\begin{examplebox}

\textbf{Example 4.9.4:} For the RLC circuit from §4.9.1 with A = {[}0,
10; −2, −6{]}, B = {[}0; 2{]}, and C = {[}1, 0{]} (only x₁ is measured),
design an observer to place the observer poles at s = −20 ± j20, which
are approximately 4× faster than the controller poles at s = −5 ± j5
from §4.9.3.

\textbf{Solution:}\\
Desired observer characteristic polynomial: (s + 20 − j20)(s + 20 + j20)
= s² + 40s + 800.

Observer error dynamics matrix: A − LC where L = {[}l₁; l₂{]}:\\
A − LC = {[}0 − l₁, 10; −2 − l₂, −6{]}.

Characteristic equation: s² + (6 + l₁)s + (6l₁ + 10l₂ + 20) = s² + 40s +
800.

Matching coefficients:\\
6 + l₁ = 40 → l₁ = \textbf{34}\\
6(34) + 10l₂ + 20 = 800 → 224 + 10l₂ = 800 → l₂ = \textbf{57.6}

L = {[}34; 57.6{]}. The observer uses the measured output x₁ to
reconstruct x₂, with estimation errors decaying with a time constant of
approximately 1/20 = 0.05 s (compared to the controller's 1/5 = 0.2 s),
ensuring the observer converges well before the controller response
settles.

\end{examplebox}

\section{4.10 Digital Control Systems}\label{digital-control-systems}

Modern control systems are predominantly implemented using digital
processors (microcontrollers, DSPs, FPGAs) that sample the continuous
plant output at discrete time intervals, compute the control law using
numerical algorithms, and output a control signal through a
digital-to-analog converter with a zero-order hold. Digital control
offers advantages including flexibility (control laws changed in
software), repeatability, noise immunity, and the ability to implement
complex algorithms such as adaptive and optimal control that would be
impractical with analog circuits.

\subsection{4.10.1 Discrete-Time Systems}\label{discrete-time-systems}

A continuous-time plant G(s) preceded by a zero-order hold (ZOH) and
sampler with period T produces the discrete-time transfer function G(z)
= (1 − z⁻¹) Z\{G(s)/s\}, where Z\{·\} denotes the z-transform. The
z-transform variable relates to the Laplace variable by z =
e\textsuperscript{sT}, which maps the left half of the s-plane (stable
region) to the interior of the unit circle in the z-plane. A
discrete-time system is stable if and only if all poles of G(z) lie
strictly inside the unit circle \textbar z\textbar{} \textless{} 1.
Poles on the unit circle correspond to sustained oscillations, and poles
outside indicate instability.

Continuous-time controllers can be converted to discrete-time using the
Tustin (bilinear) approximation s = (2/T)(z − 1)/(z + 1), which
preserves the frequency response mapping and maps the jω axis in the
s-plane to the unit circle in the z-plane without aliasing distortion.
The sample period T must be chosen small enough to adequately capture
the system dynamics --- a common rule of thumb is T ≤ 1/(10 ×
f\textsubscript{BW}), where f\textsubscript{BW} is the closed-loop
bandwidth.

\begin{examplebox}

\textbf{Example 4.10.1:} Discretize the continuous-time transfer
function G(s) = 10/(s + 5) using the zero-order hold method with a
sample period T = 0.1 s.

\textbf{Solution:}\\
G(s)/s = 10/{[}s(s + 5){]}. Partial fractions: 10/{[}s(s + 5){]} = 2/s −
2/(s + 5).

Z-transform: Z\{2/s − 2/(s + 5)\} = 2z/(z − 1) − 2z/(z −
e\textsuperscript{−5T}) = 2z/(z − 1) − 2z/(z − e⁻⁰·⁵).

e⁻⁰·⁵ = 0.6065.

G(z) = (1 − z⁻¹){[}2z/(z − 1) − 2z/(z − 0.6065){]} = 2 − 2(z − 1)/(z −
0.6065).

Simplify: G(z) = 2(z − 0.6065) − 2(z − 1) all over (z − 0.6065) = 2(1 −
0.6065)/(z − 0.6065) = \textbf{0.787/(z − 0.6065)}.

The discrete pole at z = 0.6065 corresponds to the continuous pole at s
= −5 (since e⁻⁵ˣ⁰·¹ = 0.6065), and it lies inside the unit circle,
confirming stability. The DC gain is G(1) = 0.787/(1 − 0.6065) = 2.0,
matching the continuous-time DC gain G(0) = 10/5 = 2.0.

\end{examplebox}

\subsection{4.10.2 Digital PID
Implementation}\label{digital-pid-implementation}

The continuous PID controller u(t) = K\textsubscript{p}e(t) +
K\textsubscript{i}∫e(t)dt + K\textsubscript{d}de(t)/dt is discretized
using rectangular integration for the integral term and backward
difference for the derivative term, yielding the position form: u{[}k{]}
= K\textsubscript{p}e{[}k{]} + K\textsubscript{i}T Σe{[}k{]} +
K\textsubscript{d}(e{[}k{]} − e{[}k−1{]})/T. The velocity (incremental)
form Δu{[}k{]} = u{[}k{]} − u{[}k−1{]} is often preferred because it
avoids accumulating the integral sum explicitly and provides natural
anti-windup behavior. Anti-windup is essential when the actuator
saturates --- without it, the integral term continues accumulating error
during saturation, causing large overshoot when the error reverses.
Common anti-windup strategies include clamping (freezing the integrator
when the output is saturated) and back-calculation (reducing the
integral term proportionally to the saturation amount).

The sample period T directly affects controller performance. If T is too
large, the discrete controller cannot respond to fast disturbances and
may introduce excessive phase lag; if T is unnecessarily small,
computational burden increases and quantization noise is amplified in
the derivative term. The rule of thumb T ≤ 1/(10 × f\textsubscript{BW})
ensures the discrete controller closely approximates the continuous
design. For a system with a closed-loop bandwidth of 10 Hz, this
requires T ≤ 10 ms.

\begin{examplebox}

\textbf{Example 4.10.2:} A motor speed control system has a continuous
PID controller with K\textsubscript{p} = 2.0, K\textsubscript{i} = 5.0,
and K\textsubscript{d} = 0.1. The sample period is T = 0.05 s. The
initial error sequence is e{[}0{]} = 10, e{[}1{]} = 7, e{[}2{]} = 4
(motor approaching setpoint). Compute the control output u{[}k{]} for k
= 0, 1, and 2 using the position-form digital PID (assume e{[}−1{]} = 0
and prior integral sum = 0).

\textbf{Solution:}\\
\textbf{k = 0:} Integral sum = e{[}0{]} = 10. u{[}0{]} = 2.0(10) +
5.0(0.05)(10) + 0.1(10 − 0)/0.05 = 20 + 2.5 + 20 = \textbf{42.5}.

\textbf{k = 1:} Integral sum = 10 + 7 = 17. u{[}1{]} = 2.0(7) +
5.0(0.05)(17) + 0.1(7 − 10)/0.05 = 14 + 4.25 + (−6) = \textbf{12.25}.

\textbf{k = 2:} Integral sum = 10 + 7 + 4 = 21. u{[}2{]} = 2.0(4) +
5.0(0.05)(21) + 0.1(4 − 7)/0.05 = 8 + 5.25 + (−6) = \textbf{7.25}.

The control output decreases as the error decreases. The derivative term
contributes negative values (−6 at k = 1 and k = 2) because the error is
decreasing, providing a braking effect that reduces overshoot. The
integral term steadily increases (2.5 → 4.25 → 5.25) to eliminate
steady-state error.

\end{examplebox}

\chapter{Chapter 5}\label{chapter-5}

\chapter{Embedded Systems}\label{embedded-systems}

Embedded systems are special-purpose computing systems designed to
perform dedicated functions within a larger mechanical or electrical
product. Unlike general-purpose computers, embedded systems are
optimized for specific tasks with constraints on size, power
consumption, cost, and real-time responsiveness. They combine a
microcontroller or microprocessor with firmware, peripherals, and
communication interfaces to interact directly with the physical world
through sensors and actuators. Embedded systems are ubiquitous in modern
life, found in automotive electronics, consumer appliances, medical
devices, industrial automation, telecommunications equipment, and
aerospace systems.

\section{5.1 Microcontrollers}\label{microcontrollers}

A microcontroller (MCU) is a compact integrated circuit that combines a
processor core, memory, and programmable input/output peripherals on a
single chip. Unlike general-purpose microprocessors, microcontrollers
are designed for dedicated control applications where they interact
directly with sensors, actuators, and communication buses in real time.
They are found in virtually every electronic product, from household
appliances and automotive systems to industrial controllers and medical
devices. Microcontrollers typically run firmware stored in on-chip flash
memory, often without a full operating system, executing a main loop or
responding to hardware interrupts.

\subsection{5.1.1 Architecture}\label{architecture}

Microcontroller architectures are broadly classified as Harvard or Von
Neumann, depending on whether program memory and data memory use
separate or shared buses. Harvard architecture, used by AVR and most ARM
Cortex-M implementations, provides simultaneous access to instruction
and data memory on independent buses, enabling the processor to fetch
the next instruction while reading or writing data in the same clock
cycle. This parallelism is critical for real-time performance, where
deterministic instruction timing allows precise control of interrupt
latency and peripheral servicing. Von Neumann architecture uses a single
shared bus for both instruction fetches and data access, simplifying the
memory map and reducing pin count but creating a fetch/data bottleneck
that limits throughput --- a tradeoff acceptable in cost-sensitive
applications where raw performance is less important than silicon area.
Bus width determines how much data the processor can move in a single
operation: 8-bit MCUs (PIC16, ATtiny) handle one byte per transfer and
are suited for simple control tasks, 16-bit devices (MSP430, dsPIC)
balance capability with low power, and 32-bit architectures (ARM
Cortex-M, RISC-V) provide the address space and arithmetic width needed
for complex algorithms and large memory maps. The instruction set
architecture also shapes embedded performance: RISC (Reduced Instruction
Set Computer) designs such as ARM and RISC-V execute most instructions
in a single clock cycle with a load/store memory model, yielding
predictable timing and efficient pipelining, while CISC (Complex
Instruction Set Computer) designs like x86 offer powerful multi-step
instructions at the cost of variable execution time and more complex
decode logic. Most embedded MCUs use memory-mapped I/O, where peripheral
registers occupy specific addresses in the same address space as SRAM
and flash, allowing the same load/store instructions to configure a
timer, read an ADC result, or transmit a UART byte without dedicated I/O
instructions. Architecture choice directly impacts power consumption as
well --- a RISC core completing a task in fewer clock cycles at a lower
frequency dissipates less dynamic power (proportional to V² × f) than a
slower architecture that must run longer or at a higher clock rate to
accomplish the same work. Key architectural features include the
arithmetic logic unit (ALU), register file, program counter, stack
pointer, and interrupt controller, all integrated on the same die with
memory and peripherals.

\begin{examplebox}

\textbf{Example 5.1.1:} A Harvard architecture MCU runs at a clock
frequency of 48 MHz and executes most instructions in a single cycle. If
a particular routine consists of 120 single-cycle instructions and 30
two-cycle instructions, how long does the routine take to execute?

\textbf{Solution:}\\
Total clock cycles = 120 * 1 + 30 * 2 = 120 + 60 = 180 cycles.\\
Clock period = 1 / 48 MHz = 20.83 ns.\\
Execution time = 180 * 20.83 ns = 3.75 μs.\\
The Harvard architecture enables this single-cycle execution for most
instructions because program memory and data memory are accessed
simultaneously on separate buses, eliminating the fetch/data contention
that would occur in a Von Neumann architecture.

\end{examplebox}

\subsection{5.1.2 Common Families}\label{common-families}

\textbf{ARM Cortex-M} is the dominant 32-bit microcontroller
architecture, licensed by ARM and manufactured by vendors including
STMicroelectronics (STM32), NXP (LPC, Kinetis), and Texas Instruments
(MSP432). The Cortex-M family ranges from the ultra-low-power M0/M0+ for
simple control tasks to the high-performance M7 with hardware
floating-point and DSP instructions for signal processing applications.
\textbf{AVR} is an 8-bit RISC architecture developed by Atmel (now
Microchip), widely known through the Arduino platform and the
ATmega328P. AVR devices are valued for their simple instruction set,
single-cycle execution, and extensive community support. \textbf{PIC}
(Peripheral Interface Controller) from Microchip spans 8-bit (PIC16,
PIC18), 16-bit (PIC24, dsPIC), and 32-bit (PIC32) families, with a broad
range of integrated peripherals and low power consumption options suited
to industrial and automotive applications.

\begin{examplebox}

\textbf{Example 5.1.2:} An engineer must select an MCU to sample 8
analog sensors at 1 kHz each, perform a 256-point FFT on one channel,
and communicate results over SPI at 2 MHz. Which MCU family is most
appropriate?

\textbf{Solution:}\\
Total ADC throughput required = 8 channels * 1000 samples/s = 8000
samples/s, which is easily within the capability of all families.\\
The 256-point FFT requires approximately 256 * log₂(256) = 256 * 8 =
2048 butterfly operations, each involving multiply-accumulate steps.\\
An 8-bit AVR lacks hardware multiply efficiency and floating-point
support, making it a poor fit.\\
A Cortex-M4 (e.g., STM32F4 at 168 MHz) provides a hardware FPU and DSP
instructions (single-cycle MAC), completing the FFT in under 0.1 ms.\\
It also has multiple SPI peripherals supporting well above 2 MHz.\\
The ARM Cortex-M4 family is the best choice, offering the DSP capability
for FFT, sufficient ADC channels, and SPI speed with headroom to spare.

\end{examplebox}

\subsection{5.1.3 Clock System and PLL}\label{clock-system-and-pll}

The clock system is the heartbeat of a microcontroller, providing the
timing reference for the processor core, bus interfaces, and all
peripherals. Most MCUs offer multiple clock sources: a high-speed
internal RC oscillator (HSI, typically 8-16 MHz, ±1-2\% accuracy), a
high-speed external crystal oscillator (HSE, typically 4-25 MHz, ±20 ppm
accuracy), a low-speed internal RC oscillator (LSI, \textasciitilde32
kHz for watchdog), and a low-speed external crystal (LSE, 32.768 kHz for
the real-time clock). A Phase-Locked Loop (PLL) multiplies the input
clock to generate the high-frequency system clock --- for example, an 8
MHz HSE can be multiplied to 168 MHz through the PLL. The clock
distribution tree routes the system clock through prescalers to create
separate clock domains for the AHB (Advanced High-performance Bus), APB1
(low-speed peripheral bus), and APB2 (high-speed peripheral bus),
allowing peripherals to run at appropriate speeds while the core runs at
maximum frequency. Proper clock configuration is critical for peripheral
baud rate accuracy, timer precision, and power consumption --- running
the core at a lower frequency or switching to the internal RC oscillator
during idle periods can significantly reduce power draw.

\begin{examplebox}

\textbf{Example 5.1.3:} An STM32F4 MCU uses an 8 MHz external crystal
(HSE) and a PLL configured with multiplication factor M = 8, N = 336,
and P = 2. The AHB prescaler is 1 and the APB1 prescaler is 4. Determine
(a) the PLL output (system clock), (b) the AHB bus clock, (c) the APB1
peripheral clock, and (d) the APB1 timer clock.

\textbf{Solution:}

(a) PLL output: f\textsubscript{PLL} = (HSE / M) × N / P = (8 MHz / 8) ×
336 / 2 = 1 MHz × 168 = \textbf{168 MHz}

(b) AHB clock: f\textsubscript{AHB} = f\textsubscript{PLL} / AHB
prescaler = 168 / 1 = \textbf{168 MHz}

(c) APB1 clock: f\textsubscript{APB1} = f\textsubscript{AHB} / APB1
prescaler = 168 / 4 = \textbf{42 MHz}

(d) APB1 timer clock: When the APB prescaler is not 1, the timer clock
is automatically doubled:\\
f\textsubscript{timer} = 2 × f\textsubscript{APB1} = 2 × 42 = \textbf{84
MHz}

This means timers on APB1 have finer resolution (11.9 ns per tick) than
the APB1 bus clock would suggest, which must be accounted for when
configuring timer prescalers and periods.

\end{examplebox}

\section{5.2 Memory}\label{memory}

Embedded systems rely on several distinct types of memory, each
optimized for a specific role. Non-volatile flash retains the firmware
image when power is removed, volatile SRAM provides fast read-write
workspace during program execution, and EEPROM bridges the two by
offering byte-level write access for configuration data that must
survive power cycles without the sector-erase overhead of flash.
Efficient use of all three is critical in resource-constrained embedded
designs.

\subsection{5.2.1 Flash Memory}\label{flash-memory}

Flash memory is non-volatile storage used to hold the firmware (program
code) of a microcontroller. It retains data when power is removed and
can be electrically erased and reprogrammed, typically with endurance
ratings of 10,000 to 100,000 write-erase cycles. Flash is organized in
pages or sectors, and erase operations must be performed on entire
sectors before new data can be written. In-system programming (ISP) and
in-application programming (IAP) allow firmware updates without removing
the chip from the circuit. Typical flash sizes in microcontrollers range
from a few kilobytes in small 8-bit devices to several megabytes in
high-end 32-bit MCUs.

\begin{examplebox}

\textbf{Example 5.2.1:} A firmware image is 96 KB and must be stored in
an MCU's flash memory organized as 128 sectors of 2 KB each. The flash
has an endurance of 10,000 write-erase cycles and the firmware is
updated once per week via OTA. How many sectors are needed and how long
before the flash endurance limit is reached?

\textbf{Solution:}\\
Sectors required = 96 KB / 2 KB = 48 sectors.\\
Each update erases and rewrites all 48 sectors once.\\
At one update per week, the flash undergoes 52 erase cycles per year.\\
Time to endurance limit = 10,000 cycles / 52 cycles per year = 192.3
years.\\
The flash endurance is far more than adequate for this update
frequency.\\
If updates were instead performed 10 times per day, the endurance would
last 10,000 / (10 * 365) = 2.74 years, which may require a wear-leveling
strategy or dual-bank flash for reliability.

\end{examplebox}

\subsection{5.2.2 SRAM}\label{sram}

Static Random Access Memory (SRAM) is volatile memory used for the
stack, heap, and global variables during program execution. SRAM
provides fast read and write access (single clock cycle on most MCUs)
without the need for refresh cycles, unlike DRAM. It retains data only
while power is applied, and its contents are lost on reset or
power-down. SRAM sizes in microcontrollers typically range from a few
hundred bytes to several hundred kilobytes, and efficient use of SRAM is
critical in embedded systems where memory resources are constrained.

\begin{examplebox}

\textbf{Example 5.2.2:} An MCU has 20 KB of SRAM. The firmware uses 2 KB
for the stack, 1.5 KB for global/static variables, and allocates a
512-sample circular buffer of 16-bit ADC readings. Determine the total
SRAM usage and remaining memory.

\textbf{Solution:}\\
Circular buffer size = 512 samples * 2 bytes/sample = 1024 bytes = 1
KB.\\
Total SRAM used = 2 KB (stack) + 1.5 KB (globals) + 1 KB (buffer) = 4.5
KB.\\
Remaining SRAM = 20 KB - 4.5 KB = 15.5 KB.\\
This leaves sufficient room for additional buffers or a small RTOS.\\
As a best practice, the stack should be monitored for overflow by
painting it with a known pattern at startup and periodically checking
how much has been overwritten during execution.

\end{examplebox}

\subsection{5.2.3 EEPROM}\label{eeprom}

Electrically Erasable Programmable Read-Only Memory (EEPROM) is
non-volatile memory designed for storing small amounts of configuration
data, calibration values, or operational parameters that must persist
across power cycles. Unlike flash, EEPROM can be erased and written at
the individual byte level, making it more convenient for frequent small
updates. EEPROM endurance is typically rated at 100,000 to 1,000,000
write cycles per byte, with data retention of 20 years or more. Many
microcontrollers include a small amount of on-chip EEPROM (typically 256
bytes to a few kilobytes), and external EEPROM ICs (such as the 24Cxx
series) are available via I2C or SPI for additional storage.

\begin{examplebox}

\textbf{Example 5.2.3:} A device stores a 4-byte calibration value and a
2-byte operating hours counter in EEPROM. The counter is incremented and
written every hour. The EEPROM is rated for 1,000,000 write cycles per
byte. How long before the counter bytes reach their endurance limit?

\textbf{Solution:}\\
The counter bytes are written once per hour, so 24 writes per day and
8,760 writes per year.\\
Time to endurance limit = 1,000,000 / 8,760 = 114.2 years.\\
This is well within the product's expected lifetime.\\
If the write frequency were much higher (e.g., once per second), the
limit would be reached in 1,000,000 / (86,400 * 365) = approximately
0.032 years (11.6 days), which would necessitate wear-leveling across
multiple EEPROM locations.

\end{examplebox}

\section{5.3 Peripherals}\label{peripherals}

Peripherals are the hardware blocks within a microcontroller that extend
its capabilities beyond pure computation, enabling it to interact with
the physical world and communicate with external devices. They range
from simple GPIO pins for digital control to sophisticated conversion
and transfer engines --- ADCs, DACs, timers, and DMA controllers ---
that can operate independently of the CPU to maximize throughput and
minimize power consumption. Selecting the right MCU for an application
requires matching its peripheral set and specifications to the system
requirements.

\subsection{5.3.1 GPIO}\label{gpio}

General Purpose Input/Output (GPIO) pins are the most fundamental
peripheral on a microcontroller, providing configurable digital
interfaces to external circuitry. Each GPIO pin can typically be
configured as an input (reading logic high or low) or an output (driving
logic high or low) by writing to direction registers, and the output
stage can usually be set to push-pull mode (actively driving both high
and low) or open-drain mode (pulling low only, requiring an external
pull-up resistor for the high state). Open-drain outputs are essential
for wired-OR bus topologies and level-shifting between different voltage
domains --- for example, I2C requires open-drain lines with pull-ups.
Internal pull-up and pull-down resistors (typically 20--50 kΩ) can be
enabled on input pins to define a default logic level when the pin is
floating, eliminating the need for external resistors in many designs.
Electrical characteristics vary by MCU family: drive strength is often
configurable (e.g., 2 mA, 4 mA, or 8 mA on STM32), output slew rate can
be set to low, medium, or high to control EMI emissions on
fast-switching signals, and maximum source/sink current per pin is
typically 5-25 mA with an aggregate limit per port or per chip. Most
GPIO pins support alternate function multiplexing, where each physical
pin can be remapped through configuration registers to serve as a UART
TX/RX, SPI clock, I2C data line, PWM output, or ADC input channel,
allowing a single MCU package to support diverse peripheral combinations
without dedicated pins for every function. Input pins can be configured
to trigger hardware interrupts on rising edges, falling edges, or both,
enabling event-driven firmware that responds immediately to button
presses, sensor alerts, or external timing signals without polling. For
mechanical switches and buttons, software or hardware debouncing is
required --- contact bounce produces multiple transitions over 1-10 ms
that would otherwise trigger false interrupts. When interfacing GPIO
pins with circuits operating at different voltage levels (e.g., a 3.3 V
MCU communicating with 5 V legacy logic), level-shifting circuits or
voltage translators are needed to prevent overvoltage damage, and ESD
protection diodes (either internal to the MCU or external TVS devices)
safeguard pins against electrostatic discharge events that can exceed
several kilovolts.

\begin{examplebox}

\textbf{Example 5.3.1:} A GPIO output pin on a 3.3 V MCU (maximum source
current 8 mA) must drive an LED with a forward voltage of 2.0 V and a
desired forward current of 10 mA. Design the interface.

\textbf{Solution:}\\
Since the required LED current (10 mA) exceeds the GPIO source limit (8
mA), a transistor driver is needed.\\
Use an NPN transistor (e.g., 2N2222) with the LED and a current-limiting
resistor in the collector circuit.\\
Collector resistor: R\textsubscript{C} = (3.3 V - V\textsubscript{LED} -
V\textsubscript{CE}(sat)) / I\textsubscript{LED} = (3.3 - 2.0 - 0.2) /
0.010 = 1.1 V / 10 mA = 110 Ω (use 100 Ω standard value, giving
I\textsubscript{LED} = 11 mA).\\
Base resistor: assuming minimum h\textsubscript{FE} = 100,
I\textsubscript{B} = I\textsubscript{C} / h\textsubscript{FE} = 11 mA /
100 = 0.11 mA.\\
To ensure saturation, use 10x overdrive: I\textsubscript{B} = 1.1 mA.\\
R\textsubscript{B} = (3.3 V - V\textsubscript{BE}) / I\textsubscript{B}
= (3.3 - 0.7) / 0.00110 = 2.36 kΩ (use 2.2 kΩ standard).\\
The GPIO pin now only sources about 1.2 mA, well within its rating.

\end{examplebox}

\subsection{5.3.2 Timers and PWM}\label{timers-and-pwm}

Hardware timers are counter-based peripherals that provide precise
timing, event counting, and waveform generation without continuous
processor involvement. A timer increments (or decrements) a counter
register at each tick of a clock source, which can be the system clock,
a prescaled division of it, or an external signal. When the counter
reaches a compare value or overflows, the timer can generate an
interrupt, toggle an output pin, or trigger other peripherals via
hardware. Pulse Width Modulation (PWM) is a timer output mode that
generates a periodic digital signal with a controllable duty cycle,
widely used for motor speed control, LED dimming, and digital-to-analog
conversion. The PWM frequency is set by the timer period, and the duty
cycle is set by the compare register value, allowing precise analog-like
control from a digital output.

\begin{examplebox}

\textbf{Example 5.3.2:} An MCU running at 72 MHz uses a 16-bit timer
with a prescaler of 72 to generate a 1 kHz PWM signal for motor speed
control. Determine the timer period value and the compare register value
for a 60\% duty cycle.

\textbf{Solution:}\\
Timer clock = 72 MHz / 72 (prescaler) = 1 MHz (1 μs per tick).\\
For a 1 kHz PWM frequency, the period = 1 / 1 kHz = 1 ms = 1000 timer
ticks.\\
Set the auto-reload register (ARR) = 1000 - 1 = 999.\\
For 60\% duty cycle, compare register (CCR) = 0.60 * 1000 = 600.\\
The timer counts from 0 to 999 (1000 ticks = 1 ms), and the output is
high for counts 0 to 599 (600 μs) and low for counts 600 to 999 (400
μs).\\
Duty cycle resolution = 1 / 1000 = 0.1\%, which is well within 16-bit
capacity (max count 65535).

\end{examplebox}

\subsection{5.3.3 ADC}\label{adc}

An Analog-to-Digital Converter (ADC) converts a continuous analog
voltage into a discrete digital value that the processor can read and
process. Most microcontrollers include a successive approximation
register (SAR) ADC with 10-bit or 12-bit resolution, providing 1024 or
4096 quantization levels over the input voltage range. The ADC samples
the input voltage at a rate determined by the ADC clock and conversion
time, and the result is stored in a data register. A multiplexer allows
a single ADC to read from multiple analog input pins sequentially. Key
specifications include resolution (bits), sampling rate (samples per
second), input voltage range (typically 0V to the reference voltage),
and integral/differential nonlinearity (INL/DNL) errors.

\begin{examplebox}

\textbf{Example 5.3.3:} A 12-bit ADC with a reference voltage of 3.3 V
reads a digital value of 2482. What is the corresponding analog input
voltage, and what is the resolution (smallest detectable voltage
change)?

\textbf{Solution:}\\
Resolution (LSB size) = V\textsubscript{ref} / 2ⁿ = 3.3 V / 4096 =
0.8057 mV per count.\\
Input voltage = digital value * resolution = 2482 * 0.8057 mV = 1.9997
V, approximately 2.000 V.\\
The ADC can distinguish voltage changes as small as 0.806 mV.\\
If the signal of interest spans only 0 to 1 V, the effective number of
usable codes is 1.0 / 0.0008057 = 1241 counts, equivalent to
approximately log₂(1241) = 10.3 bits of effective resolution over that
range.

\end{examplebox}

\subsection{5.3.4 DAC}\label{dac}

A Digital-to-Analog Converter (DAC) converts a digital value from the
processor into a corresponding analog output voltage. On-chip DACs are
commonly 8-bit or 12-bit and are used for generating reference voltages,
audio waveforms, control signals for analog circuits, and bias voltages.
The output voltage is determined by the formula V\textsubscript{out} =
(D / 2ⁿ) * V\textsubscript{ref}, where D is the digital input code, n is
the resolution in bits, and V\textsubscript{ref} is the reference
voltage. DAC outputs typically require an external operational amplifier
buffer to drive low-impedance loads. Some MCUs include multiple DAC
channels with DMA (Direct Memory Access) support, enabling continuous
waveform generation without processor overhead.

\begin{examplebox}

\textbf{Example 5.3.4:} A 12-bit DAC with V\textsubscript{ref} = 3.3 V
must produce an output of 1.65 V. Determine the required digital input
code. If the DAC is used to generate a sine wave at 1 kHz using a lookup
table with 100 points per cycle, what is the required DAC update rate?

\textbf{Solution:}\\
Digital code D = (V\textsubscript{out} / V\textsubscript{ref}) * 2ⁿ =
(1.65 / 3.3) * 4096 = 0.5 * 4096 = 2048.\\
Load the value 2048 into the DAC data register to produce 1.65 V at the
output.\\
For the sine wave: update rate = 1 kHz * 100 samples/cycle = 100,000
samples/s = 100 kSPS.\\
The update interval = 1 / 100,000 = 10 μs.\\
Using DMA with a timer trigger at 10 μs intervals, the DAC automatically
cycles through the 100-entry lookup table without CPU intervention,
freeing the processor for other tasks.

\end{examplebox}

\subsection{5.3.5 DMA (Direct Memory
Access)}\label{dma-direct-memory-access}

Direct Memory Access (DMA) is a hardware peripheral that transfers data
between memory and peripherals (or between memory locations) without
processor involvement, freeing the CPU to execute other code during the
transfer. A DMA controller contains multiple channels, each configurable
with a source address, destination address, transfer size, data width
(byte, half-word, or word), and direction (memory-to-peripheral,
peripheral-to-memory, or memory-to-memory). Transfers can be triggered
by peripheral events (e.g., ADC conversion complete, UART byte received,
SPI buffer empty), enabling continuous data streaming. DMA is essential
for high-throughput applications such as audio processing, continuous
ADC sampling, display frame buffer updates, and communication protocols
where the data rate would otherwise overwhelm the CPU. Most Cortex-M
MCUs have two DMA controllers with 8-16 channels each, with configurable
priority levels and burst transfer modes.

\begin{examplebox}

\textbf{Example 5.3.5:} An MCU samples a 12-bit ADC at 100 kHz and uses
DMA to transfer each sample (16-bit half-word) to a 1024-sample circular
buffer in SRAM. Determine (a) the DMA transfer rate in bytes per second,
(b) the time to fill the buffer, and (c) the CPU cycles saved per second
compared to interrupt-driven transfers (assume 30 CPU cycles per
interrupt-driven sample at 168 MHz).

\textbf{Solution:}

(a) DMA transfer rate: 100,000 samples/s × 2 bytes/sample =
\textbf{200,000 bytes/s = 200 KB/s}

(b) Buffer fill time: 1024 samples / 100,000 samples/s = \textbf{10.24
ms}\\
Using half-transfer and transfer-complete interrupts, the CPU is
interrupted only twice per buffer fill (every 5.12 ms) instead of 1024
times.

(c) CPU cycles saved: Interrupt-driven transfers would require 100,000
interrupts/s × 30 cycles/interrupt = 3,000,000 cycles/s. At 168 MHz,
this is 3,000,000 / 168,000,000 = 1.79\% of CPU time. With DMA, the CPU
is interrupted only 2 × (100,000/1024) ≈ 195 times/s, consuming 195 × 30
= 5,850 cycles/s --- a \textbf{99.8\% reduction} in CPU overhead for the
ADC data transfer.

\end{examplebox}

\subsection{5.3.6 Watchdog Timer}\label{watchdog-timer}

A watchdog timer (WDT) is a safety peripheral that resets the
microcontroller if the firmware fails to periodically ``kick'' or
``feed'' the watchdog within a specified timeout period. This provides
automatic recovery from software hangs, infinite loops, deadlocks, or
other fault conditions that would otherwise leave the system
unresponsive. The watchdog counter counts down from a programmable
reload value, and if it reaches zero before the firmware writes to the
refresh register, a system reset is triggered. Most MCUs offer two
types: the Independent Watchdog (IWDG), clocked by a separate low-speed
internal oscillator so it remains active even if the main clock fails,
and the Window Watchdog (WWDG), which not only requires a refresh before
timeout but also rejects refreshes that come too early (within a
programmable window), detecting both stuck and runaway firmware.
Watchdog timers are a fundamental requirement for safety-critical and
unattended embedded systems --- automotive (ISO 26262), medical (IEC
62304), and industrial (IEC 61508) standards all require watchdog
mechanisms.

\begin{examplebox}

\textbf{Example 5.3.6:} An independent watchdog timer is clocked at 32
kHz (LSI) with a prescaler of 64 and a 12-bit reload value of 4095.
Determine (a) the watchdog timeout period, (b) the maximum time the
firmware can go between watchdog refreshes, and (c) a suitable refresh
interval.

\textbf{Solution:}

(a) Watchdog clock after prescaler: f\textsubscript{WDT} = 32,000 / 64 =
500 Hz (2 ms per tick)\\
Timeout period: T = (reload + 1) / f\textsubscript{WDT} = 4096 / 500 =
\textbf{8.192 seconds}

(b) The firmware must refresh the watchdog before the counter reaches
zero, so the maximum time between refreshes is \textbf{8.192 seconds}.

(c) In practice, the watchdog should be refreshed well before the
timeout to account for worst-case execution paths. A common approach is
to refresh at half the timeout period: approximately \textbf{4 seconds}
(half of 8.192 s). Alternatively, refresh at the end of each pass
through the main loop or RTOS health check task. If the main loop period
is 100 ms, refreshing every iteration provides a 82× safety margin.

\end{examplebox}

\section{5.4 Communication Interfaces}\label{communication-interfaces}

Communication interfaces allow an embedded system to exchange data with
sensors, actuators, displays, storage devices, and other processors.
Each protocol involves trade-offs among speed, pin count, wiring
distance, noise immunity, and implementation complexity, and the choice
of interface is frequently dictated by the target peripheral rather than
by the MCU. The interfaces covered here span the full spectrum of
embedded communication, from the asynchronous simplicity of UART to the
high-speed, host-managed USB link.

\subsection{5.4.1 UART}\label{uart}

Universal Asynchronous Receiver/Transmitter (UART) is a serial
communication interface that transmits and receives data one bit at a
time over two signal lines: TX (transmit) and RX (receive).
Communication is asynchronous, meaning no shared clock signal is used;
instead, both devices must agree on a common baud rate (e.g., 9600,
115200 bits per second), data frame format (typically 8 data bits, no
parity, 1 stop bit, abbreviated 8N1), and voltage levels. Each data
frame begins with a start bit (logic low), followed by the data bits
(LSB first), an optional parity bit for error detection, and one or more
stop bits (logic high). UART is simple to implement and is commonly used
for debug consoles, GPS modules, Bluetooth modules, and communication
between microcontrollers. RS-232 and RS-485 are physical layer standards
that define voltage levels and electrical characteristics for UART-based
communication over longer distances.

\begin{examplebox}

\textbf{Example 5.4.1:} An MCU UART is configured at 115200 baud with
8N1 framing. How long does it take to transmit a 64-byte data packet,
and what is the effective data throughput?

\textbf{Solution:}\\
Each byte frame consists of 1 start bit + 8 data bits + 1 stop bit = 10
bits per byte.\\
Total bits to transmit = 64 bytes * 10 bits/byte = 640 bits.\\
Transmission time = 640 bits / 115200 bits/s = 5.556 ms.\\
Effective data throughput = (64 * 8 data bits) / 5.556 ms = 512 /
0.005556 = 92,160 bits/s = 92.16 kbps.\\
The overhead from start and stop bits reduces the effective rate to 80\%
of the baud rate (92,160 / 115,200 = 0.80).\\
If parity were added (8E1: 11 bits per byte), the overhead would
increase and throughput would drop to 72.7\% of the baud rate.

\end{examplebox}

\subsection{5.4.2 SPI}\label{spi}

Serial Peripheral Interface (SPI) is a synchronous, full-duplex serial
communication bus that uses four signal lines: SCLK (clock), MOSI
(Master Out Slave In), MISO (Master In Slave Out), and SS/CS (Slave
Select/Chip Select). The master device generates the clock and controls
the slave select line, enabling one slave at a time for communication.
Data is shifted out on one clock edge and sampled on the opposite edge,
with the clock polarity (CPOL) and phase (CPHA) configurable into four
modes (Mode 0-3). SPI achieves high data rates (often 10 MHz or more)
because of its dedicated clock line and full-duplex operation, making it
well-suited for high-speed peripherals such as flash memory, display
controllers, SD cards, and ADC/DAC chips. The main drawback is the
requirement for a separate chip select line for each slave device, which
increases pin usage as the number of peripherals grows.

\begin{examplebox}

\textbf{Example 5.4.2:} An MCU communicates with an external SPI flash
memory at an SPI clock rate of 8 MHz. The flash read command requires
sending a 1-byte opcode and a 3-byte address before data is returned.
How long does it take to read 256 bytes of data from the flash?

\textbf{Solution:}\\
Total bytes transferred = 1 (opcode) + 3 (address) + 256 (data) = 260
bytes.\\
Since SPI is full-duplex, each byte requires 8 clock cycles.\\
Total clock cycles = 260 * 8 = 2080 cycles.\\
Transfer time = 2080 / 8 MHz = 260 μs.\\
Effective data throughput for the read portion = 256 bytes / 260 μs =
0.985 bytes/μs = 7.876 Mbps.\\
The 4-byte command/address overhead is only 1.5\% of the total transfer,
so for bulk reads the throughput approaches the theoretical maximum of 8
Mbps (1 byte per 8 clock cycles at 8 MHz).

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-5-4-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch05_spi_timing.png}

\caption{Figure 5.4.2: SPI Mode 0 timing diagram showing an 8-bit transfer (MOSI: 0xA5, MISO: 0x3C). Data is sampled on rising clock edges; the CS line is held low for the duration of the 8-cycle transfer.}

\end{figure}

\subsection{5.4.3 I2C}\label{i2c}

Inter-Integrated Circuit (I2C) is a synchronous, half-duplex serial
communication bus that uses only two signal lines: SDA (Serial Data) and
SCL (Serial Clock). Multiple master and slave devices can share the same
two-wire bus, with each slave identified by a unique 7-bit (or 10-bit)
address. Communication begins when a master issues a START condition,
followed by the slave address and a read/write bit; the addressed slave
responds with an ACK (acknowledge) bit, and data bytes are then
transferred with an ACK after each byte. Standard I2C operates at 100
kHz, Fast mode at 400 kHz, and Fast-mode Plus at 1 MHz. I2C is widely
used for low-speed peripherals such as temperature sensors, EEPROMs,
real-time clocks, and OLED displays, where its minimal pin count and
multi-device bus topology are advantageous.

\begin{examplebox}

\textbf{Example 5.4.3:} An MCU reads a 2-byte temperature value from an
I2C sensor (7-bit address 0x48) operating in Fast mode (400 kHz).
Calculate the minimum time for a complete read transaction.

\textbf{Solution:}\\
An I2C read transaction consists of: START (1 bit) + address byte with
R/W=1 (8 bits) + ACK (1 bit) + data byte 1 (8 bits) + ACK (1 bit) + data
byte 2 (8 bits) + NACK (1 bit) + STOP (1 bit) = 29 bits.\\
However, a typical sensor requires a write-then-read sequence: first
write the register pointer (START + address W + ACK + register byte +
ACK = 19 bits), then repeated START + address R + ACK + 2 data bytes
with ACK/NACK + STOP = 29 bits.\\
Total = 19 + 29 = 48 bit periods.\\
At 400 kHz: time = 48 / 400,000 = 120 μs.\\
Including I2C protocol overhead (clock stretching, bus turnaround), a
practical measurement is typically 130-150 μs.

\end{examplebox}

\subsection{5.4.4 CAN Bus}\label{can-bus}

Controller Area Network (CAN) is a robust, message-based serial
communication protocol originally developed by Bosch for automotive
applications. CAN uses a differential two-wire bus (CAN\_H and CAN\_L)
that provides high noise immunity, making it suitable for electrically
harsh environments in vehicles, industrial automation, and medical
equipment. Messages are broadcast on the bus with an identifier (11-bit
standard or 29-bit extended) that determines both the message type and
its priority during bus arbitration; lower identifier values have higher
priority. CAN implements built-in error detection mechanisms including
CRC checks, bit stuffing, frame checks, and acknowledgment verification,
with automatic retransmission of corrupted messages. Classical CAN
supports data rates up to 1 Mbps, while CAN FD (Flexible Data-rate)
extends the payload from 8 to 64 bytes per frame and allows higher bit
rates during the data phase.

\begin{examplebox}

\textbf{Example 5.4.4:} A CAN bus operates at 500 kbps. A standard frame
with an 11-bit identifier carries 8 data bytes. Estimate the maximum
message throughput on the bus.

\textbf{Solution:}\\
A standard CAN frame consists of: 1 (SOF) + 11 (ID) + 1 (RTR) + 6
(control) + 64 (8 data bytes) + 15 (CRC) + 10 (CRC\_delim + ACK +
ACK\_delim + EOF) + 3 (IFS) = 111 bits minimum.\\
With worst-case bit stuffing (a stuff bit inserted after every 5
identical bits in the data/ID/CRC fields), approximately 19 additional
stuff bits may be added, giving roughly 130 bits per frame.\\
Maximum throughput = 500,000 bps / 130 bits per frame = 3846 frames/s.\\
Data throughput = 3846 * 8 bytes = 30,769 bytes/s × 8 bits/byte ≈ 246
kbps effective data rate, which is about 49\% of the raw bit rate due to
protocol overhead.

\end{examplebox}

\subsection{5.4.5 USB}\label{usb}

Universal Serial Bus (USB) is a widely used communication standard that
provides both data transfer and power delivery through a single cable.
USB operates on a host-device (master-slave) topology, where the host
(typically a PC) initiates all transactions and the device (the embedded
system) responds. USB device classes define standardized behaviors: CDC
(Communications Device Class) emulates a virtual serial port, HID (Human
Interface Device) handles keyboards and mice, MSC (Mass Storage Class)
presents a filesystem, and vendor-specific classes allow custom
protocols. USB 2.0 supports three speeds --- Low Speed (1.5 Mbps), Full
Speed (12 Mbps), and High Speed (480 Mbps) --- while USB 3.x adds
SuperSpeed (5-20 Gbps). Most Cortex-M microcontrollers include a Full
Speed USB peripheral with an integrated PHY, requiring minimal external
components (typically just a USB connector and two 22 Ω series resistors
on the data lines). USB device firmware is typically implemented using a
middleware stack (such as TinyUSB or the vendor's USB library) that
handles the complex protocol state machine, enumeration process, and
endpoint management.

\begin{examplebox}

\textbf{Example 5.4.5:} An embedded data logger uses USB 2.0 Full Speed
(12 Mbps) CDC class to stream sensor data to a PC. Each data packet
contains 64 bytes (the maximum bulk endpoint packet size for Full
Speed). USB bulk transfers have a protocol overhead of approximately
25\% (token, handshake, CRC, inter-packet gaps). Determine (a) the
maximum number of bulk packets per second, (b) the effective data
throughput, and (c) whether this is sufficient to stream 16-bit ADC
samples at 100 kHz.

\textbf{Solution:}

(a) Effective bit rate: 12 Mbps × 0.75 (after 25\% overhead) = 9.0
Mbps\\
Each packet: 64 bytes × 8 bits = 512 bits\\
Maximum packets/s: 9,000,000 / 512 = \textbf{17,578 packets/s}

(b) Effective data throughput: 17,578 × 64 = 1,125,000 bytes/s =
\textbf{1.125 MB/s = 9.0 Mbps}

(c) Required throughput for 100 kHz, 16-bit ADC: 100,000 × 2 = 200,000
bytes/s = 1.6 Mbps\\
Since 9.0 Mbps \textgreater\textgreater{} 1.6 Mbps, USB Full Speed is
\textbf{more than sufficient}, with capacity for 5.6× the required data
rate. The data logger could stream up to 562,500 samples/s at 16-bit
resolution before saturating the USB link.

\end{examplebox}

\section{5.5 Interrupts}\label{interrupts}

An interrupt is a hardware or software signal that causes the processor
to suspend its current execution, save its context (program counter and
status registers), and jump to a designated interrupt service routine
(ISR) to handle the event. Hardware interrupts are generated by
peripherals such as GPIO pins, timers, ADCs, and communication
interfaces when specific events occur (e.g., a timer overflow, a byte
received on UART, or a pin state change). Software interrupts (also
called traps or exceptions) are triggered by processor instructions or
fault conditions such as divide-by-zero or invalid memory access.
Interrupts are assigned priority levels, and a Nested Vectored Interrupt
Controller (NVIC) on ARM Cortex-M processors manages prioritization and
nesting, allowing higher-priority interrupts to preempt lower-priority
ones. ISRs should be kept as short as possible, typically setting a flag
or copying data to a buffer, with the main processing deferred to the
main loop or a task scheduler to minimize interrupt latency for other
events.

\begin{examplebox}

\textbf{Example 5.5:} An ARM Cortex-M4 MCU running at 168 MHz has three
interrupts: Timer (priority 1, ISR execution time 2 μs), UART RX
(priority 2, ISR execution time 1.5 μs), and ADC complete (priority 3,
ISR execution time 3 μs). If all three trigger simultaneously, determine
the total time until all ISRs complete, assuming a context switch
overhead of 12 clock cycles per switch.

\textbf{Solution:}\\
Context switch time = 12 cycles / 168 MHz = 71.4 ns per switch.\\
Execution order (highest priority first): Timer (priority 1) runs first,
then UART RX (priority 2), then ADC (priority 3).\\
Timeline: initial context switch (71.4 ns) + Timer ISR (2 μs) + context
switch (71.4 ns) + UART ISR (1.5 μs) + context switch (71.4 ns) + ADC
ISR (3 μs) + context switch to main (71.4 ns).\\
Total = 4 * 0.0714 μs + 2 + 1.5 + 3 = 0.286 + 6.5 = 6.786 μs.\\
If the UART interrupt arrived during the Timer ISR, it would pend until
the Timer ISR completes (since Timer has higher priority), then preempt
any lower-priority pending work, demonstrating the NVIC's priority-based
nesting behavior.

\end{examplebox}

\section{5.6 Real-Time Operating Systems
(RTOS)}\label{real-time-operating-systems-rtos}

A Real-Time Operating System (RTOS) is a lightweight operating system
designed to guarantee that tasks execute within deterministic time
constraints, making it essential for embedded applications with strict
timing requirements. Unlike general-purpose operating systems, an RTOS
provides a preemptive priority-based scheduler that ensures the
highest-priority ready task always runs, with context switch times
typically measured in microseconds. Key RTOS primitives include tasks
(threads), semaphores, mutexes, message queues, and event flags, which
provide structured mechanisms for multitasking, synchronization, and
inter-task communication. Popular RTOS platforms for embedded systems
include FreeRTOS (open-source, widely used on ARM Cortex-M and ESP32),
Zephyr (Linux Foundation, supporting multiple architectures), and
ThreadX (now Azure RTOS, certified for safety-critical applications). An
RTOS is beneficial when an application requires concurrent handling of
multiple time-sensitive activities (e.g., sensor sampling,
communication, display updates, and control loops) that would be
difficult to manage with a bare-metal super-loop architecture.

\begin{examplebox}

\textbf{Example 5.6:} A FreeRTOS application on a Cortex-M4 at 168 MHz
has three tasks: a control loop task (priority 3, runs every 1 ms for
200 μs), a sensor reading task (priority 2, runs every 10 ms for 500
μs), and a display update task (priority 1, runs every 100 ms for 5 ms).
Determine the CPU utilization.

\textbf{Solution:}\\
CPU utilization per task = execution time per period / period.\\
Control loop: 200 μs / 1 ms = 20.0\%.\\
Sensor reading: 500 μs / 10 ms = 5.0\%.\\
Display update: 5 ms / 100 ms = 5.0\%.\\
Total CPU utilization = 20.0\% + 5.0\% + 5.0\% = 30.0\%.\\
The remaining 70\% is spent in the idle task.\\
Using Rate Monotonic Analysis (RMA), the theoretical schedulability
bound for 3 tasks is 3 * (2\^{}(1/3) - 1) = 3 * 0.2599 = 77.98\%.\\
Since 30\% is well below 77.98\%, the task set is guaranteed schedulable
with fixed-priority preemptive scheduling.\\
The control loop has the highest priority due to its shortest period and
strictest deadline.

\end{examplebox}

\section{5.7 Power Management}\label{power-management}

Power management is a critical discipline in battery-powered and
energy-harvesting embedded systems, where runtime is directly determined
by how efficiently the hardware consumes energy. Microcontrollers
provide hardware mechanisms --- sleep modes, clock gating, and voltage
scaling --- that can reduce current consumption by orders of magnitude
compared to full-speed operation, while firmware architecture governs
how effectively those mechanisms are used. The combination of hardware
capability and thoughtful software design determines whether a device
lasts hours or years on a single cell.

\subsection{5.7.1 Sleep Modes and Wake-Up
Sources}\label{sleep-modes-and-wake-up-sources}

Modern microcontrollers provide multiple low-power sleep modes that
progressively disable on-chip subsystems to reduce power consumption
when the full processing capability is not needed. A typical Cortex-M
MCU offers three to five modes: Sleep mode (CPU halted, peripherals and
clocks active, wake on any interrupt, \textasciitilde1-10 mA), Stop mode
(CPU and most clocks halted, SRAM and registers retained, selected
peripherals active, wake on EXTI, RTC, or specific peripheral events,
\textasciitilde10-100 μA), and Standby mode (nearly everything powered
down except the backup domain and wakeup logic, SRAM contents lost, wake
only on specific pins, RTC alarm, or reset, \textasciitilde1-5 μA).
Wake-up sources include external interrupt pins (EXTI), real-time clock
(RTC) alarms, watchdog timer, UART activity detection, USB VBUS
detection, and comparator threshold crossings. The firmware must
configure the wake-up source and any peripheral retention before
entering a low-power mode, and typically re-initializes clocks and
peripherals upon waking since the PLL and HSE may have been shut down.

\begin{examplebox}

\textbf{Example 5.7.1:} A battery-powered sensor node uses a 3.3 V, 1000
mAh lithium battery. The MCU wakes every 60 seconds, samples a sensor
and transmits data over SPI radio for 50 ms at 15 mA, then returns to
Stop mode at 20 μA. Determine (a) the average current consumption, (b)
the battery life, and (c) the battery life if the wake interval were
reduced to 5 seconds.

\textbf{Solution:}

(a) Average current: I\textsubscript{avg} = (I\textsubscript{active} ×
t\textsubscript{active} + I\textsubscript{sleep} ×
t\textsubscript{sleep}) / T\textsubscript{total}\\
= (15 mA × 50 ms + 0.020 mA × 59,950 ms) / 60,000 ms\\
= (0.75 + 1.199) / 60,000 = 1.949 mA·ms / 60,000 ms = \textbf{0.03248 mA
= 32.5 μA}

(b) Battery life: t = C / I\textsubscript{avg} = 1000 mAh / 0.03248 mA =
30,787 hours = \textbf{3.52 years}

(c) At 5-second interval: I\textsubscript{avg} = (15 × 50 + 0.020 ×
4,950) / 5,000 = (750 + 99) / 5,000 = \textbf{0.170 mA = 170 μA}\\
Battery life: 1000 / 0.170 = 5,882 hours = \textbf{0.67 years (8
months)}

Reducing the wake interval by 12× increases average current by 5.2×
because the active-mode current dominates even at short duty cycles.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-5-7-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch05_sleep_power.png}

\caption{Figure 5.7.1: Average current (log scale) and battery life vs wake interval for a sensor node (Iactive = 15 mA for 50 ms, Isleep = 20 μA, C = 1000 mAh). Markers show the 60 s and 5 s operating points from §5.7.1.}

\end{figure}

\subsection{5.7.2 Low-Power Design
Techniques}\label{low-power-design-techniques}

Reducing power consumption in embedded systems requires attention at
every level: hardware design, clock management, peripheral usage, and
firmware architecture. Key techniques include:

\begin{itemize}
\tightlist
\item
  \textbf{Clock gating}: Disable clocks to unused peripherals through
  the RCC (Reset and Clock Control) peripheral. Most MCUs ship with all
  peripheral clocks enabled by default --- disabling unused ones can
  reduce active current by 10-30\%.
\item
  \textbf{Voltage scaling}: Many MCUs allow the core voltage to be
  reduced when running at lower frequencies, providing quadratic power
  savings since dynamic power is proportional to V² × f.
\item
  \textbf{Peripheral duty cycling}: Enable peripherals only when needed.
  For example, power up the ADC, take a measurement, and power it down
  rather than leaving it continuously active.
\item
  \textbf{DMA over interrupts}: Use DMA for data transfers to allow the
  CPU to enter Sleep mode between transfers instead of waking for each
  byte.
\item
  \textbf{Efficient firmware}: Avoid busy-wait loops (use WFI --- Wait
  For Interrupt --- instruction instead), minimize unnecessary memory
  accesses, and use compiler optimization flags.
\item
  \textbf{External hardware}: Use hardware power switches (load switches
  or LDOs with enable pins) to completely de-power external sensors and
  radios when not in use, as standby leakage in external ICs can exceed
  the MCU's own sleep current.
\end{itemize}

\begin{examplebox}

\textbf{Example 5.7.2:} An IoT device runs at 3.3 V with the following
current profile: MCU active at 168 MHz (30 mA), MCU active at 48 MHz
with voltage scaling (8 mA), MCU Sleep mode (5 mA), MCU Stop mode (20
μA). The firmware spends 10\% of its time in computation (requiring 168
MHz), 20\% in communication (48 MHz sufficient), and 70\% idle.
Calculate the average current for (a) no optimization (always at 168
MHz, busy-wait during idle), and (b) optimized (frequency scaling and
Stop mode during idle).

\textbf{Solution:}

(a) No optimization: I\textsubscript{avg} = 30 mA × 100\% = \textbf{30
mA}

(b) Optimized:\\
I\textsubscript{avg} = 30 × 0.10 + 8 × 0.20 + 0.020 × 0.70\\
= 3.0 + 1.6 + 0.014 = \textbf{4.61 mA}

Power reduction: (30 − 4.61) / 30 × 100 = \textbf{84.6\% reduction}.
Battery life improves from 1000/30 = 33 hours to 1000/4.61 = 217 hours
--- a \textbf{6.5× improvement}.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-5-7-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch05_lowpower_opt.png}

\caption{Figure 5.7.2: Average current and percentage power saving vs idle fraction for an IoT device using frequency scaling (168 MHz → 48 MHz) and Stop mode. At 70\% idle, the optimized design draws 4.61 mA vs 30 mA unoptimized — an 84.6\% reduction.}

\end{figure}

\section{5.8 Development and Debugging}\label{development-and-debugging}

Developing and debugging embedded firmware requires specialized tools
that provide visibility into a running system without significantly
disrupting its behavior. Unlike application software on a
general-purpose OS, embedded code executes directly on hardware with no
runtime to catch exceptions or provide debug output, making
hardware-assisted debug interfaces and structured firmware update
mechanisms essential. The following sections cover the debug and
programming infrastructure that underpins modern embedded development.

\subsection{5.8.1 Debug Interfaces (JTAG and
SWD)}\label{debug-interfaces-jtag-and-swd}

Debug interfaces provide real-time access to the processor's internal
state, enabling developers to set breakpoints, step through code,
inspect registers and memory, and flash firmware during development.
JTAG (Joint Test Action Group, IEEE 1149.1) is the traditional debug
interface using four signal lines: TDI (Test Data In), TDO (Test Data
Out), TCK (Test Clock), and TMS (Test Mode Select), plus an optional
TRST (Test Reset). JTAG supports daisy-chaining multiple devices on the
same bus for boundary scan testing of PCB solder joints. SWD (Serial
Wire Debug) is an ARM-specific two-pin alternative (SWDIO and SWCLK)
that provides the same debug capabilities as JTAG with fewer pins,
making it the standard debug interface for Cortex-M microcontrollers.
Debug probes (such as ST-LINK, J-Link, and CMSIS-DAP) bridge between the
USB port of the development PC and the target's SWD/JTAG port. ARM
CoreSight debug architecture provides features including hardware
breakpoints (typically 4-8), data watchpoints, an Instrumentation Trace
Macrocell (ITM) for printf-style debug output, and an Embedded Trace
Macrocell (ETM) for non-intrusive instruction-level tracing.

\begin{examplebox}

\textbf{Example 5.8.1:} A developer uses SWD with a J-Link debug probe
to flash and debug a Cortex-M4 target. The SWD clock is set to 4 MHz and
the firmware image is 256 KB. The flash programming speed through SWD is
approximately 50 KB/s for this MCU (including sector erase time).
Determine (a) the firmware download time, (b) the SWD raw data rate, and
(c) the effective utilization of the SWD link during programming.

\textbf{Solution:}

(a) Download time: t = 256 KB / 50 KB/s = \textbf{5.12 seconds}

(b) SWD raw data rate: SWD uses a 1-bit data line at 4 MHz. With
protocol overhead (packet headers, turnarounds, ACK bits), the effective
raw throughput is approximately 50\% of the clock rate:\\
Raw data rate = 4 MHz × 0.50 / 8 = \textbf{250 KB/s}

(c) Effective utilization: 50 / 250 = \textbf{20\%}. The remaining 80\%
is consumed by flash erase operations (sector erase takes 16-500 ms per
sector depending on the MCU), flash write latency, and read-back
verification. This is why flash programming speed is limited by the
target's flash controller rather than the SWD link bandwidth.

\end{examplebox}

\subsection{5.8.2 Bootloaders}\label{bootloaders}

A bootloader is a small program stored in a protected region of flash
memory that executes before the main application firmware and provides a
mechanism for updating the application without a dedicated debug probe.
On reset, the bootloader runs first and checks for an update trigger ---
typically a GPIO pin state (e.g., a button held during power-up), a flag
set in EEPROM or backup registers, or a command received over a
communication interface. If an update is requested, the bootloader
receives the new firmware image over UART, USB, CAN, SPI, I2C, or even
wireless (OTA --- Over-The-Air), verifies its integrity (using CRC-32 or
SHA-256 hash), erases the application flash sectors, programs the new
image, and then jumps to the application entry point. Many MCUs include
a factory-programmed system bootloader in ROM (e.g., STM32 devices
support firmware upload via UART and USB DFU from the built-in
bootloader). Custom bootloaders add features such as dual-bank (A/B)
firmware slots for rollback protection --- if the new firmware fails to
boot, the bootloader reverts to the previous known-good image.

\begin{examplebox}

\textbf{Example 5.8.2:} A custom bootloader for a Cortex-M4 MCU occupies
the first 32 KB of flash (0x0800\_0000 to 0x0800\_7FFF). The application
starts at 0x0800\_8000. The total flash is 512 KB, and a dual-bank
scheme reserves 240 KB for each firmware slot with the first 32 KB
reserved for the bootloader. The bootloader receives firmware over UART
at 115200 baud (8N1). Determine (a) the maximum application size, (b)
the time to receive a 200 KB firmware image, and (c) the total update
time including flash erase (2 seconds for 240 KB) and programming (50
KB/s).

\textbf{Solution:}

(a) Maximum application size per slot: \textbf{240 KB}\\
Memory map: Bootloader (32 KB) + Slot A (240 KB) + Slot B (240 KB) = 512
KB

(b) UART receive time: Effective throughput at 115200 baud, 8N1 =
115,200 / 10 = 11,520 bytes/s\\
t\textsubscript{receive} = 200 × 1024 / 11,520 = 204,800 / 11,520 =
\textbf{17.78 seconds}

(c) Total update time:\\
Receive: 17.78 s + Flash erase: 2.0 s + Flash program: 200/50 = 4.0 s +
CRC verify: \textasciitilde0.1 s\\
Total = \textbf{23.9 seconds}

The UART transfer dominates --- using USB CDC (1.125 MB/s) would reduce
the receive time to 0.18 s and the total update to approximately 6.3
seconds.

\end{examplebox}

\chapter{Chapter 6}\label{chapter-6}

\chapter{Digital Logic}\label{digital-logic}

Digital logic is the foundation of all modern digital systems, from
simple combinational circuits to complex microprocessors and FPGAs. It
operates on discrete binary values (0 and 1) rather than continuous
analog signals, providing noise immunity, reproducibility, and the
ability to implement arbitrary computational functions through
combinations of basic logic gates. This chapter covers the number
systems used to represent digital data, the Boolean algebra that governs
logic operations, the fundamental gate types, and the combinational and
sequential building blocks from which all digital hardware is
constructed.

\section{6.1 Number Systems}\label{number-systems}

Digital systems operate on discrete quantities represented as patterns
of binary digits, but engineers routinely work with multiple number
systems to bridge the gap between hardware-level bit patterns and
human-readable values. Binary (base-2) is the native language of digital
circuits because each digit maps directly to a voltage level --- high or
low --- making it the only representation that hardware actually
implements. Hexadecimal (base-16) and octal (base-8) serve as compact
shorthand notations for binary data, with each hex digit representing
exactly four bits and each octal digit representing three bits, so
engineers can read and write register values, memory addresses, and
configuration masks without counting long strings of ones and zeros.
Decimal (base-10) remains necessary for human-facing quantities such as
clock frequencies, voltage levels, and performance metrics, requiring
conversion between bases during design and debugging. Understanding how
these number systems relate to one another --- and to the physical
voltage thresholds in real hardware --- is essential for writing
firmware, interpreting datasheets, configuring peripherals, and
diagnosing digital logic behavior.

\begin{figure}[H]

\hypertarget{fig-6-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch06_number_systems.png}

\caption{Figure 6.1: Number System Conversion Table (Decimal, Binary, Hex, Octal)}

\end{figure}

\subsection{6.1.1 Binary}\label{binary}

The binary number system is a base-2 positional system that uses only
two digits, 0 and 1, to represent all values. Each digit position
represents a power of 2, with the least significant bit (LSB) at
position 0 representing 2⁰ = 1 and each successive position doubling in
value. Binary is the native number system of digital electronics because
it maps directly to the two voltage states of transistor-based logic
circuits --- a logic 1 corresponds to a voltage above the high threshold
V\textsubscript{IH} and a logic 0 to a voltage below the low threshold
V\textsubscript{IL}, with a forbidden region in between that provides
noise immunity. The bit width of a binary number determines its range:
an n-bit unsigned integer spans 0 to 2ⁿ − 1 (for example, an 8-bit value
ranges from 0 to 255), while signed integers use two's complement
representation, where the most significant bit (MSB) serves as the sign
bit, giving a range of −2\textsuperscript{n−1} to 2\textsuperscript{n−1}
− 1 (an 8-bit signed value ranges from −128 to +127). Two's complement
is universally used in processors because addition and subtraction
circuits work identically for signed and unsigned operands, requiring no
special hardware for negative numbers. By convention, the MSB is the
leftmost bit (highest power of 2) and the LSB is the rightmost (2⁰),
though data sheets may number bits from 0 at the LSB or from 0 at the
MSB depending on the architecture. Conversion from decimal to binary is
performed by successive division by 2, recording the remainders from LSB
to MSB, and binary arithmetic follows the same positional rules as
decimal with carries propagating from right to left. For example, the
decimal number 13 is represented as 1101 in binary (8 + 4 + 0 + 1).

\begin{examplebox}

\textbf{Example 6.1.1:} Convert the decimal number 217 to binary.

\textbf{Solution:}\\
Perform successive division by 2, recording remainders:\\
217 / 2 = 108 remainder 1 (LSB)\\
108 / 2 = 54 remainder 0\\
54 / 2 = 27 remainder 0\\
27 / 2 = 13 remainder 1\\
13 / 2 = 6 remainder 1\\
6 / 2 = 3 remainder 0\\
3 / 2 = 1 remainder 1\\
1 / 2 = 0 remainder 1 (MSB)\\
Reading remainders from MSB to LSB: 217 decimal = 1101 1001 binary.\\
Verification: 128 + 64 + 0 + 16 + 8 + 0 + 0 + 1 = 217.

\end{examplebox}

\subsection{6.1.2 Hexadecimal}\label{hexadecimal}

Hexadecimal is a base-16 number system that uses digits 0-9 and letters
A-F (representing values 10-15) to provide a compact representation of
binary data. Each hexadecimal digit maps directly to a 4-bit binary
group (nibble), making it straightforward to convert between binary and
hex by simple grouping --- no division or multiplication is required,
just a one-to-one substitution of each 4-bit nibble for its hex digit.
For example, the binary value 1010 1111 splits into 1010 (A) and 1111
(F), giving 0xAF. This direct correspondence makes hex the dominant
notation in embedded systems and computer engineering: memory addresses
are written in hex (0x0800\_0000 for the start of STM32 flash),
peripheral register values are documented as hex masks (0x3F to enable
bits 0-5), color codes use two hex digits per RGB channel (\#FF8000 for
orange), and debugger memory dumps display data in hex columns for
readability. Two common prefix conventions identify hex values --- the
0x prefix used in C, Python, and most programming languages, and the h
suffix (such as 3Fh) found in assembly language and some datasheets.
Converting from hex to decimal requires expanding each digit by its
positional weight (powers of 16), while converting from decimal to hex
uses successive division by 16. An 8-bit byte requires exactly two hex
digits, a 16-bit half-word requires four, and a 32-bit word requires
eight, so hex notation scales cleanly with standard data widths and
allows engineers to instantly identify which bits are set in a register
or memory value.

\begin{examplebox}

\textbf{Example 6.1.2:} A 32-bit register contains the binary value 1100
1010 0011 1111 0000 1001 1110 0101. Express this in hexadecimal and
determine the decimal value of the upper 8 bits.

\textbf{Solution:}\\
Group into 4-bit nibbles and convert each to hex:\\
1100 = C, 1010 = A, 0011 = 3, 1111 = F, 0000 = 0, 1001 = 9, 1110 = E,
0101 = 5.\\
The hexadecimal value is 0xCA3F09E5.\\
The upper 8 bits are 1100 1010 = 0xCA. Converting to decimal: C = 12, A
= 10, so 12 * 16 + 10 = 192 + 10 = 202 decimal.

\end{examplebox}

\subsection{6.1.3 Octal}\label{octal}

Octal is a base-8 number system that uses digits 0-7, with each digit
representing a 3-bit binary group. While less common than hexadecimal in
modern digital systems, octal is still used in Unix/Linux file
permissions and some legacy computing contexts. Conversion between
binary and octal is performed by grouping binary digits into sets of
three from the LSB. For example, the binary value 101 110 is represented
as 56 in octal.

\begin{examplebox}

\textbf{Example 6.1.3:} Convert the octal number 375 to binary and then
to decimal.

\textbf{Solution:}\\
Convert each octal digit to its 3-bit binary equivalent:\\
3 = 011, 7 = 111, 5 = 101.\\
Binary: 011 111 101 = 11111101 (dropping the leading zero).\\
Decimal: 3 * 8² + 7 * 8¹ + 5 * 8⁰ = 3 * 64 + 7 * 8 + 5 * 1 = 192 + 56 +
5 = 253.\\
Verification from binary: 128 + 64 + 32 + 16 + 8 + 4 + 0 + 1 = 253.

\end{examplebox}

\section{6.2 Boolean Algebra}\label{boolean-algebra}

Boolean algebra is the mathematical foundation of digital logic,
operating on variables that can assume only two values: true (1) or
false (0). The three fundamental Boolean operations are AND (logical
conjunction, denoted A * B or A AND B), OR (logical disjunction, denoted
A + B or A OR B), and NOT (logical complement, denoted A' or NOT A).
Boolean expressions can be simplified using a set of identities and
theorems including the commutative, associative, distributive, identity,
complement, idempotent, absorption, and De Morgan's laws. De Morgan's
theorems are particularly important in digital design: (A * B)' = A' +
B' and (A + B)' = A' * B', allowing conversion between AND and OR forms.
Simplification of Boolean expressions directly reduces the number of
logic gates required in a circuit, lowering cost, power consumption, and
propagation delay.

\begin{figure}[H]

\hypertarget{fig-6-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch06_logic_gates.png}

\caption{Figure 6.2: Logic Gate Truth Tables}

\end{figure}

\subsection{6.2.1 Truth Tables}\label{truth-tables}

A truth table is a tabular representation that lists all possible
combinations of input values and their corresponding output values for a
Boolean function. For a function with n input variables, the truth table
has 2ⁿ rows covering every possible input combination. Truth tables
provide a complete and unambiguous specification of a logic function and
serve as the starting point for deriving Boolean expressions, designing
logic circuits, and verifying equivalence between different
implementations. They are also used to define the behavior of standard
logic gates and to validate the correctness of combinational circuits.

\begin{examplebox}

\textbf{Example 6.2.1:} Construct the truth table for the Boolean
function F(A, B, C) = A'B + BC'.

\textbf{Solution:}\\
List all 2³ = 8 input combinations and evaluate F:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llllllll@{}}
\toprule\noalign{}
A & B & C & A' & A'B & C' & BC' & F = A'B + BC' \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 \\
0 & 1 & 1 & 1 & 1 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 & 0 & 1 & 1 & 1 \\
1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\
\end{longtable}
}

The function F is 1 for input combinations (A,B,C) = (0,1,0), (0,1,1),
and (1,1,0), corresponding to minterms m2, m3, and m6.

\end{examplebox}

\subsection{6.2.2 Karnaugh Maps}\label{karnaugh-maps}

A Karnaugh map (K-map) is a graphical method for simplifying Boolean
expressions by visually identifying groups of adjacent cells that share
common variables. The map arranges truth table outputs in a grid where
adjacent cells differ by exactly one variable (Gray code ordering), and
groups of 1s in powers of two (1, 2, 4, 8) are circled to form
simplified product terms. K-maps are practical for functions of up to
four or five variables; beyond that, algorithmic methods such as the
Quine-McCluskey algorithm are used. K-maps can also handle ``don't
care'' conditions (inputs that will never occur or whose output value is
irrelevant), allowing further simplification by treating them as either
0 or 1 as convenient.

\begin{examplebox}

\textbf{Example 6.2.2:} Simplify the Boolean function F(A, B, C, D) =
sum of minterms (0, 1, 2, 5, 8, 9, 10) using a Karnaugh map.

\textbf{Solution:}\\
Arrange the 4-variable K-map with AB on rows and CD on columns (Gray
code order):

\begin{verbatim}
        CD=00  CD=01  CD=11  CD=10
AB=00 |  1   |  1   |  0   |  1   |
AB=01 |  0   |  1   |  0   |  0   |
AB=11 |  0   |  0   |  0   |  0   |
AB=10 |  1   |  1   |  0   |  1   |
\end{verbatim}

Two quads and one pair can be identified:\\
Group 1 (quad): minterms 0, 1, 8, 9 (AB=00/10, CD=00/01). Rows AB=00 and
AB=10 share B=0 (B'=1); columns CD=00 and CD=01 share C=0 (C'=1).
Result: B'C'.\\
Group 2 (quad): minterms 0, 2, 8, 10 (AB=00/10, CD=00/10). Common: B'
and D'. Result: B'D'.\\
Group 3 (pair): minterms 1 and 5 (AB=00/01, CD=01). These cells are
adjacent (differ only in the B bit), with common variables A'=1 (both
rows have A=0), C'=1, D=1. Result: A'C'D.\\
Check: B'C' covers \{0,1,8,9\}. B'D' covers \{0,2,8,10\}. A'C'D covers
\{1,5\}. All minterms \{0,1,2,5,8,9,10\} covered.\\
Simplified expression: \textbf{F = B'C' + B'D' + A'C'D}.

\end{examplebox}

\section{6.3 Logic Gates}\label{logic-gates}

Logic gates are the fundamental building blocks of all digital circuits,
each implementing a basic Boolean operation on one or more binary inputs
to produce a single binary output. At the physical level, a logic gate
is a small circuit of transistors --- CMOS technology implements gates
using complementary pairs of PMOS and NMOS transistors, where the gate
topology (series or parallel connections) determines the Boolean
function realized. The three primitive operations --- AND, OR, and NOT
--- can be combined to implement any Boolean function, but in practice
the NAND and NOR gates are preferred because they are functionally
complete (any function can be built from one gate type alone) and map
more efficiently to CMOS transistor structures. Every gate introduces a
propagation delay, typically ranging from sub-nanosecond in modern CMOS
processes to a few nanoseconds in discrete logic ICs, and the cumulative
delay through cascaded gates determines the maximum operating speed of a
digital circuit. Fan-in refers to the number of inputs a gate accepts
--- higher fan-in increases the gate's propagation delay and reduces
output drive strength because more transistors are stacked in series.
Fan-out is the number of gate inputs that one output can reliably drive;
exceeding the fan-out limit degrades voltage levels and increases
switching delay, potentially causing logic errors. Complex digital
systems --- processors, memory controllers, communication interfaces ---
are built hierarchically from these simple gate primitives: gates form
adders and multiplexers, which form ALUs and register files, which form
complete datapaths and control units.

\subsection{6.3.1 AND Gate}\label{and-gate}

The AND gate produces a high output (1) only when all of its inputs are
high. For a two-input AND gate, the Boolean expression is Y = A * B. The
AND function is fundamental to enable logic, where one signal gates
(enables or disables) the passage of another signal. AND gates are
implemented in CMOS technology using series-connected NMOS transistors
and parallel PMOS transistors.

\begin{examplebox}

\textbf{Example 6.3.1:} A 3-input AND gate has inputs A = 1, B = 1, C =
0. Determine the output. Then write the Boolean expression for a 3-input
AND gate and list the number of input combinations that produce a high
output.

\textbf{Solution:}\\
Y = A * B * C = 1 * 1 * 0 = 0.\\
The output is low because not all inputs are high.\\
The Boolean expression for a 3-input AND is Y = A * B * C.\\
With 3 inputs there are 2³ = 8 possible input combinations.\\
Only one combination (A=1, B=1, C=1) produces a high output.\\
The remaining 7 combinations produce a low output.\\
In general, an n-input AND gate produces a high output for only 1 out of
2ⁿ input combinations.

\end{examplebox}

\subsection{6.3.2 OR Gate}\label{or-gate}

The OR gate produces a high output (1) when any one or more of its
inputs are high. For a two-input OR gate, the Boolean expression is Y =
A + B. OR gates are used in logic circuits where any one of several
conditions should trigger an output. In CMOS implementation, OR gates
are typically constructed as a NOR gate followed by an inverter.

\begin{examplebox}

\textbf{Example 6.3.2:} A 4-input OR gate has inputs A = 0, B = 0, C =
0, D = 0. Determine the output. How many input combinations produce a
low output for an n-input OR gate?

\textbf{Solution:}\\
Y = A + B + C + D = 0 + 0 + 0 + 0 = 0.\\
The output is low because none of the inputs are high.\\
For an n-input OR gate, the output is low only when all inputs are 0,
which is exactly 1 combination out of 2ⁿ.\\
Therefore, 2ⁿ - 1 combinations produce a high output.\\
For this 4-input OR gate: 2⁴ - 1 = 15 out of 16 combinations produce a
high output, and only 1 combination (all zeros) produces a low output.

\end{examplebox}

\subsection{6.3.3 NOT Gate (Inverter)}\label{not-gate-inverter}

The NOT gate, or inverter, produces an output that is the logical
complement of its input: Y = A'. It is the simplest logic gate,
implemented in CMOS with a single complementary pair of PMOS and NMOS
transistors. Inverters are fundamental building blocks in digital
circuits, used for signal inversion, level shifting, and as components
within more complex gates. A chain of an even number of inverters can
serve as a buffer to restore signal integrity.

\begin{examplebox}

\textbf{Example 6.3.3:} A CMOS inverter is powered from
V\textsubscript{DD} = 3.3 V with a switching threshold at
V\textsubscript{DD}/2. The inverter has a propagation delay of 5 ns. If
4 inverters are chained together as a buffer, what is the total
propagation delay and the output logic level for an input of logic 1?

\textbf{Solution:}\\
Each inverter inverts the signal and adds 5 ns of delay.\\
Through 4 inverters: input 1 -\textgreater{} 0 -\textgreater{} 1
-\textgreater{} 0 -\textgreater{} 1.\\
Output = 1 (same as input, since 4 is even).\\
Total propagation delay = 4 * 5 ns = 20 ns.\\
The buffer restores the signal to a clean logic level (close to
V\textsubscript{DD} = 3.3 V for logic 1) at the cost of 20 ns latency.\\
If only 2 inverters were used, the delay would be 10 ns with the same
buffering function but less drive capability.

\end{examplebox}

\subsection{6.3.4 NAND Gate}\label{nand-gate}

The NAND gate produces a low output (0) only when all inputs are high;
otherwise, the output is high. Its Boolean expression is Y = (A * B)'.
The NAND gate is functionally complete, meaning any Boolean function can
be implemented using only NAND gates. This property makes it the
preferred universal gate in CMOS design because it requires fewer
transistors than an AND gate (which needs a NAND plus an inverter) and
is naturally implemented by the series-NMOS, parallel-PMOS CMOS
structure.

\begin{examplebox}

\textbf{Example 6.3.4:} Implement the function Y = A + B (OR gate) using
only 2-input NAND gates.

\textbf{Solution:}\\
Apply De Morgan's theorem: A + B = (A' * B')`. First, generate A' = (A *
A)' using a NAND gate with both inputs tied to A.\\
Similarly, B' = (B * B)`. Then Y = (A' * B')' = NAND(A', B').\\
Total NAND gates required: 3.\\
Gate 1: inputs A, A -\textgreater{} output A'.\\
Gate 2: inputs B, B -\textgreater{} output B'.\\
Gate 3: inputs A', B' -\textgreater{} output (A' * B')' = A + B.\\
This demonstrates the functional completeness of the NAND gate.

\end{examplebox}

\subsection{6.3.5 NOR Gate}\label{nor-gate}

The NOR gate produces a high output (1) only when all inputs are low;
otherwise, the output is low. Its Boolean expression is Y = (A + B)'.
Like the NAND gate, the NOR gate is functionally complete and can
implement any Boolean function. NOR gates are naturally implemented in
CMOS with series-PMOS and parallel-NMOS transistors. Historically, NOR
gates were used exclusively in the Apollo Guidance Computer.

\begin{examplebox}

\textbf{Example 6.3.5:} Implement the AND function Y = A * B using only
2-input NOR gates.

\textbf{Solution:}\\
Apply De Morgan's theorem: A * B = (A' + B')`. First, generate A' = (A +
A)' using a NOR gate with both inputs tied to A.\\
Similarly, B' = (B + B)`. Then compute A' + B' by applying De Morgan's:
(A' + B') needs a NOR followed by an inverter, but we can combine
steps.\\
Y = A * B = (A' + B')' = NOR(A', B').\\
Gate 1: NOR(A, A) = A'.\\
Gate 2: NOR(B, B) = B'.\\
Gate 3: NOR(A', B') = (A' + B')' = A * B.\\
Total NOR gates required: 3.\\
This confirms the NOR gate's functional completeness, mirroring the NAND
implementation of an OR gate.

\end{examplebox}

\subsection{6.3.6 XOR Gate}\label{xor-gate}

The Exclusive OR (XOR) gate produces a high output (1) when its inputs
differ (one high, one low) and a low output when inputs are the same.
Its Boolean expression is Y = A XOR B = A'B + AB'. XOR gates are
essential in arithmetic circuits (half adders and full adders), parity
generators and checkers, and error detection codes such as CRC. They
also function as a controlled inverter: when one input is held high, the
XOR gate inverts the other input; when held low, it passes the signal
unchanged.

\begin{examplebox}

\textbf{Example 6.3.6:} A 4-bit even parity generator uses XOR gates to
produce a parity bit P such that the total number of 1s in the 5-bit
word (D₃ D₂ D₁ D₀ P) is even. For the data word D₃D₂D₁D₀ = 1011,
determine P.

\textbf{Solution:}\\
P = D₃ XOR D₂ XOR D₁ XOR D₀.\\
Step 1: D₃ XOR D₂ = 1 XOR 0 = 1.\\
Step 2: result XOR D₁ = 1 XOR 1 = 0.\\
Step 3: result XOR D₀ = 0 XOR 1 = 1.\\
Therefore P = 1. The transmitted word is 1011\_1. Verification: the
number of 1s in 10111 is 4, which is even. This requires 3 two-input XOR
gates connected in a cascade structure, with a propagation delay of 3
gate delays.

\end{examplebox}

\subsection{6.3.7 Logic Families and Voltage
Levels}\label{logic-families-and-voltage-levels}

Digital logic gates are manufactured in different technology families,
each with distinct voltage thresholds, speed, and power characteristics.
The two dominant families are CMOS (Complementary
Metal-Oxide-Semiconductor) and TTL (Transistor-Transistor Logic). A
gate's input and output voltage levels are specified by four parameters:
V\textsubscript{IH} (minimum input voltage recognized as high),
V\textsubscript{IL} (maximum input voltage recognized as low),
V\textsubscript{OH} (minimum output voltage when driving high), and
V\textsubscript{OL} (maximum output voltage when driving low). The noise
margin is the voltage difference between guaranteed output levels and
required input levels: NM\textsubscript{H} = V\textsubscript{OH} −
V\textsubscript{IH} and NM\textsubscript{L} = V\textsubscript{IL} −
V\textsubscript{OL}. For 5 V CMOS (74HC series), typical values are
V\textsubscript{OH} = 4.9 V, V\textsubscript{OL} = 0.1 V,
V\textsubscript{IH} = 3.5 V, V\textsubscript{IL} = 1.5 V, giving noise
margins of 1.4 V. For 5 V TTL (74LS series), typical values are
V\textsubscript{OH} = 2.7 V, V\textsubscript{OL} = 0.5 V,
V\textsubscript{IH} = 2.0 V, V\textsubscript{IL} = 0.8 V, giving noise
margins of 0.7 V and 0.3 V. CMOS gates have near-zero static power
dissipation (current flows only during switching) but dynamic power
increases with frequency as P\textsubscript{dyn} = C\textsubscript{L} ×
V\textsubscript{DD}² × f, where C\textsubscript{L} is the load
capacitance. Fan-out, the number of gate inputs one output can drive, is
effectively unlimited for CMOS at low frequencies (since inputs draw
negligible DC current) but is limited at high frequencies by output
drive current and capacitive loading. When interfacing between different
voltage levels (e.g., 3.3 V and 5 V logic), level-shifting circuits or
bidirectional voltage translators are required to prevent damage and
ensure valid logic levels.

\begin{examplebox}

\textbf{Example 6.3.7:} A 74HC00 CMOS NAND gate operates at
V\textsubscript{DD} = 5 V with V\textsubscript{OH} = 4.9 V,
V\textsubscript{OL} = 0.1 V, V\textsubscript{IH} = 3.5 V, and
V\textsubscript{IL} = 1.5 V. Calculate the high and low noise margins.
If this gate drives a 74LS00 TTL NAND gate with V\textsubscript{IH} =
2.0 V and V\textsubscript{IL} = 0.8 V, are the logic levels compatible?

\textbf{Solution:}\\
CMOS noise margins: NM\textsubscript{H} = V\textsubscript{OH} −
V\textsubscript{IH} = 4.9 − 3.5 = 1.4 V.\\
NM\textsubscript{L} = V\textsubscript{IL} − V\textsubscript{OL} = 1.5 −
0.1 = 1.4 V.\\
For the CMOS-to-TTL interface: The CMOS high output (4.9 V) exceeds the
TTL V\textsubscript{IH} requirement (2.0 V) by 2.9 V --- compatible.\\
The CMOS low output (0.1 V) is well below the TTL V\textsubscript{IL}
requirement (0.8 V) by 0.7 V --- compatible.\\
The CMOS gate can directly drive the TTL gate with generous noise
margins.\\
The reverse (TTL driving CMOS) is problematic: V\textsubscript{OH}(TTL)
= 2.7 V \textless{} V\textsubscript{IH}(CMOS) = 3.5 V, so a pull-up
resistor or level shifter is needed.

\end{examplebox}

\section{6.4 Combinational Circuits}\label{combinational-circuits}

Combinational circuits are logic circuits whose outputs depend solely on
the current combination of input values, with no memory of previous
states --- in contrast to sequential circuits, which incorporate storage
elements and whose outputs depend on both current inputs and past
history. This memoryless property means that a combinational circuit's
behavior is completely specified by a truth table or a set of Boolean
expressions: given the same inputs at any point in time, the circuit
always produces the same outputs. Design of combinational circuits
follows a systematic process: define the desired input-output
relationship in a truth table, derive Boolean expressions from the
minterms (or maxterms), simplify using Boolean algebra or Karnaugh maps
to minimize gate count, and implement the result with physical logic
gates. Common combinational building blocks include multiplexers (data
selectors), demultiplexers (data distributors), encoders, decoders, and
arithmetic circuits such as adders, subtractors, and comparators. These
modules serve as the datapath components in processors and digital
systems --- the ALU, the instruction decoder, the address calculator,
and the bus routing logic are all fundamentally combinational. Because
combinational outputs can change whenever any input changes (after
propagation delay), glitches and hazards must be considered when outputs
feed clocked elements, and careful timing analysis ensures that all
combinational paths settle before the next clock edge captures the
result.

\subsection{6.4.1 Adders}\label{adders}

A half adder adds two single-bit inputs (A and B) and produces a sum (S
= A XOR B) and a carry output (C = A AND B). A full adder extends this
to three inputs (A, B, and carry-in) to produce a sum and carry-out,
enabling multi-bit addition by cascading full adders in a ripple-carry
configuration. The critical path through a ripple-carry adder grows
linearly with the number of bits, limiting speed. Faster alternatives
include carry-lookahead adders, which compute carry signals in parallel
using generate and propagate logic, reducing the delay to O(log n) for
an n-bit addition.

\begin{examplebox}

\textbf{Example 6.4.1:} Add the 4-bit binary numbers A = 1011 and B =
0110 using a ripple-carry adder. Show the carry chain.

\textbf{Solution:}\\
Add bit by bit from LSB to MSB, propagating carries:\\
Bit 0: A₀ + B₀ + C\textsubscript{in} = 1 + 0 + 0 = 1, Sum₀ = 1, C₁ =
0.\\
Bit 1: A₁ + B₁ + C₁ = 1 + 1 + 0 = 10, Sum₁ = 0, C₂ = 1.\\
Bit 2: A₂ + B₂ + C₂ = 0 + 1 + 1 = 10, Sum₂ = 0, C₃ = 1.\\
Bit 3: A₃ + B₃ + C₃ = 1 + 0 + 1 = 10, Sum₃ = 0, C\textsubscript{out} =
1.\\
Result: C\textsubscript{out} Sum₃ Sum₂ Sum₁ Sum₀ = 1\_0001 = 10001
binary = 17 decimal.\\
Verification: 1011 (11) + 0110 (6) = 17. The ripple-carry delay is 4
full-adder delays since the carry must propagate through all 4 stages
sequentially.

\end{examplebox}

\subsection{6.4.2 Multiplexers}\label{multiplexers}

A multiplexer (MUX) is a combinational circuit that selects one of 2ⁿ
input data lines and routes it to a single output, controlled by n
select lines. A 2:1 MUX has the Boolean expression Y = S'A + SB, where S
is the select line and A, B are the data inputs. Multiplexers can
implement any Boolean function of n variables by using the function's
truth table values as data inputs and the variables as select lines.
They are fundamental building blocks in data routing, bus architectures,
and FPGA lookup tables (LUTs).

\begin{examplebox}

\textbf{Example 6.4.2:} An 8:1 multiplexer is used to implement the
Boolean function F(A, B, C) = sum of minterms (1, 2, 4, 6, 7). Connect
variables A, B, C to the select lines S₂, S₁, S₀ respectively. Determine
the data input connections.

\textbf{Solution:}\\
The select inputs address the minterms directly. Connect each data input
D\textsubscript{i} to 1 if minterm i is in the function, and to 0
otherwise:\\
D₀ (ABC = 000, minterm 0) = 0.\\
D₁ (ABC = 001, minterm 1) = 1.\\
D₂ (ABC = 010, minterm 2) = 1.\\
D₃ (ABC = 011, minterm 3) = 0.\\
D₄ (ABC = 100, minterm 4) = 1.\\
D₅ (ABC = 101, minterm 5) = 0.\\
D₆ (ABC = 110, minterm 6) = 1.\\
D₇ (ABC = 111, minterm 7) = 1.\\
Connect D₁, D₂, D₄, D₆, D₇ to V\textsubscript{CC} (logic 1) and D₀, D₃,
D₅ to GND (logic 0). The single 8:1 MUX implements the entire 3-variable
function with no additional gates.

\end{examplebox}

\subsection{6.4.3 Decoders}\label{decoders}

A decoder is a combinational circuit that converts an n-bit binary input
into one of 2ⁿ unique output lines, with exactly one output active for
each input combination. A 2-to-4 decoder, for example, takes a 2-bit
input and activates one of four output lines. Decoders are used in
memory address decoding (selecting a specific memory chip or register),
instruction decoding in processors, and seven-segment display drivers. A
decoder with an enable input can also function as a demultiplexer,
routing a single input signal to one of several outputs.

\begin{examplebox}

\textbf{Example 6.4.3:} A 3-to-8 decoder is used for memory address
decoding. The system has 8 memory chips, each 8 KB in size, mapped to a
64 KB address space starting at address 0x0000. Determine the address
range for each chip select output and which decoder output selects the
chip at address 0x6000.

\textbf{Solution:}\\
Each chip occupies 8 KB = 0x2000 addresses.\\
The 3 decoder inputs are connected to address lines A₁₅, A₁₄, A₁₃ (the 3
MSBs of the 16-bit address).\\
Decoder output mapping:\\
Y₀: A₁₅-A₁₃ = 000 -\textgreater{} 0x0000 to 0x1FFF (chip 0).\\
Y₁: A₁₅-A₁₃ = 001 -\textgreater{} 0x2000 to 0x3FFF (chip 1).\\
Y₂: A₁₅-A₁₃ = 010 -\textgreater{} 0x4000 to 0x5FFF (chip 2).\\
Y₃: A₁₅-A₁₃ = 011 -\textgreater{} 0x6000 to 0x7FFF (chip 3).\\
Y₄: A₁₅-A₁₃ = 100 -\textgreater{} 0x8000 to 0x9FFF (chip 4).\\
Y₅ through Y₇: 0xA000 to 0xFFFF (chips 5-7).\\
Address 0x6000 falls in the range 0x6000-0x7FFF, so decoder output Y₃
selects the corresponding chip.

\end{examplebox}

\subsection{6.4.4 Encoders}\label{encoders}

An encoder is the functional complement of a decoder: it converts 2ⁿ
input lines into an n-bit binary output code. A simple 4-to-2 encoder
produces a 2-bit output representing which of its 4 inputs is active,
with the assumption that only one input is active at a time. A priority
encoder removes this restriction by assigning priority levels to the
inputs and encoding the highest-priority active input, outputting both
the binary code and a valid flag indicating that at least one input is
asserted. Priority encoders are used in interrupt controllers (selecting
the highest-priority pending interrupt), keyboard scanners, and
leading-zero detectors in floating-point units.

\begin{examplebox}

\textbf{Example 6.4.4:} An 8-to-3 priority encoder has inputs I₇
(highest priority) through I₀ (lowest priority) and outputs a 3-bit code
Y₂Y₁Y₀ plus a valid bit V. If inputs I₅, I₃, and I₁ are simultaneously
active (all others inactive), determine the output code and identify
which input is encoded.

\textbf{Solution:}\\
The priority encoder selects the highest-priority active input.\\
Among I₅, I₃, and I₁, the highest priority is I₅.\\
The output code encodes input 5: Y₂Y₁Y₀ = 101 (binary for 5).\\
The valid bit V = 1, indicating at least one input is active.\\
Inputs I₃ and I₁ are ignored because they have lower priority than I₅.\\
If I₅ were deasserted while I₃ and I₁ remained active, the output would
change to Y₂Y₁Y₀ = 011 (encoding I₃).\\
The priority encoder resolves simultaneous assertions without the
ambiguity that would cause errors in a simple encoder.

\end{examplebox}

\section{6.5 Sequential Circuits}\label{sequential-circuits}

Sequential circuits are logic circuits whose outputs depend on both the
current inputs and the history of past inputs, giving them memory
capability. They contain storage elements (latches or flip-flops) that
maintain state between clock cycles, in addition to combinational logic.
Sequential circuits are classified as synchronous (state changes occur
only on clock edges) or asynchronous (state changes occur whenever
inputs change). All practical digital systems, from simple counters to
complex processors, are built from sequential circuits.

\subsection{6.5.1 Latches}\label{latches}

A latch is a level-sensitive bistable storage element that can hold one
bit of data. The SR (Set-Reset) latch, constructed from cross-coupled
NOR or NAND gates, stores a bit based on which input (Set or Reset) was
last activated, with the constraint that both inputs must not be
asserted simultaneously. The D (Data) latch captures the value of the D
input whenever the enable (or gate) signal is active and holds that
value when the enable goes inactive. While simple, latches are
level-sensitive, meaning they are transparent (input changes pass
through to the output) for the entire duration the enable signal is
active, which can cause timing problems in synchronous designs.

\begin{examplebox}

\textbf{Example 6.5.1:} A D latch has Enable = 1. The D input changes in
the following sequence: D = 0 at t = 0 ns, D = 1 at t = 15 ns, D = 0 at
t = 30 ns. Enable goes low at t = 25 ns. Determine the output Q at t =
10 ns, t = 20 ns, and t = 35 ns.

\textbf{Solution:}\\
While Enable = 1, the latch is transparent and Q follows D.\\
At t = 10 ns: Enable = 1 and D = 0 (set at t = 0), so Q = 0.\\
At t = 20 ns: Enable = 1 and D = 1 (changed at t = 15), so Q = 1.\\
At t = 25 ns: Enable goes low. The latch captures and holds the current
value of D, which is 1 at that instant.\\
At t = 30 ns: D changes to 0, but Enable = 0, so the latch is opaque and
Q remains at its latched value.\\
At t = 35 ns: Q = 1 (held from the value captured when Enable went low).
This illustrates the transparency problem: the D change at t = 15 ns
passed through to Q because Enable was still high.

\end{examplebox}

\subsection{6.5.2 Flip-Flops}\label{flip-flops}

A flip-flop is an edge-triggered bistable storage element that captures
its input only on the rising or falling edge of a clock signal,
providing well-defined timing for synchronous circuit operation. The D
flip-flop is the most common type, capturing the D input value at the
clock edge and holding it stable at Q until the next active clock edge.
JK flip-flops add the ability to toggle (complement) the stored value
when both J and K inputs are high, and T (Toggle) flip-flops toggle the
output on each active clock edge when the T input is high. Key timing
parameters include setup time (minimum time the input must be stable
before the clock edge), hold time (minimum time the input must remain
stable after the clock edge), and clock-to-Q delay (propagation delay
from the clock edge to the output change). Violating setup or hold times
can cause metastability, a condition where the flip-flop enters an
indeterminate state that may take an unpredictable amount of time to
resolve.

\begin{examplebox}

\textbf{Example 6.5.2:} A positive-edge-triggered D flip-flop has a
setup time t\textsubscript{su} = 2 ns, hold time t\textsubscript{h} = 1
ns, and clock-to-Q delay t\textsubscript{cq} = 3 ns. The clock period is
10 ns. What is the maximum combinational logic delay allowed between two
cascaded flip-flops?

\textbf{Solution:}\\
In a synchronous pipeline, the output of flip-flop 1 passes through
combinational logic and must arrive at the input of flip-flop 2 before
its setup time.\\
The timing constraint is: t\textsubscript{cq} + t\textsubscript{logic} +
t\textsubscript{su} \textless= T\textsubscript{clk}.\\
Solving for maximum logic delay: t\textsubscript{logic}(max) =
T\textsubscript{clk} - t\textsubscript{cq} - t\textsubscript{su} = 10 -
3 - 2 = 5 ns.\\
Any combinational path longer than 5 ns will violate the setup time of
the receiving flip-flop, causing potential metastability or incorrect
data capture.\\
The maximum operating frequency is f\textsubscript{max} = 1 /
(t\textsubscript{cq} + t\textsubscript{logic} + t\textsubscript{su}).\\
If the logic delay is 4 ns: f\textsubscript{max} = 1 / (3 + 4 + 2) = 1 /
9 ns = 111.1 MHz.

\end{examplebox}

\subsection{6.5.3 Counters}\label{counters}

A counter is a sequential circuit that cycles through a defined sequence
of states, typically incrementing or decrementing a binary value on each
clock pulse. Binary counters count in natural binary sequence (0, 1, 2,
\ldots, 2ⁿ - 1) and are built by cascading flip-flops with appropriate
feedback. Synchronous counters clock all flip-flops simultaneously,
ensuring clean transitions and predictable timing, while asynchronous
(ripple) counters clock each stage from the output of the previous
stage, introducing cumulative propagation delay. Counters are used in
frequency division, event counting, timing generation, and as the basis
for address generators and program counters in processors. Modulo-N
counters reset to zero after reaching N-1, enabling division of a clock
frequency by any integer value.

\begin{examplebox}

\textbf{Example 6.5.3:} Design a modulo-6 counter using a 3-bit binary
counter. The input clock is 12 MHz. Determine the output frequency and
the reset logic.

\textbf{Solution:}\\
A 3-bit binary counter naturally counts from 000 to 111 (modulo-8).\\
To create a modulo-6 counter, detect the count of 6 (binary 110) and
force an asynchronous reset to 000.\\
Reset logic: RESET = Q₂ * Q₁ * Q₀', but since we want to detect 110, we
need RESET = Q₂ AND Q₁ (since Q₀ = 0 at count 110, and this is the first
time Q₂ and Q₁ are both high after reset).\\
More precisely, detect count 110: RESET = Q₂ AND Q₁ AND (NOT Q₀).
However, Q₀ is 0 at count 6, so RESET = Q₂ AND Q₁ suffices (count 6 =
110 is the first occurrence of Q₂=Q₁=1).\\
The counter cycles: 000, 001, 010, 011, 100, 101, 110 (reset)
-\textgreater{} 000.\\
Count sequence is 0-5 (6 states).\\
Output frequency = 12 MHz / 6 = 2 MHz, taken from the most significant
bit (Q₂) or the reset signal.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-6-5-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch06_counter_timing.png}

\caption{Figure 6.5.3: 3-Bit Binary Counter Timing Diagram}

\end{figure}

\subsection{6.5.4 Shift Registers}\label{shift-registers}

A shift register is a chain of flip-flops where the output of each stage
feeds the input of the next, shifting data one position per clock cycle.
They support serial-in/serial-out (SISO), serial-in/parallel-out (SIPO),
parallel-in/serial-out (PISO), and parallel-in/parallel-out (PIPO)
configurations. Shift registers are used for serial-to-parallel and
parallel-to-serial data conversion in communication interfaces,
temporary data storage, and time delays. Linear Feedback Shift Registers
(LFSRs) use XOR feedback from selected tap positions to generate
pseudo-random binary sequences, widely used in CRC calculation,
scrambling, and built-in self-test (BIST) circuits.

\begin{examplebox}

\textbf{Example 6.5.4:} An 8-bit serial-in/parallel-out (SIPO) shift
register receives the serial bit stream 1 0 1 1 0 1 0 0 (MSB first) at a
clock rate of 2 MHz. After 8 clock pulses, what is the parallel output
and how long did the conversion take?

\textbf{Solution:}\\
The bits are shifted in one per clock cycle, MSB first. After 8 clock
pulses, the register contains the complete byte:\\
Clock 1: shift in 1 -\textgreater{} register = xxxxxxx1\\
Clock 2: shift in 0 -\textgreater{} register = xxxxxx10\\
Clock 3: shift in 1 -\textgreater{} register = xxxxx101\\
Clock 4: shift in 1 -\textgreater{} register = xxxx1011\\
Clock 5: shift in 0 -\textgreater{} register = xxx10110\\
Clock 6: shift in 1 -\textgreater{} register = xx101101\\
Clock 7: shift in 0 -\textgreater{} register = x1011010\\
Clock 8: shift in 0 -\textgreater{} register = 10110100\\
Parallel output after 8 clocks: 1011 0100 = 0xB4 = 180 decimal.\\
Conversion time = 8 clock cycles / 2 MHz = 4 μs. The serial-to-parallel
conversion trades time for pin count, using 1 data pin instead of 8.

\end{examplebox}

\subsection{6.5.5 State Machines}\label{state-machines}

A finite state machine (FSM) is a sequential circuit that transitions
between a finite number of states based on its current state and input
values, producing outputs according to a defined mapping. Moore machines
produce outputs that depend only on the current state, making their
outputs synchronous and glitch-free since they change only on clock
edges. Mealy machines produce outputs that depend on both the current
state and the current inputs, allowing faster response (output can
change within a clock cycle when inputs change) but with the risk of
glitches on the outputs. FSMs are designed by defining a state diagram
(circles for states, arrows for transitions labeled with input
conditions), deriving a state table, assigning binary codes to states,
and implementing the next-state logic and output logic with flip-flops
and combinational gates. State machines are the backbone of digital
controllers, protocol handlers, traffic light controllers, vending
machines, and the control units within processors.

\begin{examplebox}

\textbf{Example 6.5.5:} Design a Moore state machine that detects the
input sequence ``101'' on a serial input X, asserting output Z = 1 for
one clock cycle when the sequence is detected. The detector should be
overlapping, meaning the final ``1'' of one detection can serve as the
first ``1'' of the next.

\textbf{Solution:}\\
Define four states based on progress toward detecting ``101'':\\
S0 = idle (no relevant bits received), Z = 0.\\
S1 = received ``1'', Z = 0.\\
S2 = received ``10'', Z = 0.\\
S3 = received ``101'' (sequence detected), Z = 1.

State transitions (current state, input X → next state):\\
S0, X=0 → S0. S0, X=1 → S1.\\
S1, X=0 → S2. S1, X=1 → S1 (restart with new ``1'').\\
S2, X=0 → S0 (reset, ``100'' is not a prefix of ``101''). S2, X=1 → S3
(sequence complete).\\
S3, X=0 → S2 (overlapping: the ``1'' from S3 serves as start, then ``0''
→ S2). S3, X=1 → S1 (overlapping: restart with new ``1'').

Using 2-bit state encoding (S0=00, S1=01, S2=10, S3=11) with two D
flip-flops Q₁Q₀, the next-state equations are:\\
Q₁\textsuperscript{+} = Q₀ · X' (S1→S2 and S3→S2) + Q₁ · Q₀' · X
(S2→S3).\\
After K-map simplification: Q₁\textsuperscript{+} = Q₀ · X' + Q₁ · Q₀' ·
X, Q₀\textsuperscript{+} = X.\\
Output: Z = Q₁ · Q₀ (high only in state S3 = 11). This requires 2
flip-flops, 2 AND gates, 1 OR gate, and 1 inverter.

\end{examplebox}

\section{6.6 Programmable Logic}\label{programmable-logic}

Programmable logic devices allow engineers to implement custom digital
logic functions in silicon without designing an application-specific
integrated circuit (ASIC). Rather than committing to a fixed gate-level
design at manufacturing time, programmable devices can be configured ---
and often reconfigured --- in the field by loading a bitstream that
defines connections between logic elements. This flexibility compresses
development time and cost: a design can be tested in real hardware,
debugged, and updated without a new silicon tape-out. The two dominant
families are FPGAs (Field-Programmable Gate Arrays), which use volatile
SRAM-based configuration cells and offer the largest capacity and
highest performance, and CPLDs (Complex Programmable Logic Devices),
which use non-volatile flash and offer instant-on operation with
predictable timing. Together they span a wide range of applications from
simple glue logic to complete system-on-chip implementations.

\subsection{6.6.1 FPGA}\label{fpga}

A Field-Programmable Gate Array (FPGA) is an integrated circuit that can
be configured by the user after manufacturing to implement virtually any
digital logic function. FPGAs consist of an array of configurable logic
blocks (CLBs) containing lookup tables (LUTs), flip-flops, and
multiplexers, surrounded by programmable interconnects and I/O blocks.
The logic function of each CLB is defined by the contents of its LUTs
(typically 4-input or 6-input), which can implement any Boolean function
of their input variables. FPGAs are programmed using hardware
description languages (HDL) such as Verilog or VHDL, which are
synthesized into a configuration bitstream that defines the LUT contents
and routing connections. They are used for prototyping ASICs,
implementing custom digital signal processing, high-speed communication
interfaces, and applications requiring hardware-level parallelism and
deterministic timing that software cannot achieve.

\begin{examplebox}

\textbf{Example 6.6.1:} An FPGA has 5000 6-input LUTs and 5000
flip-flops. A design requires 200 instances of an 8-bit register (8
flip-flops each) and 150 instances of a 4-input Boolean function (1 LUT
each). Determine the resource utilization.

\textbf{Solution:}\\
Flip-flop usage: 200 registers * 8 flip-flops each = 1600 flip-flops.\\
Utilization = 1600 / 5000 = 32.0\%.\\
LUT usage: each 4-input Boolean function fits in one 6-input LUT (since
a 6-input LUT can implement any function of up to 6 variables).\\
LUTs used = 150.\\
Additionally, the 8-bit registers may require LUTs for enable/load
logic; assume 1 LUT per register for load control = 200 LUTs.\\
Total LUTs = 150 + 200 = 350.\\
LUT utilization = 350 / 5000 = 7.0\%.\\
Both resources are well within capacity.\\
The design uses 32\% of flip-flops and 7\% of LUTs, leaving substantial
room for additional logic such as state machines, communication
interfaces, and debug circuitry.

\end{examplebox}

\subsection{6.6.2 CPLD}\label{cpld}

A Complex Programmable Logic Device (CPLD) is a programmable logic
device that combines multiple programmable logic array blocks with a
fixed interconnect structure on a single chip. Unlike FPGAs, CPLDs use
non-volatile configuration memory (typically flash), so they are
operational immediately at power-up without requiring an external
configuration memory. CPLDs offer predictable pin-to-pin timing because
of their fixed interconnect architecture, making them well-suited for
glue logic, bus interface control, and simple state machines. They are
typically smaller than FPGAs (hundreds to a few thousand logic elements)
and are used where a small to moderate amount of programmable logic is
needed with instant-on capability and deterministic timing.

\begin{examplebox}

\textbf{Example 6.6.2:} A CPLD with a guaranteed pin-to-pin propagation
delay of 7.5 ns is used as bus interface glue logic. It decodes a 16-bit
address bus to generate 4 chip select signals and provides a
bidirectional 8-bit data bus buffer with read/write control. Estimate
the total macrocell usage if each chip select requires 1 macrocell and
each data bus buffer bit requires 2 macrocells (one for direction
control logic, one for the output). The CPLD has 128 macrocells.

\textbf{Solution:}\\
Chip select logic: 4 chip selects * 1 macrocell each = 4 macrocells.\\
Data bus buffering: 8 bits * 2 macrocells per bit = 16 macrocells.\\
Additional control logic (read/write timing, bus enable): estimate 4
macrocells.\\
Total macrocells used = 4 + 16 + 4 = 24 macrocells.\\
Utilization = 24 / 128 = 18.75\%.\\
The maximum bus interface speed is limited by the pin-to-pin delay:
minimum cycle time = 2 * 7.5 ns = 15 ns (for a read requiring address
decode and data return), supporting bus speeds up to 1 / 15 ns = 66.7
MHz.\\
The instant-on capability ensures the chip selects are valid immediately
at power-up, preventing bus contention during system initialization.

\end{examplebox}

\subsection{6.6.3 Timing Analysis}\label{timing-analysis}

Timing analysis ensures that all signals in a synchronous digital
circuit arrive at their destinations within the required time windows.
Every logic gate introduces a propagation delay --- the time from an
input change to the corresponding output change --- characterized by
t\textsubscript{pHL} (high-to-low transition) and t\textsubscript{pLH}
(low-to-high transition), which may differ due to asymmetric PMOS/NMOS
drive strengths. The critical path is the longest combinational delay
between any two flip-flops in the design and determines the maximum
clock frequency: f\textsubscript{max} = 1 / (t\textsubscript{cq} +
t\textsubscript{crit} + t\textsubscript{su}), where t\textsubscript{cq}
is the clock-to-Q delay of the source flip-flop, t\textsubscript{crit}
is the critical path delay, and t\textsubscript{su} is the setup time of
the destination flip-flop. The hold time constraint ensures that data
remains stable long enough after the clock edge: t\textsubscript{cq} +
t\textsubscript{min} ≥ t\textsubscript{h}, where t\textsubscript{min} is
the minimum combinational delay and t\textsubscript{h} is the hold time.
Hazards are unwanted momentary glitches in combinational logic outputs
caused by unequal propagation delays through different signal paths. A
static-1 hazard produces a brief 0 glitch when the output should remain
at 1, and a static-0 hazard produces a brief 1 glitch when the output
should remain at 0. Hazards can be eliminated by adding redundant
product terms identified from the K-map or by registering outputs with
flip-flops.

\begin{examplebox}

\textbf{Example 6.6.3:} A synchronous circuit uses flip-flops with
t\textsubscript{cq} = 1.2 ns, t\textsubscript{su} = 0.8 ns, and
t\textsubscript{h} = 0.3 ns. The combinational logic between two
flip-flops consists of a 3-level gate network with gate delays of 2.5
ns, 1.8 ns, and 3.0 ns. Determine the critical path delay, maximum clock
frequency, and whether the hold time constraint is satisfied assuming
the minimum path delay through the logic is 1.5 ns.

\textbf{Solution:}\\
Critical path delay: t\textsubscript{crit} = 2.5 + 1.8 + 3.0 = 7.3 ns.\\
Maximum clock frequency: f\textsubscript{max} = 1 / (t\textsubscript{cq}
+ t\textsubscript{crit} + t\textsubscript{su}) = 1 / (1.2 + 7.3 + 0.8) =
1 / 9.3 ns = 107.5 MHz.\\
Hold time check: t\textsubscript{cq} + t\textsubscript{min} = 1.2 + 1.5
= 2.7 ns ≥ t\textsubscript{h} = 0.3 ns --- satisfied with 2.4 ns of
margin.\\
The design can safely operate at up to 107.5 MHz. If a higher frequency
is needed, the critical path must be shortened by using faster gates,
reducing logic levels (pipelining), or restructuring the combinational
logic.

\end{examplebox}

\chapter{Chapter 7}\label{chapter-7}

\chapter{Circuit Analysis}\label{circuit-analysis}

Circuit analysis is the systematic study of electrical circuits to
determine voltages, currents, and power at every point in a network. It
provides the essential analytical techniques that underpin all branches
of electrical engineering, from power systems and electronics to
communications and control. By applying fundamental laws and theorems to
circuit models composed of ideal elements such as resistors, capacitors,
inductors, and sources, engineers can predict circuit behavior, verify
designs, and troubleshoot faults.

\section{7.1 Electric Charge and
Current}\label{electric-charge-and-current}

Electric charge and current are the most fundamental quantities in
electrical engineering. Every circuit phenomenon --- voltage drops,
power dissipation, magnetic fields, signal propagation --- ultimately
traces back to the movement and accumulation of electric charge.
Understanding charge, current, and voltage at a conceptual level
provides the foundation for all circuit analysis techniques that follow.

\subsection{7.1.1 Electric Charge}\label{electric-charge}

Electric charge is an intrinsic property of subatomic particles that
gives rise to electromagnetic forces. The two types of charge are
positive (carried by protons) and negative (carried by electrons). The
SI unit of charge is the coulomb (C), and the elementary charge is e ≈
1.602 × 10⁻¹⁹ C --- the magnitude of charge on a single electron or
proton. One coulomb equals approximately 6.242 × 10¹⁸ elementary
charges. Charge is conserved (it cannot be created or destroyed, only
transferred) and quantized (it always appears in integer multiples of
e). In conductors such as copper, the outer valence electrons are
loosely bound and free to move through the crystal lattice, forming a
``sea'' of mobile charge carriers. In insulators, electrons are tightly
bound and cannot move freely.

\begin{examplebox}

\textbf{Example 7.1.1:} A copper wire has a cross-sectional area of 2.08
mm² (14 AWG). Copper has a free electron density of n = 8.5 × 10²⁸
electrons/m³. If the wire carries a current of 15 A, determine (a) the
total charge that flows through the wire in 1 minute, (b) the number of
electrons that pass a cross-section in that time, and (c) the drift
velocity of the electrons.

\textbf{Solution:}

(a) Charge: Q = I × t = 15 × 60 = \textbf{900 C}

(b) Number of electrons: N = Q/e = 900 / (1.602 × 10⁻¹⁹) = \textbf{5.62
× 10²¹ electrons}

(c) Drift velocity: v\textsubscript{d} = I / (n × A × e) = 15 / (8.5 ×
10²⁸ × 2.08 × 10⁻⁶ × 1.602 × 10⁻¹⁹)\\
v\textsubscript{d} = 15 / (2.831 × 10⁴) = 5.30 × 10⁻⁴ m/s = \textbf{0.53
mm/s}

Despite the large current, the electrons drift remarkably slowly --- the
electrical signal propagates near the speed of light because the
electric field pushes all electrons in the wire simultaneously.

\end{examplebox}

\subsection{7.1.2 Current}\label{current}

Electric current is the rate of flow of electric charge past a point in
a circuit, defined mathematically as I = dQ/dt and measured in amperes
(A), where one ampere equals one coulomb per second. Conventional
current direction is defined as the direction positive charges would
move --- from higher potential (+) to lower potential (−) --- which is
opposite to the actual electron flow in metallic conductors. This
convention, established before the discovery of the electron, is
universally used in circuit analysis and causes no practical difficulty
as long as it is applied consistently. Current can be direct (DC), where
the magnitude and direction are constant, or alternating (AC), where the
current periodically reverses direction --- most power systems operate
with 50 or 60 Hz AC. Current density J = I/A (A/m²) describes how
current is distributed across a conductor cross-section and is an
important design parameter for preventing overheating. The magnitudes
encountered in practice span an enormous range: picoamperes in
photodiode dark current, nanoamperes in CMOS leakage, milliamperes in
sensor circuits, amperes in household wiring, and kiloamperes in
industrial power systems and arc furnaces. Current is always measured by
placing an ammeter (or current-sensing resistor) in series with the
circuit element of interest, since the instrument must carry the same
current as the element being measured. Kirchhoff's Current Law (KCL) ---
which states that the algebraic sum of all currents entering and leaving
any node is zero --- is the fundamental conservation principle governing
current distribution in every circuit and is developed fully in §7.3.3.
For safety and conductor sizing, the National Electrical Code specifies
maximum allowable current (ampacity) for each conductor gauge and
insulation type.

\begin{examplebox}

\textbf{Example 7.1.2:} A rechargeable battery with a capacity of 2,500
mAh is charged at a constant current of 500 mA. Determine (a) the
charging time, (b) the total charge stored in coulombs, and (c) the
number of electrons transferred during charging.

\textbf{Solution:}

(a) Charging time: t = capacity / I = 2,500 mAh / 500 mA = \textbf{5
hours}

(b) Total charge: Q = I × t = 0.5 A × (5 × 3,600 s) = 0.5 × 18,000 =
\textbf{9,000 C}

(c) Number of electrons: N = Q/e = 9,000 / (1.602 × 10⁻¹⁹) =
\textbf{5.62 × 10²² electrons}

\end{examplebox}

\subsection{7.1.3 Voltage and Energy}\label{voltage-and-energy}

Voltage (also called electric potential difference or electromotive
force) is the work done per unit charge in moving charge between two
points: V = W/Q, measured in volts (V), where one volt equals one joule
per coulomb. Voltage is always measured between two points --- it is a
relative quantity, not an absolute one. A voltage source (such as a
battery or generator) provides the energy that drives current through a
circuit by maintaining a potential difference across its terminals.

The energy delivered to or consumed by a circuit element is W = Q × V =
V × I × t, measured in joules (J). Power is the rate of energy transfer:
P = dW/dt = V × I, measured in watts (W). The kilowatt-hour (kWh) is the
practical unit of electrical energy used for billing: 1 kWh = 3.6 × 10⁶
J. The concepts of charge, current, voltage, and power are related by
the fundamental equations: I = Q/t, V = W/Q, P = V × I, and W = P × t.

\begin{examplebox}

\textbf{Example 7.1.3:} An electric vehicle battery pack is rated at 75
kWh and operates at a nominal voltage of 400 V. Determine (a) the total
stored energy in joules and megajoules, (b) the battery capacity in
ampere-hours, (c) the current draw when the motor consumes 150 kW, and
(d) the driving time at that power level.

\textbf{Solution:}

(a) Energy: W = 75 kWh × 3.6 × 10⁶ J/kWh = \textbf{270 × 10⁶ J = 270 MJ}

(b) Capacity: Q = W/V → Ah = kWh/V × 1,000 = 75,000 Wh / 400 V =
\textbf{187.5 Ah}

(c) Current: I = P/V = 150,000 / 400 = \textbf{375 A}

(d) Driving time: t = W/P = 75 kWh / 150 kW = \textbf{0.5 hours (30
minutes)}

\end{examplebox}

\section{7.2 Passive Components}\label{passive-components}

Passive components are circuit elements that cannot generate energy ---
they can only store or dissipate it. The three fundamental passive
components are resistors (which dissipate energy as heat), capacitors
(which store energy in an electric field), and inductors (which store
energy in a magnetic field). Understanding their physical construction,
ratings, and non-ideal behaviors is essential for selecting appropriate
components in practical circuit design.

\subsection{7.2.1 Resistors}\label{resistors}

A resistor opposes the flow of electric current, converting electrical
energy irreversibly into heat. Resistance is measured in ohms (Ω) and is
determined by the material's resistivity ρ, length L, and
cross-sectional area A according to R = ρL/A. Ohm's Law --- V = IR ---
is the fundamental relationship governing resistor behavior: the voltage
across a resistor is directly proportional to the current through it,
and the power dissipated is P = I²R = V²/R. In practical design,
selecting the right resistor involves balancing several criteria: the
resistance value and tolerance (how closely the actual value matches the
nominal), the temperature coefficient (how much resistance drifts with
temperature, measured in ppm/°C), the power rating (maximum continuous
dissipation without overheating), and the physical package size. Common
resistor technologies include carbon film for general-purpose use, metal
film for precision and low noise, wirewound for high-power applications,
and surface-mount (SMD) thick-film and thin-film for compact PCB
designs. Resistors combine simply: in series, resistances add directly
(R\textsubscript{total} = R₁ + R₂ + \ldots{} + Rₙ), while in parallel
they combine as reciprocals (1/R\textsubscript{total} = 1/R₁ + 1/R₂ +
\ldots{} + 1/Rₙ). Standard resistor values follow the E-series (E12,
E24, E96, E192), which are logarithmically spaced to provide
approximately uniform percentage coverage across each decade. The most
common resistor types are:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Construction
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Tolerance
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Temp. Coefficient
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Applications
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Carbon film & Carbon deposited on ceramic & ±5\% & −200 to −500 ppm/°C &
General purpose \\
Metal film & Metal alloy on ceramic & ±1\% or ±0.1\% & ±50 to ±100
ppm/°C & Precision circuits \\
Wirewound & Resistance wire on core & ±0.01\% to ±5\% & ±20 to ±50
ppm/°C & Power, precision \\
SMD thick film & Ruthenium oxide on alumina & ±1\% to ±5\% & ±100 to
±200 ppm/°C & Surface-mount PCBs \\
SMD thin film & Nichrome sputtered on alumina & ±0.1\% to ±1\% & ±25
ppm/°C & Precision SMD \\
\end{longtable}
}

The four-band resistor color code encodes resistance value: the first
two bands are significant digits, the third is the multiplier (number of
zeros), and the fourth indicates tolerance (gold = ±5\%, brown = ±1\%).
For example, red-violet-orange-gold = 27 × 10³ = 27 kΩ ±5\%. Five-band
and six-band codes provide additional precision and a temperature
coefficient band.

Power rating specifies the maximum continuous power a resistor can
safely dissipate without exceeding its temperature limit. Standard
through-hole ratings are 1/8 W, 1/4 W, 1/2 W, 1 W, and 2 W, while SMD
sizes range from 0201 (1/20 W) to 2512 (1 W). Exceeding the power rating
causes overheating, resistance drift, and eventual failure. Derating
curves reduce the allowable power at elevated ambient temperatures --- a
typical resistor is derated to zero at 150°C.

\begin{examplebox}

\textbf{Example 7.2.1:} A circuit requires a 4.7 kΩ resistor that will
drop 12 V. Determine (a) the current through the resistor, (b) the power
dissipated, (c) the minimum standard power rating, and (d) the color
code for a 4-band resistor with ±5\% tolerance.

\textbf{Solution:}

(a) Current: I = V/R = 12 / 4,700 = \textbf{2.55 mA}

(b) Power: P = V²/R = 144 / 4,700 = 0.0306 W = \textbf{30.6 mW}

(c) The next standard power rating above 30.6 mW is \textbf{1/8 W (125
mW)}, which provides a comfortable 4:1 derating margin.

(d) 4.7 kΩ = 47 × 10² Ω. First band: 4 = yellow. Second band: 7 =
violet. Multiplier: 10² = red. Tolerance: ±5\% = gold. Color code:
\textbf{yellow-violet-red-gold}.

\end{examplebox}

\subsection{7.2.2 Capacitors}\label{capacitors}

A capacitor stores energy in an electric field established between two
conductive plates separated by a dielectric material. The capacitance C
= εA/d depends on the plate area A, the plate separation d, and the
permittivity ε of the dielectric, and is measured in farads (F), though
practical values range from picofarads (pF) in RF tuning circuits to
millifarads (mF) in power supply filtering and up to thousands of farads
in supercapacitors used for energy storage. The voltage across a
capacitor cannot change instantaneously --- the current-voltage
relationship i = C(dv/dt) means that a capacitor resists sudden voltage
changes by drawing or supplying current proportional to the rate of
voltage change, which is the basis for capacitor behavior in AC and
transient circuits. The energy stored is W = ½CV². In the frequency
domain, a capacitor presents an impedance Z = 1/(jωC) that decreases
with increasing frequency, making capacitors behave as short circuits at
high frequencies and open circuits at DC. This frequency-dependent
behavior is what makes capacitors essential in filtering (bypassing
high-frequency noise to ground), coupling (passing AC signals while
blocking DC bias), decoupling (providing local charge reservoirs near
ICs to suppress supply noise), and timing circuits (setting RC time
constants). Capacitor types are distinguished by their dielectric
material, which determines the capacitance range, voltage rating,
stability, equivalent series resistance (ESR), and frequency performance
--- selecting the right type for each application is one of the most
important practical skills in circuit design.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Capacitance Range
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Voltage Range
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Characteristics
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ceramic (C0G/NP0) & 1 pF -- 10 nF & 16--500 V & Ultra-stable, low loss,
precision \\
Ceramic (X7R) & 100 pF -- 100 μF & 6.3--100 V & Moderate stability,
general purpose \\
Ceramic (Y5V) & 10 nF -- 100 μF & 6.3--50 V & High capacitance density,
poor stability \\
Aluminum electrolytic & 0.1 μF -- 1 F & 6.3--500 V & Polarized, high
capacitance, high ESR \\
Tantalum & 0.1 μF -- 1 mF & 2.5--50 V & Polarized, stable, low ESR,
failure-prone \\
Film (polyester/PP) & 100 pF -- 100 μF & 50--2,000 V & Non-polarized,
low loss, excellent stability \\
Supercapacitor (EDLC) & 0.1 F -- 3,000 F & 2.5--5.5 V & Ultra-high
capacitance, energy storage \\
\end{longtable}
}

Equivalent Series Resistance (ESR) is the parasitic resistance of a real
capacitor, representing losses in the dielectric, plates, and leads. ESR
is critical in power supply filtering --- a capacitor with high ESR
cannot effectively suppress ripple even if its capacitance value is
adequate. Aluminum electrolytics have the highest ESR (0.1--5 Ω), while
ceramic and film capacitors have very low ESR (\textless{} 0.01 Ω).
Voltage derating is the practice of selecting a capacitor rated well
above the circuit operating voltage to improve reliability and account
for the voltage coefficient --- ceramic capacitors (especially X7R and
Y5V) can lose 50\% or more of their rated capacitance near their maximum
voltage.

\begin{examplebox}

\textbf{Example 7.2.2:} A 5 V power supply uses a 100 μF aluminum
electrolytic capacitor (ESR = 0.15 Ω) in parallel with a 10 μF ceramic
capacitor (ESR = 0.005 Ω) for output filtering. A load step of 2 A
occurs. Determine (a) the initial voltage drop from ESR for each
capacitor acting alone, (b) the voltage droop from capacitor discharge
if the supply takes 50 μs to respond, and (c) why both capacitors are
needed.

\textbf{Solution:}

(a) ESR voltage drop (instantaneous):\\
Electrolytic alone: ΔV\textsubscript{ESR} = I × ESR = 2 × 0.15 =
\textbf{300 mV}\\
Ceramic alone: ΔV\textsubscript{ESR} = I × ESR = 2 × 0.005 = \textbf{10
mV}

(b) Voltage droop from discharge (using combined capacitance):\\
C\textsubscript{total} = 100 + 10 = 110 μF.\\
ΔV = I × Δt / C = 2 × 50 × 10⁻⁶ / (110 × 10⁻⁶) = \textbf{0.91 V}

(c) The \textbf{ceramic capacitor handles the fast ESR transient} (10 mV
vs.~300 mV), while the \textbf{electrolytic provides bulk charge
storage} to limit the voltage droop (100 μF \textgreater\textgreater{}
10 μF). Together they provide both fast transient response and sustained
current delivery --- this is why power supply designs use both types in
parallel.

\end{examplebox}

\subsection{7.2.3 Inductors}\label{inductors}

An inductor stores energy in a magnetic field generated by current
flowing through a coil of wire. Inductance L is measured in henries (H),
though practical values range from nanohenries (nH) for PCB traces and
chip inductors to henries for power-line reactors and filter chokes. The
voltage across an inductor is proportional to the rate of change of
current: v = L(di/dt), which means the current through an inductor
cannot change instantaneously --- any attempt to abruptly interrupt
inductor current produces a large voltage spike, which is why flyback
diodes and snubber circuits are essential when switching inductive
loads. The energy stored in the magnetic field is W = ½LI². In the
frequency domain, an inductor presents an impedance Z = jωL that
increases with frequency, making inductors behave as open circuits at
high frequencies and short circuits at DC --- the dual behavior to
capacitors. Inductor construction varies widely by application: air-core
inductors avoid saturation effects and are used in RF circuits,
ferrite-core inductors provide high inductance in compact packages for
switching power supplies and EMI filters, iron-powder cores offer higher
saturation current for power applications, and toroidal shapes minimize
radiated EMI by containing the magnetic flux within the core. Key
specifications for inductor selection include the inductance value,
saturation current I\textsubscript{sat} (above which the core saturates
and inductance drops sharply), DC resistance (DCR, which causes I²R
losses and reduces efficiency), and the quality factor Q =
ωL/R\textsubscript{DC}, which measures how much energy is stored versus
dissipated per cycle. Inductors are indispensable in switching power
converters (as energy-transfer elements), LC filters (for frequency
selection), RF matching networks, and current-sensing applications.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Inductance Range
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Current Range
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Characteristics
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Air core & 1 nH -- 10 μH & up to 100+ A & No saturation, low inductance,
RF applications \\
Ferrite core & 1 μH -- 10 mH & 0.1--50 A & High frequency (switching
supplies, filters) \\
Iron powder core & 1 μH -- 10 mH & 0.5--100 A & Higher saturation than
ferrite, moderate frequency \\
Laminated iron core & 1 mH -- 100 H & 0.1--1,000 A & Power-line
frequency, transformers, reactors \\
Toroidal & 10 μH -- 100 mH & 0.1--50 A & Low EMI (contained field),
compact, efficient \\
\end{longtable}
}

The quality factor Q = ω L / R\textsubscript{DC} measures how much
energy an inductor stores versus how much it dissipates per cycle.
Higher Q indicates a more ideal inductor. At higher frequencies, skin
effect and proximity effect increase the effective resistance, reducing
Q. Saturation current is the DC current at which inductance drops by a
specified amount (typically 10--30\%) due to magnetic core saturation
--- exceeding this current causes the inductor to lose its energy
storage ability and behave more like a short circuit, which can be
destructive in switching converter applications.

Self-resonant frequency (SRF) is the frequency at which the inductor's
parasitic capacitance (between turns) resonates with its inductance,
causing the component to behave as a capacitor above this frequency. An
inductor should only be used at frequencies well below its SRF ---
typically below SRF/3.

\begin{examplebox}

\textbf{Example 7.2.3:} A buck converter switching at 500 kHz requires a
10 μH inductor carrying a DC current of 3 A with 30\% peak-to-peak
ripple. Determine (a) the peak inductor current, (b) the energy stored
at peak current, (c) the minimum required saturation current rating, (d)
the inductive reactance at the switching frequency, and (e) the minimum
acceptable SRF.

\textbf{Solution:}

(a) Ripple current: ΔI = 0.30 × 3 = 0.9 A. Peak current:
I\textsubscript{peak} = I\textsubscript{DC} + ΔI/2 = 3 + 0.45 =
\textbf{3.45 A}

(b) Energy at peak: W = ½LI² = 0.5 × 10 × 10⁻⁶ × 3.45² = \textbf{59.5
μJ}

(c) Saturation rating must exceed peak current with margin:
I\textsubscript{sat} ≥ 1.2 × I\textsubscript{peak} = 1.2 × 3.45 =
\textbf{4.14 A minimum} (select a 4.7 A or higher rated inductor)

(d) Inductive reactance: X\textsubscript{L} = 2πfL = 2π × 500,000 × 10 ×
10⁻⁶ = \textbf{31.4 Ω}

(e) Minimum SRF ≥ 3 × f\textsubscript{sw} = 3 × 500 kHz = \textbf{1.5
MHz}

\end{examplebox}

\subsection{7.2.4 Wire and Cable}\label{wire-and-cable}

Wire is a single metallic conductor, while cable is an assembly of two
or more insulated conductors within a common outer jacket or sheath.
Copper is the dominant conductor material due to its low resistivity (ρ
= 1.72 × 10⁻⁸ Ω·m at 20°C), excellent ductility, and good corrosion
resistance. Aluminum (ρ = 2.82 × 10⁻⁸ Ω·m) is used for larger sizes in
power distribution because of its lower cost and weight per unit
conductance, but requires larger cross-sections and special connectors
to compensate for its higher resistivity and tendency to cold-flow under
pressure.

Wire gauge in North America follows the American Wire Gauge (AWG)
system, where smaller numbers indicate larger conductors. Each decrease
of 3 gauge numbers approximately doubles the cross-sectional area and
halves the resistance per unit length. Each decrease of 10 gauge numbers
multiplies the area by approximately 10. Common reference points are:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
AWG
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Diameter (mm)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Area (mm²)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Resistance (Ω/km at 20°C)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Application
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
4/0 (0000) & 11.68 & 107.2 & 0.161 & Service entrance, large feeders \\
2/0 (00) & 9.27 & 67.4 & 0.256 & Subpanels, large branch circuits \\
1/0 (0) & 8.25 & 53.5 & 0.323 & Service entrance, grounding electrode \\
4 & 5.19 & 21.2 & 0.815 & Range, dryer circuits (240 V) \\
6 & 4.11 & 13.3 & 1.296 & Large appliances, subpanels \\
10 & 2.59 & 5.26 & 3.277 & Dryers, water heaters, 30 A circuits \\
12 & 2.05 & 3.31 & 5.211 & General-purpose 20 A branch circuits \\
14 & 1.63 & 2.08 & 8.286 & General-purpose 15 A branch circuits \\
18 & 1.02 & 0.823 & 20.95 & Thermostat, low-voltage control \\
22 & 0.644 & 0.326 & 52.96 & Data, signal, electronics \\
\end{longtable}
}

Conductors are either solid (a single strand, used for smaller gauges up
to about 10 AWG) or stranded (multiple smaller wires twisted together).
Stranded wire is more flexible and resistant to fatigue from vibration
or repeated bending, making it preferred for portable cords, equipment
wiring, and larger gauges. The stranding is specified by the number of
strands and their individual gauge --- for example, 7/0.0254'' means 7
strands each 0.0254 inches in diameter.

\textbf{Insulation types} determine the conductor's temperature rating,
voltage rating, and suitability for various environments:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Designation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Material
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Temp. Rating
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Common Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
THHN & Thermoplastic (nylon jacket) & 90°C dry & Building wire in
conduit \\
THWN-2 & Thermoplastic (nylon jacket) & 90°C dry/wet & Indoor and
outdoor in conduit \\
XHHW-2 & Cross-linked polyethylene & 90°C dry/wet & Industrial, direct
burial \\
NM-B (Romex) & Thermoplastic jacket & 90°C dry & Residential branch
circuits \\
UF-B & Thermoplastic jacket & 90°C dry, 75°C wet & Underground feeder,
direct burial \\
USE-2 & Cross-linked polyethylene & 90°C wet & Underground service
entrance \\
SOOW & Rubber (oil-resistant) & 90°C & Portable power cords, temporary
wiring \\
MC & Metal clad (aluminum armor) & Per inner conductor & Commercial,
industrial feeders \\
\end{longtable}
}

\textbf{Cable assemblies} combine multiple conductors for specific
applications. NM-B (non-metallic sheathed cable, commonly called Romex)
contains two or three insulated conductors plus a bare ground within a
PVC jacket and is the standard residential wiring method. MC
(metal-clad) cable uses an interlocking aluminum armor for physical
protection in commercial installations. AC (armored cable, BX) uses a
flexible steel armor. Tray cable (TC) is rated for installation in cable
trays in industrial facilities. For power distribution, medium-voltage
cables (5--35 kV) include semiconducting shields and insulation rated
for the system voltage class.

\textbf{Conduit} provides a raceway for pulling individual conductors,
offering physical protection and a grounding path. Common types include
EMT (electrical metallic tubing --- thin-wall steel, most common
commercial), RMC (rigid metal conduit --- thick-wall threaded steel,
maximum protection), PVC (rigid polyvinyl chloride --- non-metallic,
corrosion resistant, underground), and ENT (electrical nonmetallic
tubing --- flexible corrugated plastic, concealed in walls).

\begin{examplebox}

\textbf{Example 7.2.4:} A 120 V, 20 A branch circuit runs 150 feet (45.7
m) from the panel to an outlet using 12 AWG copper THHN in EMT conduit.
Determine (a) the one-way conductor resistance, (b) the voltage drop at
full load, (c) the voltage drop as a percentage of source voltage, and
(d) whether it meets the NEC 3\% recommendation for branch circuits.

\textbf{Solution:}

(a) 12 AWG resistance: 5.211 Ω/km. One-way length: 45.7 m = 0.0457 km.\\
R\textsubscript{one-way} = 5.211 × 0.0457 = \textbf{0.238 Ω}

(b) Voltage drop (single-phase, round-trip through hot and neutral):\\
V\textsubscript{drop} = 2 × I × R = 2 × 20 × 0.238 = \textbf{9.52 V}

(c) Percentage: V\textsubscript{drop}\% = 9.52/120 × 100 =
\textbf{7.93\%}

(d) The NEC recommends ≤ 3\% for branch circuits (3.6 V at 120 V). At
7.93\%, this circuit \textbf{does not meet} the recommendation.
Solutions include upsizing to 10 AWG (R = 3.277 Ω/km,
V\textsubscript{drop} = 5.99 V = 4.99\% --- still over 3\%) or
shortening the run. Using 8 AWG (R = 2.061 Ω/km): V\textsubscript{drop}
= 2 × 20 × 2.061 × 0.0457 = 3.77 V = 3.14\% --- marginal. For a 150-foot
20 A run, \textbf{6 AWG} (R = 1.296 Ω/km, V\textsubscript{drop} = 2.37 V
= 1.97\%) would comfortably meet the 3\% recommendation.

\end{examplebox}

\section{7.3 Fundamental Laws}\label{fundamental-laws}

Three fundamental laws govern the behavior of all electrical circuits.
Ohm's Law relates voltage, current, and resistance in a single element,
while Kirchhoff's two laws --- the voltage law (KVL) and the current law
(KCL) --- express conservation of energy and conservation of charge at
the circuit level. Together, these laws form the basis for all circuit
analysis methods.

\subsection{7.3.1 Ohm's Law}\label{ohms-law}

Ohm's Law states that the voltage across a resistor is directly
proportional to the current flowing through it: V = I × R, where V is
voltage in volts, I is current in amperes, and R is resistance in ohms
(Ω). Equivalently, the current through a resistor is I = V / R, and the
resistance is R = V / I. Ohm's Law applies to resistive elements and is
the most frequently used relationship in circuit analysis. The power
dissipated by a resistor can be expressed in three equivalent forms: P =
V × I = I² × R = V² / R.

\begin{examplebox}

\textbf{Example 7.3.1:} A 470 Ω resistor carries a current of 25 mA.
Find the voltage across it and the power it dissipates.

\textbf{Solution:}\\
Applying Ohm's Law: V = I × R = 0.025 A × 470 Ω = 11.75 V.\\
The power dissipated is P = I² × R = (0.025)² × 470 = 0.29375 W ≈ 294
mW.\\
Alternatively, P = V² / R = (11.75)² / 470 = 138.0625 / 470 ≈ 294 mW.

\end{examplebox}

\subsection{7.3.2 Kirchhoff's Voltage Law
(KVL)}\label{kirchhoffs-voltage-law-kvl}

Kirchhoff's Voltage Law states that the algebraic sum of all voltages
around any closed loop in a circuit equals zero. This law is a
consequence of the conservation of energy: a charge traversing a closed
path returns to its starting potential. When applying KVL, voltage rises
(such as across a source) are assigned one polarity and voltage drops
(such as across a resistor in the direction of current) are assigned the
opposite polarity. KVL is the foundation of mesh analysis and loop
analysis, enabling the formulation of simultaneous equations that
describe the behavior of multi-loop circuits.

\begin{examplebox}

\textbf{Example 7.3.2:} A series loop contains a 24 V source, a 100 Ω
resistor, a 150 Ω resistor, and a 50 Ω resistor. Find the voltage across
each resistor.

\textbf{Solution:}\\
The loop current is I = V\textsubscript{source} / R\textsubscript{total}
= 24 V / (100 + 150 + 50) Ω = 24 / 300 = 0.08 A = 80 mA.\\
By KVL, the sum of voltage drops must equal the source voltage: V₁ =
0.08 × 100 = 8 V, V₂ = 0.08 × 150 = 12 V, V₃ = 0.08 × 50 = 4 V.\\
Check: 8 + 12 + 4 = 24 V = V\textsubscript{source}.

\end{examplebox}

\subsection{7.3.3 Kirchhoff's Current Law
(KCL)}\label{kirchhoffs-current-law-kcl}

Kirchhoff's Current Law states that the algebraic sum of all currents
entering and leaving any node in a circuit equals zero. This law is a
consequence of the conservation of charge: charge cannot accumulate at a
node. By convention, currents entering a node are positive and currents
leaving are negative (or vice versa, as long as the convention is
applied consistently). KCL is the foundation of nodal analysis, which
formulates equations based on node voltages to solve for all circuit
unknowns.

\begin{examplebox}

\textbf{Example 7.3.3:} At a node in a circuit, three branches meet.
Branch 1 carries 3 A into the node, branch 2 carries 1.2 A into the
node, and branch 3 carries current out of the node. Find the current in
branch 3.

\textbf{Solution:} By KCL, the sum of currents entering a node equals
the sum of currents leaving: I₁ + I₂ = I₃. Therefore I₃ = 3 + 1.2 = 4.2
A leaving the node.

\end{examplebox}

\section{7.4 DC Circuit Analysis}\label{dc-circuit-analysis}

DC circuit analysis determines the voltages and currents in circuits
powered by constant (time-invariant) sources. The fundamental approach
is to reduce complex networks to simpler equivalents using series and
parallel combinations, then apply Ohm's Law to find the desired
quantities.

\subsection{7.4.1 Series Circuits}\label{series-circuits}

In a series circuit, components are connected end-to-end so that the
same current flows through each element. The total resistance is the sum
of the individual resistances: R\textsubscript{total} = R₁ + R₂ +
\ldots{} + Rₙ. The voltage divides across the series elements in
proportion to their resistances, with the voltage across any resistor
given by V\textsubscript{k} = V\textsubscript{source} ×
(R\textsubscript{k} / R\textsubscript{total}). Series circuits have the
property that if any element opens (breaks), current flow through the
entire circuit ceases.

\begin{examplebox}

\textbf{Example 7.4.1:} A 12 V battery powers three resistors in series:
R₁ = 220 Ω, R₂ = 330 Ω, R₃ = 150 Ω. Find the circuit current and the
voltage across R₂.

\textbf{Solution:}\\
R\textsubscript{total} = 220 + 330 + 150 = 700 Ω.\\
The series current is I = 12 V / 700 Ω = 17.14 mA.\\
Using the voltage divider, V₂ = 12 × (330 / 700) = 12 × 0.4714 = 5.66 V.

\end{examplebox}

\subsection{7.4.2 Parallel Circuits}\label{parallel-circuits}

In a parallel circuit, components are connected across the same pair of
nodes so that the same voltage appears across each element. The total
resistance is found from the reciprocal relation:
1/R\textsubscript{total} = 1/R₁ + 1/R₂ + \ldots{} + 1/Rₙ. For two
resistors in parallel, this simplifies to R\textsubscript{total} = (R₁ ×
R₂) / (R₁ + R₂). The current divides among the parallel branches in
inverse proportion to their resistances, with the current through any
branch given by I\textsubscript{k} = I\textsubscript{total} ×
(R\textsubscript{total} / R\textsubscript{k}). Parallel circuits have
the property that if one branch opens, current continues to flow through
the remaining branches.

\begin{examplebox}

\textbf{Example 7.4.2:} Two resistors, R₁ = 1 kΩ and R₂ = 2.2 kΩ, are
connected in parallel across a 10 V source. Find the total resistance,
total current, and the current through each branch.

\textbf{Solution:}\\
R\textsubscript{total} = (R₁ × R₂) / (R₁ + R₂) = (1000 × 2200) / (1000 +
2200) = 2,200,000 / 3200 = 687.5 Ω.\\
Total current: I\textsubscript{total} = 10 V / 687.5 Ω = 14.55 mA.\\
Branch currents: I₁ = 10 / 1000 = 10 mA, I₂ = 10 / 2200 = 4.55 mA.\\
Check: 10 + 4.55 = 14.55 mA.

\end{examplebox}

\subsection{7.4.3 Series-Parallel
Circuits}\label{series-parallel-circuits}

Series-parallel circuits contain combinations of both series and
parallel connections that cannot be reduced to a single series or single
parallel network. Analysis proceeds by identifying series and parallel
groups, simplifying them step by step from the innermost combinations
outward until the entire circuit is reduced to a single equivalent
resistance. Once the total current or voltage is found, the process is
reversed (working back outward) to determine the voltage and current at
each element. Careful identification of which elements share the same
current (series) versus the same voltage (parallel) is essential for
correct simplification.

\begin{examplebox}

\textbf{Example 7.4.3:} A circuit has R₁ = 100 Ω in series with a
parallel combination of R₂ = 200 Ω and R₃ = 300 Ω, all powered by a 20 V
source. Find the total current from the source and the voltage across
R₁.

\textbf{Solution:}\\
First, combine the parallel pair: R₂₃ = (200 × 300) / (200 + 300) =
60,000 / 500 = 120 Ω.\\
Total resistance: R\textsubscript{total} = R₁ + R₂₃ = 100 + 120 = 220
Ω.\\
Total current: I = 20 / 220 = 90.9 mA.\\
Voltage across R₁: V₁ = I × R₁ = 0.0909 × 100 = 9.09 V.\\
Voltage across the parallel combination: V₂₃ = 20 - 9.09 = 10.91 V.

\end{examplebox}

\section{7.5 Analysis Methods}\label{analysis-methods}

When circuits are too complex for simple series-parallel reduction,
systematic methods based on Kirchhoff's laws provide a structured
approach to solving for all unknowns. Nodal analysis applies KCL at
nodes, mesh analysis applies KVL around loops, and superposition
decomposes multi-source problems into single-source sub-problems.

\subsection{7.5.1 Nodal Analysis}\label{nodal-analysis}

Nodal analysis is a systematic method for solving circuits by writing
KCL equations at each non-reference node in terms of node voltages. One
node is designated as the reference (ground) node with a voltage of
zero, and the remaining node voltages are the unknowns. For a circuit
with n non-reference nodes, nodal analysis produces n simultaneous
equations. When voltage sources are present, they can be handled by
using the supernode technique, which encloses the voltage source and its
two nodes in a single region and writes a combined KCL equation for the
supernode along with the constraint equation imposed by the source
voltage.

\begin{examplebox}

\textbf{Example 7.5.1:} A circuit has two non-reference nodes (V₁ and
V₂). A 10 mA current source feeds into node V₁. A 2 kΩ resistor connects
V₁ to ground, a 4 kΩ resistor connects V₁ to V₂, and a 3 kΩ resistor
connects V₂ to ground. Find V₁ and V₂ using nodal analysis.

\textbf{Solution:}\\
KCL at node V₁: 0.010 = V₁/2000 + (V₁ - V₂)/4000.\\
KCL at node V₂: (V₁ - V₂)/4000 = V₂/3000.\\
From node V₂: 3000(V₁ - V₂) = 4000V₂, so 3V₁ = 7V₂, giving V₁ =
(7/3)V₂.\\
Substituting into node V₁: 0.010 = (7/3)V₂/2000 + ((7/3)V₂ - V₂)/4000 =
7V₂/6000 + (4/3)V₂/4000 = 7V₂/6000 + V₂/3000 = 7V₂/6000 + 2V₂/6000 =
9V₂/6000 = 3V₂/2000.\\
Therefore V₂ = 0.010 × 2000/3 = 6.67 V and V₁ = (7/3) × 6.67 = 15.56 V.

\end{examplebox}

\subsection{7.5.2 Mesh Analysis}\label{mesh-analysis}

Mesh analysis is a systematic method for solving planar circuits by
assigning a circulating current variable (mesh current) to each
independent loop and writing KVL equations around each mesh. For a
circuit with m independent meshes, mesh analysis produces m simultaneous
equations in terms of the mesh currents. Shared elements between
adjacent meshes carry the algebraic sum or difference of the two mesh
currents. When current sources are present, they can be handled using
the supermesh technique, which excludes the current source from the mesh
equations and instead writes a combined KVL equation around the
supermesh along with the constraint equation imposed by the source
current.

\begin{examplebox}

\textbf{Example 7.5.2:} A single-loop circuit has a 30 V source, a 5 kΩ
resistor, and a 10 kΩ resistor in series. A second mesh shares the 10 kΩ
resistor and contains a 15 V source and a 20 kΩ resistor. Find the mesh
currents I₁ (left loop, clockwise) and I₂ (right loop, clockwise).

\textbf{Solution:}\\
KVL for mesh 1: 30 = 5000I₁ + 10000(I₁ - I₂), giving 30 = 15000I₁ -
10000I₂ \ldots{} (1).\\
KVL for mesh 2: 15 = 20000I₂ + 10000(I₂ - I₁), giving 15 = -10000I₁ +
30000I₂ \ldots{} (2).\\
From (2): I₁ = (30000I₂ - 15)/10000 = 3I₂ - 0.0015.\\
Substituting into (1): 30 = 15000(3I₂ - 0.0015) - 10000I₂ = 45000I₂ -
22.5 - 10000I₂ = 35000I₂ - 22.5.\\
So 35000I₂ = 52.5, I₂ = 1.5 mA.\\
Then I₁ = 3(0.0015) - 0.0015 = 0.003 A = 3 mA.

\end{examplebox}

\subsection{7.5.3 Superposition}\label{superposition}

The superposition theorem states that in a linear circuit with multiple
independent sources, the voltage or current at any element equals the
algebraic sum of the contributions from each independent source acting
alone, with all other independent sources deactivated. Voltage sources
are deactivated by replacing them with short circuits (zero voltage),
and current sources are deactivated by replacing them with open circuits
(zero current). Dependent sources are never deactivated and remain
active in every sub-circuit. Superposition is useful for understanding
the individual contribution of each source but requires solving the
circuit once for each independent source, making it less efficient than
nodal or mesh analysis for circuits with many sources.

\begin{examplebox}

\textbf{Example 7.5.3:} A 6 kΩ resistor is connected between two
sources: a 12 V voltage source on the left and a 6 V voltage source on
the right, each with the positive terminal facing the resistor. Find the
current through the 6 kΩ resistor using superposition.

\textbf{Solution:}\\
Source 1 alone (replace 6 V source with short circuit): I₁ = 12 V / 6 kΩ
= 2 mA (flowing left to right).\\
Source 2 alone (replace 12 V source with short circuit): I₂ = 6 V / 6 kΩ
= 1 mA (flowing right to left).\\
By superposition, the net current is I = I₁ - I₂ = 2 - 1 = 1 mA flowing
left to right.

\end{examplebox}

\subsection{7.5.4 Dependent Sources}\label{dependent-sources}

A dependent (controlled) source produces a voltage or current that is a
function of another voltage or current elsewhere in the circuit. There
are four types: voltage-controlled voltage source (VCVS,
V\textsubscript{out} = μV\textsubscript{x}), voltage-controlled current
source (VCCS, I\textsubscript{out} =
g\textsubscript{m}V\textsubscript{x}), current-controlled voltage source
(CCVS, V\textsubscript{out} = rI\textsubscript{x}), and
current-controlled current source (CCCS, I\textsubscript{out} =
βI\textsubscript{x}). Dependent sources are essential for modeling real
devices: the BJT small-signal model uses a CCCS (I\textsubscript{c} =
βI\textsubscript{b}), the MOSFET small-signal model uses a VCCS
(I\textsubscript{d} = g\textsubscript{m}V\textsubscript{gs}), and the
ideal operational amplifier uses a VCVS (V\textsubscript{out} =
A\textsubscript{OL}(V⁺ − V⁻)).

Circuits with dependent sources are analyzed using the same nodal and
mesh methods as circuits with independent sources, with one critical
difference: dependent sources are never deactivated during superposition
analysis, since their output depends on circuit variables that change
when other sources are turned off. When finding Thévenin or Norton
equivalents, the dependent source remains active and the Thévenin
resistance must be found by applying a test source (voltage or current)
at the output terminals rather than by simply combining resistances.

\begin{examplebox}

\textbf{Example 7.5.4:} A circuit has a 10 V independent voltage source
in series with a 2 kΩ resistor connected to node A. A VCCS with
g\textsubscript{m} = 5 mA/V, controlled by V\textsubscript{A}, is
connected from ground to node A (injecting current
g\textsubscript{m}V\textsubscript{A} into node A). A 4 kΩ resistor
connects node A to ground. Find V\textsubscript{A}.

\textbf{Solution:}\\
KCL at node A: current from the 10 V source + current from VCCS =
current through 4 kΩ to ground.\\
(10 − V\textsubscript{A})/2000 + g\textsubscript{m}V\textsubscript{A} =
V\textsubscript{A}/4000.\\
(10 − V\textsubscript{A})/2000 + 0.005V\textsubscript{A} =
V\textsubscript{A}/4000.\\
Multiply through by 4000: 2(10 − V\textsubscript{A}) +
20V\textsubscript{A} = V\textsubscript{A}.\\
20 − 2V\textsubscript{A} + 20V\textsubscript{A} = V\textsubscript{A}.\\
20 + 18V\textsubscript{A} = V\textsubscript{A}, so 17V\textsubscript{A}
= −20, V\textsubscript{A} = \textbf{−1.18 V}. The negative voltage
indicates that the VCCS drives enough current to reverse the polarity at
node A, demonstrating how dependent sources can produce unexpected
results compared to passive circuits.

\end{examplebox}

\section{7.6 Circuit Theorems}\label{circuit-theorems}

Circuit theorems provide powerful shortcuts for analyzing complex
networks by replacing portions of a circuit with simpler equivalent
models. These theorems are particularly useful when analyzing the effect
of a single load or source change without resolving the entire circuit.

\subsection{7.6.1 Thévenin's Theorem}\label{thuxe9venins-theorem}

Thévenin's theorem states that any linear two-terminal network can be
replaced by an equivalent circuit consisting of a single voltage source
(V\textsubscript{Th}) in series with a single resistance
(R\textsubscript{Th}). The Thévenin voltage V\textsubscript{Th} is the
open-circuit voltage measured across the two terminals with no load
connected. The Thévenin resistance R\textsubscript{Th} is the equivalent
resistance seen from the terminals when all independent sources are
deactivated (voltage sources shorted, current sources opened).
Thévenin's theorem is particularly useful for analyzing the effect of
varying a load resistance, since the load sees a simple series circuit
regardless of the complexity of the original network.

\begin{examplebox}

\textbf{Example 7.6.1:} A network consists of a 48 V source in series
with a 6 Ω resistor, connected in parallel with a 12 Ω resistor, with
output terminals across the 12 Ω resistor. Find the Thévenin equivalent.

\textbf{Solution:}\\
V\textsubscript{Th} (open-circuit voltage): With no load, the current
through the 6 Ω resistor and 12 Ω resistor in series is I = 48 / (6 +
12) = 2.667 A.\\
The open-circuit voltage across the 12 Ω resistor is V\textsubscript{Th}
= 2.667 × 12 = 32 V.\\
R\textsubscript{Th} (deactivate the 48 V source by shorting it):
R\textsubscript{Th} = 6 Ω in parallel with 12 Ω = (6 × 12) / (6 + 12) =
72 / 18 = 4 Ω.\\
The Thévenin equivalent is a 32 V source in series with a 4 Ω resistor.

\end{examplebox}

\subsection{7.6.2 Norton's Theorem}\label{nortons-theorem}

Norton's theorem states that any linear two-terminal network can be
replaced by an equivalent circuit consisting of a single current source
(I\textsubscript{N}) in parallel with a single resistance
(R\textsubscript{N}). The Norton current I\textsubscript{N} is the
short-circuit current measured through the terminals when they are
directly connected. The Norton resistance R\textsubscript{N} equals the
Thévenin resistance R\textsubscript{Th}, and the two equivalent circuits
are related by I\textsubscript{N} = V\textsubscript{Th} /
R\textsubscript{Th}. Norton's theorem is the dual of Thévenin's theorem
and is preferred when the load is connected in parallel or when
current-source representations are more convenient for analysis.

\begin{examplebox}

\textbf{Example 7.6.2:} Using the Thévenin equivalent from the previous
section (V\textsubscript{Th} = 32 V, R\textsubscript{Th} = 4 Ω), find
the Norton equivalent circuit.

\textbf{Solution:}\\
The Norton resistance equals the Thévenin resistance: R\textsubscript{N}
= R\textsubscript{Th} = 4 Ω.\\
The Norton current is I\textsubscript{N} = V\textsubscript{Th} /
R\textsubscript{Th} = 32 V / 4 Ω = 8 A.\\
The Norton equivalent is an 8 A current source in parallel with a 4 Ω
resistor.\\
Verification: connecting the terminals through a short circuit yields
I\textsubscript{sc} = 8 A, and the open-circuit voltage is
V\textsubscript{oc} = I\textsubscript{N} × R\textsubscript{N} = 8 × 4 =
32 V = V\textsubscript{Th}.

\end{examplebox}

\subsection{7.6.3 Maximum Power Transfer}\label{maximum-power-transfer}

The maximum power transfer theorem states that a load receives maximum
power from a source when the load resistance equals the Thévenin
resistance of the source network: R\textsubscript{load} =
R\textsubscript{Th}. Under this condition, the power delivered to the
load is P\textsubscript{max} = V\textsubscript{Th}² / (4 ×
R\textsubscript{Th}), and the efficiency is 50\% since an equal amount
of power is dissipated in the source resistance. While maximum power
transfer is critical in communications and signal processing (where
signal power is limited), power systems are designed for maximum
efficiency rather than maximum power transfer, operating with load
resistance much larger than source resistance.

\begin{examplebox}

\textbf{Example 7.6.3:} An audio amplifier has a Thévenin equivalent
output of V\textsubscript{Th} = 10 V and R\textsubscript{Th} = 8 Ω. What
load resistance receives maximum power, and how much power is delivered?

\textbf{Solution:}\\
For maximum power transfer, R\textsubscript{load} = R\textsubscript{Th}
= 8 Ω.\\
The maximum power delivered to the load is P\textsubscript{max} =
V\textsubscript{Th}² / (4 × R\textsubscript{Th}) = (10)² / (4 × 8) = 100
/ 32 = 3.125 W.\\
The total current is I = V\textsubscript{Th} / (R\textsubscript{Th} +
R\textsubscript{load}) = 10 / 16 = 0.625 A, and the efficiency is 50\%
since equal power (3.125 W) is dissipated in the source resistance.

\end{examplebox}

\section{7.7 AC Circuit Analysis}\label{ac-circuit-analysis}

AC circuit analysis extends DC methods to circuits driven by sinusoidal
sources using the phasor transform and complex impedance. By
representing sinusoidal voltages and currents as phasors (see Appendix
A), all DC analysis techniques --- Ohm's Law, KVL, KCL, nodal and mesh
analysis, Thévenin and Norton theorems --- apply directly with
impedances replacing resistances.

\subsection{7.7.1 Impedance}\label{impedance}

Impedance (Z) is the AC generalization of resistance, expressed as a
complex number Z = R + jX, where R is resistance (real part) and X is
reactance (imaginary part), both measured in ohms. Inductive reactance
is X\textsubscript{L} = ωL (positive imaginary), and capacitive
reactance is X\textsubscript{C} = -1/(ωC) (negative imaginary), where ω
= 2πf is the angular frequency. The magnitude \textbar Z\textbar{} =
√(R² + X²) determines the ratio of voltage amplitude to current
amplitude, and the angle θ = arctan(X/R) determines the phase shift
between voltage and current. All DC analysis techniques (Ohm's law, KVL,
KCL, nodal analysis, mesh analysis, Thévenin/Norton) apply directly to
AC circuits when voltages and currents are expressed as phasors and
resistances are replaced by impedances.

\begin{examplebox}

\textbf{Example 7.7.1:} A series circuit has R = 100 Ω and L = 50 mH
driven by a 120 V\textsubscript{rms}, 60 Hz source. Find the impedance,
current magnitude, and phase angle.

\textbf{Solution:}\\
ω = 2π × 60 = 376.99 rad/s.\\
Inductive reactance: X\textsubscript{L} = ωL = 376.99 × 0.050 = 18.85
Ω.\\
Impedance: Z = 100 + j18.85 Ω.\\
Magnitude: \textbar Z\textbar{} = √(100² + 18.85²) = √(10,000 + 355.3) =
√10,355.3 = 101.76 Ω.\\
Current: I = V / \textbar Z\textbar{} = 120 / 101.76 = 1.179
A\textsubscript{rms}.\\
Phase angle: θ = arctan(18.85 / 100) = arctan(0.1885) = 10.68°.\\
The current lags the voltage by 10.68°.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-7-7-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch07_impedance_rl.png}

\caption{Figure 7.7.1: Series RL Impedance vs Frequency}

\end{figure}

\subsection{7.7.2 Resonance}\label{resonance}

Resonance occurs in an AC circuit when the inductive reactance equals
the capacitive reactance (ωL = 1/ωC), causing them to cancel and leaving
only the resistive component of impedance. The resonant frequency is f₀
= 1 / (2π√(LC)). In a series RLC circuit, resonance produces minimum
impedance (Z = R) and maximum current, making series resonant circuits
useful as bandpass filters and in tuning applications. In a parallel RLC
circuit, resonance produces maximum impedance and minimum current drawn
from the source. The quality factor Q = f₀ / bandwidth characterizes the
sharpness of the resonance peak, with higher Q indicating a narrower,
more selective frequency response.

\begin{examplebox}

\textbf{Example 7.7.2:} A series RLC circuit has R = 10 Ω, L = 1 mH, and
C = 10 nF. Find the resonant frequency, the quality factor, and the
bandwidth.

\textbf{Solution:}\\
Resonant frequency: f₀ = 1 / (2π√(LC)) = 1 / (2π√(0.001 × 10 × 10⁻⁹)) =
1 / (2π√(10⁻¹¹)) = 1 / (2π × 3.162 × 10⁻⁶) = 50,329 Hz ≈ 50.3 kHz.\\
Quality factor: Q = (1/R)√(L/C) = (1/10)√(0.001 / 10 × 10⁻⁹) = 0.1 ×
√(100,000) = 0.1 × 316.2 = 31.62.\\
Bandwidth: BW = f₀ / Q = 50,329 / 31.62 = 1,591 Hz ≈ 1.59 kHz.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-7-7-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch07_resonance_rlc.png}

\caption{Figure 7.7.2: Series RLC Resonance}

\end{figure}

\subsection{7.7.3 Power in AC Circuits}\label{power-in-ac-circuits}

In AC circuits, power has three components: real power (P), reactive
power (Q), and apparent power (S). Real power (measured in watts, W) is
the average power actually consumed by resistive elements: P =
V\textsubscript{rms} × I\textsubscript{rms} × cos(φ), where φ is the
phase angle between voltage and current. Reactive power (measured in
volt-amperes reactive, VAR) represents energy oscillating between the
source and reactive elements: Q = V\textsubscript{rms} ×
I\textsubscript{rms} × sin(φ). Apparent power (measured in volt-amperes,
VA) is the product of RMS voltage and current: S = V\textsubscript{rms}
× I\textsubscript{rms} = √(P² + Q²). The power factor, cos(φ), ranges
from 0 to 1 and indicates how effectively the circuit converts apparent
power into useful real power.

\begin{examplebox}

\textbf{Example 7.7.3:} A load draws 5 A\textsubscript{rms} from a 240
V\textsubscript{rms}, 60 Hz supply with a power factor of 0.75 lagging.
Find P, Q, and S.

\textbf{Solution:}\\
Apparent power: S = V\textsubscript{rms} × I\textsubscript{rms} = 240 ×
5 = 1200 VA.\\
Real power: P = S × cos(φ) = 1200 × 0.75 = 900 W.\\
The phase angle is φ = arccos(0.75) = 41.41°.\\
Reactive power: Q = S × sin(φ) = 1200 × sin(41.41°) = 1200 × 0.6614 =
793.7 VAR (inductive).\\
Check: S = √(P² + Q²) = √(810,000 + 629,960) = √1,439,960 ≈ 1200 VA.

\end{examplebox}

\subsection{7.7.4 Mutual Inductance and Coupled
Circuits}\label{mutual-inductance-and-coupled-circuits}

When two inductors are placed in close proximity, the changing magnetic
flux from one inductor links with the other, creating mutual inductance
M measured in henries. The coupling coefficient k = M/√(L₁L₂) ranges
from 0 (no coupling) to 1 (perfect coupling), with typical values of
0.95--0.99 for iron-core transformers and 0.01--0.5 for air-core coils.
The dot convention indicates the polarity of the mutual coupling:
current entering the dotted terminal of one coil induces a voltage with
positive polarity at the dotted terminal of the other coil. The voltage
equations for coupled coils in the frequency domain are V₁ = jωL₁I₁ +
jωMI₂ and V₂ = jωMI₁ + jωL₂I₂ (with + for aiding dots, − for opposing
dots).

An ideal transformer (k = 1, no losses) transforms voltages by the turns
ratio V₁/V₂ = N₁/N₂, transforms currents inversely I₁/I₂ = N₂/N₁, and
reflects impedances by the square of the turns ratio:
Z\textsubscript{reflected} = (N₁/N₂)² × Z\textsubscript{load}. This
impedance transformation is the basis for impedance matching in audio
systems, RF circuits, and power distribution.

\begin{examplebox}

\textbf{Example 7.7.4:} A transformer with N₁/N₂ = 5:1, L₁ = 100 mH, and
k = 0.98 connects a 50 Ω source to an 8 Ω speaker load. Determine (a)
the reflected impedance seen by the source, (b) the mutual inductance,
and (c) whether this transformer provides a reasonable impedance match.

\textbf{Solution:}

(a) Reflected impedance: Z\textsubscript{reflected} = (N₁/N₂)² ×
Z\textsubscript{load} = (5)² × 8 = \textbf{200 Ω}.

(b) L₂ = L₁/(N₁/N₂)² = 100 mH/25 = 4 mH. M = k√(L₁L₂) = 0.98 × √(0.100 ×
0.004) = 0.98 × √(4 × 10⁻⁴) = 0.98 × 0.02 = \textbf{19.6 mH}.

(c) The source sees 200 Ω instead of the optimal 50 Ω --- this is a
\textbf{4:1 mismatch}. A turns ratio of √(50/8) = 2.5:1 would provide a
perfect match, reflecting 8 Ω to exactly 50 Ω.

\end{examplebox}

\section{7.8 Transient Analysis}\label{transient-analysis}

Transient analysis examines circuit behavior during the transition
between steady states, such as when a switch opens or closes. The
transient response is governed by the energy storage elements
(capacitors and inductors) in the circuit, with the time constant or
damping ratio determining how quickly the circuit reaches its new steady
state.

\subsection{7.8.1 RC Circuits}\label{rc-circuits}

When a DC source is suddenly applied to or removed from an RC
(resistor-capacitor) circuit, the voltage and current do not change
instantaneously but follow an exponential trajectory governed by the
time constant τ = R × C. During charging, the capacitor voltage rises as
V\textsubscript{c}(t) = V\textsubscript{s} × (1 -
e\textsuperscript{-t/τ}), approaching the source voltage asymptotically.
During discharging, the capacitor voltage decays as
V\textsubscript{c}(t) = V₀ × e\textsuperscript{-t/τ}, where V₀ is the
initial voltage. After approximately 5 time constants (5τ), the
transient is considered complete and the circuit has reached its new
steady state. RC circuits are used in timing circuits, filters, coupling
and decoupling networks, and power supply smoothing.

\begin{examplebox}

\textbf{Example 7.8.1:} A 10 μF capacitor, initially uncharged, is
connected to a 9 V battery through a 47 kΩ resistor. Find the time
constant and the capacitor voltage at t = 0.5 s.

\textbf{Solution:}\\
Time constant: τ = R × C = 47,000 × 10 × 10⁻⁶ = 0.47 s.\\
At t = 0.5 s: V\textsubscript{c}(0.5) = 9 × (1 -
e\textsuperscript{-0.5/0.47}) = 9 × (1 - e\textsuperscript{-1.064}) = 9
× (1 - 0.3453) = 9 × 0.6547 = 5.89 V.\\
The capacitor has charged to about 65.5\% of the source voltage, which
is consistent with being slightly past one time constant.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-7-8-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch07_rc_charging.png}

\caption{Figure 7.8.1: RC Charging Curve}

\end{figure}

\subsection{7.8.2 RL Circuits}\label{rl-circuits}

When a DC source is applied to an RL (resistor-inductor) circuit, the
current increases exponentially toward its steady-state value with a
time constant τ = L / R. The current during energization follows I(t) =
(V\textsubscript{s} / R) × (1 - e\textsuperscript{-t/τ}), while the
inductor voltage decays as V\textsubscript{L}(t) = V\textsubscript{s} ×
e\textsuperscript{-t/τ}. The inductor resists changes in current by
generating a back-EMF proportional to the rate of current change
(V\textsubscript{L} = L × dI/dt). After 5τ, the current reaches
approximately 99.3\% of its final value and the inductor behaves as a
short circuit in DC steady state. RL circuits appear in relay coils,
motor windings, and inductive loads, where the stored energy (E = ½ × L
× I²) must be managed during switching to prevent voltage spikes.

\begin{examplebox}

\textbf{Example 7.8.2:} A 200 mH inductor with 50 Ω of series resistance
is connected to a 24 V DC source at t = 0. Find the time constant, the
steady-state current, and the current at t = 2 ms.

\textbf{Solution:}\\
Time constant: τ = L / R = 0.200 / 50 = 4 ms.\\
Steady-state current: I\textsubscript{ss} = V\textsubscript{s} / R = 24
/ 50 = 0.48 A = 480 mA.\\
At t = 2 ms: I(0.002) = 0.48 × (1 - e\textsuperscript{-0.002/0.004}) =
0.48 × (1 - e\textsuperscript{-0.5}) = 0.48 × (1 - 0.6065) = 0.48 ×
0.3935 = 188.9 mA.\\
The inductor voltage at t = 2 ms is V\textsubscript{L} = 24 ×
e\textsuperscript{-0.5} = 24 × 0.6065 = 14.56 V.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-7-8-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch07_rl_transient.png}

\caption{Figure 7.8.2: RL Circuit Transient Response}

\end{figure}

\subsection{7.8.3 RLC Circuits}\label{rlc-circuits}

RLC circuits containing a resistor, inductor, and capacitor exhibit
second-order transient behavior characterized by a second-order
differential equation. The nature of the transient response depends on
the damping ratio ζ (zeta), determined by the relative values of R, L,
and C. When ζ \textless{} 1 (underdamped), the response oscillates with
exponentially decaying amplitude at the damped natural frequency. When ζ
= 1 (critically damped), the response returns to steady state in the
shortest time without oscillation. When ζ \textgreater{} 1 (overdamped),
the response decays exponentially without oscillation but more slowly
than the critically damped case. The natural resonant frequency ω₀ =
1/√(LC) and the damping ratio ζ = R/(2√(L/C)) for a series RLC circuit
are the key parameters that fully characterize the transient behavior.

\begin{examplebox}

\textbf{Example 7.8.3:} A series RLC circuit has R = 100 Ω, L = 10 mH,
and C = 1 μF. Determine ω₀, ζ, and classify the transient response.

\textbf{Solution:}\\
Natural resonant frequency: ω₀ = 1/√(LC) = 1/√(0.010 × 10⁻⁶) = 1/√(10⁻⁸)
= 1/(10⁻⁴) = 10,000 rad/s.\\
Damping ratio: ζ = R / (2√(L/C)) = 100 / (2 × √(0.010 / 10⁻⁶)) = 100 /
(2 × √10,000) = 100 / (2 × 100) = 0.5.\\
Since ζ = 0.5 \textless{} 1, the circuit is underdamped and will exhibit
oscillatory transient behavior with an exponentially decaying
envelope.\\
The damped natural frequency is ω\textsubscript{d} = ω₀√(1 - ζ²) =
10,000 × √(1 - 0.25) = 10,000 × 0.866 = 8,660 rad/s (about 1,378 Hz).

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-7-8-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch07_rlc_underdamped.png}

\caption{Figure 7.8.3: Underdamped RLC Step Response}

\end{figure}

\section{7.9 Two-Port Networks}\label{two-port-networks}

A two-port network is a circuit abstraction with four terminals grouped
into two ports --- an input port and an output port --- each carrying a
voltage and current. Two-port models are fundamental to characterizing
amplifiers, filters, transmission lines, and transformers as ``black
boxes'' described entirely by their terminal relationships, without
needing to know the internal circuit topology.

\subsection{7.9.1 Two-Port Parameters}\label{two-port-parameters}

Two-port networks are characterized by parameter sets that relate the
port voltages (V₁, V₂) and currents (I₁, I₂). Each parameter set is
measured under specific terminal conditions:

\textbf{Z-parameters (impedance, open-circuit):} V₁ = Z₁₁I₁ + Z₁₂I₂ and
V₂ = Z₂₁I₁ + Z₂₂I₂. Each Z\textsubscript{ij} is found by open-circuiting
one port: Z₁₁ = V₁/I₁\textbar{}\textsubscript{I₂=0}, Z₂₁ =
V₂/I₁\textbar{}\textsubscript{I₂=0}, etc. For a reciprocal network (no
dependent sources), Z₁₂ = Z₂₁.

\textbf{Y-parameters (admittance, short-circuit):} I₁ = Y₁₁V₁ + Y₁₂V₂
and I₂ = Y₂₁V₁ + Y₂₂V₂. Each Y\textsubscript{ij} is found by
short-circuiting one port: Y₁₁ = I₁/V₁\textbar{}\textsubscript{V₂=0},
etc. The Y-parameter matrix is the inverse of the Z-parameter matrix.

\textbf{h-parameters (hybrid):} V₁ = h₁₁I₁ + h₁₂V₂ and I₂ = h₂₁I₁ +
h₂₂V₂. Hybrid parameters mix open-circuit and short-circuit conditions
and are widely used for BJT transistor models, where h₁₁ =
h\textsubscript{ie} (input impedance), h₂₁ = h\textsubscript{fe}
(current gain), h₁₂ = h\textsubscript{re} (reverse voltage ratio), and
h₂₂ = h\textsubscript{oe} (output admittance).

\textbf{ABCD-parameters (transmission):} V₁ = AV₂ − BI₂ and I₁ = CV₂ −
DI₂ (with I₂ defined as flowing out of port 2). Transmission parameters
are uniquely suited for cascaded networks because the overall ABCD
matrix is simply the product of the individual ABCD matrices. For a
reciprocal network, AD − BC = 1.

\begin{examplebox}

\textbf{Example 7.9.1:} Find the Z-parameters for a T-network consisting
of Z\textsubscript{a} = 10 Ω in series with port 1, Z\textsubscript{b} =
20 Ω in series with port 2, and Z\textsubscript{c} = 50 Ω as the shunt
element between the two series arms.

\textbf{Solution:}\\
With I₂ = 0 (port 2 open): Z₁₁ = V₁/I₁ = Z\textsubscript{a} +
Z\textsubscript{c} = 10 + 50 = \textbf{60 Ω}.\\
Z₂₁ = V₂/I₁ = Z\textsubscript{c} = \textbf{50 Ω} (voltage across the
shunt element).\\
By symmetry of the measurement process: Z₂₂ = Z\textsubscript{b} +
Z\textsubscript{c} = 20 + 50 = \textbf{70 Ω}.\\
Z₁₂ = Z\textsubscript{c} = \textbf{50 Ω}.\\
Since Z₁₂ = Z₂₁, the network is reciprocal, as expected for a passive
circuit with no dependent sources.

\end{examplebox}

\subsection{7.9.2 Two-Port
Interconnections}\label{two-port-interconnections}

Two-port networks can be interconnected in standard configurations, each
governed by a specific parameter set:

\textbf{Series connection:} When two two-ports are connected in series
at both ports (port currents are shared), the overall Z-parameters add:
Z\textsubscript{total} = Z\textsubscript{A} + Z\textsubscript{B}. This
is analogous to series impedances in a one-port circuit.

\textbf{Parallel connection:} When two two-ports are connected in
parallel at both ports (port voltages are shared), the overall
Y-parameters add: Y\textsubscript{total} = Y\textsubscript{A} +
Y\textsubscript{B}. This is analogous to parallel admittances.

\textbf{Cascade connection:} When the output port of one network feeds
the input port of the next, the overall ABCD matrix is the matrix
product of the individual ABCD matrices in order:
{[}ABCD{]}\textsubscript{total} = {[}ABCD{]}\textsubscript{A} ×
{[}ABCD{]}\textsubscript{B}. This is the most common interconnection for
filters, transmission line segments, and amplifier stages.

Two-port analysis has broad applications: filter sections are cascaded
using ABCD matrices to build complex frequency responses, transmission
line segments are modeled as ABCD networks for impedance and voltage
analysis, and transistor amplifiers use h-parameters for small-signal
gain and impedance calculations.

\begin{examplebox}

\textbf{Example 7.9.2:} Two identical two-port networks, each with ABCD
parameters A = 1, B = 10 Ω, C = 0.02 S, D = 1, are cascaded. Find the
overall ABCD parameters and the voltage gain V₂/V₁ when the cascade is
terminated in a 50 Ω load.

\textbf{Solution:}\\
For a cascade, {[}ABCD{]}\textsubscript{total} = {[}ABCD{]}₁ ×
{[}ABCD{]}₂:

A\textsubscript{T} = A₁A₂ + B₁C₂ = (1)(1) + (10)(0.02) = \textbf{1.2}

B\textsubscript{T} = A₁B₂ + B₁D₂ = (1)(10) + (10)(1) = \textbf{20 Ω}

C\textsubscript{T} = C₁A₂ + D₁C₂ = (0.02)(1) + (1)(0.02) = \textbf{0.04
S}

D\textsubscript{T} = C₁B₂ + D₁D₂ = (0.02)(10) + (1)(1) = \textbf{1.2}

Verify determinant: A\textsubscript{T}D\textsubscript{T} −
B\textsubscript{T}C\textsubscript{T} = 1.2 × 1.2 − 20 × 0.04 = 1.44 −
0.80 = \textbf{0.64}.\\
Each individual stage has AD − BC = 1 − 0.2 = \textbf{0.8}, and (0.8)² =
0.64 ✓ (consistent with cascading two identical stages).\\
Since AD − BC = 0.64 ≠ 1, the cascade is \textbf{not a reciprocal
network} --- as expected, because the individual stages are also
non-reciprocal (AD − BC = 0.8 ≠ 1).\\
With Z\textsubscript{L} = 50 Ω: V₂/V₁ = Z\textsubscript{L} /
(A\textsubscript{T}Z\textsubscript{L} + B\textsubscript{T}) = 50 / (1.2
× 50 + 20) = 50 / 80 = \textbf{0.625} (−4.08 dB).

\end{examplebox}

\chapter{Chapter 8}\label{chapter-8}

\chapter{Signal Processing}\label{signal-processing}

Signal processing is the branch of electrical engineering concerned with
the analysis, manipulation, and interpretation of signals --- quantities
that carry information and vary as a function of time, frequency, or
space. It provides the mathematical and computational tools to extract
useful information from raw data, remove noise and interference,
compress data for efficient storage and transmission, and transform
signals between different representations. Signal processing techniques
are foundational to communications, audio and video systems, radar,
medical imaging, control systems, and machine learning.

\section{8.1 Signals and Systems}\label{signals-and-systems}

The study of signals and systems provides the mathematical foundation
for all of signal processing. A signal is any quantity that varies as a
function of one or more independent variables (most commonly time), and
a system is any process that transforms an input signal into an output
signal. By classifying signals and characterizing systems according to
properties such as linearity, time invariance, and causality, engineers
can apply powerful general-purpose tools --- convolution, correlation,
and transform methods --- to analyze, design, and optimize a vast range
of processing algorithms.

\subsection{8.1.1 Signal Classification}\label{signal-classification}

Signals are classified along several dimensions that determine which
mathematical tools and processing techniques are appropriate for their
analysis. The most fundamental distinction is between continuous-time
signals, defined for all values of time t, and discrete-time signals,
defined only at specific time instants n (typically uniformly spaced
samples produced by an analog-to-digital converter). Orthogonal to this
is the amplitude distinction: analog signals take continuous amplitude
values, while digital signals are both discrete in time and quantized in
amplitude to a finite set of levels. Signals may be deterministic ---
completely described by a mathematical expression such as x(t) = A
cos(ωt + φ) --- or random (stochastic), requiring statistical
descriptions such as mean, variance, autocorrelation, and power spectral
density. Periodic signals repeat at a fixed interval T such that x(t) =
x(t + T), enabling Fourier series decomposition into discrete harmonics,
while aperiodic signals require the continuous Fourier transform for
frequency analysis. The energy-power classification distinguishes energy
signals, which have finite total energy E = ∫\textbar x(t)\textbar²dt
and are typically transient (pulses, decaying exponentials), from power
signals, which persist indefinitely with finite average power P =
lim(1/T)∫\textbar x(t)\textbar²dt (sinusoids, periodic waveforms, random
noise). Additional classifications include causal versus non-causal
(whether the signal is zero for t \textless{} 0), bounded versus
unbounded, and even versus odd symmetry. Correctly classifying a signal
is the essential first step in any analysis, because it determines
whether to use Fourier series or Fourier transform, continuous or
discrete methods, deterministic or statistical tools, and time-domain or
frequency-domain representations.

\begin{examplebox}

\textbf{Example 8.1.1:} Classify the signal x(t) = 5cos(2π × 1000t) and
determine its period, frequency, and average power (assuming a 1 Ω
reference).

\textbf{Solution:}\\
The signal is continuous-time, analog, deterministic, and periodic.\\
The angular frequency is ω = 2π × 1000 rad/s, so the frequency is f =
1000 Hz and the period is T = 1/f = 1 ms.\\
Since the signal persists indefinitely, it is a power signal.\\
The average power into 1 Ω is P = (A²/2) = (5²/2) = 12.5 W, where A = 5
is the peak amplitude (using the RMS value of a sinusoid,
V\textsubscript{rms} = 5/√2 = 3.536 V, gives P = V\textsubscript{rms}² /
1 = 12.5 W).

\end{examplebox}

\subsection{8.1.2 Linear Time-Invariant (LTI)
Systems}\label{linear-time-invariant-lti-systems}

A system is linear if it obeys the principles of superposition
(additivity and homogeneity): the response to a weighted sum of inputs
equals the same weighted sum of the individual responses. A system is
time-invariant if its behavior does not change with time --- a delayed
input produces an identically delayed output. LTI systems are the most
analytically tractable class of systems because they are completely
characterized by their impulse response h(t), and the output for any
input x(t) is obtained by convolution: y(t) = x(t) * h(t). In the
frequency domain, convolution becomes multiplication: Y(ω) = X(ω) ·
H(ω), where H(ω) is the system's frequency response (the Fourier
transform of the impulse response). This property makes frequency-domain
analysis a powerful tool for understanding and designing LTI systems.

\begin{examplebox}

\textbf{Example 8.1.2:} An LTI system has impulse response h(t) =
2e\textsuperscript{-3t}u(t), where u(t) is the unit step. Find the
frequency response magnitude \textbar H(ω)\textbar{} at ω = 4 rad/s.

\textbf{Solution:}\\
The frequency response is the Fourier transform of h(t): H(ω) = 2 / (3 +
jω).\\
At ω = 4: H(4) = 2 / (3 + j4).\\
The magnitude is \textbar H(4)\textbar{} = 2 / √(3² + 4²) = 2 / √(9 +
16) = 2 / √25 = 2/5 = 0.4.\\
The phase is θ = -arctan(4/3) = -53.13°.\\
This means a sinusoidal input at ω = 4 rad/s is attenuated to 40\% of
its amplitude and shifted by -53.13°.

\end{examplebox}

\subsection{8.1.3 Convolution}\label{convolution}

Convolution is the mathematical operation that relates the input,
output, and impulse response of an LTI system. For continuous-time
systems, the convolution integral is y(t) = ∫x(τ)h(t - τ)dτ, where the
integration is over all τ. For discrete-time systems, the convolution
sum is y{[}n{]} = Σ x{[}k{]}h{[}n - k{]}, where the summation is over
all k. Graphically, convolution involves flipping one signal in time,
shifting it, multiplying the two signals point by point, and integrating
(or summing) the product. Convolution in the time domain corresponds to
multiplication in the frequency domain, which is the basis for efficient
frequency-domain filtering using the FFT.

\begin{examplebox}

\textbf{Example 8.1.3:} Compute the discrete-time convolution y{[}n{]} =
x{[}n{]} * h{[}n{]} where x{[}n{]} = \{1, 2, 3\} (for n = 0, 1, 2) and
h{[}n{]} = \{1, 1\} (for n = 0, 1).

\textbf{Solution:}\\
Apply the convolution sum y{[}n{]} = Σ x{[}k{]}h{[}n-k{]}:\\
y{[}0{]} = x{[}0{]}h{[}0{]} = 1 × 1 = 1.\\
y{[}1{]} = x{[}0{]}h{[}1{]} + x{[}1{]}h{[}0{]} = 1 × 1 + 2 × 1 = 3.\\
y{[}2{]} = x{[}1{]}h{[}1{]} + x{[}2{]}h{[}0{]} = 2 × 1 + 3 × 1 = 5.\\
y{[}3{]} = x{[}2{]}h{[}1{]} = 3 × 1 = 3.\\
Therefore y{[}n{]} = \{1, 3, 5, 3\} for n = 0, 1, 2, 3.\\
Note the output length is len(x) + len(h) - 1 = 3 + 2 - 1 = 4 samples.

\end{examplebox}

\subsection{8.1.4 Correlation}\label{correlation}

Correlation measures the similarity between two signals as a function of
a time shift applied to one of them. The cross-correlation of signals
x(t) and y(t) is defined as R\textsubscript{xy}(τ) = ∫x(t)y(t + τ)dt,
which quantifies how well x aligns with a time-shifted version of y.
When a signal is correlated with itself, the result is the
autocorrelation R\textsubscript{xx}(τ), which reveals periodic structure
and is always maximum at zero lag: R\textsubscript{xx}(0) equals the
signal's total energy (or average power for power signals). The
autocorrelation and power spectral density form a Fourier transform pair
(Wiener-Khinchin theorem), connecting time-domain correlation analysis
to frequency-domain spectral analysis. Cross-correlation is widely used
in radar and sonar (measuring time delay to determine range), GPS (code
acquisition), template matching, and system identification.

\begin{examplebox}

\textbf{Example 8.1.4:} A radar transmits a pulse x(t) and receives the
echo y(t) = 0.01 × x(t - 25 μs) + noise. The cross-correlation
R\textsubscript{xy}(τ) peaks at τ = 25 μs. Determine the target range if
the signal propagates at the speed of light (c = 3 × 10⁸ m/s).

\textbf{Solution:}\\
The cross-correlation peak at τ = 25 μs indicates the round-trip delay
to the target and back.\\
The round-trip distance is d\textsubscript{round-trip} = c × τ = 3 × 10⁸
× 25 × 10⁻⁶ = 7500 m.\\
Since the signal travels to the target and returns, the one-way range is
R = d/2 = 7500/2 = 3750 m = 3.75 km.\\
The correlation peak height of 0.01 relative to the autocorrelation peak
reflects the signal attenuation over the path.

\end{examplebox}

\subsection{8.1.5 Sampling Theorem and
Aliasing}\label{sampling-theorem-and-aliasing}

The Nyquist-Shannon sampling theorem establishes the fundamental bridge
between continuous-time and discrete-time signals: a band-limited signal
with no frequency content above f\textsubscript{max} can be perfectly
reconstructed from its samples if the sampling rate satisfies
f\textsubscript{s} ≥ 2f\textsubscript{max}. The critical rate
f\textsubscript{N} = 2f\textsubscript{max} is the Nyquist rate, and the
corresponding frequency f\textsubscript{s}/2 is the Nyquist frequency
(the highest frequency representable at sampling rate
f\textsubscript{s}). When a signal is sampled, its spectrum is
replicated at integer multiples of f\textsubscript{s}; if
f\textsubscript{s} \textless{} 2f\textsubscript{max}, adjacent spectral
copies overlap, causing \textbf{aliasing} --- high-frequency components
fold back into the baseband as spurious low-frequency artifacts that
cannot be removed by any post-processing. An \textbf{anti-aliasing
filter} (analog lowpass with cutoff at f\textsubscript{s}/2) must
precede the sampler to attenuate frequency content above the Nyquist
frequency. In practice, the sampling rate is chosen 2--10× above
f\textsubscript{max} to allow a realizable anti-aliasing filter with a
gradual roll-off. Reconstruction of the continuous-time signal from its
samples uses sinc interpolation: x(t) = Σ x{[}n{]} · sinc((t − nT)/T),
where T = 1/f\textsubscript{s}. Real DACs approximate this with
zero-order hold (staircase output) followed by a reconstruction lowpass
filter. \textbf{Bandpass sampling} extends the theorem to narrowband
signals centered at a carrier frequency: a signal occupying bandwidth B
centered at f\textsubscript{c} can be sampled at f\textsubscript{s} ≥ 2B
(much less than 2f\textsubscript{c}) provided the sampling rate is
chosen so that spectral replicas do not overlap, enabling direct RF
digitization in software-defined radio receivers.

\begin{examplebox}

\textbf{Example 8.1.5:} An audio signal contains frequencies up to 20
kHz. It is sampled at f\textsubscript{s} = 44.1 kHz (CD standard). A 25
kHz tone from an ultrasonic source leaks into the signal path. Determine
whether aliasing occurs and, if so, identify the aliased frequency.

\textbf{Solution:}\\
The Nyquist frequency is f\textsubscript{s}/2 = 44,100/2 = 22,050 Hz.\\
The 25 kHz component exceeds this limit.\\
If the anti-aliasing filter fails to attenuate it, the aliased frequency
is f\textsubscript{alias} = f\textsubscript{s} − f\textsubscript{signal}
= 44,100 − 25,000 = 19,100 Hz.\\
This 19.1 kHz alias falls within the audible band and would appear as a
spurious tone that cannot be distinguished from a genuine 19.1 kHz
signal.\\
To prevent this, the anti-aliasing filter must attenuate 25 kHz by at
least 90 dB (below the 16-bit noise floor of −96 dB).\\
CD systems use steep analog filters with a transition band from 20 kHz
to 22.05 kHz, which is why the sampling rate was chosen as 44.1 kHz
rather than exactly 40 kHz --- the extra 10\% provides margin for a
realizable filter.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-1-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_aliasing.png}

\caption{Figure 8.1.5: Sampling and Aliasing}

\end{figure}

\section{8.2 Fourier Analysis}\label{fourier-analysis-1}

Fourier analysis is the cornerstone of signal processing, providing the
framework for decomposing signals into their constituent frequency
components. The Fourier series represents periodic signals as sums of
harmonically related sinusoids, the Fourier transform extends this to
aperiodic signals with continuous spectra, and the Discrete Fourier
Transform (DFT) --- efficiently computed via the FFT algorithm --- makes
spectral analysis practical for sampled data. Together, these tools
enable engineers to design filters, analyze spectral content, detect
signals in noise, and understand the frequency-domain behavior of
systems.

\subsection{8.2.1 Fourier Series}\label{fourier-series}

The Fourier series is built on a profound insight: any periodic signal,
no matter how complex its shape, can be decomposed into a sum of
harmonically related sinusoids at integer multiples of the fundamental
frequency f₀ = 1/T. This means a square wave, a sawtooth, a rectified
sine, or any other periodic waveform is fully described by the
amplitudes and phases of its harmonic components --- the fundamental (n
= 1), second harmonic (n = 2), third harmonic (n = 3), and so on. The
trigonometric form expresses the series as a sum of cosines and sines
with real coefficients aₙ and bₙ, while the complex exponential form
uses basis functions e\textsuperscript{j2πnf₀t} with complex
coefficients cₙ, which is more compact and better suited for
mathematical manipulation. Convergence of the series requires the
Dirichlet conditions: the signal must have a finite number of
discontinuities, extrema, and finite energy per period. At points of
continuity, the series converges exactly to the signal; at
discontinuities, it converges to the midpoint of the jump, and the Gibbs
phenomenon produces approximately 9\% overshoot at the edges of the
discontinuity regardless of how many terms are included. Parseval's
theorem relates the average power of the periodic signal to the sum of
the squared magnitudes of its Fourier coefficients, providing a direct
link between time-domain and frequency-domain energy accounting. In
practice, the Fourier series is essential for analyzing power system
harmonics (quantifying the distortion caused by nonlinear loads like
rectifiers and VFDs), designing audio synthesizers (building complex
timbres from pure tones), and understanding the spectral content of any
repetitive waveform encountered in communications and instrumentation.

\begin{examplebox}

\textbf{Example 8.2.1:} A periodic square wave has amplitude A = 5 V,
period T = 2 ms, and 50\% duty cycle. Find the fundamental frequency and
the amplitudes of the first three nonzero harmonic components in the
trigonometric Fourier series.

\textbf{Solution:}\\
Fundamental frequency: f₀ = 1/T = 1/0.002 = 500 Hz.\\
For a symmetric square wave, the Fourier series contains only odd
harmonics with amplitudes aₙ = 4A/(nπ) for odd n.\\
First harmonic (n = 1): a₁ = 4 × 5 / (1 × π) = 20/π = 6.366 V.\\
Third harmonic (n = 3): a₃ = 20 / (3π) = 2.122 V.\\
Fifth harmonic (n = 5): a₅ = 20 / (5π) = 1.273 V.\\
The series is x(t) = 6.366 sin(2π × 500t) + 2.122 sin(2π × 1500t) +
1.273 sin(2π × 2500t) + \ldots{}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-2-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_fourier_series.png}

\caption{Figure 8.2.1: Fourier Series Harmonics of a Square Wave}

\end{figure}

\subsection{8.2.2 Fourier Transform}\label{fourier-transform}

The Fourier Transform extends frequency-domain analysis to aperiodic
signals by representing them as a continuous spectrum of frequencies
rather than discrete harmonics. The forward transform X(f) =
∫x(t)e\textsuperscript{-j2πft}dt decomposes the signal into its
frequency components, and the inverse transform x(t) =
∫X(f)e\textsuperscript{j2πft}df reconstructs the signal from its
spectrum. Important properties include linearity, time shifting
(introduces a phase shift), frequency shifting (modulation), time
scaling, and the duality between time and frequency domains. The
convolution theorem states that convolution in time corresponds to
multiplication in frequency and vice versa. Common transform pairs
include the rectangular pulse (sinc spectrum), Gaussian (Gaussian
spectrum), and the impulse function δ(t) (flat spectrum equal to 1 for
all frequencies).

\begin{examplebox}

\textbf{Example 8.2.2:} Find the Fourier Transform of a rectangular
pulse x(t) = 1 for \textbar t\textbar{} ≤ 0.5 ms, and 0 otherwise.
Determine the first null (zero crossing) of the spectrum.

\textbf{Solution:}\\
The pulse has width τ = 1 ms.\\
The Fourier Transform is X(f) = τ × sinc(fτ) = 0.001 × sinc(0.001f),
where sinc(x) = sin(πx)/(πx).\\
The magnitude \textbar X(f)\textbar{} = 0.001 ×
\textbar sinc(0.001f)\textbar.\\
The first null occurs where sinc(0.001f) = 0, i.e., when π × 0.001f = π,
so f = 1/0.001 = 1000 Hz = 1 kHz.\\
The main lobe of the spectrum extends from -1 kHz to +1 kHz, and the
spectral width is inversely proportional to the pulse duration.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-2-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_fourier_transform.png}

\caption{Figure 8.2.2: Rectangular Pulse and Sinc Spectrum}

\end{figure}

\subsection{8.2.3 Discrete Fourier Transform
(DFT)}\label{discrete-fourier-transform-dft}

The Discrete Fourier Transform is the computable form of Fourier
analysis for sampled data and is the workhorse of modern digital signal
processing. It maps a finite-length sequence of N time-domain samples to
N frequency-domain samples, defined as X{[}k{]} = Σ
x{[}n{]}e\textsuperscript{-j2πkn/N} for k = 0, 1, \ldots, N-1, and the
inverse DFT (IDFT) recovers the original time-domain sequence from the
spectral samples. The DFT can be understood as sampling the
Discrete-Time Fourier Transform (DTFT) --- which is continuous in
frequency --- at N equally spaced points around the unit circle,
yielding a frequency resolution of Δf = f\textsubscript{s}/N, where
f\textsubscript{s} is the sampling rate. Because the DFT implicitly
treats the input sequence as one period of a periodic signal, analyzing
a signal that is not exactly periodic within the N-sample window
introduces spectral leakage: energy from a single frequency tone spreads
into adjacent bins, obscuring nearby weaker components. Windowing
functions such as Hanning, Hamming, Blackman, and flat-top are applied
to the time-domain data before the DFT to taper the edges of the
analysis block and suppress leakage sidelobes, at the cost of slightly
widening the main lobe and reducing frequency resolution. Zero-padding
--- appending zeros to extend the sequence to a longer length ---
increases the number of frequency-domain samples and provides finer
interpolation of the spectral shape, but does not improve the
fundamental resolving ability, which is set by the original observation
window duration T = N/f\textsubscript{s}. The DFT's direct computation
requires O(N²) operations, but the Fast Fourier Transform (FFT)
algorithm reduces this to O(N log N), making real-time spectral analysis
practical. The DFT is ubiquitous in spectrum analyzers, audio
processing, communications receivers (OFDM demodulation), radar signal
processing, vibration analysis, and medical imaging.

\begin{examplebox}

\textbf{Example 8.2.3:} A signal is sampled at f\textsubscript{s} = 8000
Hz and a 256-point DFT is computed. Find the frequency resolution (bin
spacing) and determine which DFT bin index corresponds to a 1500 Hz
tone.

\textbf{Solution:}\\
Frequency resolution: Δf = f\textsubscript{s} / N = 8000 / 256 = 31.25
Hz per bin.\\
The bin index for 1500 Hz: k = f / Δf = 1500 / 31.25 = 48.\\
Therefore, the 1500 Hz component appears at bin k = 48.\\
If the signal were zero-padded to N = 512, the new resolution would be
Δf = 8000/512 = 15.625 Hz, providing finer spectral interpolation but
the same fundamental resolving ability (still limited by the original
256-sample observation window of 32 ms).

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-2-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_dft_bins.png}

\caption{Figure 8.2.3: DFT Frequency Bins}

\end{figure}

\subsection{8.2.4 Fast Fourier Transform
(FFT)}\label{fast-fourier-transform-fft}

The Fast Fourier Transform is an efficient algorithm for computing the
DFT, reducing the computational complexity from O(N²) to O(N log N) by
exploiting the symmetry and periodicity of the complex exponential basis
functions. The most common variant is the radix-2 Cooley-Tukey
algorithm, which recursively divides the N-point DFT into two N/2-point
DFTs (requiring N to be a power of 2), combines the results using
butterfly operations, and achieves dramatic speedup for large N. For
example, a 1024-point DFT requires approximately 1,048,576 complex
multiplications by direct computation but only about 5,120 using the
FFT. The FFT has made real-time spectral analysis practical and is the
computational engine behind applications ranging from audio equalizers
and speech recognition to radar processing and medical imaging.
Split-radix, mixed-radix, and prime-factor algorithms extend FFT
efficiency to sequences whose lengths are not powers of 2.

\begin{examplebox}

\textbf{Example 8.2.4:} Compare the number of complex multiplications
required for a 4096-point DFT using direct computation versus the
radix-2 FFT.

\textbf{Solution:}\\
Direct DFT: N² = 4096² = 16,777,216 complex multiplications.\\
Radix-2 FFT: (N/2)log₂N = (4096/2) × log₂(4096) = 2048 × 12 = 24,576
complex multiplications.\\
Speedup ratio: 16,777,216 / 24,576 = 682.7×.\\
The FFT computes the same result nearly 683 times faster, making
real-time spectral analysis of a 4096-point block practical even on
modest hardware.

\end{examplebox}

\subsection{8.2.5 Discrete Cosine Transform
(DCT)}\label{discrete-cosine-transform-dct}

The Discrete Cosine Transform expresses a finite sequence of data points
as a sum of cosine functions at different frequencies, producing a
purely real-valued transform output (unlike the complex-valued DFT). The
most widely used variant, the DCT-II, is defined as X{[}k{]} = Σ
x{[}n{]} · cos{[}π(2n + 1)k / (2N){]} for k = 0, 1, \ldots, N-1, and has
the important property that it concentrates the energy of typical
real-world signals into a small number of low-frequency coefficients.
This energy compaction property makes the DCT the foundation of lossy
data compression: JPEG image compression applies the DCT to 8×8 pixel
blocks and quantizes the resulting coefficients, discarding
high-frequency components that contribute little to visual quality.
Similarly, MP3 and AAC audio codecs use the Modified DCT (MDCT) --- a
variant with overlapping windows that eliminates blocking artifacts ---
to transform audio samples before perceptual quantization. The DCT is
closely related to the DFT of a symmetrically extended sequence, and
fast DCT algorithms achieve O(N log N) complexity by leveraging this
relationship. The DCT also appears in spectral analysis as an
alternative to the DFT when the signal is real-valued and the phase
information is not needed.

\begin{examplebox}

\textbf{Example 8.2.5:} An 8-point DCT-II is applied to the data block x
= \{100, 102, 104, 106, 108, 106, 104, 102\}. Applying X{[}k{]} = Σ
x{[}n{]} · cos{[}π(2n+1)k/(2N){]} gives coefficients X = \{832.0, −5.13,
−12.62, 1.80, 0.00, −1.20, −0.90, 1.02\}. If coefficients with magnitude
less than 2.0 are set to zero (quantized out), calculate the compression
ratio and the reconstruction error.

\textbf{Solution:}\\
Original data requires 8 values to represent.\\
After thresholding, 3 coefficients are significant: X{[}0{]} = 832.0,
X{[}1{]} = −5.13, and X{[}2{]} = −12.62 (the remaining 5 are set to
zero).\\
Compression ratio: 8/3 ≈ \textbf{2.7:1}.\\
Energy of discarded coefficients: 1.80² + 0² + 1.20² + 0.90² + 1.02² =
3.24 + 0 + 1.44 + 0.81 + 1.04 = 6.53.\\
Total signal energy: 832.0² + 5.13² + 12.62² + 6.53 = 692,224 + 26.3 +
159.3 + 6.53 = 692,416.\\
Energy retained: (692,416 − 6.53) / 692,416 = \textbf{99.999\%}.\\
The RMS error per sample is √(6.53/8) = √0.8163 = \textbf{0.90} (about
0.9\% of the mean signal value of 104) --- illustrating the DCT's energy
compaction property: even discarding 5 of 8 coefficients preserves the
signal with negligible error. In practice, smooth correlated data (such
as image pixel blocks in JPEG) yields even stronger compaction,
achieving ratios of 10:1 or higher.

\end{examplebox}

\subsection{8.2.6 Hilbert Transform and Analytic
Signals}\label{hilbert-transform-and-analytic-signals}

The Hilbert transform is an operation that shifts every frequency
component of a real signal by −90° (positive frequencies) or +90°
(negative frequencies), producing the quadrature companion of the
original signal. For a signal x(t), the Hilbert transform is x̂(t) =
(1/π) ∫ x(τ)/(t − τ) dτ, which in the frequency domain corresponds to
multiplication by −j·sgn(f): the magnitude spectrum is unchanged, but
positive frequencies are shifted by −90° and negative frequencies by
+90°. The \textbf{analytic signal} z(t) = x(t) + jx̂(t) is a complex
signal whose spectrum exists only at positive frequencies --- the
negative-frequency content has been suppressed. From the analytic
signal, the \textbf{instantaneous envelope} (amplitude) is A(t) =
\textbar z(t)\textbar{} = √(x² + x̂²), and the \textbf{instantaneous
phase} is φ(t) = arctan(x̂(t)/x(t)), from which the \textbf{instantaneous
frequency} f\textsubscript{i}(t) = (1/2π)(dφ/dt) can be derived. These
quantities are essential for analyzing amplitude-modulated and
frequency-modulated signals, characterizing non-stationary vibration
signals, and demodulating communications waveforms. The Hilbert
transform also enables single-sideband (SSB) modulation by cancelling
one sideband through phasing, and it is computed efficiently in discrete
time by taking the FFT, zeroing the negative-frequency bins, and taking
the inverse FFT.

\begin{examplebox}

\textbf{Example 8.2.6:} A vibration signal x(t) = (1 + 0.5cos(2π × 8t))
× cos(2π × 200t) represents a 200 Hz carrier amplitude-modulated at 8
Hz. Compute the analytic signal and extract the instantaneous envelope
to recover the modulation.

\textbf{Solution:}\\
The signal is an AM waveform with carrier f\textsubscript{c} = 200 Hz
and modulation f\textsubscript{m} = 8 Hz.\\
The Hilbert transform of cos(2πf\textsubscript{c}t) is
sin(2πf\textsubscript{c}t), so x̂(t) = (1 + 0.5cos(2π × 8t)) × sin(2π ×
200t).\\
The analytic signal is z(t) = x(t) + jx̂(t) = (1 + 0.5cos(2π × 8t)) ×
e\textsuperscript{j2π×200t}.\\
The instantaneous envelope: A(t) = \textbar z(t)\textbar{} = \textbar1 +
0.5cos(2π × 8t)\textbar{} ×
\textbar e\textsuperscript{j2π×200t}\textbar{} = 1 + 0.5cos(2π × 8t).\\
This cleanly recovers the 8 Hz modulating envelope without rectification
or lowpass filtering, ranging from 0.5 (minimum) to 1.5 (maximum).\\
The modulation index is m = 0.5/1.0 = 50\%.\\
In practice, this is computed by FFT: for N = 1024 samples at
f\textsubscript{s} = 2048 Hz, take the FFT, set bins 513--1024 to zero
(negative frequencies), double bins 2--512 (positive frequencies), keep
bin 1 (DC) unchanged, and take the inverse FFT to obtain z{[}n{]}.\\
The envelope is then A{[}n{]} = \textbar z{[}n{]}\textbar.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-2-6}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_hilbert.png}

\caption{Figure 8.2.6: Hilbert Transform Envelope Extraction}

\end{figure}

\subsection{8.2.7 Goertzel Algorithm}\label{goertzel-algorithm}

The Goertzel algorithm is a computationally efficient method for
evaluating the DFT at a single frequency bin (or a small number of
bins), requiring only O(N) operations per bin compared to the O(N log N)
of a full FFT. When only a few specific frequencies need to be detected
--- rather than the complete spectrum --- the Goertzel algorithm is
faster than computing the entire FFT and extracting the desired bins.
The algorithm reformulates the DFT computation as a second-order IIR
filter: for each input sample x{[}n{]}, the recursion s{[}n{]} =
x{[}n{]} + 2cos(2πk/N) × s{[}n−1{]} − s{[}n−2{]} is iterated for n = 0
to N−1 (with s{[}−1{]} = s{[}−2{]} = 0), and after processing all N
samples, the DFT output is X{[}k{]} = s{[}N−1{]} −
e\textsuperscript{−j2πk/N} × s{[}N−2{]}. The power at bin k can be
computed without complex arithmetic: \textbar X{[}k{]}\textbar² =
s{[}N−1{]}² + s{[}N−2{]}² − 2cos(2πk/N) × s{[}N−1{]} × s{[}N−2{]}. Per
frequency bin, the Goertzel algorithm requires N real multiplications
and 2N real additions (the recursion), plus a single complex multiply
for the final output --- compared to (N/2)log₂N complex multiplications
for the entire FFT. The crossover point where a full FFT becomes more
efficient is approximately when the number of bins needed exceeds
2·log₂(N).

The most prominent application is \textbf{DTMF (Dual-Tone
Multi-Frequency) detection} in telephony, where each key press generates
two simultaneous tones from a set of 8 frequencies (697, 770, 852, 941
Hz for rows and 1209, 1336, 1477, 1633 Hz for columns). The Goertzel
algorithm evaluates the DFT at these 8 specific frequencies, detecting
which two tones are present. Other applications include power line
frequency measurement (monitoring 50/60 Hz and harmonics), audio pitch
detection, and radar Doppler bin extraction.

\begin{examplebox}

\textbf{Example 8.2.7:} A DTMF detector samples at f\textsubscript{s} =
8000 Hz and uses an N = 205 sample block (25.625 ms). The digit ``5''
produces tones at 770 Hz and 1336 Hz. Calculate (a) the DFT bin indices
for all 8 DTMF frequencies, (b) the number of multiplications for the
Goertzel approach versus a full 256-point FFT, and (c) the frequency
resolution.

\textbf{Solution:}

(a) Bin index for each frequency: k = round(f × N /
f\textsubscript{s})\\
697 Hz: k = round(697 × 205 / 8000) = round(17.86) = 18 → actual f = 18
× 8000/205 = 702.4 Hz\\
770 Hz: k = round(770 × 205 / 8000) = round(19.73) = 20 → actual f = 20
× 8000/205 = 780.5 Hz\\
852 Hz: k = round(852 × 205 / 8000) = round(21.83) = 22 → actual f = 22
× 8000/205 = 858.5 Hz\\
941 Hz: k = round(941 × 205 / 8000) = round(24.11) = 24 → actual f = 24
× 8000/205 = 936.6 Hz\\
1209 Hz: k = 31, 1336 Hz: k = 34, 1477 Hz: k = 38, 1633 Hz: k = 42\\
The chosen N = 205 provides bin indices that closely match the DTMF
frequencies (\textless{} 1.4\% error).

(b) Computational cost:\\
Goertzel (8 bins): 8 × N = 8 × 205 = \textbf{1,640 real
multiplications}\\
256-point FFT (zero-padded): (N/2) × log₂N = 128 × 8 = \textbf{1,024
complex multiplications} = 4,096 real multiplications\\
Goertzel is \textbf{2.5× more efficient} for 8 bins out of 256.

(c) Frequency resolution: Δf = f\textsubscript{s} / N = 8000 / 205 =
\textbf{39.0 Hz}, sufficient to distinguish the closest DTMF pair (770
and 852 Hz, separated by 82 Hz).

\end{examplebox}

\section{8.3 Laplace Transform}\label{laplace-transform}

The Laplace transform is the primary tool for analyzing continuous-time
linear systems in engineering, extending the concept of frequency-domain
analysis to the complex frequency plane s = σ + jω. By converting
differential equations into algebraic equations, it simplifies circuit
analysis, control system design, and the study of transient and
steady-state behavior. The s-domain provides a unified framework for
understanding stability, frequency response, and system dynamics through
the geometry of poles and zeros.

\subsection{8.3.1 Definition and
Properties}\label{definition-and-properties}

The Laplace transform converts a time-domain function x(t) into a
complex frequency-domain function X(s), where s = σ + jω is the complex
frequency variable. The one-sided (unilateral) Laplace transform is
defined as X(s) = ∫₀\textsuperscript{∞} x(t)e\textsuperscript{-st}dt and
is the standard form used in engineering for causal systems with initial
conditions. Key properties include linearity, time differentiation
(sX(s) - x(0⁻) for the first derivative), time integration (X(s)/s),
time shifting (e\textsuperscript{-as}X(s)), frequency shifting (X(s-a)),
and the initial and final value theorems. The Laplace transform
generalizes the Fourier transform by replacing jω with s, enabling
analysis of signals and systems that do not have a Fourier transform
(such as growing exponentials) and naturally incorporating initial
conditions into the solution.

\begin{examplebox}

\textbf{Example 8.3.1:} Find the Laplace transform of x(t) =
3e\textsuperscript{-2t}cos(5t)u(t), where u(t) is the unit step
function.

\textbf{Solution:}\\
Using the transform pair: L\{e\textsuperscript{-at}cos(ωt)u(t)\} = (s +
a) / ((s + a)² + ω²).\\
Here a = 2 and ω = 5.\\
Applying linearity with the scaling factor of 3: X(s) = 3(s + 2) / ((s +
2)² + 25) = 3(s + 2) / (s² + 4s + 4 + 25) = 3(s + 2) / (s² + 4s + 29).\\
The region of convergence is Re\{s\} \textgreater{} -2.

\end{examplebox}

\subsection{8.3.2 Transfer Functions}\label{transfer-functions}

A transfer function H(s) is the ratio of the Laplace transform of the
output to the Laplace transform of the input, assuming zero initial
conditions: H(s) = Y(s)/X(s). For circuits and systems described by
linear constant-coefficient differential equations, the transfer
function is a rational function (ratio of polynomials) in s. The roots
of the numerator polynomial are the zeros of the system (frequencies
where the output is zero), and the roots of the denominator polynomial
are the poles (frequencies where the response is theoretically
infinite). The locations of poles and zeros in the s-plane completely
determine the system's frequency response, stability, and transient
behavior. A system is stable if and only if all poles have negative real
parts (lie in the left half of the s-plane).

\begin{examplebox}

\textbf{Example 8.3.2:} A system has transfer function H(s) = 10(s + 3)
/ ((s + 1)(s + 5)). Find the poles, zeros, DC gain, and determine
stability.

\textbf{Solution:}\\
Zeros: s + 3 = 0, so z₁ = -3.\\
Poles: s + 1 = 0 and s + 5 = 0, so p₁ = -1 and p₂ = -5.\\
Both poles have negative real parts (left half-plane), so the system is
stable.\\
DC gain: H(0) = 10(0 + 3) / ((0 + 1)(0 + 5)) = 30 / 5 = 6.\\
The system amplifies DC signals by a factor of 6 and rolls off at higher
frequencies due to the two poles.

\end{examplebox}

\subsection{8.3.3 Inverse Laplace
Transform}\label{inverse-laplace-transform}

The inverse Laplace transform recovers the time-domain function from its
s-domain representation using partial fraction expansion for rational
functions. The process involves factoring the denominator into its roots
(poles), decomposing X(s) into a sum of simpler fractions with known
inverse transforms, and looking up or computing each term's time-domain
equivalent. First-order poles at s = -a correspond to exponential terms
Ae\textsuperscript{-at}, complex conjugate poles at s = -σ ± jω
correspond to damped sinusoids, and repeated poles introduce
polynomial-times-exponential terms. Tables of common Laplace transform
pairs and the linearity property allow most engineering problems to be
solved without evaluating the complex contour integral directly.

\begin{examplebox}

\textbf{Example 8.3.3:} Find the inverse Laplace transform of X(s) = (5s
+ 13) / ((s + 1)(s + 3)).

\textbf{Solution:}\\
Perform partial fraction expansion: X(s) = A/(s + 1) + B/(s + 3).\\
Multiplying both sides by (s + 1)(s + 3): 5s + 13 = A(s + 3) + B(s +
1).\\
Setting s = -1: 5(-1) + 13 = A(2), so 8 = 2A, A = 4.\\
Setting s = -3: 5(-3) + 13 = B(-2), so -2 = -2B, B = 1.\\
Therefore X(s) = 4/(s + 1) + 1/(s + 3).\\
Using the inverse transform table: x(t) = 4e\textsuperscript{-t} +
e\textsuperscript{-3t} for t ≥ 0.

\end{examplebox}

\subsection{8.3.4 s-Domain Circuit
Analysis}\label{s-domain-circuit-analysis}

The Laplace transform provides a systematic method for analyzing
circuits with energy storage elements (capacitors and inductors) by
converting integro-differential equations into algebraic equations in s.
Each circuit element is replaced by its s-domain impedance: a resistor
has impedance R, an inductor has impedance sL (with an initial-condition
voltage source LI₀ in series), and a capacitor has impedance 1/(sC)
(with an initial-condition voltage source V₀/s in series). Once the
circuit is transformed, standard techniques --- voltage division,
current division, nodal analysis, mesh analysis, and Thévenin/Norton
equivalents --- are applied directly in the s-domain to find the output
Y(s). The transfer function H(s) = Y(s)/X(s) characterizes the circuit's
frequency response and transient behavior, and the time-domain output is
recovered by inverse Laplace transform (partial fraction expansion).
This approach unifies DC analysis (s = 0), AC steady-state analysis (s =
jω), and transient analysis into a single framework, making it the
standard method for analyzing filters, amplifiers, control loops, and
power supply feedback networks.

\begin{examplebox}

\textbf{Example 8.3.4:} A series RLC circuit has R = 100 Ω, L = 10 mH,
and C = 1 μF. The input is a step voltage V\textsubscript{in}(t) =
10u(t) V with zero initial conditions. Find the transfer function H(s) =
V\textsubscript{C}(s)/V\textsubscript{in}(s), the natural frequency,
damping ratio, and determine whether the response is underdamped,
critically damped, or overdamped.

\textbf{Solution:}\\
The s-domain circuit is a voltage divider: H(s) = (1/sC) / (R + sL +
1/sC) = 1 / (s²LC + sRC + 1).\\
Substituting values: H(s) = 1 / (s² × 10⁻² × 10⁻⁶ + s × 100 × 10⁻⁶ + 1)
= 1 / (10⁻⁸s² + 10⁻⁴s + 1).\\
Dividing by 10⁻⁸: H(s) = 10⁸ / (s² + 10⁴s + 10⁸).\\
Comparing with the standard form ω\textsubscript{n}² / (s² +
2ζω\textsubscript{n}s + ω\textsubscript{n}²): ω\textsubscript{n}² = 10⁸,
so ω\textsubscript{n} = 10⁴ rad/s (f\textsubscript{n} = 1,592 Hz).\\
2ζω\textsubscript{n} = 10⁴, so ζ = 10⁴ / (2 × 10⁴) = 0.5.\\
Since ζ = 0.5 \textless{} 1, the circuit is underdamped.\\
The damped natural frequency is ω\textsubscript{d} =
ω\textsubscript{n}√(1 - ζ²) = 10⁴ × √0.75 = 8,660 rad/s.\\
The step response will oscillate at f\textsubscript{d} = 1,378 Hz with
an exponential decay envelope e\textsuperscript{-5000t}.

\end{examplebox}

\section{8.4 Z-Transform}\label{z-transform}

The Z-transform plays the same role for discrete-time systems that the
Laplace transform plays for continuous-time systems, providing an
algebraic framework for analyzing difference equations, designing
digital filters, and studying stability. The z-plane maps directly to
the s-plane through the relationship z = e\textsuperscript{sT}, with the
unit circle in the z-plane corresponding to the jω-axis in the s-plane.
Stability, causality, and frequency response of discrete-time systems
are all characterized by the locations of poles and zeros relative to
the unit circle.

\subsection{8.4.1 Definition and
Properties}\label{definition-and-properties-1}

The Z-transform is the discrete-time counterpart of the Laplace
transform, converting a discrete-time sequence x{[}n{]} into a function
of the complex variable z: X(z) = Σ x{[}n{]}z⁻ⁿ. The relationship
between the Z-transform and the Laplace transform is z =
e\textsuperscript{sT}, where T is the sampling period. Key properties
include linearity, time shifting (z⁻ᵏX(z) for a delay of k samples),
convolution (multiplication of Z-transforms), and the initial and final
value theorems. The region of convergence (ROC) in the z-plane
determines which sequences correspond to a given Z-transform and whether
the associated system is stable and/or causal. A causal LTI system is
stable if and only if all poles of its transfer function H(z) lie inside
the unit circle \textbar z\textbar{} = 1.

\begin{examplebox}

\textbf{Example 8.4.1:} Find the Z-transform of the sequence x{[}n{]} =
(0.8)ⁿu{[}n{]}, where u{[}n{]} is the unit step, and determine the
region of convergence.

\textbf{Solution:}\\
Using the Z-transform pair for aⁿu{[}n{]}: X(z) = z / (z - a) = z / (z -
0.8), or equivalently X(z) = 1 / (1 - 0.8z⁻¹).\\
The ROC is \textbar z\textbar{} \textgreater{} \textbar a\textbar{} =
0.8, which is the region outside a circle of radius 0.8 in the
z-plane.\\
Since the ROC includes the unit circle (\textbar z\textbar{} = 1
\textgreater{} 0.8), the sequence has a valid DTFT and represents a
stable signal.

\end{examplebox}

\subsection{8.4.2 Discrete-Time Transfer
Functions}\label{discrete-time-transfer-functions}

The transfer function of a discrete-time LTI system is H(z) = Y(z)/X(z),
relating the Z-transforms of the output and input sequences. For systems
described by linear constant-coefficient difference equations, H(z) is a
rational function in z (or z⁻¹). The poles and zeros of H(z) in the
z-plane determine the system's frequency response (evaluated on the unit
circle z = e\textsuperscript{jωT}), stability, and transient behavior.
FIR (Finite Impulse Response) filters have transfer functions with all
poles at the origin (H(z) is a polynomial in z⁻¹), while IIR (Infinite
Impulse Response) filters have non-trivial poles that create feedback
and recursion in the time domain.

\begin{examplebox}

\textbf{Example 8.4.2:} A discrete-time system is described by the
difference equation y{[}n{]} = 0.5y{[}n-1{]} + x{[}n{]}. Find H(z), the
pole location, and determine if the system is stable.

\textbf{Solution:}\\
Taking the Z-transform: Y(z) = 0.5z⁻¹Y(z) + X(z).\\
Solving for the transfer function: H(z) = Y(z)/X(z) = 1 / (1 - 0.5z⁻¹) =
z / (z - 0.5).\\
The system has one pole at z = 0.5 and one zero at z = 0.\\
Since \textbar0.5\textbar{} \textless{} 1, the pole lies inside the unit
circle, so the system is stable.\\
This is an IIR system (first-order, single-pole lowpass filter).

\end{examplebox}

\subsection{8.4.3 Inverse Z-Transform}\label{inverse-z-transform}

The inverse Z-transform recovers the discrete-time sequence x{[}n{]}
from its Z-transform X(z), analogous to the inverse Laplace transform
for continuous-time signals. For rational X(z) = B(z)/A(z), the most
practical method is partial fraction expansion: factor the denominator
into its roots, decompose X(z)/z into partial fractions (dividing by z
first simplifies the expansion), find the residues, multiply each term
by z, and look up the corresponding sequence from a table of Z-transform
pairs. A pole at z = a contributes a term of the form aⁿu{[}n{]} for a
causal sequence. Complex conjugate poles produce damped sinusoidal
sequences, and repeated poles introduce terms of the form n ×
aⁿu{[}n{]}. Long division (power series expansion) provides an
alternative computational method: dividing the numerator polynomial by
the denominator in ascending powers of z⁻¹ directly yields the output
samples x{[}0{]}, x{[}1{]}, x{[}2{]}, \ldots, which is particularly
useful for verifying results or when only a few output samples are
needed. For systems described by difference equations, long division is
equivalent to iterating the difference equation forward from initial
conditions.

\begin{examplebox}

\textbf{Example 8.4.3:} Find the inverse Z-transform of X(z) = (3z² -
4z) / (z² - 3z + 2), and determine the first three samples x{[}0{]},
x{[}1{]}, x{[}2{]}.

\textbf{Solution:}\\
Factor the denominator: z² - 3z + 2 = (z - 1)(z - 2).\\
Partial fraction expansion of X(z)/z: X(z)/z = (3z - 4) / {[}(z - 1)(z -
2){]}.\\
Setting z = 1: A = (3 - 4) / (1 - 2) = -1 / -1 = 1.\\
Setting z = 2: B = (6 - 4) / (2 - 1) = 2 / 1 = 2.\\
So X(z)/z = 1/(z - 1) + 2/(z - 2), giving X(z) = z/(z - 1) + 2z/(z -
2).\\
Using the Z-transform pair z/(z - a) ↔ aⁿu{[}n{]}: x{[}n{]} = 1ⁿu{[}n{]}
+ 2 × 2ⁿu{[}n{]} = (1 + 2\textsuperscript{n+1})u{[}n{]}.\\
Verification: x{[}0{]} = 1 + 2 = 3, x{[}1{]} = 1 + 4 = 5, x{[}2{]} = 1 +
8 = 9.\\
Check via long division: dividing (3z² - 4z) by (z² - 3z + 2) gives 3 +
5z⁻¹ + 9z⁻² + \ldots, confirming x{[}0{]} = 3, x{[}1{]} = 5, x{[}2{]} =
9.

\end{examplebox}

\subsection{8.4.4 Bilinear Transform}\label{bilinear-transform}

The bilinear transform is the standard method for converting a
continuous-time (analog) transfer function H\textsubscript{a}(s) into an
equivalent discrete-time (digital) transfer function H(z), preserving
the frequency-domain characteristics while mapping the entire jω-axis of
the s-plane onto the unit circle of the z-plane. The substitution s =
(2/T)(z − 1)/(z + 1) --- where T is the sampling period --- maps the
left half of the s-plane (stable region) to the interior of the unit
circle, ensuring that a stable analog prototype yields a stable digital
filter. The inverse mapping z = (1 + sT/2)/(1 − sT/2) confirms this:
when Re\{s\} \textless{} 0, \textbar z\textbar{} \textless{} 1. The
bilinear transform introduces \textbf{frequency warping}: the
relationship between analog frequency Ω and digital frequency ω is
nonlinear, Ω = (2/T)tan(ω/2), compressing the infinite analog frequency
range into the finite digital range {[}0, π/T{]}. To compensate,
\textbf{pre-warping} adjusts the critical analog prototype frequencies
before the transformation so that the digital filter's passband edges,
cutoff frequencies, or center frequency land at the desired locations.
For a cutoff frequency ω\textsubscript{c} in the digital domain
(rad/sample), the pre-warped analog frequency is Ω\textsubscript{c} =
(2/T)tan(ω\textsubscript{c}/2). The bilinear transform is preferred over
impulse invariance (which can alias) because it avoids aliasing entirely
--- the price is the nonlinear frequency mapping, which distorts the
shape of wideband filters but is negligible for narrowband designs. All
standard IIR filter design procedures (Butterworth, Chebyshev, Elliptic)
in DSP software use the bilinear transform internally.

\begin{examplebox}

\textbf{Example 8.4.4:} Design a first-order digital lowpass filter with
a −3 dB cutoff at 2 kHz using the bilinear transform applied to a
first-order analog prototype H\textsubscript{a}(s) =
Ω\textsubscript{c}/(s + Ω\textsubscript{c}). The sampling rate is
f\textsubscript{s} = 10 kHz.

\textbf{Solution:}\\
Digital cutoff frequency: ω\textsubscript{c} = 2π × 2000/10000 = 0.4π
rad/sample.\\
Pre-warped analog frequency: Ω\textsubscript{c} =
(2/T)tan(ω\textsubscript{c}/2) = 2 × 10000 × tan(0.4π/2) = 20000 ×
tan(0.2π) = 20000 × 0.7265 = 14531 rad/s.\\
Analog prototype: H\textsubscript{a}(s) = 14531/(s + 14531).\\
Apply bilinear transform s = (2/T)(z − 1)/(z + 1) = 20000(z − 1)/(z +
1): H(z) = 14531 / (20000(z − 1)/(z + 1) + 14531) = 14531(z + 1) /
(20000(z − 1) + 14531(z + 1)) = 14531(z + 1) / (34531z − 5469).\\
Dividing numerator and denominator by 34531: H(z) = 0.4208(z + 1) / (z −
0.1584) = 0.4208(1 + z⁻¹) / (1 − 0.1584z⁻¹).\\
Difference equation: y{[}n{]} = 0.1584y{[}n−1{]} + 0.4208x{[}n{]} +
0.4208x{[}n−1{]}.\\
Verification at ω = 0 (DC): H(1) = 0.4208 × 2 / (1 − 0.1584) =
0.8416/0.8416 = 1.0 (0 dB, passes DC).\\
At ω = ω\textsubscript{c} = 0.4π:
\textbar H(e\textsuperscript{j0.4π})\textbar{} = 1/√2 = 0.707 (−3 dB),
confirming the cutoff is correctly placed at 2 kHz.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-4-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_bilinear.png}

\caption{Figure 8.4.4: Bilinear Transform: Analog vs Digital Filter}

\end{figure}

\subsection{8.4.5 Stability Analysis in the
z-Plane}\label{stability-analysis-in-the-z-plane}

A causal discrete-time LTI system is stable (bounded-input
bounded-output, or BIBO stable) if and only if all poles of its transfer
function H(z) lie strictly inside the unit circle \textbar z\textbar{}
\textless{} 1. While direct inspection of pole locations works for
low-order systems, higher-order systems require algebraic stability
tests analogous to the Routh-Hurwitz criterion in the s-domain. The
\textbf{Jury stability criterion} tests a polynomial D(z) = a₀zⁿ +
a₁zⁿ⁻¹ + \ldots{} + aₙ by constructing a triangular array from the
coefficients and checking conditions on the array elements. For a
polynomial of degree n, the necessary conditions are: D(1)
\textgreater{} 0, (−1)ⁿD(−1) \textgreater{} 0, and \textbar a₀\textbar{}
\textgreater{} \textbar aₙ\textbar. The Jury array then provides n − 2
additional conditions from the first elements of each row.

For \textbf{second-order systems} H(z) = b₀ / (1 + a₁z⁻¹ + a₂z⁻²), the
stability conditions reduce to a simple set of three inequalities known
as the \textbf{stability triangle}: 1. 1 + a₁ + a₂ \textgreater{} 0
(ensures no pole at z = +1) 2. 1 − a₁ + a₂ \textgreater{} 0 (ensures no
pole at z = −1) 3. \textbar a₂\textbar{} \textless{} 1 (ensures poles
are inside the unit circle)

These three conditions define a triangular region in the (a₁, a₂)
coefficient plane within which all second-order systems are stable. This
is particularly useful for fixed-point IIR filter design, where
coefficient quantization can push a₁ and a₂ outside the stability
triangle.

The \textbf{Schur-Cohn stability test} provides an alternative using the
reflection coefficients (PARCOR coefficients) of the polynomial: the
system is stable if and only if all reflection coefficients have
magnitude less than 1. This test is closely related to the lattice
filter structure and is computationally efficient for verifying
stability after coefficient quantization.

\begin{examplebox}

\textbf{Example 8.4.5:} A second-order IIR filter has transfer function
H(z) = 1 / (1 − 1.5z⁻¹ + 0.72z⁻²). Determine (a) whether the filter is
stable using the stability triangle conditions, (b) the pole locations,
and (c) the maximum value of a₂ that maintains stability if a₁ is fixed
at −1.5.

\textbf{Solution:}

(a) Stability triangle check (a₁ = −1.5, a₂ = 0.72):\\
Condition 1: 1 + (−1.5) + 0.72 = 0.22 \textgreater{} 0 ✓\\
Condition 2: 1 − (−1.5) + 0.72 = 3.22 \textgreater{} 0 ✓\\
Condition 3: \textbar0.72\textbar{} = 0.72 \textless{} 1 ✓\\
All three conditions are satisfied → \textbf{Stable}

(b) Pole locations from z² − 1.5z + 0.72 = 0:\\
z = (1.5 ± √(2.25 − 2.88)) / 2 = (1.5 ± √(−0.63)) / 2 = (1.5 ± j0.7937)
/ 2\\
z = 0.75 ± j0.3969\\
\textbar z\textbar{} = √(0.75² + 0.3969²) = √(0.5625 + 0.1575) = √0.72 =
\textbf{0.8485}\\
Both poles lie inside the unit circle at radius 0.8485, confirming
stability. The pole angle is θ = arctan(0.3969/0.75) = 27.9°,
corresponding to a resonant frequency of f\textsubscript{r} = θ/(2π) ×
f\textsubscript{s}.

(c) From condition 1: a₂ \textgreater{} −1 − a₁ = −1 + 1.5 = 0.5. From
condition 3: a₂ \textless{} 1. Combined with condition 2 (always
satisfied for a₁ = −1.5, a₂ \textgreater{} 0): the maximum a₂ for
stability is a₂ \textless{} \textbf{1.0}. In Q15 fixed-point with the
pole radius at √a₂ = √0.72 = 0.8485, quantizing a₂ = 0.72 to Q15 gives
0.72 × 32768 = 23593 → 23593/32768 = 0.71997, which remains safely
within the stability triangle.

\end{examplebox}

\section{8.5 Digital Filters}\label{digital-filters}

Digital filters are discrete-time systems designed to selectively modify
the spectral content of a signal --- passing desired frequency
components while attenuating unwanted ones. Unlike analog filters built
from resistors, capacitors, and inductors, digital filters are
implemented as algorithms in software or dedicated hardware (DSP chips,
FPGAs), offering perfect reproducibility, easy reconfigurability, and
the ability to realize filter characteristics that are impractical in
the analog domain. The two fundamental architectures are FIR
(non-recursive, guaranteed stable, linear phase possible) and IIR
(recursive, computationally efficient, sharper transitions).

\subsection{8.5.1 FIR Filters}\label{fir-filters}

Finite Impulse Response filters compute their output as a weighted sum
of a finite number of input samples: y{[}n{]} = Σ b\textsubscript{k} ·
x{[}n - k{]} for k = 0 to M, where the b\textsubscript{k} coefficients
define the filter's impulse response of length M + 1. FIR filters are
inherently stable (no feedback, no poles outside the origin) and can be
designed to have exactly linear phase (constant group delay), which
preserves the waveform shape of the signal --- a critical property in
applications such as audio processing and data communications. Design
methods include the window method (applying a window function to the
ideal impulse response), frequency sampling, and the Parks-McClellan
(Remez exchange) algorithm for optimal equiripple designs. The primary
trade-off is that FIR filters typically require a higher order (more
coefficients) than IIR filters to achieve the same transition band
sharpness, resulting in greater computational cost and latency.

\begin{examplebox}

\textbf{Example 8.5.1:} A 4-tap FIR filter has coefficients b = \{0.25,
0.25, 0.25, 0.25\}. If the input sequence is x{[}n{]} = \{1, 2, 3, 4, 5,
0, 0, \ldots\}, compute the first four output samples.

\textbf{Solution:}\\
y{[}n{]} = 0.25x{[}n{]} + 0.25x{[}n-1{]} + 0.25x{[}n-2{]} +
0.25x{[}n-3{]} (a simple moving average).\\
y{[}0{]} = 0.25(1) + 0.25(0) + 0.25(0) + 0.25(0) = 0.25.\\
y{[}1{]} = 0.25(2) + 0.25(1) + 0.25(0) + 0.25(0) = 0.75.\\
y{[}2{]} = 0.25(3) + 0.25(2) + 0.25(1) + 0.25(0) = 1.5.\\
y{[}3{]} = 0.25(4) + 0.25(3) + 0.25(2) + 0.25(1) = 2.5.\\
This filter computes the 4-point running average, smoothing the input
signal.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-5-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_fir_filter.png}

\caption{Figure 8.5.1: FIR Lowpass Filter Response}

\end{figure}

\subsection{8.5.2 IIR Filters}\label{iir-filters}

Infinite Impulse Response filters use both feedforward and feedback
(recursive) terms: y{[}n{]} = Σ b\textsubscript{k} · x{[}n - k{]} - Σ
a\textsubscript{k} · y{[}n - k{]}, where the a\textsubscript{k}
coefficients create the recursive (pole) structure. Because of their
poles, IIR filters can achieve sharp frequency transitions with far
fewer coefficients than FIR filters, making them computationally
efficient for applications with strict selectivity requirements. IIR
filters are commonly designed by transforming classical analog filter
prototypes (Butterworth, Chebyshev Type I and II, Elliptic) to the
digital domain using the bilinear transform, which maps the s-plane to
the z-plane while preserving stability. However, IIR filters cannot
achieve exactly linear phase, and care must be taken to ensure stability
by verifying that all poles remain inside the unit circle. Quantization
of coefficients in fixed-point implementations can shift pole locations
and potentially cause instability or limit-cycle oscillations.

\begin{examplebox}

\textbf{Example 8.5.2:} A first-order IIR lowpass filter is defined by
y{[}n{]} = 0.1x{[}n{]} + 0.9y{[}n-1{]}. Find H(z), the pole location,
and the magnitude response at DC (ω = 0) and at the Nyquist frequency (ω
= π).

\textbf{Solution:}\\
H(z) = 0.1 / (1 - 0.9z⁻¹) = 0.1z / (z - 0.9).\\
The pole is at z = 0.9 (inside the unit circle, so stable).\\
At DC (z = e\textsuperscript{j0} = 1): \textbar H(1)\textbar{} = 0.1 /
\textbar1 - 0.9\textbar{} = 0.1 / 0.1 = 1.0 (0 dB, passes DC).\\
At Nyquist (z = e\textsuperscript{jπ} = -1): \textbar H(-1)\textbar{} =
0.1 / \textbar1 + 0.9\textbar{} = 0.1 / 1.9 = 0.0526 (-25.6 dB).\\
This confirms the lowpass behavior with strong attenuation near the
Nyquist frequency.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-5-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_iir_filter.png}

\caption{Figure 8.5.2: IIR Lowpass Filter Response}

\end{figure}

\subsection{8.5.3 Filter Design
Specifications}\label{filter-design-specifications}

Filter design begins with a set of frequency-domain specifications that
define the desired behavior across the frequency range. The passband is
the frequency range where signals should pass with minimal attenuation
(passband ripple typically specified in dB), and the stopband is the
range where signals should be attenuated by at least a minimum amount
(stopband attenuation in dB). The transition band is the frequency
region between the passband edge and the stopband edge, and a narrower
transition band requires a higher-order filter. Common filter types
include lowpass (passes frequencies below a cutoff), highpass (passes
above a cutoff), bandpass (passes a range of frequencies), and
bandstop/notch (rejects a range). The choice between FIR and IIR, the
filter order, and the approximation method are determined by the
specific requirements for magnitude response, phase linearity,
computational budget, and implementation constraints.

\begin{examplebox}

\textbf{Example 8.5.3:} A digital lowpass filter is needed with passband
edge at 2 kHz, stopband edge at 3 kHz, maximum passband ripple of 1 dB,
minimum stopband attenuation of 40 dB, and a sampling rate of 16 kHz.
Estimate the required order for a Butterworth IIR filter.

\textbf{Solution:}\\
Normalized frequencies: Ω\textsubscript{p} = 2π × 2000/16000 = 0.25π
rad/sample, Ω\textsubscript{s} = 2π × 3000/16000 = 0.375π rad/sample.\\
Using the bilinear transform pre-warping: ω\textsubscript{p} =
tan(Ω\textsubscript{p}/2) = tan(0.125π) = 0.4142, ω\textsubscript{s} =
tan(Ω\textsubscript{s}/2) = tan(0.1875π) = 0.6682.\\
Selectivity ratio: k = ω\textsubscript{p}/ω\textsubscript{s} =
0.4142/0.6682 = 0.6198.\\
The Butterworth order formula: n ≥ log{[}(10\textsuperscript{As/10} -
1)/(10\textsuperscript{Ap/10} - 1){]} / (2 × log(1/k)) = log{[}(10⁴ -
1)/(10⁰·¹ - 1){]} / (2 × log(1.614)) = log{[}9999/0.2589{]} / (2 ×
0.2080) = log(38,622) / 0.4160 = 4.587 / 0.4160 = 11.03.\\
Therefore n = 12 (round up to the next integer).\\
A 12th-order Butterworth filter satisfies the specifications.

\end{examplebox}

\subsection{8.5.4 Multirate Signal
Processing}\label{multirate-signal-processing}

Multirate signal processing involves changing the sampling rate of a
discrete-time signal, either by reducing it (decimation) or increasing
it (interpolation). Decimation by a factor M reduces the sampling rate
by keeping every M-th sample and discarding the rest; an anti-aliasing
lowpass filter with cutoff π/M must precede the downsampler to prevent
aliasing of high-frequency components into the reduced-rate signal.
Interpolation by a factor L increases the sampling rate by inserting L -
1 zeros between each original sample (upsampling) followed by a lowpass
anti-imaging filter with cutoff π/L and gain L to reconstruct the
intermediate values. Rational sample rate conversion by L/M is achieved
by first interpolating by L, then decimating by M. Multirate techniques
are essential in digital audio (CD to DAC conversion at 44.1 kHz to 192
kHz), software-defined radio (channelization of wideband signals), and
efficient filter implementations using polyphase decomposition, which
reduces computational cost by operating filters at the lower sampling
rate.

\begin{examplebox}

\textbf{Example 8.5.4:} A signal sampled at 48 kHz must be converted to
16 kHz for a telephony codec. Determine the decimation factor, the
required anti-aliasing filter cutoff frequency, and the number of output
samples for a 1-second input.

\textbf{Solution:}\\
Decimation factor: M = 48,000 / 16,000 = 3.\\
Before decimating, apply a lowpass filter with cutoff f\textsubscript{c}
= f\textsubscript{s,new} / 2 = 16,000 / 2 = 8000 Hz (or equivalently,
the normalized frequency cutoff is π/M = π/3 rad/sample).\\
This prevents frequencies above 8 kHz from aliasing into the 0--8 kHz
band of the decimated signal.\\
Input samples for 1 second: 48,000.\\
Output samples: 48,000 / 3 = 16,000 samples.\\
The anti-aliasing filter must have sufficient stopband attenuation
(typically ≥ 60 dB) to suppress aliased components below the noise
floor.

\end{examplebox}

\subsection{8.5.5 Fixed-Point Filter
Implementation}\label{fixed-point-filter-implementation}

Many embedded DSP systems and FPGAs implement digital filters using
fixed-point arithmetic rather than floating-point, offering lower cost,
lower power consumption, and higher throughput at the expense of limited
dynamic range and susceptibility to quantization effects. In fixed-point
representation, numbers are stored as scaled integers with an implied
binary point; a Q15 format, for example, uses 16 bits to represent
values from -1.0 to +0.99997 with a resolution of 2⁻¹⁵ ≈ 30.5 × 10⁻⁶.
\textbf{Coefficient quantization} rounds the ideal filter coefficients
to the nearest representable fixed-point value, which shifts the actual
pole and zero locations from their designed positions --- for IIR
filters, this can significantly distort the frequency response or even
cause instability if a pole moves outside the unit circle.
\textbf{Roundoff noise} accumulates at each multiply-accumulate
operation and appears as additive white noise at the filter output, with
variance proportional to 2⁻²ᴮ where B is the word length.
\textbf{Overflow} occurs when intermediate accumulations exceed the
fixed-point range, producing severe distortion; saturation arithmetic
(clamping to the maximum value) is preferred over wraparound to limit
the damage. Cascade (second-order sections) and parallel filter
structures are more robust to quantization than high-order direct-form
implementations because each second-order section has its own
well-separated poles, reducing sensitivity to coefficient rounding.
Scaling strategies (L₁, L₂, or L\textsubscript{∞} norms) set the gain at
each stage to prevent overflow while maximizing the
signal-to-roundoff-noise ratio.

\begin{examplebox}

\textbf{Example 8.5.5:} A 6th-order IIR bandpass filter is implemented
in Q15 fixed-point (16-bit) on a DSP. The filter is realized as a
cascade of three second-order sections (biquads). Each biquad has a
32-bit accumulator. Estimate the output roundoff noise power if each
biquad contributes an independent roundoff noise variance of σ² =
2⁻²ᴮ/12, where B = 15 bits, and compare to a single direct-form VI
implementation.

\textbf{Solution:}\\
Roundoff noise variance per biquad (one quantization per section
output): σ\textsubscript{q}² = 2⁻³⁰ / 12 = 9.31 × 10⁻¹⁰ / 12 = 7.76 ×
10⁻¹¹.\\
For 3 cascaded biquads (assuming unity gain and independent noise),
total output noise variance: σ\textsubscript{total}² = 3 ×
σ\textsubscript{q}² = 3 × 7.76 × 10⁻¹¹ = 2.33 × 10⁻¹⁰.\\
RMS noise: σ\textsubscript{total} = √(2.33 × 10⁻¹⁰) = 1.53 × 10⁻⁵, or
about -96.3 dB relative to full scale.\\
For a direct-form implementation of order 6, there are 6 feedback
multiplications each contributing roundoff noise, amplified by the
filter's pole locations.\\
With tightly clustered poles (common in narrowband bandpass filters),
the noise gain can be 10-100× higher, yielding output noise 20-40 dB
worse than the cascade form.\\
This is why cascade biquad structures are the standard practice for
fixed-point IIR filter implementation.

\end{examplebox}

\subsection{8.5.6 Polyphase Filter
Structures}\label{polyphase-filter-structures}

Polyphase decomposition is an efficient implementation technique for
multirate filters that reduces computational cost by operating the
filter at the lower sampling rate rather than the higher one. In a
decimation-by-M system, the standard approach filters at the high input
rate and then discards (M − 1) of every M output samples --- wasting
computation on samples that are immediately thrown away. The polyphase
decomposition splits the filter's N coefficients into M subfilters
(phases), each containing N/M coefficients, and processes the input
directly at the decimated rate. Each phase operates on a different
time-offset subset of the input samples, and the M subfilter outputs are
summed to produce the final result. This reduces the number of
multiply-accumulate operations per output sample from N to N/M --- the
same factor as the decimation ratio. For interpolation-by-L, the
polyphase structure distributes the filter coefficients across L phases
that each produce one of the L output samples per input sample, again
computing only the needed outputs at the output rate rather than first
upsampling (inserting zeros) and filtering at the high rate.
\textbf{Polyphase filter banks} generalize this concept to uniformly
split a wideband signal into M subbands simultaneously, forming the
basis of channelizers in software-defined radio (SDR), audio coding (MP3
uses a 32-band polyphase filter bank), and OFDM modulation/demodulation.
The DFT filter bank combines polyphase decomposition with an M-point FFT
to efficiently implement M bandpass filters in parallel, enabling
real-time channelization of wide RF bandwidths.

\begin{examplebox}

\textbf{Example 8.5.6:} A 240-tap FIR lowpass filter is used as an
anti-aliasing filter before decimation by M = 6 from 48 kS/s to 8 kS/s.
Calculate the computational cost (multiplications per output sample) for
the direct approach versus the polyphase implementation.

\textbf{Solution:}\\
Direct approach: the filter runs at the input rate of 48 kS/s, requiring
240 multiplications per input sample.\\
The output rate is 48,000/6 = 8,000 samples/s.\\
Multiplications per second: 240 × 48,000 = 11,520,000.\\
Per output sample: 11,520,000 / 8,000 = 1,440 multiplications
(equivalently, 240 multiplications are computed for each of the 6 input
samples, but 5 out of 6 outputs are discarded).\\
Polyphase approach: the 240 coefficients are distributed into M = 6
subfilters of 240/6 = 40 coefficients each.\\
Each subfilter runs at the output rate of 8 kS/s.\\
Multiplications per output sample: 6 × 40 = 240.\\
Multiplications per second: 240 × 8,000 = 1,920,000.\\
Savings: 11,520,000 / 1,920,000 = 6× reduction --- exactly equal to the
decimation factor M.\\
The polyphase structure computes only the samples that will actually be
used, eliminating all wasted computation.

\end{examplebox}

\subsection{8.5.7 Allpass Filters and Group Delay
Equalization}\label{allpass-filters-and-group-delay-equalization}

An allpass filter is a system with unity magnitude response at all
frequencies --- \textbar H(e\textsuperscript{jω})\textbar{} = 1 for all
ω --- but a frequency-dependent phase response. For a first-order
digital allpass filter, the transfer function is H(z) = (a* + z⁻¹) / (1
+ az⁻¹), where a is a real coefficient with \textbar a\textbar{}
\textless{} 1. For a second-order allpass section: H(z) = (a₂ + a₁z⁻¹ +
z⁻²) / (1 + a₁z⁻¹ + a₂z⁻²) --- the numerator coefficients are the
denominator coefficients in reversed order, which places the zeros at
the reciprocal conjugate locations of the poles (z\textsubscript{zero} =
1/z\textsubscript{pole}*), ensuring the unit-circle magnitude is exactly
1. Although allpass filters do not modify the spectrum's magnitude, they
reshape its phase, making them essential for \textbf{group delay
equalization} --- the process of flattening the total group delay of a
system to make it approximately constant across the passband.

IIR filters (Butterworth, Chebyshev, Elliptic) inherently have nonlinear
phase and non-constant group delay, especially near the passband edge
where the group delay peaks sharply. This phase distortion spreads pulse
edges in time and distorts waveform shapes --- unacceptable in
applications like data communications (causing intersymbol
interference), audio (pre-echo and smearing), and measurement systems.
By cascading an allpass equalizer with the IIR filter, the combined
group delay can be made nearly constant without affecting the magnitude
response. The equalizer design involves: (1) computing the group delay
of the original IIR filter, (2) determining the desired flat group delay
(equal to the maximum group delay of the IIR filter), (3) designing
allpass sections whose group delay fills in the ``valleys'' to make the
total group delay flat, and (4) cascading the allpass sections with the
original filter.

Allpass filters also enable \textbf{complementary filter pairs}: if H(z)
is a lowpass filter, then G(z) = z⁻ᴺ − H(z) is the complementary
highpass (power complementary if \textbar H\textbar² +
\textbar G\textbar² = 1). Allpass-based complementary pairs use two
allpass filters A₀(z) and A₁(z) to create H\textsubscript{LP}(z) =
(A₀(z²) + z⁻¹A₁(z²))/2 and H\textsubscript{HP}(z) = (A₀(z²) −
z⁻¹A₁(z²))/2, guaranteeing perfect reconstruction (the sum exactly
equals a pure delay). This structure is used in QMF (Quadrature Mirror
Filter) banks for audio coding and subband processing.

\begin{examplebox}

\textbf{Example 8.5.7:} A 4th-order Chebyshev Type I lowpass IIR filter
with 0.5 dB passband ripple has a group delay that varies from 8.2
samples at DC to 22.7 samples at the passband edge (ω = 0.4π). A cascade
of two second-order allpass sections is designed to equalize the group
delay to approximately 23 samples (flat). The allpass sections have
coefficients a₁₁ = −1.38, a₂₁ = 0.69 (section 1) and a₁₂ = −0.85, a₂₂ =
0.42 (section 2). Calculate (a) the group delay variation before
equalization, (b) the total system order after adding the equalizer, and
(c) the latency penalty introduced by equalization.

\textbf{Solution:}

(a) Group delay variation before equalization:\\
Δτ = τ\textsubscript{max} − τ\textsubscript{min} = 22.7 − 8.2 =
\textbf{14.5 samples}\\
At f\textsubscript{s} = 48 kHz, this corresponds to 14.5 / 48,000 =
0.302 ms of time-domain spreading.

(b) Total system order:\\
Original IIR filter: 4th order (2 biquad sections)\\
Allpass equalizer: 2 × 2nd order = 4th order (2 more biquad sections)\\
Total: \textbf{8th order} (4 biquad sections in cascade)\\
The equalizer doubles the computational cost but does not change the
magnitude response.

(c) Latency penalty:\\
Before equalization: group delay at DC = 8.2 samples\\
After equalization: group delay ≈ 23 samples (flat across passband)\\
Added latency = 23 − 8.2 = \textbf{14.8 samples} = 14.8 / 48,000 = 0.308
ms\\
This is the fundamental trade-off: achieving flat group delay requires
increasing the minimum delay to match the maximum, adding latency equal
to the original group delay variation. For audio at 48 kHz, 0.3 ms is
imperceptible; for real-time control systems, this added latency may
need consideration.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-5-7}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_allpass.png}

\caption{Figure 8.5.7: Allpass Filter: Magnitude and Group Delay}

\end{figure}

\section{8.6 Spectral Analysis}\label{spectral-analysis}

Spectral analysis encompasses the techniques used to estimate and
interpret the frequency content of signals, bridging the gap between
theoretical transform methods and practical measurement of real-world
data. Because real signals are finite in duration, noisy, and often
non-stationary, spectral estimation requires careful consideration of
resolution, variance, and leakage trade-offs. Methods range from
classical periodogram-based approaches to modern parametric and
time-frequency techniques.

\subsection{8.6.1 Power Spectral Density}\label{power-spectral-density}

The Power Spectral Density (PSD) describes how the power of a signal is
distributed across frequency and is defined as the Fourier transform of
the autocorrelation function (Wiener-Khinchin theorem). For
deterministic power signals, the PSD is computed as the limit of the
squared magnitude of the Fourier transform divided by the observation
interval. For random signals, the PSD must be estimated from finite data
records using methods such as the periodogram (squared magnitude of the
FFT divided by N) or the averaged periodogram (Welch's method), which
divides the data into overlapping segments, windows each segment,
computes the periodogram of each, and averages the results to reduce
variance. The PSD has units of power per unit frequency (e.g., V²/Hz or
W/Hz) and integrating the PSD over a frequency band yields the signal
power in that band.

\begin{examplebox}

\textbf{Example 8.6.1:} A white noise signal has a flat PSD of S(f) = 2
× 10⁻⁶ V²/Hz over a bandwidth of 0 to 10 kHz. Find the total noise power
and the RMS noise voltage.

\textbf{Solution:}\\
Since the PSD is flat, the total power is P = S(f) × BW = 2 × 10⁻⁶ ×
10,000 = 0.02 V².\\
The RMS noise voltage is V\textsubscript{rms} = √P = √0.02 = 0.1414 V =
141.4 mV.\\
If the bandwidth were reduced to 1 kHz using a lowpass filter, the noise
power would drop to 2 × 10⁻⁶ × 1000 = 0.002 V² (V\textsubscript{rms} =
44.7 mV), demonstrating why bandwidth limiting is an effective
noise-reduction technique.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-6-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_psd.png}

\caption{Figure 8.6.1: White Noise Power Spectral Density}

\end{figure}

\subsection{8.6.2 Windowing}\label{windowing}

Windowing is the process of multiplying a finite-length signal segment
by a window function before computing the DFT, in order to control
spectral leakage caused by the abrupt truncation of the signal at the
segment boundaries. The rectangular window (no modification) provides
the narrowest main lobe and best frequency resolution but has the
highest sidelobe levels (-13 dB), allowing energy from strong spectral
components to leak into adjacent frequency bins. Tapered windows reduce
sidelobe levels at the cost of a wider main lobe: the Hanning window
achieves -31 dB sidelobes, the Hamming window -43 dB, and the Blackman
window -58 dB. The choice of window involves a trade-off between
frequency resolution (main lobe width) and spectral leakage (sidelobe
level), determined by the application requirements. The Kaiser window
provides a continuously adjustable parameter β that allows the designer
to smoothly trade off between these competing objectives.

\begin{examplebox}

\textbf{Example 8.6.2:} A 1024-point FFT is used to analyze a signal
sampled at 44.1 kHz. Compare the frequency resolution using a
rectangular window versus a Hanning window.

\textbf{Solution:}\\
With a rectangular window, the frequency resolution is approximately Δf
= f\textsubscript{s} / N = 44,100 / 1024 = 43.07 Hz.\\
The main lobe width is 2 × Δf = 86.13 Hz, and the highest sidelobe is at
-13 dB.\\
With a Hanning window, the main lobe widens to approximately 4 × Δf =
172.3 Hz (twice the rectangular window), but the highest sidelobe drops
to -31 dB, an 18 dB improvement in sidelobe suppression.\\
For resolving two tones spaced 100 Hz apart, the rectangular window
succeeds but may show leakage artifacts. With a Hanning window, the
Rayleigh resolution criterion is approximately 2 × Δf = 86.1 Hz, so the
100 Hz separation is marginally above the resolution limit --- the two
tones may be resolvable depending on their relative amplitudes and SNR,
though with more spectral smearing than the rectangular window.

\end{examplebox}

\subsection{8.6.3 Time-Frequency
Analysis}\label{time-frequency-analysis}

Traditional Fourier analysis provides excellent frequency resolution but
no time localization --- it reveals which frequencies are present in a
signal but not when they occur. The Short-Time Fourier Transform (STFT)
addresses this by computing the Fourier transform of successive windowed
segments of the signal, producing a spectrogram that displays signal
energy as a function of both time and frequency. The STFT is subject to
the uncertainty principle: a shorter window provides better time
resolution but poorer frequency resolution, and vice versa. The Wavelet
Transform overcomes this fixed resolution limitation by using analysis
functions (wavelets) that are scaled and translated, providing fine time
resolution at high frequencies and fine frequency resolution at low
frequencies. Wavelets are particularly effective for analyzing transient
events, non-stationary signals, and multi-scale phenomena in
applications such as speech processing, biomedical signal analysis,
image compression (JPEG 2000), and seismic data interpretation.

\begin{examplebox}

\textbf{Example 8.6.3:} An STFT is performed on a signal sampled at 16
kHz using a 512-sample Hanning window with 50\% overlap (256-sample
hop). Determine the time resolution, frequency resolution, and the total
number of STFT frames for a 2-second recording.

\textbf{Solution:}\\
Window duration: T\textsubscript{w} = 512 / 16,000 = 32 ms.\\
Frequency resolution: Δf = f\textsubscript{s} / N = 16,000 / 512 = 31.25
Hz.\\
Time resolution (hop size): Δt = 256 / 16,000 = 16 ms.\\
Total samples in 2 seconds: 2 × 16,000 = 32,000.\\
Number of frames: (32,000 - 512) / 256 + 1 = 31,488 / 256 + 1 = 123 + 1
= 124 frames.\\
The resulting spectrogram has 124 time frames and 257 frequency bins
(N/2 + 1), covering 0 to 8 kHz.

\end{examplebox}

\subsection{8.6.4 Parametric Spectral
Estimation}\label{parametric-spectral-estimation}

Parametric methods estimate the PSD by fitting a mathematical model to
the observed data, rather than directly computing the Fourier transform.
The most common approach is the autoregressive (AR) model, which assumes
the signal is the output of an all-pole filter driven by white noise:
x{[}n{]} = -Σ a\textsubscript{k}x{[}n-k{]} + w{[}n{]}, where the
a\textsubscript{k} are the AR coefficients and w{[}n{]} is white noise
with variance σ². The AR PSD is then S(f) = σ²T / \textbar1 + Σ
a\textsubscript{k}e\textsuperscript{-j2πfkT}\textbar², which produces
smooth spectral estimates with sharp peaks corresponding to the model's
poles --- ideal for resolving closely spaced sinusoidal components or
narrow spectral peaks. The AR model order p determines the number of
poles and must be chosen carefully: too low and genuine spectral
features are smoothed away, too high and spurious peaks appear from
fitting noise. Common AR parameter estimation methods include the
Yule-Walker (autocorrelation) method, the Burg method (which guarantees
a stable model and is well-suited for short data records), and the
covariance method. More advanced subspace methods --- MUSIC (Multiple
Signal Classification) and ESPRIT (Estimation of Signal Parameters via
Rotational Invariance Techniques) --- decompose the data correlation
matrix into signal and noise subspaces and can resolve closely spaced
sinusoids well beyond the Fourier resolution limit, but require
knowledge of the number of signal components and assume the signal
consists of sinusoids in white noise.

\begin{examplebox}

\textbf{Example 8.6.4:} Two sinusoids at frequencies f₁ = 1000 Hz and f₂
= 1050 Hz (50 Hz apart) are sampled at f\textsubscript{s} = 10 kHz. Only
N = 64 samples are available. Determine whether classical FFT-based
spectral analysis can resolve the two components, and explain why a
parametric method may succeed.

\textbf{Solution:}\\
FFT frequency resolution: Δf = f\textsubscript{s} / N = 10,000 / 64 =
156.25 Hz.\\
Since the two sinusoids are separated by only 50 Hz, which is less than
one frequency bin (156.25 Hz), the FFT cannot resolve them --- they will
appear as a single broadened peak.\\
Even with a rectangular window (narrowest main lobe), the Rayleigh
resolution limit is Δf = 156.25 Hz, far exceeding the 50 Hz
separation.\\
Zero-padding to 256 or 1024 points would interpolate the spectrum more
finely but cannot improve the fundamental resolution beyond 156.25 Hz.\\
An AR model of order p = 4 (two poles per sinusoid) applied via the Burg
method estimates the AR coefficients from the 64 samples and places two
sharp spectral peaks at the sinusoidal frequencies.\\
The AR spectral estimate achieves super-resolution because it imposes a
model structure (all-pole) that matches the signal, effectively
extrapolating the autocorrelation beyond the measured data length.\\
The MUSIC algorithm with a correlation matrix of size 16 × 16 would
similarly resolve the two components, provided the SNR is sufficient
(typically \textgreater{} 10 dB).

\end{examplebox}

\subsection{8.6.5 Cepstral Analysis}\label{cepstral-analysis}

The cepstrum is the inverse Fourier transform of the logarithm of the
magnitude spectrum, providing a representation in the \textbf{quefrency}
domain (with units of time) that separates spectral features occurring
at different rates. The power cepstrum is defined as c{[}n{]} =
IDFT\{log\textbar DFT\{x{[}n{]}\}\textbar²\}, and the complex cepstrum
uses the full complex logarithm (preserving phase) to allow signal
reconstruction. Because the logarithm converts the multiplicative
combination of spectral envelope and fine structure into an additive
sum, the cepstrum cleanly separates slowly varying formant structure
(low-quefrency cepstral coefficients) from rapidly varying harmonic or
echo structure (high-quefrency peaks called \textbf{rahmonics}). In
speech processing, the spectral envelope encodes phoneme identity while
the harmonic fine structure encodes pitch; cepstral analysis extracts
both independently. \textbf{Mel-Frequency Cepstral Coefficients (MFCCs)}
--- computed by applying the DCT to log-energies from a mel-scaled
filter bank --- are the dominant feature representation in speech
recognition, speaker identification, and audio classification. The mel
scale warps the linear frequency axis to approximate the nonlinear
frequency perception of the human ear, with closer spacing at low
frequencies and wider spacing at high frequencies: f\textsubscript{mel}
= 2595 × log₁₀(1 + f/700). Typically 12--13 MFCCs (plus delta and
delta-delta coefficients) capture the essential spectral shape of each
speech frame. Cepstral analysis also detects echoes and periodic
structure: an echo delayed by τ seconds appears as a peak in the
cepstrum at quefrency τ, enabling blind echo detection and pitch
estimation for musical signals.

\begin{examplebox}

\textbf{Example 8.6.5:} A speech frame sampled at f\textsubscript{s} =
16 kHz uses a 25 ms Hamming window (N = 400 samples, zero-padded to 512
for FFT). Compute the MFCCs using a 26-channel mel filter bank. If the
speaker's fundamental frequency is f₀ = 125 Hz, at what quefrency index
does the pitch peak appear in the cepstrum?

\textbf{Solution:}\\
The mel filter bank spans 0 to f\textsubscript{s}/2 = 8000 Hz.\\
The mel frequency at 8000 Hz is f\textsubscript{mel} = 2595 × log₁₀(1 +
8000/700) = 2595 × log₁₀(12.43) = 2595 × 1.094 = 2840 mel.\\
The 26 triangular filters are uniformly spaced from 0 to 2840 mel, with
center frequencies mapped back to Hz.\\
For each filter, the log-energy is computed from the FFT magnitude
spectrum, and the DCT of the 26 log-energies yields the MFCCs:
c\textsubscript{k} = Σ (log E\textsubscript{m}) × cos{[}πk(m −
0.5)/26{]} for k = 0 to 12, producing 13 coefficients.\\
The pitch period is T₀ = 1/f₀ = 1/125 = 8 ms = 128 samples at 16 kHz.\\
In the 512-point cepstrum, the pitch appears as a peak at quefrency
index n = 128, corresponding to 8 ms.\\
This peak is distinct from the vocal tract (formant) information
concentrated in the first 3--5 ms of the cepstrum (indices 0--80),
demonstrating the cepstrum's ability to separate source (pitch) from
filter (formants).

\end{examplebox}

\subsection{8.6.6 Wavelet Transform}\label{wavelet-transform}

The wavelet transform decomposes a signal into scaled and translated
versions of a mother wavelet ψ(t), providing multi-resolution analysis
that simultaneously captures both time and frequency information with
resolution that adapts to the signal content. The continuous wavelet
transform (CWT) is defined as W(a,b) = (1/√\textbar a\textbar) ∫ x(t)
ψ*((t − b)/a) dt, where a is the scale parameter (inversely related to
frequency) and b is the translation (time shift). Unlike the STFT, which
uses a fixed window size for all frequencies, the wavelet transform uses
short windows at high frequencies (fine time resolution, coarse
frequency resolution) and long windows at low frequencies (coarse time
resolution, fine frequency resolution) --- matching the natural
structure of many real-world signals such as speech, music, and
transients. The \textbf{discrete wavelet transform (DWT)} samples the
scale and translation on a dyadic grid (a = 2\textsuperscript{j}, b =
k2\textsuperscript{j}) and is efficiently implemented by Mallat's filter
bank algorithm: the signal is passed through a lowpass filter h{[}n{]}
(scaling function) and a highpass filter g{[}n{]} (wavelet function),
each followed by downsampling by 2, producing approximation coefficients
(low-frequency content) and detail coefficients (high-frequency content)
at each decomposition level. Iterating on the approximation coefficients
creates a multi-level decomposition tree. Common wavelet families
include Haar (simplest, piecewise constant), Daubechies (compact
support, varying smoothness, db1--db20), Symlets (near-symmetric
Daubechies), and Coiflets (symmetric with vanishing moments).
\textbf{Applications} include signal denoising (thresholding small
wavelet coefficients to remove noise while preserving edges), data
compression (JPEG 2000 uses the CDF 9/7 biorthogonal wavelet), feature
extraction for pattern recognition, ECG and EEG analysis in biomedical
engineering, transient detection in power systems, and multi-scale edge
detection in image processing.

\begin{examplebox}

\textbf{Example 8.6.6:} A noisy signal x{[}n{]} = s{[}n{]} + w{[}n{]}
(clean signal plus white Gaussian noise, σ = 0.5) is decomposed using a
3-level DWT with Daubechies db4 wavelets. The signal has 1024 samples at
f\textsubscript{s} = 8 kHz. Determine the frequency bands at each
decomposition level and describe the soft-thresholding denoising
procedure.

\textbf{Solution:}\\
At each DWT level, the signal is split into a low-frequency
approximation and a high-frequency detail band, with each level halving
the bandwidth and the number of samples.\\
Level 1: detail d₁ covers 2--4 kHz (512 coefficients), approximation a₁
covers 0--2 kHz.\\
Level 2: detail d₂ covers 1--2 kHz (256 coefficients), approximation a₂
covers 0--1 kHz.\\
Level 3: detail d₃ covers 0.5--1 kHz (128 coefficients), approximation
a₃ covers 0--0.5 kHz (128 coefficients).\\
For soft-thresholding denoising, compute the universal threshold λ =
σ√(2 ln N) = 0.5 × √(2 × ln(1024)) = 0.5 × √(2 × 6.931) = 0.5 × √13.863
= 0.5 × 3.724 = 1.862.\\
Apply soft thresholding to each detail coefficient: d̂{[}k{]} =
sign(d{[}k{]}) × max(\textbar d{[}k{]}\textbar{} − λ, 0).\\
Coefficients with magnitude below 1.862 are set to zero (noise), while
larger coefficients are shrunk toward zero by λ (preserving signal
edges).\\
The approximation coefficients a₃ are typically left unmodified.\\
Reconstruct the denoised signal by applying the inverse DWT using the
thresholded detail coefficients and the original approximation
coefficients.\\
This method preserves sharp transients and edges that would be smoothed
by a conventional lowpass filter, because the wavelet basis captures
localized features at each scale independently.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-8-6-6}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch08_wavelet.png}

\caption{Figure 8.6.6: Wavelet Transform Multi-Level Decomposition}

\end{figure}

\section{8.7 Adaptive Filtering}\label{adaptive-filtering}

Adaptive filters are self-adjusting digital filters whose coefficients
are updated automatically to minimize an error signal, enabling them to
operate in environments where the signal statistics are unknown or
time-varying. Unlike fixed filters designed from specifications,
adaptive filters learn the optimal filter response from the data itself
by iteratively adjusting their weights to minimize a cost function
(typically mean squared error). This makes them indispensable for
applications where the interference characteristics change over time or
cannot be predicted in advance, including noise cancellation, echo
cancellation, channel equalization, and system identification.

\subsection{8.7.1 LMS Algorithm}\label{lms-algorithm}

The Least Mean Squares (LMS) algorithm is the most widely used adaptive
filtering algorithm due to its simplicity, low computational cost, and
robust convergence properties. At each time step n, the LMS algorithm
updates the filter weight vector w{[}n{]} using the stochastic gradient
descent rule: w{[}n+1{]} = w{[}n{]} + 2μ · e{[}n{]} · x{[}n{]}, where
x{[}n{]} is the input vector containing the M most recent input samples,
e{[}n{]} = d{[}n{]} - w\textsuperscript{T}{[}n{]}x{[}n{]} is the error
between the desired signal d{[}n{]} and the filter output, and μ is the
step size (learning rate) that controls the trade-off between
convergence speed and steady-state misadjustment. The step size must
satisfy 0 \textless{} μ \textless{} 1/(M · P\textsubscript{x}) for
convergence, where M is the filter order and P\textsubscript{x} is the
input signal power. A larger μ converges faster but produces more
residual error; a smaller μ converges slowly but achieves lower
steady-state misadjustment. The Normalized LMS (NLMS) variant divides
the step size by the input power estimate, providing more consistent
convergence behavior across varying signal levels.

\begin{examplebox}

\textbf{Example 8.7.1:} An LMS adaptive filter of order M = 4 is used
for noise cancellation. The input signal power is P\textsubscript{x} =
0.5 W. Determine the maximum step size for convergence and suggest a
practical step size. If the current weight vector is w = {[}0.1, -0.2,
0.3, 0.1{]}, the input vector is x = {[}1.0, 0.5, -0.3, 0.8{]}, and the
desired signal is d = 0.7, compute one LMS update.

\textbf{Solution:}\\
Maximum step size: μ\textsubscript{max} = 1 / (M × P\textsubscript{x}) =
1 / (4 × 0.5) = 0.5.\\
A practical step size is typically 10\% of the maximum: μ = 0.05.\\
Filter output: y = w\textsuperscript{T}x = 0.1(1.0) + (-0.2)(0.5) +
0.3(-0.3) + 0.1(0.8) = 0.1 - 0.1 - 0.09 + 0.08 = -0.01.\\
Error: e = d - y = 0.7 - (-0.01) = 0.71.\\
Weight update: w{[}n+1{]} = w{[}n{]} + 2μ · e · x = {[}0.1, -0.2, 0.3,
0.1{]} + 2(0.05)(0.71){[}1.0, 0.5, -0.3, 0.8{]} = {[}0.1, -0.2, 0.3,
0.1{]} + {[}0.071, 0.0355, -0.0213, 0.0568{]} = {[}0.171, -0.1645,
0.2787, 0.1568{]}.\\
The large error indicates the filter has not yet converged; repeated
iterations will drive e{[}n{]} toward zero.

\end{examplebox}

\subsection{8.7.2 Applications of Adaptive
Filters}\label{applications-of-adaptive-filters}

Adaptive filters are deployed across a wide range of engineering
applications where the environment or interference is non-stationary. In
\textbf{active noise cancellation} (ANC), a reference microphone
captures ambient noise, an adaptive filter models the acoustic path to
the listener, and the filtered output is played through a speaker in
anti-phase to cancel the noise. In \textbf{echo cancellation} for
telephony and teleconferencing, the adaptive filter models the echo path
(acoustic coupling between loudspeaker and microphone) and subtracts the
estimated echo from the microphone signal. In \textbf{channel
equalization} for digital communications, an adaptive equalizer
compensates for intersymbol interference (ISI) caused by multipath
propagation, using a training sequence to initially converge and then
switching to decision-directed mode. In \textbf{system identification},
an adaptive filter driven by a known input estimates the impulse
response of an unknown system by minimizing the difference between the
unknown system's output and the filter's output.

\begin{examplebox}

\textbf{Example 8.7.2:} A telephone echo canceller uses a 128-tap
adaptive filter (representing 16 ms of echo at 8 kHz sampling rate). The
echo path delay is approximately 40 ms (320 samples) due to a hybrid
coupler reflection. Explain why this filter cannot cancel the echo and
determine the minimum filter length required.

\textbf{Solution:}\\
The 128-tap filter can model echo paths up to 128 samples = 128/8000 =
16 ms in duration.\\
Since the echo arrives at 40 ms (320 samples), this delay exceeds the
filter's modeling capability by 320 - 128 = 192 samples.\\
The filter must be at least 320 taps long to capture the full echo path
delay.\\
In practice, the filter should be longer to account for the echo's decay
tail --- a typical choice would be 512 taps (64 ms) to model both the
delay and the room reverberation.\\
At 8 kHz with 512 taps, each LMS update requires 512 multiply-accumulate
operations, which is easily handled by modern DSP processors.

\end{examplebox}

\subsection{8.7.3 Recursive Least Squares
(RLS)}\label{recursive-least-squares-rls}

The Recursive Least Squares algorithm is a faster-converging alternative
to LMS that minimizes the weighted sum of all past squared errors rather
than the instantaneous squared error. At each time step, RLS updates the
filter weights using the exact least-squares solution through a matrix
inversion lemma (avoiding the expensive direct matrix inversion): the
algorithm maintains an inverse correlation matrix P{[}n{]} and computes
a gain vector k{[}n{]} = P{[}n-1{]}x{[}n{]} / (λ +
x\textsuperscript{T}{[}n{]}P{[}n-1{]}x{[}n{]}), where λ is the
forgetting factor (typically 0.95--1.0) that exponentially down-weights
older data. The weight update is w{[}n{]} = w{[}n-1{]} + k{[}n{]} ×
e{[}n{]}, and the inverse correlation matrix is updated as P{[}n{]} =
(P{[}n-1{]} - k{[}n{]}x\textsuperscript{T}{[}n{]}P{[}n-1{]}) / λ. RLS
converges in approximately M iterations (where M is the filter order)
compared to the many hundreds or thousands required by LMS, making it
ideal for fast-changing environments such as mobile communication
channels. The computational cost is O(M²) per sample (versus O(M) for
LMS), and numerical stability requires careful implementation --- the
QR-decomposition-based RLS and square-root RLS variants address
potential ill-conditioning of the P matrix. The forgetting factor λ
controls the effective memory of the algorithm: λ = 1 gives infinite
memory (growing window), while λ \textless{} 1 allows the filter to
track time-varying systems by progressively discounting older data.

\begin{examplebox}

\textbf{Example 8.7.3:} An RLS adaptive equalizer with M = 8 taps and
forgetting factor λ = 0.99 is used to equalize a mobile radio channel.
The LMS algorithm with the same filter order requires 500 iterations to
converge within 1 dB of the optimal solution. Estimate the RLS
convergence time and compare the computational cost per sample of both
algorithms.

\textbf{Solution:}\\
RLS convergence: approximately M to 2M iterations = 8 to 16
iterations.\\
Compared to LMS at 500 iterations, RLS converges roughly 30--60×
faster.\\
Computational cost per sample --- LMS: 2M + 1 multiplications = 2 × 8 +
1 = 17 multiply-accumulate operations (M for output, M for weight
update, 1 for error).\\
RLS: approximately 4M² + 4M multiplications for the full matrix update =
4 × 64 + 32 = 288 operations.\\
Cost ratio: RLS/LMS = 288/17 ≈ 17×.\\
The effective memory length of the RLS filter is approximately 1/(1 - λ)
= 1/0.01 = 100 samples.\\
At a symbol rate of 10 kSymbols/s, this means the equalizer adapts to
channel changes within 100/10,000 = 10 ms --- adequate for pedestrian
mobile channels (coherence time \textasciitilde50 ms at 900 MHz, 10
km/h) but potentially too slow for vehicular speeds where λ should be
reduced to 0.95--0.98.

\end{examplebox}

\subsection{8.7.4 Kalman Filter}\label{kalman-filter}

The Kalman filter is an optimal recursive state estimator that combines
a dynamic system model (prediction) with noisy measurements (correction)
to produce a minimum-variance estimate of the system state at each time
step. Unlike adaptive FIR/IIR filters that estimate filter coefficients,
the Kalman filter estimates the internal state vector x{[}n{]} of a
linear state-space system: \textbf{prediction} x̂{[}n\textbar n−1{]} =
Ax̂{[}n−1{]} + Bu{[}n−1{]} and P{[}n\textbar n−1{]} =
AP{[}n−1{]}A\textsuperscript{T} + Q; \textbf{update} K{[}n{]} =
P{[}n\textbar n−1{]}H\textsuperscript{T}(HP{[}n\textbar n−1{]}H\textsuperscript{T}
+ R)⁻¹, x̂{[}n{]} = x̂{[}n\textbar n−1{]} +
K\href{z\%5Bn\%5D\%20−\%20Hx̂\%5Bn\%7Cn−1\%5D}{n}, and P{[}n{]} = (I −
K{[}n{]}H)P{[}n\textbar n−1{]}, where A is the state transition matrix,
H is the observation matrix, Q is the process noise covariance, R is the
measurement noise covariance, K{[}n{]} is the Kalman gain, and P{[}n{]}
is the error covariance matrix. The Kalman gain optimally balances trust
between the model prediction and the measurement: when measurement noise
R is large, K is small (trust the model); when process noise Q is large,
K is large (trust the measurement). The \textbf{Extended Kalman Filter
(EKF)} handles nonlinear systems by linearizing around the current
estimate using Jacobians, while the \textbf{Unscented Kalman Filter
(UKF)} uses sigma points to propagate the state distribution through the
nonlinearity without linearization, providing better accuracy for highly
nonlinear systems. Applications span GPS navigation, inertial
measurement unit (IMU) sensor fusion, target tracking, battery
state-of-charge estimation, and financial time-series analysis.

\begin{examplebox}

\textbf{Example 8.7.4:} A GPS receiver tracks position along one axis
using a constant-velocity Kalman filter. The state vector is x =
{[}position, velocity{]}\textsuperscript{T}, the state transition matrix
(for Δt = 1 s) is A = {[}{[}1, 1{]}, {[}0, 1{]}{]}, the observation
matrix is H = {[}1, 0{]} (GPS measures position only), the process noise
covariance is Q = {[}{[}0.25, 0.5{]}, {[}0.5, 1.0{]}{]} m², and the
measurement noise variance is R = 9 m². At time n−1, the estimated state
is x̂ = {[}100 m, 2 m/s{]}\textsuperscript{T} with error covariance P =
{[}{[}4, 0{]}, {[}0, 1{]}{]}. A GPS measurement of z = 105 m arrives.
Compute the predicted state, Kalman gain, and updated state estimate.

\textbf{Solution:}\\
\textbf{Prediction:} x̂{[}n\textbar n−1{]} = Ax̂{[}n−1{]} =
{[}{[}1,1{]},{[}0,1{]}{]} × {[}100, 2{]}\textsuperscript{T} = {[}102,
2{]}\textsuperscript{T} (position advances by velocity × Δt).\\
P{[}n\textbar n−1{]} = APA\textsuperscript{T} + Q =
{[}{[}1,1{]},{[}0,1{]}{]} × {[}{[}4,0{]},{[}0,1{]}{]} ×
{[}{[}1,0{]},{[}1,1{]}{]} + {[}{[}0.25,0.5{]},{[}0.5,1.0{]}{]} =
{[}{[}5,1{]},{[}1,1{]}{]} + {[}{[}0.25,0.5{]},{[}0.5,1.0{]}{]} =
{[}{[}5.25, 1.5{]},{[}1.5, 2.0{]}{]}.\\
\textbf{Kalman gain:} S = HP{[}n\textbar n−1{]}H\textsuperscript{T} + R
= {[}1,0{]} × {[}{[}5.25,1.5{]},{[}1.5,2.0{]}{]} ×
{[}1,0{]}\textsuperscript{T} + 9 = 5.25 + 9 = 14.25.\\
K = P{[}n\textbar n−1{]}H\textsuperscript{T}/S = {[}5.25,
1.5{]}\textsuperscript{T} / 14.25 = {[}0.368,
0.105{]}\textsuperscript{T}.\\
\textbf{Innovation:} z − Hx̂{[}n\textbar n−1{]} = 105 − 102 = 3 m.\\
\textbf{Update:} x̂{[}n{]} = {[}102, 2{]}\textsuperscript{T} + {[}0.368,
0.105{]}\textsuperscript{T} × 3 = {[}102 + 1.105, 2 +
0.315{]}\textsuperscript{T} = {[}103.1, 2.32{]}\textsuperscript{T}.\\
The Kalman filter corrects the predicted position from 102 m toward the
measurement of 105 m, but only partially (to 103.1 m) because it
accounts for the 9 m² GPS measurement noise.\\
The velocity estimate is also updated to 2.32 m/s, reflecting the
position innovation's implication that the object may be moving slightly
faster than modeled.

\end{examplebox}

\subsection{8.7.5 Wiener Filter}\label{wiener-filter}

The Wiener filter is the theoretically optimal linear filter for
estimating a desired signal from a noisy observation, minimizing the
mean squared error (MSE) between the filter output and the desired
signal in the statistical (ensemble average) sense. In the frequency
domain, the Wiener filter transfer function is H(f) =
S\textsubscript{xd}(f) / S\textsubscript{xx}(f), where
S\textsubscript{xd}(f) is the cross-power spectral density between the
input and the desired signal and S\textsubscript{xx}(f) is the input
auto-power spectral density. For the common case of additive noise ---
where the observed signal is x(t) = d(t) + n(t) with signal and noise
uncorrelated --- the Wiener filter simplifies to H(f) =
S\textsubscript{dd}(f) / (S\textsubscript{dd}(f) +
S\textsubscript{nn}(f)) = SNR(f) / (1 + SNR(f)), where SNR(f) =
S\textsubscript{dd}(f)/S\textsubscript{nn}(f) is the frequency-dependent
signal-to-noise ratio. At frequencies where the SNR is high, H(f) ≈ 1
(pass the signal); where the SNR is low, H(f) ≈ 0 (suppress the noise).
The Wiener filter requires knowledge of the signal and noise power
spectra, which must be estimated in practice --- this is exactly what
adaptive filters (LMS, RLS) accomplish by iteratively converging toward
the Wiener solution without explicit spectral estimation. The
discrete-time FIR Wiener filter solves the \textbf{Wiener-Hopf equation}
Rw = p, where R is the input autocorrelation matrix, w is the optimal
weight vector, and p is the cross-correlation vector between input and
desired signal. This matrix equation has the direct solution
w\textsubscript{opt} = R⁻¹p, which the LMS algorithm approximates
iteratively and the RLS algorithm tracks recursively. Applications
include noise reduction in audio and images, channel equalization,
linear prediction for speech coding, and optimal interpolation.

\begin{examplebox}

\textbf{Example 8.7.5:} A signal d(t) with flat PSD
S\textsubscript{dd}(f) = 1.0 × 10⁻³ V²/Hz is corrupted by additive white
noise with PSD S\textsubscript{nn}(f) = 2.5 × 10⁻⁴ V²/Hz over a
bandwidth of 0--4 kHz. Design the Wiener filter and calculate the noise
reduction (in dB) and the output SNR.

\textbf{Solution:}\\
Since both PSDs are flat (white signal in white noise), the Wiener
filter is a simple frequency-independent gain: H(f) =
S\textsubscript{dd} / (S\textsubscript{dd} + S\textsubscript{nn}) = 1.0
× 10⁻³ / (1.0 × 10⁻³ + 2.5 × 10⁻⁴) = 1.0 × 10⁻³ / 1.25 × 10⁻³ = 0.8.\\
The filter passes 80\% of the input amplitude at all frequencies.\\
Input SNR = S\textsubscript{dd}/S\textsubscript{nn} = 1.0 × 10⁻³ / 2.5 ×
10⁻⁴ = 4.0 (6.02 dB).\\
Signal power at output: P\textsubscript{d,out} = H² ×
S\textsubscript{dd} × BW = 0.64 × 1.0 × 10⁻³ × 4000 = 2.56 W.\\
Noise power at output: P\textsubscript{n,out} = H² × S\textsubscript{nn}
× BW = 0.64 × 2.5 × 10⁻⁴ × 4000 = 0.64 W.\\
Output SNR = 2.56/0.64 = 4.0 (6.02 dB).\\
The output SNR equals the input SNR --- for white-in-white noise the
Wiener filter cannot improve SNR, it only minimizes MSE by scaling.\\
However, if the signal PSD is concentrated in a narrower band (e.g.,
0--1 kHz), the Wiener filter suppresses noise in the 1--4 kHz band where
SNR is zero, yielding substantial noise reduction.\\
With S\textsubscript{dd}(f) = 4.0 × 10⁻³ V²/Hz for 0--1 kHz and 0
elsewhere, H(f) = 0.941 in-band and 0 out-of-band, reducing total noise
power from 1.0 W to 0.221 W --- a 6.5 dB noise reduction.

\end{examplebox}

\subsection{8.7.6 Compressive Sensing}\label{compressive-sensing}

Compressive sensing (CS), also called compressed sampling or sparse
recovery, is a signal acquisition framework that enables reconstruction
of a signal from far fewer measurements than the Nyquist rate requires,
provided the signal is \textbf{sparse} in some known basis or transform
domain. A signal x of length N is K-sparse if it has at most K nonzero
coefficients in a representation basis Ψ (e.g., Fourier, wavelet, or
DCT), where K \textless\textless{} N. Instead of sampling at the Nyquist
rate, CS acquires M \textless\textless{} N linear measurements y = Φx,
where Φ is an M × N measurement matrix, and recovers x by solving the
underdetermined system subject to a sparsity constraint. The key
theoretical result is that if Φ satisfies the \textbf{Restricted
Isometry Property (RIP)} --- meaning it approximately preserves
distances between sparse vectors --- then exact recovery is possible
from M ≥ C × K × ln(N/K) measurements, where C is a small constant.
Random Gaussian and random Bernoulli matrices satisfy the RIP with high
probability, as do certain structured random matrices (partial Fourier,
random convolution). Recovery algorithms solve the optimization problem:
minimize ‖x‖₁ subject to y = Φx (basis pursuit), which can be formulated
as a linear program, or use greedy iterative methods such as
\textbf{Orthogonal Matching Pursuit (OMP)} that sequentially identify
the support of the sparse signal. For noisy measurements y = Φx + e, the
formulation becomes minimize ‖x‖₁ subject to ‖y − Φx‖₂ ≤ ε (basis
pursuit denoising, also known as LASSO). Applications include MRI
acceleration (reducing scan time by 4--8× by acquiring fewer k-space
samples), single-pixel cameras, radar imaging, spectrum sensing in
cognitive radio, and seismic data acquisition where sensor deployment is
expensive.

\begin{examplebox}

\textbf{Example 8.7.6:} A signal of length N = 256 is known to be K = 8
sparse in the DCT domain (only 8 of 256 DCT coefficients are nonzero). A
random Gaussian measurement matrix Φ of size M × 256 is used. Determine
the minimum number of measurements M required for reliable recovery, the
compression ratio, and compare to the Nyquist requirement.

\textbf{Solution:}\\
Using the CS measurement bound M ≥ C × K × ln(N/K) with C ≈ 2 (practical
constant for Gaussian matrices): M ≥ 2 × 8 × ln(256/8) = 16 × ln(32) =
16 × 3.466 = 55.5, so M = 56 measurements.\\
Compression ratio: N/M = 256/56 = 4.57:1.\\
Compared to Nyquist sampling, which requires all N = 256 samples, CS
requires only 56 measurements --- a 78\% reduction.\\
The measurement matrix Φ is 56 × 256, and each measurement
y\textsubscript{i} is a random linear combination of all 256 signal
values.\\
Recovery via OMP proceeds iteratively: at each step, the algorithm
identifies the column of Φ most correlated with the current residual r =
y − Φx̂, adds its index to the support set, and solves a least-squares
problem over the selected columns.\\
After K = 8 iterations, the algorithm has identified all 8 nonzero DCT
coefficients and their values.\\
In practice, M is chosen 3--5× larger than the theoretical minimum to
provide robustness against noise, so M = 80--120 measurements would be
typical for reliable recovery at moderate SNR.\\
For an MRI application, this means a 256 × 256 image with sparsity K =
2000 in the wavelet domain could be reconstructed from approximately
20,000 k-space samples instead of 65,536, reducing scan time by roughly
3×.

\end{examplebox}

\chapter{Chapter 9}\label{chapter-9}

\chapter{Electromagnetics}\label{electromagnetics}

Electromagnetics is the study of electric and magnetic fields, their
interactions, and the propagation of electromagnetic waves. It provides
the physical foundation for virtually all of electrical engineering,
from circuit theory and power transmission to wireless communications,
optics, and antenna design. The behavior of electromagnetic fields is
governed by Maxwell's equations, a set of four fundamental relationships
that unify electricity, magnetism, and light into a single coherent
framework.

\section{9.1 Electrostatics}\label{electrostatics}

Electrostatics deals with electric charges at rest and the fields and
potentials they produce. The concepts of electric field, potential, and
capacitance developed in electrostatics form the foundation for
understanding circuit behavior, dielectric materials, electrostatic
discharge (ESD) protection, and energy storage. Coulomb's law and
Gauss's law provide the tools to calculate fields from charge
distributions, while the concept of electric potential simplifies energy
and voltage calculations throughout electrical engineering.

\subsection{9.1.1 Electric Charge and Coulomb's
Law}\label{electric-charge-and-coulombs-law}

Electric charge is a fundamental property of matter --- as intrinsic as
mass --- and is the ultimate source of all electromagnetic phenomena. It
exists in two forms: positive (carried by protons) and negative (carried
by electrons), with the elementary charge quantized at e ≈ 1.602 × 10⁻¹⁹
C, meaning all observable charges appear in integer multiples of this
value. Charge is strictly conserved: it can be transferred between
objects but can never be created or destroyed, a principle that
underpins Kirchhoff's Current Law in circuit analysis. Coulomb's Law
quantifies the electrostatic force between two point charges: F =
q₁q₂/(4πε₀r²), where ε₀ ≈ 8.854 × 10⁻¹² F/m is the permittivity of free
space and r is the separation distance. The force acts along the line
connecting the two charges --- like charges repel and unlike charges
attract --- and follows an inverse-square law identical in form to
Newton's law of gravitation, though the electrostatic force is vastly
stronger (approximately 10³⁶ times) at atomic scales. The principle of
superposition applies: the total force on any charge due to a collection
of other charges is the vector sum of the individual pairwise Coulomb
forces, which generalizes naturally from discrete point charges to
continuous charge distributions described by charge density ρ (C/m³),
surface charge density σ (C/m²), or line charge density λ (C/m). This
transition from discrete to continuous descriptions is essential for
analyzing practical structures such as charged conductors, capacitor
plates, and semiconductor junctions, and leads directly to the concept
of the electric field as a continuous vector field in space.

\begin{examplebox}

\textbf{Example 9.1.1:} Two point charges, q₁ = +4 μC and q₂ = -2 μC,
are separated by 30 cm in air. Find the magnitude and direction of the
electrostatic force between them.

\textbf{Solution:}\\
F = k\textbar q₁\textbar\textbar q₂\textbar/r² = (8.99 × 10⁹)(4 ×
10⁻⁶)(2 × 10⁻⁶) / (0.30)² = (8.99 × 10⁹)(8 × 10⁻¹²) / 0.09 = 0.07192 /
0.09 = 0.799 N ≈ 0.8 N.\\
Since the charges are opposite in sign, the force is attractive,
directed along the line connecting the two charges, pulling them toward
each other.

\end{examplebox}

\subsection{9.1.2 Electric Field}\label{electric-field}

The electric field E is defined as the force per unit positive test
charge at a point in space: E = F/q, measured in volts per meter (V/m)
or equivalently newtons per coulomb (N/C). For a point charge Q, the
electric field at distance r is E = Q/(4πε₀r²) directed radially outward
for positive Q. Electric field lines originate on positive charges and
terminate on negative charges, with the density of field lines
representing the field strength. Gauss's Law states that the total
electric flux through any closed surface equals the enclosed charge
divided by ε₀: ∮E·dA = Q\textsubscript{enclosed}/ε₀. Gauss's Law is
particularly powerful for calculating electric fields of charge
distributions with high symmetry (spherical, cylindrical, or planar).

\begin{examplebox}

\textbf{Example 9.1.2:} Find the electric field at a distance of 20 cm
from a point charge of Q = +5 nC in free space.

\textbf{Solution:}\\
E = Q / (4πε₀r²) = kQ/r² = (8.99 × 10⁹)(5 × 10⁻⁹) / (0.20)² = 44.95 /
0.04 = 1,123.75 V/m ≈ 1,124 V/m.\\
The field is directed radially outward from the positive charge.\\
Equivalently using Gauss's Law with a spherical Gaussian surface of
radius 0.20 m: E × 4πr² = Q/ε₀, so E = Q / (4πε₀r²), yielding the same
result.

\end{examplebox}

\subsection{9.1.3 Electric Potential}\label{electric-potential}

Electric potential V is the work done per unit charge in moving a
positive test charge from a reference point (typically infinity) to a
given location in an electric field: V = -∫E·dl. The potential
difference (voltage) between two points determines the energy gained or
lost by a charge moving between them: W = qΔV. The electric field is the
negative gradient of the potential: E = -∇V, meaning the field points in
the direction of steepest potential decrease. Equipotential surfaces are
perpendicular to electric field lines at every point. For a point
charge, V = Q/(4πε₀r), and for multiple charges, the total potential is
the algebraic (scalar) sum of individual potentials -- simpler than
vector addition of electric fields.

\begin{examplebox}

\textbf{Example 9.1.3:} Two charges, q₁ = +3 μC at the origin and q₂ =
-1 μC at x = 40 cm, lie along the x-axis. Find the electric potential at
the midpoint (x = 20 cm).

\textbf{Solution:}\\
The distance from each charge to the midpoint is r = 0.20 m.\\
V = V₁ + V₂ = kq₁/r + kq₂/r = (8.99 × 10⁹)(3 × 10⁻⁶) / 0.20 + (8.99 ×
10⁹)(-1 × 10⁻⁶) / 0.20 = 134,850 + (-44,950) = 89,900 V ≈ 89.9 kV.\\
The net potential is positive because the larger positive charge
dominates at the midpoint.

\end{examplebox}

\subsection{9.1.4 Capacitance}\label{capacitance}

Capacitance is the ability of a structure to store electric charge and
energy in an electric field, defined as C = Q/V, where Q is the stored
charge and V is the voltage across the structure, measured in farads
(F). A parallel-plate capacitor has capacitance C = εA/d, where ε is the
permittivity of the dielectric material between the plates, A is the
plate area, and d is the plate separation. The energy stored in a
capacitor is W = ½CV² = ½Q²/C = ½QV. Dielectric materials inserted
between capacitor plates increase the capacitance by a factor of the
relative permittivity (dielectric constant) εᵣ, while also increasing
the breakdown voltage. Capacitors in parallel add directly
(C\textsubscript{total} = C₁ + C₂), while capacitors in series combine
as reciprocals (1/C\textsubscript{total} = 1/C₁ + 1/C₂).

\begin{examplebox}

\textbf{Example 9.1.4:} A parallel-plate capacitor has plates of area A
= 0.02 m² separated by d = 0.5 mm of a dielectric with εᵣ = 4.5. Find
the capacitance and the energy stored when charged to 100 V.

\textbf{Solution:}\\
C = ε₀εᵣA/d = (8.854 × 10⁻¹² × 4.5 × 0.02) / (0.5 × 10⁻³) = (7.969 ×
10⁻¹³) / (5 × 10⁻⁴) = 1.594 × 10⁻⁹ F ≈ 1.59 nF.\\
Energy stored: W = ½CV² = 0.5 × 1.594 × 10⁻⁹ × (100)² = 0.5 × 1.594 ×
10⁻⁹ × 10,000 = 7.97 × 10⁻⁶ J ≈ 7.97 μJ.

\end{examplebox}

\subsection{9.1.5 Dielectric Materials and Boundary
Conditions}\label{dielectric-materials-and-boundary-conditions}

A dielectric is an insulating material that becomes polarized when
placed in an electric field, aligning its internal molecular dipoles to
partially cancel the applied field and thereby increasing the
capacitance of any structure containing it. The electric displacement
field D = εE = ε₀ε\textsubscript{r}E accounts for both the free-space
field and the bound charge effects within the dielectric, where
ε\textsubscript{r} (the relative permittivity or dielectric constant)
ranges from 1 for vacuum to approximately 2-4 for common PCB substrates
(FR-4 ≈ 4.3), 3.9 for SiO₂, 7-10 for alumina, and up to several thousand
for ferroelectric ceramics (BaTiO₃). At the boundary between two
different dielectric media, the tangential component of E is continuous
(E\textsubscript{t1} = E\textsubscript{t2}) and the normal component of
D is continuous in the absence of free surface charge
(D\textsubscript{n1} = D\textsubscript{n2}, which means
ε₁E\textsubscript{n1} = ε₂E\textsubscript{n2}). These boundary
conditions determine how electric field lines refract at material
interfaces: tan θ₁ / tan θ₂ = ε₁/ε₂, analogous to Snell's law for
optics. The dielectric strength is the maximum electric field a material
can withstand before electrical breakdown occurs (e.g., \textasciitilde3
MV/m for air, \textasciitilde20 MV/m for polyethylene,
\textasciitilde500 MV/m for SiO₂ thin films). Dielectric loss,
quantified by the loss tangent tan δ = ε″/ε′ (the ratio of the imaginary
to real parts of the complex permittivity), represents energy dissipated
as heat in an alternating electric field and is critical in
high-frequency applications --- low-loss substrates like PTFE (tan δ ≈
0.0002) are preferred for RF circuits.

\begin{examplebox}

\textbf{Example 9.1.5:} A parallel-plate capacitor has a plate area of
10 cm² and a 2 mm gap filled with two dielectric layers: 1 mm of alumina
(ε\textsubscript{r1} = 9.0) and 1 mm of PTFE (ε\textsubscript{r2} =
2.1). Find the total capacitance and the electric field in each layer
when 500 V is applied across the plates.

\textbf{Solution:}\\
The two dielectric layers act as two capacitors in series.\\
C₁ = ε₀ε\textsubscript{r1}A/d₁ = 8.854 × 10⁻¹² × 9.0 × 10 × 10⁻⁴ / 1 ×
10⁻³ = 79.69 × 10⁻¹² / 10⁻³ = 79.69 pF.\\
C₂ = ε₀ε\textsubscript{r2}A/d₂ = 8.854 × 10⁻¹² × 2.1 × 10⁻³ m² / (1 ×
10⁻³ m) = 18.59 pF.\\
Total: 1/C = 1/C₁ + 1/C₂ = 1/79.69 + 1/18.59 = 0.01255 + 0.05379 =
0.06634 pF⁻¹, so C = 15.07 pF.\\
For the electric fields, the normal component of D is continuous across
the boundary: D = ε₁E₁ = ε₂E₂, and V = E₁d₁ + E₂d₂ = 500 V.\\
From continuity: E₁ = (ε₂/ε₁)E₂ = (2.1/9.0)E₂ = 0.2333E₂.\\
Substituting: 0.2333E₂ × 10⁻³ + E₂ × 10⁻³ = 500, so E₂(1.2333 × 10⁻³) =
500, E₂ = 405.4 kV/m (in PTFE).\\
E₁ = 0.2333 × 405.4 = 94.6 kV/m (in alumina).\\
The field is 4.3× stronger in the lower-permittivity PTFE layer --- this
is why breakdown in multi-layer dielectrics typically initiates in the
lower-ε material.

\end{examplebox}

\subsection{9.1.6 Laplace's and Poisson's
Equations}\label{laplaces-and-poissons-equations}

Laplace's equation ∇²V = 0 and Poisson's equation ∇²V = −ρ/ε govern the
spatial distribution of electric potential in charge-free and
charge-containing regions, respectively. These second-order partial
differential equations, combined with boundary conditions (specified
voltages on conductors or specified charge distributions), uniquely
determine the potential and hence the electric field everywhere in a
region --- this is guaranteed by the \textbf{uniqueness theorem}, which
states that a solution satisfying both the PDE and the boundary
conditions is the only solution. Laplace's equation applies in regions
free of charge (the dielectric space between capacitor plates, the
insulation in a coaxial cable, or the air surrounding a charged
conductor), while Poisson's equation applies where space charge exists
(inside a semiconductor depletion region, in an electron beam, or in a
plasma).

For simple geometries with high symmetry, analytical solutions exist:
the potential between coaxial cylinders (radii a and b, inner conductor
at V₀) is V(r) = V₀ ln(b/r)/ln(b/a), and between concentric spheres is
V(r) = V₀ a(b − r) / (r(b − a)). For the vast majority of practical
geometries --- PCB trace cross-sections, high-voltage bushing profiles,
IC interconnect structures, electric motor slot geometries --- no
closed-form solution exists, and numerical methods are used. The
\textbf{finite difference method (FDM)} discretizes the region onto a
rectangular grid and approximates the Laplacian as V\textsubscript{i,j}
= (V\textsubscript{i+1,j} + V\textsubscript{i−1,j} +
V\textsubscript{i,j+1} + V\textsubscript{i,j−1})/4 (the average of the
four nearest neighbors in 2D), iterating until convergence. The
\textbf{finite element method (FEM)} divides the region into triangular
or tetrahedral elements, approximates V within each element using
polynomial basis functions, and solves a global matrix equation --- FEM
handles complex geometries, material interfaces, and irregular
boundaries far better than FDM and is the standard method in commercial
electromagnetic simulation software (ANSYS Maxwell, COMSOL, CST). The
\textbf{boundary element method (BEM)} discretizes only the surfaces
(boundaries) rather than the volume, reducing a 3D problem to a 2D
surface mesh, and is efficient for open-region problems like antenna and
EMC simulations where the surrounding space extends to infinity.

\begin{examplebox}

\textbf{Example 9.1.6:} Two parallel conducting plates are separated by
10 mm. The top plate is at V = 100 V and the bottom plate is at V = 0 V.
A 5 mm thick dielectric slab (ε\textsubscript{r} = 4) rests on the
bottom plate, with air (ε\textsubscript{r} = 1) filling the upper 5 mm.
Using Laplace's equation with the boundary condition that
D\textsubscript{n} is continuous at the dielectric interface, find the
potential and electric field in each region.

\textbf{Solution:}\\
In each region the potential satisfies ∇²V = 0 (no free charge),
reducing to d²V/dz² = 0 in this 1D geometry, so V varies linearly within
each layer: V₁(z) = A₁z + B₁ (dielectric, 0 ≤ z ≤ 5 mm) and V₂(z) = A₂z
+ B₂ (air, 5 mm ≤ z ≤ 10 mm).

Boundary conditions: V₁(0) = 0 → B₁ = 0. V₂(10 mm) = 100 V → A₂(0.01) +
B₂ = 100.\\
At the interface (z = 5 mm): V₁ = V₂ (continuity of potential) and ε₁E₁
= ε₂E₂ (continuity of D\textsubscript{n}).

E₁ = −dV₁/dz = −A₁ and E₂ = −dV₂/dz = −A₂.\\
From D\textsubscript{n} continuity: 4ε₀A₁ = ε₀A₂ → A₂ = 4A₁.\\
From V continuity at z = 5 mm: A₁(0.005) = A₂(0.005) + B₂.\\
From V₂(0.01) = 100: A₂(0.01) + B₂ = 100.\\
Solving: B₂ = 100 − 0.01A₂ = 100 − 0.04A₁. Then: 0.005A₁ = 0.005(4A₁) +
100 − 0.04A₁ = 0.02A₁ + 100 − 0.04A₁ = 100 − 0.02A₁.\\
So 0.005A₁ + 0.02A₁ = 100, giving 0.025A₁ = 100, A₁ = 4,000 V/m.\\
A₂ = 4 × 4,000 = 16,000 V/m.

E\textsubscript{dielectric} = \textbf{4,000 V/m} (4 kV/m),
E\textsubscript{air} = \textbf{16,000 V/m} (16 kV/m).\\
V at interface = 4,000 × 0.005 = \textbf{20 V}. The electric field is 4×
stronger in the air gap (lower ε), concentrating 80\% of the voltage
drop across the air and only 20\% across the dielectric --- a critical
consideration in high-voltage insulation design where air breakdown (3
MV/m) limits the overall voltage rating.

\end{examplebox}

\section{9.2 Magnetostatics}\label{magnetostatics}

Magnetostatics describes magnetic fields produced by steady (DC)
currents and permanent magnets, and the forces these fields exert on
moving charges and current-carrying conductors. Magnetic fields are
fundamentally different from electric fields --- they always form closed
loops, exert forces perpendicular to motion, and cannot do work on
stationary charges. The concepts of magnetic field intensity, flux,
inductance, and magnetic materials are essential for designing
transformers, inductors, electric motors, magnetic sensors, and data
storage devices.

\subsection{9.2.1 Magnetic Fields}\label{magnetic-fields}

Magnetic fields are produced by moving electric charges --- that is, by
electric currents --- and in turn exert forces on other moving charges,
establishing a deep connection between electricity and magnetism that is
formalized in Maxwell's equations. The magnetic flux density B (measured
in tesla, T) describes the strength and direction of the field, while
the magnetic field intensity H (measured in A/m) describes the field
produced by free currents independent of the material response; the two
are related by B = μH, where μ = μ₀μ\textsubscript{r} is the
permeability (μ₀ = 4π × 10⁻⁷ H/m for free space). The Biot-Savart law
provides the most general method for calculating B from an arbitrary
current distribution: dB = (μ₀/4π)(Idl × r̂)/r², integrating over the
current path. For geometries with high symmetry, Ampere's law ∮H·dl =
I\textsubscript{enclosed} offers a far simpler approach, directly
yielding the field around long straight conductors (B = μ₀I/(2πr) with
concentric circular field lines), inside solenoids (B = μ₀nI), and
within toroidal coils. A fundamental distinction from electrostatics is
that isolated magnetic poles (monopoles) have never been observed ---
magnetic field lines always form closed loops with no beginning or end,
expressed mathematically as ∇·B = 0 (Gauss's Law for magnetism). The
force on a charge q moving with velocity v through a magnetic field is
the Lorentz force F = qv × B, which is always perpendicular to the
velocity and therefore changes the direction of motion without doing
work --- this is the operating principle behind cyclotrons, mass
spectrometers, and Hall-effect sensors. The magnetic flux Φ = ∫B·dA
through a surface, measured in webers (Wb), is the quantity that links
magnetic fields to electromagnetic induction through Faraday's law,
connecting this section to the wave phenomena developed later in the
chapter.

\begin{examplebox}

\textbf{Example 9.2.1:} A long, straight conductor carries a current of
15 A. Find the magnetic field strength at a distance of 5 cm from the
conductor.

\textbf{Solution:}\\
B = μ₀I / (2πr) = (4π × 10⁻⁷ × 15) / (2π × 0.05) = (4π × 10⁻⁷ × 15) /
(0.1π) = (60π × 10⁻⁷) / (0.1π) = 60 × 10⁻⁶ T = 60 μT.\\
The field lines form concentric circles around the conductor, with the
direction given by the right-hand rule (curling the fingers of the right
hand in the direction of field circulation, the thumb points in the
direction of current flow).

\end{examplebox}

\subsection{9.2.2 Ampère's Law}\label{ampuxe8res-law}

Ampère's Law relates the magnetic field circulating around a closed path
to the total current passing through any surface bounded by that path:
∮B·dl = μ₀I\textsubscript{enclosed}. This law is the magnetic analog of
Gauss's Law and is most useful for calculating magnetic fields in
configurations with high symmetry, such as long straight conductors,
solenoids, and toroidal coils. For a solenoid of n turns per unit length
carrying current I, Ampère's Law yields a uniform interior field B =
μ₀nI. Maxwell later added a displacement current term μ₀ε₀(∂E/∂t) to
Ampere's Law to account for time-varying electric fields, completing the
set of equations that predict electromagnetic wave propagation.

\begin{examplebox}

\textbf{Example 9.2.2:} A solenoid has 500 turns, a length of 25 cm, and
carries 2 A of current. Find the magnetic field inside the solenoid.

\textbf{Solution:}\\
The number of turns per unit length: n = N/l = 500 / 0.25 = 2000
turns/m.\\
By Ampere's Law, the interior magnetic field is B = μ₀nI = (4π ×
10⁻⁷)(2000)(2) = 4π × 10⁻⁷ × 4000 = 16π × 10⁻⁴ = 5.027 × 10⁻³ T ≈ 5.03
mT.\\
The field is uniform and directed along the axis of the solenoid.

\end{examplebox}

\subsection{9.2.3 Magnetic Force}\label{magnetic-force}

A charge q moving with velocity v in a magnetic field B experiences the
Lorentz force: F = qv × B, which is perpendicular to both the velocity
and the field, causing the charge to follow a curved path rather than
accelerate along the field direction. For a current-carrying conductor
of length L in a uniform field, the force is F = IL × B, which is the
operating principle behind electric motors, loudspeakers, and
galvanometers. Two parallel conductors carrying currents in the same
direction attract each other, while currents in opposite directions
repel --- this force between current-carrying conductors is the basis
for the SI definition of the ampere. The torque on a current loop
(magnetic dipole) in a uniform field is τ = m × B, where m = NIA is the
magnetic moment (N turns, current I, area A).

\begin{examplebox}

\textbf{Example 9.2.3:} A straight conductor 0.5 m long carries a
current of 10 A and is placed perpendicular to a uniform magnetic field
of B = 0.3 T. Find the force on the conductor.

\textbf{Solution:}\\
Since the conductor is perpendicular to the field (θ = 90°), the force
is F = BIL sin(θ) = 0.3 × 10 × 0.5 × sin(90°) = 0.3 × 10 × 0.5 × 1 = 1.5
N.\\
The force direction is perpendicular to both the current and the
magnetic field, determined by the right-hand rule (or equivalently, F =
IL × B).

\end{examplebox}

\subsection{9.2.4 Inductance}\label{inductance}

Inductance is the property of a circuit element that opposes changes in
current by storing energy in a magnetic field. Self-inductance L relates
the voltage induced across a coil to the rate of change of current
through it: V = -L(dI/dt), measured in henrys (H). For a solenoid of N
turns, length l, cross-sectional area A, and core permeability μ, the
inductance is L = μN²A/l. Mutual inductance M quantifies the coupling
between two coils, where a changing current in one coil induces a
voltage in the other: V₂ = -M(dI₁/dt). The energy stored in an inductor
is W = ½LI², and inductors in series add directly
(L\textsubscript{total} = L₁ + L₂ when no mutual coupling exists) while
inductors in parallel combine as reciprocals.

\begin{examplebox}

\textbf{Example 9.2.4:} A solenoid has N = 300 turns, length l = 20 cm,
cross-sectional area A = 5 cm², and an air core (μ = μ₀). Find the
inductance and the energy stored when the current is 2 A.

\textbf{Solution:}\\
L = μ₀N²A/l = (4π × 10⁻⁷)(300²)(5 × 10⁻⁴) / 0.20 = (4π × 10⁻⁷)(90,000)(5
× 10⁻⁴) / 0.20 = (4π × 10⁻⁷ × 45) / 0.20 = (56.55 × 10⁻⁶) / 0.20 = 2.827
× 10⁻⁴ H ≈ 283 μH.\\
Energy stored: W = ½LI² = 0.5 × 2.827 × 10⁻⁴ × (2)² = 5.654 × 10⁻⁴ J ≈
565 μJ.

\end{examplebox}

\subsection{9.2.5 Magnetic Materials and
Hysteresis}\label{magnetic-materials-and-hysteresis}

Magnetic materials are classified by how they respond to an applied
magnetic field H, characterized by the relationship B = μH = μ₀μᵣH,
where μᵣ is the relative permeability. \textbf{Diamagnetic} materials
(copper, silver, bismuth) have μᵣ slightly less than 1 and weakly oppose
the applied field. \textbf{Paramagnetic} materials (aluminum, platinum)
have μᵣ slightly greater than 1 and weakly align with the field.
\textbf{Ferromagnetic} materials (iron, nickel, cobalt, and their
alloys) have μᵣ ranging from hundreds to hundreds of thousands and
exhibit strong magnetization, making them essential for transformer
cores, inductors, and permanent magnets. Ferromagnetic materials display
a nonlinear B-H relationship and \textbf{hysteresis} --- when the
applied field is cycled, the B-H curve forms a loop because the material
retains some magnetization (remanence B\textsubscript{r}) even after H
returns to zero. The coercivity H\textsubscript{c} is the reverse field
needed to demagnetize the material. Soft magnetic materials (silicon
steel, ferrites) have narrow hysteresis loops (low H\textsubscript{c}),
minimizing core losses in transformers and inductors. Hard magnetic
materials (NdFeB, SmCo, Alnico) have wide loops (high H\textsubscript{c}
and B\textsubscript{r}), making them ideal for permanent magnets in
motors, generators, and loudspeakers.

\begin{examplebox}

\textbf{Example 9.2.5:} A toroidal inductor core made of silicon steel
has a mean path length of 20 cm, cross-sectional area of 4 cm², relative
permeability μᵣ = 3000, and a winding of 200 turns carrying 0.5 A. Find
H, B, and the magnetic flux in the core. If the core saturates at
B\textsubscript{sat} = 1.8 T, what is the maximum current before
saturation?

\textbf{Solution:}\\
Magnetic field intensity: H = NI/l = 200 × 0.5 / 0.20 = 500 A/m.\\
Flux density: B = μ₀μᵣH = 4π × 10⁻⁷ × 3000 × 500 = 1.885 T.\\
This exceeds B\textsubscript{sat} = 1.8 T, so in practice the core would
already be in saturation, and the actual B would be limited to
approximately 1.8 T with μᵣ dropping sharply.\\
The maximum current before saturation: B\textsubscript{sat} = μ₀μᵣ ×
NI\textsubscript{max}/l, so I\textsubscript{max} = B\textsubscript{sat}
× l / (μ₀μᵣN) = 1.8 × 0.20 / (4π × 10⁻⁷ × 3000 × 200) = 0.36 / 0.7540 =
0.477 A.\\
The core saturates just below 0.5 A; a larger core area or an air gap
would increase the saturation current.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-9-2-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch09_hysteresis.png}

\caption{Figure 9.2.5: B-H Hysteresis Loop}

\end{figure}

\subsection{9.2.6 Magnetic Circuits and Core
Design}\label{magnetic-circuits-and-core-design}

A magnetic circuit is an analogy to an electric circuit in which
magnetic flux Φ (analogous to current) is driven through a core by
magnetomotive force (MMF) ℱ = NI (analogous to voltage) against
reluctance ℛ = l/(μA) (analogous to resistance), where l is the magnetic
path length, μ is the permeability, and A is the cross-sectional area.
Ohm's law for magnetic circuits is Φ = ℱ/ℛ, and series/parallel
reluctance combinations follow the same rules as resistors. \textbf{Air
gaps} are intentionally introduced in inductor cores to increase the
total reluctance, which serves three purposes: storing energy in the gap
(E = ½LI², with most energy in the high-reluctance gap rather than the
core), linearizing the inductance (the large gap reluctance dominates
over the nonlinear core reluctance, making L nearly independent of
current), and increasing the saturation current (since the core operates
at lower flux density). The inductance of a gapped core is L =
N²/(ℛ\textsubscript{core} + ℛ\textsubscript{gap}) =
N²μ₀A/l\textsubscript{g} when the gap reluctance dominates. \textbf{Core
materials} for power applications include laminated silicon steel (high
B\textsubscript{sat} ≈ 1.5--1.8 T, used at 50/60 Hz in power
transformers), ferrite (MnZn and NiZn, B\textsubscript{sat} ≈ 0.3--0.5
T, low core loss at 20 kHz--5 MHz for switching converters), powdered
iron (distributed air gap, B\textsubscript{sat} ≈ 1.0--1.4 T, moderate
loss), and amorphous/nanocrystalline alloys (B\textsubscript{sat} ≈
1.2--1.5 T, very low loss, used in high-efficiency transformers). Core
loss consists of hysteresis loss (proportional to frequency ×
B\textsuperscript{n}, where n ≈ 1.6--2.5) and eddy current loss
(proportional to f² × B²), and is characterized by the Steinmetz
equation P\textsubscript{core} = k × f\textsuperscript{α} ×
B\textsuperscript{β} (W/m³), where k, α, and β are material-specific
constants.

\begin{examplebox}

\textbf{Example 9.2.6:} A power inductor for a buck converter must
provide L = 100 μH at I\textsubscript{max} = 5 A without saturating. The
chosen ferrite core (E-core, effective area A\textsubscript{e} = 1.27
cm², effective path length l\textsubscript{e} = 7.7 cm, μᵣ = 2500,
B\textsubscript{sat} = 0.35 T) requires an air gap. Calculate the number
of turns, the required air gap length, and verify that the core does not
saturate.

\textbf{Solution:}\\
First, determine the minimum inductance factor: L =
N²μ₀A\textsubscript{e}/l\textsubscript{g} when gap dominates, so we need
to find N and l\textsubscript{g} together.\\
The peak flux density constraint: B\textsubscript{max} =
LI\textsubscript{max}/(NA\textsubscript{e}) \textless{}
B\textsubscript{sat}.\\
So N \textgreater{} LI\textsubscript{max}/(B\textsubscript{sat} ×
A\textsubscript{e}) = 100 × 10⁻⁶ × 5 / (0.35 × 1.27 × 10⁻⁴) = 5 × 10⁻⁴ /
4.445 × 10⁻⁵ = 11.2 turns --- round up to N = 12.\\
Air gap length: l\textsubscript{g} = N²μ₀A\textsubscript{e}/L = 12² × 4π
× 10⁻⁷ × 1.27 × 10⁻⁴ / 100 × 10⁻⁶ = 144 × 1.596 × 10⁻¹⁰ / 10⁻⁴ = 2.298 ×
10⁻⁸ / 10⁻⁴ = 0.230 mm.\\
Verify: ℛ\textsubscript{gap} = l\textsubscript{g}/(μ₀A\textsubscript{e})
= 2.3 × 10⁻⁴ / (4π × 10⁻⁷ × 1.27 × 10⁻⁴) = 1.442 × 10⁶ A-turns/Wb.\\
ℛ\textsubscript{core} = l\textsubscript{e}/(μ₀μᵣA\textsubscript{e}) =
0.077 / (4π × 10⁻⁷ × 2500 × 1.27 × 10⁻⁴) = 1.935 × 10⁵ A-turns/Wb.\\
Gap reluctance is 7.5× the core reluctance, confirming the gap
dominates.\\
B\textsubscript{max} = LI\textsubscript{max}/(NA\textsubscript{e}) = 100
× 10⁻⁶ × 5 / (12 × 1.27 × 10⁻⁴) = 0.328 T \textless{} 0.35 T --- the
core operates at 94\% of saturation, providing adequate margin.

\end{examplebox}

\subsection{9.2.7 Eddy Currents and Induction
Heating}\label{eddy-currents-and-induction-heating}

When a time-varying magnetic field penetrates an electrically conductive
material, it induces circulating currents within the conductor called
\textbf{eddy currents}, as described by Faraday's law. These currents
flow in closed loops perpendicular to the magnetic flux and produce I²R
losses (Joule heating) that dissipate energy within the material. Eddy
current losses in transformer and motor cores are proportional to
f²B²t²/ρ (where f is frequency, B is peak flux density, t is lamination
thickness, and ρ is resistivity), which is why magnetic cores are built
from thin laminations (0.35 mm for 60 Hz power transformers, 0.1 mm for
400 Hz aerospace, 25 μm for amorphous metal at 10+ kHz) insulated from
each other to break the eddy current paths, or from high-resistivity
ferrite materials for frequencies above \textasciitilde100 kHz.
\textbf{Induction heating} deliberately exploits eddy current losses: a
work coil carrying high-frequency AC (typically 10 kHz--3 MHz) generates
a concentrated alternating magnetic field that induces intense eddy
currents in a conductive workpiece, heating it from within. The heating
is concentrated near the surface to a depth of approximately one skin
depth δ = √(2ρ/(ωμ)), making induction heating ideal for surface
hardening of steel (at 100--500 kHz, δ ≈ 0.1--0.5 mm), through-heating
of billets for forging (at 1--10 kHz, δ ≈ 2--10 mm), and cooking
(induction cooktops at 20--75 kHz). Induction heating is highly
efficient (80--90\% of input power delivered to the workpiece) because
energy is generated directly in the material without thermal contact
resistance. \textbf{Eddy current non-destructive testing (NDT)} uses a
probe coil to induce eddy currents in a conductive part and detects
changes in the coil impedance caused by surface cracks, subsurface
voids, conductivity variations, or coating thickness differences --- the
eddy currents are disrupted by defects, altering the reflected impedance
measurably.

\begin{examplebox}

\textbf{Example 9.2.7:} An induction cooktop operates at f = 25 kHz and
heats a stainless steel pan (ρ = 7.2 × 10⁻⁷ Ω·m, μ\textsubscript{r} =
600, density = 7,900 kg/m³, specific heat = 500 J/(kg·°C)). The pan
bottom has diameter 200 mm and thickness 3 mm. Calculate the skin depth,
the fraction of pan thickness carrying significant current, and the time
to raise the pan temperature by 100°C if the cooktop delivers 1,800 W to
the pan.

\textbf{Solution:}\\
Skin depth: δ = √(2ρ/(ωμ)) = √(2 × 7.2 × 10⁻⁷ / (2π × 25000 × 600 × 4π ×
10⁻⁷)) = √(1.44 × 10⁻⁶ / (2π × 25000 × 7.540 × 10⁻⁴)) = √(1.44 × 10⁻⁶ /
118.4) = √(1.216 × 10⁻⁸) = 0.110 mm.\\
The pan thickness is 3 mm = 27.2δ, so the eddy currents are concentrated
in the bottom \textasciitilde0.3 mm (3δ, where approximately 95\% of the
induced current flows) --- the surface heats first, then conducts heat
through the pan thickness.\\
Pan mass: m = ρ\textsubscript{density} × V = 7900 × π(0.1)² × 0.003 =
7900 × 9.42 × 10⁻⁵ = 0.744 kg.\\
Energy required: Q = mc × ΔT = 0.744 × 500 × 100 = 37,200 J.\\
Time: t = Q/P = 37,200/1,800 = 20.7 seconds.\\
The ferromagnetic nature of stainless steel (μ\textsubscript{r} = 600)
is critical --- aluminum (μ\textsubscript{r} = 1) would have δ ≈ 0.52 mm
at 25 kHz (about 5× larger than the stainless steel pan), resulting in
less concentrated heating and lower coupling efficiency, which is why
standard induction cooktops require ferromagnetic cookware.

\end{examplebox}

\section{9.3 Maxwell's Equations}\label{maxwells-equations}

Maxwell's equations are the four fundamental laws governing all
classical electromagnetic phenomena, unifying electricity, magnetism,
and light into a single theoretical framework. In differential form,
they describe how charge densities and current densities create and
sustain electric and magnetic fields at every point in space and time.
Together with the Lorentz force law and the constitutive relations
(relating D to E and B to H in materials), Maxwell's equations provide a
complete description of electromagnetic behavior from DC circuits to
optical frequencies.

\subsection{9.3.1 Gauss's Law for
Electricity}\label{gausss-law-for-electricity}

Gauss's Law for electricity states that the electric flux through any
closed surface is proportional to the total charge enclosed: ∮E·dA =
Q\textsubscript{enclosed}/ε₀, or in differential form, ∇·E = ρ/ε₀, where
ρ is the volume charge density. This equation implies that electric
field lines originate and terminate on electric charges, and that a net
outward flux through a closed surface indicates a net positive charge
inside. In the absence of free charges, the divergence of E is zero.
Gauss's Law is one of the four Maxwell's equations and is the
fundamental statement of how electric charges produce electric fields.

\begin{examplebox}

\textbf{Example 9.3.1:} A hollow conducting sphere of radius 10 cm
carries a total charge of Q = +8 nC. Find the electric field at r = 5 cm
(inside) and r = 20 cm (outside).

\textbf{Solution:}\\
By Gauss's Law with a spherical Gaussian surface:\\
Inside (r = 5 cm): The enclosed charge is zero (all charge resides on
the outer surface of a conductor), so E = 0.\\
Outside (r = 20 cm): E × 4πr² = Q/ε₀, so E = Q / (4πε₀r²) = (8.99 ×
10⁹)(8 × 10⁻⁹) / (0.20)² = 71.92 / 0.04 = 1,798 V/m directed radially
outward.

\end{examplebox}

\subsection{9.3.2 Gauss's Law for
Magnetism}\label{gausss-law-for-magnetism}

Gauss's Law for magnetism states that the magnetic flux through any
closed surface is always zero: ∮B·dA = 0, or in differential form, ∇·B =
0. This equation reflects the experimental observation that magnetic
monopoles do not exist --- every magnetic field line that enters a
closed surface must also exit it. Magnetic field lines always form
continuous closed loops, whether produced by permanent magnets or by
currents. This is in contrast to electric field lines, which begin on
positive charges and end on negative charges.

\begin{examplebox}

\textbf{Example 9.3.2:} A bar magnet is placed inside a closed cubical
box with sides of 20 cm. The magnetic flux entering through three faces
is Φ₁ = 0.5 mWb, Φ₂ = 0.3 mWb, and Φ₃ = 0.8 mWb. If the flux through two
other faces is Φ₄ = -0.4 mWb and Φ₅ = -0.6 mWb (outgoing), find the flux
through the sixth face.

\textbf{Solution:}\\
By Gauss's Law for magnetism, the total flux through any closed surface
is zero: Φ₁ + Φ₂ + Φ₃ + Φ₄ + Φ₅ + Φ₆ = 0.\\
Defining incoming as positive: 0.5 + 0.3 + 0.8 + (-0.4) + (-0.6) + Φ₆ =
0, so 0.6 + Φ₆ = 0, giving Φ₆ = -0.6 mWb (outgoing through face 6).\\
The net outgoing flux equals the net incoming flux, as required.

\end{examplebox}

\subsection{9.3.3 Faraday's Law of
Induction}\label{faradays-law-of-induction}

Faraday's Law states that a time-varying magnetic flux through a circuit
induces an electromotive force (EMF) equal to the negative rate of
change of the flux: EMF = -dΦ/dt, or in differential form, ∇ × E =
-∂B/∂t. The negative sign (Lenz's Law) indicates that the induced EMF
opposes the change in flux that produced it, which is a consequence of
conservation of energy. Faraday's Law is the operating principle behind
transformers, electric generators, and induction motors, where relative
motion between conductors and magnetic fields converts between
mechanical and electrical energy. It also explains how a time-varying
magnetic field produces an electric field, which is essential for
electromagnetic wave propagation.

\begin{examplebox}

\textbf{Example 9.3.3:} A circular loop of wire with radius 8 cm and 50
turns is placed in a magnetic field that decreases uniformly from 0.6 T
to 0.2 T in 10 ms. Find the induced EMF.

\textbf{Solution:}\\
The area of the loop: A = πr² = π(0.08)² = 0.02011 m².\\
The change in flux per turn: ΔΦ = ΔB × A = (0.6 - 0.2) × 0.02011 = 0.4 ×
0.02011 = 8.044 × 10⁻³ Wb.\\
The induced EMF: \textbar EMF\textbar{} = N × \textbar ΔΦ/Δt\textbar{} =
50 × (8.044 × 10⁻³) / (10 × 10⁻³) = 50 × 0.8044 = 40.22 V.\\
By Lenz's Law, the induced current flows in a direction that creates a
magnetic field opposing the decrease (i.e., in the same direction as the
original field).

\end{examplebox}

\subsection{9.3.4 Ampère-Maxwell Law}\label{ampuxe8re-maxwell-law}

The Ampère-Maxwell Law is the generalization of Ampère's Law that
includes Maxwell's displacement current: ∮B·dl =
μ₀(I\textsubscript{enclosed} + ε₀ dΦ\textsubscript{E}/dt), or in
differential form, ∇ × B = μ₀J + μ₀ε₀(∂E/∂t). The displacement current
term ε₀(∂E/∂t) accounts for the magnetic field produced by a
time-varying electric field, even in the absence of conduction current.
This addition was Maxwell's key insight: it completed the symmetry
between electric and magnetic fields (a changing B produces E via
Faraday's Law, and a changing E produces B via the displacement current)
and predicted the existence of electromagnetic waves traveling at the
speed of light, c = 1/√(μ₀ε₀).

\begin{examplebox}

\textbf{Example 9.3.4:} A parallel-plate capacitor with plate area A =
0.01 m² has an electric field increasing at a rate of dE/dt = 5 × 10¹²
V/(m·s). Find the displacement current between the plates.

\textbf{Solution:}\\
The displacement current is I\textsubscript{d} = ε₀ × A × (dE/dt) =
(8.854 × 10⁻¹²)(0.01)(5 × 10¹²) = 8.854 × 10⁻¹² × 5 × 10¹⁰ = 0.4427 A ≈
443 mA.\\
This displacement current produces the same magnetic field around the
capacitor as if a conduction current of 443 mA were flowing between the
plates, maintaining continuity of current in the circuit.

\end{examplebox}

\subsection{9.3.5 Electromagnetic Boundary
Conditions}\label{electromagnetic-boundary-conditions}

When electromagnetic fields encounter an interface between two different
media, the fields must satisfy boundary conditions derived from
Maxwell's equations in integral form. These conditions govern how field
components change across the boundary and are essential for solving
reflection, refraction, waveguide, and shielding problems. The four
boundary conditions are: (1) the tangential component of E is
continuous, n̂ × (E₂ − E₁) = 0 (from Faraday's law); (2) the tangential
component of H is discontinuous by the surface current density, n̂ × (H₂
− H₁) = J\textsubscript{s} (from Ampère's law); (3) the normal component
of D is discontinuous by the surface charge density, n̂ · (D₂ − D₁) =
ρ\textsubscript{s} (from Gauss's law for electricity); and (4) the
normal component of B is continuous, n̂ · (B₂ − B₁) = 0 (from Gauss's law
for magnetism). At a \textbf{perfect electric conductor (PEC)} surface,
the tangential E-field is zero and the tangential H-field equals the
surface current: E\textsubscript{tan} = 0 and H\textsubscript{tan} =
J\textsubscript{s}. These conditions explain why current flows on the
surface of a conductor, why waveguide modes have specific field patterns
at the walls, and why an electromagnetic wave reflecting from a PEC
undergoes a 180° phase reversal of the electric field. At a
\textbf{dielectric-dielectric interface} with no free charge or current
(ρ\textsubscript{s} = 0, J\textsubscript{s} = 0), both
E\textsubscript{tan} and H\textsubscript{tan} are continuous, while the
normal components obey ε₁E\textsubscript{n1} = ε₂E\textsubscript{n2} and
μ₁H\textsubscript{n1} = μ₂H\textsubscript{n2}. These conditions,
combined with the wave equation, yield Snell's law of refraction and the
Fresnel reflection coefficients for oblique incidence.

\begin{examplebox}

\textbf{Example 9.3.5:} A 1 GHz electromagnetic wave propagates in free
space (μ₁ = μ₀, ε₁ = ε₀) and strikes a ferrite-loaded absorber material
(μ₂ = 5μ₀, ε₂ = 12ε₀) at normal incidence. The incident magnetic field
has a tangential amplitude of H\textsubscript{i} = 10 mA/m. Find the
tangential H and E fields on both sides of the boundary, and the surface
current density if the ferrite were replaced by a PEC.

\textbf{Solution:}\\
For the dielectric interface (no surface current), the tangential H is
continuous: H\textsubscript{tan,1} = H\textsubscript{tan,2}.\\
The total tangential H on side 1 is the sum of incident and reflected
fields.\\
The intrinsic impedances are η₁ = √(μ₀/ε₀) = 377 Ω and η₂ = √(5μ₀/12ε₀)
= 377√(5/12) = 377 × 0.6455 = 243.4 Ω.\\
The reflection coefficient is Γ = (η₂ − η₁)/(η₂ + η₁) = (243.4 −
377)/(243.4 + 377) = −133.6/620.4 = −0.2153.\\
The tangential E at the boundary: E\textsubscript{tan} =
η₁H\textsubscript{i}(1 + Γ) = 377 × 0.01 × (1 − 0.2153) = 377 × 0.01 ×
0.7847 = 2.958 V/m (continuous across boundary).\\
The tangential H at the boundary: H\textsubscript{tan} =
H\textsubscript{i}(1 − Γ) = 0.01 × (1 − (−0.2153)) = 0.01 × 1.2153 =
12.15 mA/m (continuous).\\
Verification: E\textsubscript{tan}/H\textsubscript{tan} = 2.958/0.01215
= 243.5 Ω ≈ η₂, confirming the transmitted wave impedance.\\
If replaced by a PEC: E\textsubscript{tan} = 0 (Γ = −1), and the surface
current density is J\textsubscript{s} = n̂ × H\textsubscript{tan} =
2H\textsubscript{i} = 20 mA/m (the incident and reflected H-fields add
at the PEC surface).

\end{examplebox}

\subsection{9.3.6 Electromagnetic
Potentials}\label{electromagnetic-potentials}

The electromagnetic potentials --- the magnetic vector potential
\textbf{A} and the electric scalar potential φ --- provide an
alternative formulation of Maxwell's equations that simplifies the
calculation of fields from known source distributions and is essential
for antenna theory, radiation problems, and quantum electrodynamics.
Since ∇ · B = 0 always holds, B can be expressed as the curl of a vector
potential: B = ∇ × A. Substituting into Faraday's law gives ∇ × (E +
∂A/∂t) = 0, which means E + ∂A/∂t is irrotational and can be written as
the gradient of a scalar: E = −∇φ − ∂A/∂t. The potentials are not unique
--- a \textbf{gauge transformation} A → A + ∇ψ, φ → φ − ∂ψ/∂t leaves the
physical fields E and B unchanged for any scalar function ψ. This
freedom is exploited by choosing a gauge that simplifies the equations.

The \textbf{Lorenz gauge} ∇ · A + με(∂φ/∂t) = 0 decouples the equations
for A and φ into two independent inhomogeneous wave equations: ∇²A −
με(∂²A/∂t²) = −μJ and ∇²φ − με(∂²φ/∂t²) = −ρ/ε, where J is the current
density and ρ is the charge density. These are solved by the
\textbf{retarded potentials}, which account for the finite propagation
speed of electromagnetic effects: A(r, t) = (μ/4π) ∫ J(r′, t −
\textbar r − r′\textbar/v) / \textbar r − r′\textbar{} dV′, where the
source current is evaluated at the retarded time t\textsubscript{r} = t
− \textbar r − r′\textbar/v (the time at which the signal left the
source to arrive at the observation point at time t). The
\textbf{Coulomb gauge} ∇ · A = 0 makes φ satisfy the instantaneous
Poisson equation ∇²φ = −ρ/ε (no retardation for the scalar potential),
which is useful in electrostatics and circuit-level analysis but
complicates the vector potential equation.

For a \textbf{magnetic dipole} (small current loop of area A carrying
current I), the vector potential at far distances simplifies to A = (μ₀
m sin θ)/(4πr²) φ̂, where m = IA is the magnetic moment. This leads
directly to the familiar dipole radiation fields used in antenna theory.
For a \textbf{Hertzian dipole} (short current element of length dl
carrying current I₀e\textsuperscript{jωt}), the retarded vector
potential yields the complete near-field and far-field expressions, from
which the radiation pattern, radiation resistance, and directivity of
all wire antennas are derived.

\begin{examplebox}

\textbf{Example 9.3.6:} A short current element (Hertzian dipole) of
length dl = 0.05λ carries a peak current I₀ = 2 A at frequency f = 300
MHz. Using the vector potential formulation, calculate (a) the radiation
resistance, (b) the radiated power, and (c) the maximum electric field
magnitude at a distance of 1 km.

\textbf{Solution:}

(a) Radiation resistance of a Hertzian dipole:\\
R\textsubscript{rad} = 80π²(dl/λ)² = 80π²(0.05)² = 80 × 9.8696 × 0.0025
= \textbf{1.974 Ω}

(b) Radiated power:\\
P\textsubscript{rad} = ½I₀²R\textsubscript{rad} = 0.5 × 4 × 1.974 =
\textbf{3.95 W}

(c) Maximum electric field at r = 1 km:\\
The far-field electric field of a Hertzian dipole is maximum at θ =
90°:\\
\textbar E\textsubscript{max}\textbar{} = (η₀ I₀ dl) / (2λr) = (377 × 2
× 0.05λ) / (2λ × 1000)\\
= (377 × 0.1) / 2000 = 37.7 / 2000 = \textbf{18.85 mV/m}

Verification via Poynting vector: S\textsubscript{max} = E²/(2η₀) =
(0.01885)²/(2 × 377) = 3.553 × 10⁻⁴ / 754 = 4.71 × 10⁻⁷ W/m². Total
radiated power: P = S\textsubscript{max} × 4πr² / 1.5 (directivity D =
1.5 for a Hertzian dipole) = 4.71 × 10⁻⁷ × 4π × 10⁶ / 1.5 = 3.96 W ---
consistent with part (b).

\end{examplebox}

\section{9.4 Electromagnetic Waves}\label{electromagnetic-waves}

Electromagnetic waves are self-sustaining oscillations of coupled
electric and magnetic fields that propagate through space at the speed
of light. Predicted by Maxwell's equations and experimentally confirmed
by Heinrich Hertz in 1887, electromagnetic waves span an enormous
frequency range from ELF radio waves to gamma rays, enabling
technologies from broadcast radio and cellular communications to radar,
medical imaging, and fiber optics. Understanding wave propagation, the
electromagnetic spectrum, polarization, and the interaction of waves
with materials is essential for designing antennas, transmission
systems, and shielding.

\subsection{9.4.1 Wave Equation}\label{wave-equation}

The electromagnetic wave equation is derived from Maxwell's equations in
a source-free region, yielding ∇²E = μ₀ε₀(∂²E/∂t²) for the electric
field and an identical equation for the magnetic field. This
second-order partial differential equation has solutions in the form of
traveling waves propagating at velocity v = 1/√(με), which in free space
equals the speed of light c ≈ 3 × 10⁸ m/s. In a plane wave, the electric
and magnetic fields are perpendicular to each other and to the direction
of propagation, forming a transverse electromagnetic (TEM) wave. The
ratio of the electric field magnitude to the magnetic field magnitude is
the intrinsic impedance of the medium: η = √(μ/ε), which equals η₀ ≈ 377
Ω in free space.

\begin{examplebox}

\textbf{Example 9.4.1:} An electromagnetic wave propagates through a
non-magnetic dielectric with εᵣ = 2.25 and μᵣ = 1. Find the wave
velocity, the intrinsic impedance, and the wavelength at 1 GHz.

\textbf{Solution:}\\
Wave velocity: v = c / √(εᵣμᵣ) = 3 × 10⁸ / √2.25 = 3 × 10⁸ / 1.5 = 2 ×
10⁸ m/s.\\
Intrinsic impedance: η = η₀ / √(εᵣ) = 377 / 1.5 = 251.3 Ω.\\
Wavelength at 1 GHz: λ = v / f = 2 × 10⁸ / 10⁹ = 0.2 m = 20 cm.\\
Compared to free space (λ₀ = 30 cm), the wavelength is shorter by a
factor of √εᵣ = 1.5.

\end{examplebox}

\subsection{9.4.2 Electromagnetic
Spectrum}\label{electromagnetic-spectrum}

The electromagnetic spectrum encompasses all electromagnetic waves
ordered by frequency (or equivalently, wavelength), from extremely low
frequency (ELF) radio waves to gamma rays. Radio waves (3 kHz to 300
GHz) are used for broadcasting, cellular communications, Wi-Fi, radar,
and satellite links. Microwaves (300 MHz to 300 GHz) overlap with radio
and are used in point-to-point communications, microwave ovens, and
radar systems. Infrared radiation (300 GHz to 400 THz) is used in
thermal imaging, fiber optic communications, and remote controls.
Visible light (400-790 THz) is the narrow band detectable by the human
eye. Ultraviolet, X-rays, and gamma rays occupy progressively higher
frequencies and are used in medical imaging, sterilization, and
scientific instrumentation. All electromagnetic waves travel at the
speed of light in vacuum and obey the relationship c = fλ, where f is
frequency and λ is wavelength.

\begin{examplebox}

\textbf{Example 9.4.2:} A 5G cellular system operates at a frequency of
28 GHz (millimeter wave). Find the wavelength in free space and classify
the region of the electromagnetic spectrum.

\textbf{Solution:}\\
λ = c / f = (3 × 10⁸) / (28 × 10⁹) = 1.071 × 10⁻² m = 10.71 mm.\\
This falls at the boundary of the centimeter-wave and millimeter-wave
regions of the microwave spectrum (wavelengths between 1 mm and 10 mm
correspond to 30--300 GHz).\\
At 28 GHz, the wavelength is just above 10 mm, placing it at the
boundary between centimeter-wave and millimeter-wave bands, which is why
5G mmWave communications require highly directional antennas and suffer
greater atmospheric attenuation than lower-frequency bands.

\end{examplebox}

\subsection{9.4.3 Polarization}\label{polarization}

Polarization describes the orientation of the electric field vector of
an electromagnetic wave as it propagates through space. In linear
polarization, the electric field oscillates in a single plane
(horizontal or vertical relative to a reference). In circular
polarization, the electric field vector rotates at the wave frequency,
tracing a circle when viewed along the direction of propagation; it is
right-hand circular (RHCP) or left-hand circular (LHCP) depending on the
rotation direction. Elliptical polarization is the general case where
the tip of the electric field vector traces an ellipse. Polarization is
critical in antenna design (an antenna must be matched to the
polarization of the incoming wave for maximum reception), optical
systems, radar (circular polarization helps reject rain clutter), and
display technologies.

\begin{examplebox}

\textbf{Example 9.4.3:} A vertically polarized antenna receives a signal
from a linearly polarized transmitter whose polarization is tilted 30°
from vertical. If the incident wave has a power density of 2 μW/m², find
the polarization loss factor and the effective received power density.

\textbf{Solution:}\\
The polarization loss factor (PLF) is cos²(θ), where θ is the angle
between the antenna polarization and the wave polarization.\\
PLF = cos²(30°) = (√3/2)² = 3/4 = 0.75.\\
The effective received power density is S\textsubscript{eff} = PLF ×
S\textsubscript{incident} = 0.75 × 2 μW/m² = 1.5 μW/m².\\
The polarization mismatch causes a loss of 10 × log₁₀(0.75) = -1.25 dB,
meaning 25\% of the available power is lost due to the polarization
misalignment.

\end{examplebox}

\subsection{9.4.4 Skin Effect}\label{skin-effect}

When an electromagnetic wave impinges on a conductor (or when
alternating current flows through a conductor), the fields and current
density are confined to a thin layer near the surface, a phenomenon
known as the skin effect. The skin depth δ = √(2/(ωμσ)) = 1/√(πfμσ) is
the distance at which the field amplitude decays to 1/e (36.8\%) of its
surface value, where f is the frequency, μ is the permeability, and σ is
the conductivity of the material. At 60 Hz in copper (σ = 5.8 × 10⁷
S/m), the skin depth is approximately 8.5 mm, so current distributes
relatively uniformly through typical wire cross-sections. At 1 MHz, δ ≈
0.066 mm (66 μm), and at 1 GHz, δ ≈ 2.1 μm --- meaning current flows
only in a microscopically thin surface layer. The skin effect increases
the effective AC resistance of conductors (R\textsubscript{AC}
\textgreater{} R\textsubscript{DC}) because the current is confined to a
smaller cross-sectional area. This is why high-frequency conductors use
stranded wire (Litz wire), hollow tubes, or surface plating (silver or
gold over copper) to minimize losses. In electromagnetic shielding, a
conductor thickness of 5δ provides approximately 99.3\% attenuation
(about 43 dB) of an incident wave.

\begin{examplebox}

\textbf{Example 9.4.4:} Calculate the skin depth in copper (σ = 5.8 ×
10⁷ S/m, μᵣ = 1) at frequencies of 60 Hz, 1 MHz, and 10 GHz. For a 1 mm
diameter copper wire at 1 MHz, estimate the ratio of AC to DC
resistance.

\textbf{Solution:}\\
Skin depth formula: δ = 1/√(πfμ₀σ) = 1/√(π × f × 4π × 10⁻⁷ × 5.8 ×
10⁷).\\
At 60 Hz: δ = 1/√(π × 60 × 4π × 10⁻⁷ × 5.8 × 10⁷) = 1/√(π × 60 × 72.88)
= 1/√(13,738) = 8.53 mm.\\
At 1 MHz: δ = 1/√(π × 10⁶ × 72.88) = 1/√(2.289 × 10⁸) = 66.1 μm.\\
At 10 GHz: δ = 1/√(π × 10¹⁰ × 72.88) = 1/√(2.289 × 10¹²) = 0.661 μm.\\
For a 1 mm diameter wire (radius a = 0.5 mm) at 1 MHz where δ = 66.1 μm
\textless\textless{} a, the current flows in an annular ring of
thickness δ.\\
R\textsubscript{AC}/R\textsubscript{DC} ≈ a/(2δ) = 500/132.2 = 3.78.\\
The AC resistance is nearly 4× the DC resistance due to the skin effect.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-9-4-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch09_skin_depth.png}

\caption{Figure 9.4.4: Skin Depth vs Frequency}

\end{figure}

\subsection{9.4.5 Wave Reflection and Transmission at
Interfaces}\label{wave-reflection-and-transmission-at-interfaces}

When an electromagnetic wave traveling in one medium encounters the
boundary with a second medium of different electromagnetic properties,
part of the wave energy is reflected and part is transmitted. At
\textbf{normal incidence} on the boundary between two lossless
dielectric media with intrinsic impedances η₁ and η₂, the reflection
coefficient is Γ = (η₂ - η₁)/(η₂ + η₁) and the transmission coefficient
is τ = 2η₂/(η₁ + η₂). The fraction of incident power reflected is
\textbar Γ\textbar² and the fraction transmitted is 1 -
\textbar Γ\textbar² = 4η₁η₂/(η₁ + η₂)². For a wave in air (η₁ = 377 Ω)
striking glass (η₂ = 377/√ε\textsubscript{r}), a significant fraction is
reflected --- this is the physical basis for anti-reflection coatings
(§18.2.1). For oblique incidence, the Fresnel equations describe the
reflection and transmission coefficients as functions of angle and
polarization: the reflection coefficient for parallel (TM) polarization
vanishes at Brewster's angle θ\textsubscript{B} = arctan(n₂/n₁), while
perpendicular (TE) polarization has no such zero. At a perfect conductor
(η₂ = 0), the reflection coefficient is Γ = -1 (total reflection with
180° phase reversal), and the boundary condition requires the tangential
electric field to be zero at the surface --- the superposition of
incident and reflected waves forms a standing wave with the first
E-field node at the surface. This standing wave pattern is exploited in
cavity resonators, waveguide terminations, and microwave heating
(standing wave ovens).

\begin{examplebox}

\textbf{Example 9.4.5:} A 10 GHz plane wave in free space (η₁ = 377 Ω)
is normally incident on a semi-infinite slab of lossless dielectric with
ε\textsubscript{r} = 9 and μ\textsubscript{r} = 1. Calculate the
intrinsic impedance of the dielectric, the reflection and transmission
coefficients, and the percentage of power reflected and transmitted.

\textbf{Solution:}\\
Intrinsic impedance of the dielectric: η₂ = η₀/√ε\textsubscript{r} =
377/√9 = 377/3 = 125.7 Ω.\\
Reflection coefficient: Γ = (η₂ - η₁)/(η₂ + η₁) = (125.7 - 377)/(125.7 +
377) = -251.3/502.7 = -0.50.\\
Transmission coefficient: τ = 2η₂/(η₁ + η₂) = 2 × 125.7/502.7 =
251.4/502.7 = 0.50.\\
Power reflected: \textbar Γ\textbar² = 0.25 = 25\%.\\
Power transmitted: 1 - \textbar Γ\textbar² = 0.75 = 75\%.\\
Verification: the transmitted power can also be calculated as
(η₁/η₂)\textbar τ\textbar² = (377/125.7) × 0.25 = 3.0 × 0.25 = 0.75 =
75\%.\\
The negative sign of Γ indicates a 180° phase reversal of the reflected
E-field, which occurs because the wave enters a denser medium (higher ε,
lower η).

\end{examplebox}

\subsection{9.4.6 Poynting Vector and Electromagnetic Power
Flow}\label{poynting-vector-and-electromagnetic-power-flow}

The Poynting vector S = E × H describes the instantaneous power flow per
unit area (W/m²) of an electromagnetic wave, with its direction
indicating the direction of energy propagation. For a plane wave in a
lossless medium, the electric and magnetic fields are perpendicular to
each other and to the propagation direction, and the time-averaged
Poynting vector is S\textsubscript{avg} = ½Re\{E × H*\} =
\textbar E₀\textbar²/(2η) = ½η\textbar H₀\textbar², where η is the
intrinsic impedance of the medium. The total power radiated by an
antenna or passing through a surface is obtained by integrating the
Poynting vector over that surface: P = ∮S·dA. For a point source
radiating isotropically with total power P\textsubscript{t}, the power
density at distance r is S = P\textsubscript{t}/(4πr²), which defines
the inverse-square law for power decay with distance. The
\textbf{radiation intensity} U(θ, φ) = r²S(r, θ, φ) is the power per
unit solid angle (W/sr), independent of distance, and provides a
convenient measure of the angular distribution of radiated power. The
Poynting vector also applies to guided waves: in a coaxial transmission
line, the power flows in the dielectric between the conductors (not in
the conductors themselves), with S directed axially and concentrated
near the inner conductor where E and H are strongest. In a waveguide,
the power flow pattern follows the mode structure, and the total
transmitted power is obtained by integrating S over the guide
cross-section.

\begin{examplebox}

\textbf{Example 9.4.6:} A 10 GHz radar transmitter radiates 1 kW through
an antenna with a gain of 30 dBi. Calculate the peak power density at a
distance of 5 km, the electric field strength at that distance, and
compare to the ICNIRP occupational exposure limit of 50 W/m² for
frequencies above 2 GHz.

\textbf{Solution:}\\
Antenna gain in linear: G = 10\textsuperscript{30/10} = 1000.\\
Peak power density: S = P\textsubscript{t}G/(4πr²) = 1000 × 1000 / (4π ×
(5000)²) = 10⁶ / (4π × 2.5 × 10⁷) = 10⁶ / 3.1416 × 10⁸ = 3.18 × 10⁻³
W/m² = 3.18 mW/m².\\
Electric field: S = E²/(2η₀), so E = √(2η₀S) = √(2 × 377 × 3.18 × 10⁻³)
= √(2.396) = 1.55 V/m.\\
The power density of 3.18 mW/m² is well below the 50 W/m² ICNIRP limit
--- by a factor of 15,700 (42 dB).\\
The minimum safe distance where S = 50 W/m²: r =
√(P\textsubscript{t}G/(4πS\textsubscript{limit})) = √(10⁶/(4π × 50)) =
√(1592) = 39.9 m.\\
Personnel should not stand within 40 m of the antenna main beam during
transmission.

\end{examplebox}

\subsection{9.4.7 Wave Propagation in Lossy
Media}\label{wave-propagation-in-lossy-media}

When an electromagnetic wave propagates through a lossy medium --- one
with finite conductivity σ or dielectric loss tangent tan δ --- the wave
is attenuated exponentially as it travels, described by the complex
propagation constant γ = α + jβ, where α is the attenuation constant
(Np/m) and β is the phase constant (rad/m). In a general medium with
complex permittivity ε\textsubscript{c} = ε′ − jε″ = ε′(1 − j tan δ),
where ε″ = σ/ω + ε′ tan δ accounts for both conduction losses and
dielectric polarization losses, the propagation constant is γ =
jω√(με\textsubscript{c}). For a \textbf{good conductor} (σ
\textgreater\textgreater{} ωε, i.e., conduction current dominates
displacement current), α ≈ β ≈ √(πfμσ) = 1/δ, and the wave attenuates by
1/e (8.686 dB) per skin depth --- this is the basis of electromagnetic
shielding and the skin effect. For a \textbf{low-loss dielectric} (σ
\textless\textless{} ωε, tan δ \textless\textless{} 1), α ≈ (ω/2)√(με) ×
tan δ = (π f tan δ √(ε\textsubscript{r}))/c, and the wave propagates
with modest attenuation that increases linearly with frequency and loss
tangent --- critical for selecting PCB substrate materials, radome
designs, and fiber optic cladding. The \textbf{loss tangent} tan δ =
ε″/ε′ is the figure of merit for dielectric loss: FR-4 PCB material has
tan δ ≈ 0.02 (acceptable below \textasciitilde1 GHz), Rogers RO4003C has
tan δ ≈ 0.0027 (suitable to 10+ GHz), and fused silica has tan δ ≈
0.0001 (used in precision RF windows). In biological tissue, which has
both significant conductivity and dielectric loss, electromagnetic wave
penetration depth varies dramatically with frequency: at 900 MHz
(cellular), the penetration depth in muscle tissue is \textasciitilde4
cm, dropping to \textasciitilde2 cm at 2.4 GHz (Wi-Fi) and
\textasciitilde0.5 mm at 60 GHz (5G mmWave), which is why
millimeter-wave radiation is absorbed almost entirely by the skin
surface. The specific absorption rate (SAR) quantifies the rate of
energy absorption in tissue: SAR = σ\textbar E\textbar²/(2ρ) (W/kg),
regulated to ≤ 1.6 W/kg (FCC) or ≤ 2.0 W/kg (ICNIRP) averaged over 1 g
or 10 g of tissue, respectively.

\begin{examplebox}

\textbf{Example 9.4.7:} A 5 GHz Wi-Fi signal propagates through a
concrete wall (ε\textsubscript{r} = 6.0, tan δ = 0.04,
μ\textsubscript{r} = 1) with thickness 200 mm. Calculate the attenuation
constant, the total attenuation through the wall (in dB), and compare to
a dry plywood wall (ε\textsubscript{r} = 2.0, tan δ = 0.01, thickness 12
mm).

\textbf{Solution:}\\
For the low-loss dielectric approximation (tan δ \textless\textless{}
1): α = (πf tan δ √ε\textsubscript{r}) / c = (π × 5 × 10⁹ × 0.04 × √6.0)
/ (3 × 10⁸) = (π × 5 × 10⁹ × 0.04 × 2.449) / (3 × 10⁸) = (1.539 × 10⁹) /
(3 × 10⁸) = 5.13 Np/m.\\
Attenuation through 200 mm: A = α × d = 5.13 × 0.2 = 1.026 Np = 1.026 ×
8.686 = 8.91 dB.\\
Adding reflection loss at both air-concrete interfaces: Γ = (η₂ −
η₁)/(η₂ + η₁) = (377/√6 − 377)/(377/√6 + 377) = (153.9 − 377)/(153.9 +
377) = −0.420, so reflection loss per surface = −10 log₁₀(1 − 0.420²) =
−10 log₁₀(0.824) = 0.84 dB, total reflection = 1.68 dB.\\
Total wall loss ≈ 8.91 + 1.68 = 10.6 dB.\\
For the plywood wall: α = (π × 5 × 10⁹ × 0.01 × √2.0) / (3 × 10⁸) =
(2.22 × 10⁸) / (3 × 10⁸) = 0.74 Np/m.\\
Attenuation: 0.74 × 0.012 = 0.0089 Np = 0.077 dB.\\
With minimal reflection loss (\textasciitilde0.3 dB total), the plywood
wall attenuates by only \textasciitilde0.4 dB --- essentially
transparent.\\
This explains why concrete walls severely degrade Wi-Fi coverage while
wood-frame construction does not.

\end{examplebox}

\section{9.5 Transmission Lines}\label{transmission-lines-1}

Transmission lines are structures designed to guide electromagnetic
energy from a source to a load with controlled impedance and minimal
loss. Unlike ordinary wires at DC or low frequencies, transmission lines
at RF and microwave frequencies exhibit wave behavior --- signals
propagate as voltage and current waves with finite velocity, and
impedance mismatches cause reflections that can degrade performance or
damage equipment. Understanding characteristic impedance, reflection,
standing waves, and impedance matching is essential for RF circuit
design, antenna feed systems, high-speed digital interconnects, and
power delivery networks.

\subsection{9.5.1 Characteristic
Impedance}\label{characteristic-impedance}

The characteristic impedance Z₀ of a transmission line is the ratio of
voltage to current for a wave traveling in one direction along the line,
determined by the line's distributed inductance and capacitance per unit
length: Z₀ = √(L'/C'), where L' and C' are the inductance and
capacitance per unit length. For a coaxial cable, Z₀ = (1/2π)√(μ/ε) ·
ln(b/a), where a and b are the inner and outer conductor radii. Common
transmission line impedances include 50 Ω (RF and test equipment), 75 Ω
(video and cable TV), and 100 Ω (differential data lines). When a
transmission line is terminated in a load equal to Z₀, all power is
delivered to the load with no reflections -- the matched condition.

\begin{examplebox}

\textbf{Example 9.5.1:} A coaxial cable has inner conductor radius a =
0.5 mm, outer conductor radius b = 2.3 mm, and a dielectric with εᵣ =
2.3 and μᵣ = 1. Find the characteristic impedance.

\textbf{Solution:}\\
Z₀ = (1/(2π)) × √(μ/ε) × ln(b/a) = (1/(2π)) × (η₀/√εᵣ) × ln(b/a) =
(1/(2π)) × (377/√2.3) × ln(2.3/0.5) = (1/(2π)) × (377/1.517) × ln(4.6) =
(1/6.2832) × 248.5 × 1.526 = (1/6.2832) × 379.2 = 60.35 Ω.\\
This is close to the standard 50 Ω coaxial impedance; adjusting the
ratio b/a or the dielectric constant would achieve exactly 50 Ω.

\end{examplebox}

\subsection{9.5.2 Reflection and Standing
Waves}\label{reflection-and-standing-waves}

When a transmission line is terminated in a load impedance
Z\textsubscript{L} that differs from the characteristic impedance Z₀, a
portion of the incident wave is reflected back toward the source. The
reflection coefficient Γ = (Z\textsubscript{L} - Z₀)/(Z\textsubscript{L}
+ Z₀) quantifies the fraction of the incident voltage wave that is
reflected, ranging from -1 (short circuit) through 0 (matched load) to
+1 (open circuit). The interaction of the forward and reflected waves
creates a standing wave pattern with fixed positions of voltage maxima
and minima along the line. The Voltage Standing Wave Ratio (VSWR) = (1 +
\textbar Γ\textbar)/(1 - \textbar Γ\textbar) is a common measure of
impedance mismatch, with VSWR = 1 indicating a perfect match. Minimizing
reflections is essential in RF systems to maximize power transfer and
prevent damage to transmitters.

\begin{examplebox}

\textbf{Example 9.5.2:} A 50 Ω transmission line is terminated with a 75
Ω load. Find the reflection coefficient, VSWR, and the fraction of
incident power reflected.

\textbf{Solution:}\\
Reflection coefficient: Γ = (Z\textsubscript{L} - Z₀) /
(Z\textsubscript{L} + Z₀) = (75 - 50) / (75 + 50) = 25/125 = 0.2.\\
VSWR = (1 + \textbar Γ\textbar) / (1 - \textbar Γ\textbar) = (1 + 0.2) /
(1 - 0.2) = 1.2 / 0.8 = 1.5:1.\\
Fraction of power reflected: \textbar Γ\textbar² = (0.2)² = 0.04 =
4\%.\\
Therefore 96\% of the incident power is delivered to the load.\\
The return loss is -20 × log₁₀(\textbar Γ\textbar) = -20 × log₁₀(0.2) =
13.98 dB.

\end{examplebox}

\subsection{9.5.3 Smith Chart}\label{smith-chart}

The Smith Chart is a graphical tool that maps the complex impedance
plane onto a polar plot, enabling visual analysis of transmission line
impedance matching, reflection coefficients, and VSWR. The chart plots
normalized impedance z = Z/Z₀ using circles of constant resistance and
arcs of constant reactance, with the center representing a perfect match
(z = 1 + j0). Moving along the transmission line toward the generator
corresponds to clockwise rotation on the Smith Chart, with one full
revolution representing a half-wavelength of line. The Smith Chart is
used to design impedance matching networks (using series/shunt reactive
elements or transmission line stubs), determine the input impedance of a
terminated line, and convert between impedance and admittance
representations. Despite the availability of computational tools, the
Smith Chart remains widely taught and used because it provides intuitive
visualization of impedance transformation and matching.

\begin{examplebox}

\textbf{Example 9.5.3:} An antenna with input impedance
Z\textsubscript{L} = 25 - j30 Ω is connected to a 50 Ω transmission
line. Find the normalized impedance and locate it on the Smith Chart.

\textbf{Solution:}\\
Normalized impedance: z = Z\textsubscript{L} / Z₀ = (25 - j30) / 50 =
0.5 - j0.6.\\
On the Smith Chart, this point lies at the intersection of the r = 0.5
constant-resistance circle and the x = -0.6 constant-reactance arc (in
the lower half, indicating capacitive reactance).\\
The reflection coefficient magnitude is \textbar Γ\textbar{} =
\textbar z - 1\textbar{} / \textbar z + 1\textbar{} = \textbar(0.5 -
j0.6) - 1\textbar{} / \textbar(0.5 - j0.6) + 1\textbar{} = \textbar(-0.5
- j0.6)\textbar{} / \textbar(1.5 - j0.6)\textbar{} = √(0.25 + 0.36) /
√(2.25 + 0.36) = 0.7810 / 1.6155 = 0.483.\\
VSWR = (1 + 0.483) / (1 - 0.483) = 2.87:1.

\end{examplebox}

\subsection{9.5.4 Waveguides}\label{waveguides}

A waveguide is a hollow metallic structure (typically rectangular or
circular cross-section) that guides electromagnetic waves by confining
them within the conducting walls, without requiring a center conductor.
Waveguides operate above a cutoff frequency f\textsubscript{c}
determined by their cross-sectional dimensions; below this frequency,
waves cannot propagate and are exponentially attenuated (evanescent
modes). For a rectangular waveguide with interior dimensions a × b (a
\textgreater{} b), the cutoff frequency of the TE\textsubscript{mn} mode
is f\textsubscript{c} = (c/2)√((m/a)² + (n/b)²), where m and n are mode
indices. The dominant mode (lowest cutoff) is the TE₁₀ mode with
f\textsubscript{c} = c/(2a). Waveguides are preferred over coaxial
cables at microwave and millimeter-wave frequencies because they have
lower loss (no center conductor, current flows on inner surfaces only),
higher power handling capability, and no radiation leakage. Standard
waveguide sizes are designated by WR (waveguide rectangular) numbers ---
for example, WR-90 (22.86 × 10.16 mm) covers the X-band (8.2--12.4 GHz).
Waveguides are used in radar transmitters, satellite communication
feeds, particle accelerators, and industrial microwave heating.

\begin{examplebox}

\textbf{Example 9.5.4:} A WR-90 rectangular waveguide has interior
dimensions a = 22.86 mm and b = 10.16 mm. Calculate the cutoff frequency
of the dominant TE₁₀ mode and determine the usable frequency range. Find
the guide wavelength at 10 GHz.

\textbf{Solution:}\\
Cutoff frequency (TE₁₀): f\textsubscript{c} = c/(2a) = 3 × 10⁸ / (2 ×
0.02286) = 3 × 10⁸ / 0.04572 = 6.562 GHz.\\
The usable range is typically 1.25f\textsubscript{c} to
1.9f\textsubscript{c} (avoiding near-cutoff dispersion and the next mode
TE₂₀): 8.2 to 12.5 GHz (the X-band).\\
The TE₂₀ cutoff is f\textsubscript{c20} = c/a = 13.12 GHz, so
single-mode operation is guaranteed below 13.12 GHz.\\
Guide wavelength at 10 GHz: λ\textsubscript{g} = λ₀/√(1 -
(f\textsubscript{c}/f)²) = (c/f)/√(1 - (6.562/10)²) = 0.03/√(1 - 0.4305)
= 0.03/√0.5695 = 0.03/0.7547 = 39.75 mm.\\
The guide wavelength (39.75 mm) is longer than the free-space wavelength
(30 mm), a characteristic of all waveguide modes above cutoff.

\end{examplebox}

\subsection{9.5.5 Microstrip and
Stripline}\label{microstrip-and-stripline}

Microstrip and stripline are planar transmission line structures
fabricated on printed circuit boards (PCBs) that guide high-frequency
signals between components with controlled impedance. A
\textbf{microstrip} consists of a signal trace on the top surface of a
dielectric substrate with a continuous ground plane on the bottom; it is
the most common PCB transmission line because the trace is accessible
for component mounting. The characteristic impedance depends on the
trace width w, substrate height h, and dielectric constant
ε\textsubscript{r}: an approximate formula for a thin microstrip is Z₀ ≈
(87 / √(ε\textsubscript{r} + 1.41)) × ln(5.98h / (0.8w + t)), where t is
the trace thickness. Because the electric field exists partly in the
dielectric and partly in the air above the trace, the effective
dielectric constant ε\textsubscript{eff} is less than
ε\textsubscript{r}, typically ε\textsubscript{eff} ≈ (ε\textsubscript{r}
+ 1)/2 + (ε\textsubscript{r} - 1)/(2√(1 + 12h/w)). A \textbf{stripline}
embeds the signal trace between two ground planes with dielectric
filling the entire space, creating a homogeneous environment where
ε\textsubscript{eff} = ε\textsubscript{r}; its impedance is Z₀ ≈
(60/√ε\textsubscript{r}) × ln(4b / (0.67π(0.8w + t))), where b is the
ground-to-ground spacing. Stripline provides better shielding and
eliminates radiation but requires inner-layer routing and vias for
component connections. Typical PCB substrates include FR-4
(ε\textsubscript{r} ≈ 4.3, tan δ ≈ 0.02 --- adequate to \textasciitilde1
GHz), Rogers RO4003 (ε\textsubscript{r} ≈ 3.55, tan δ ≈ 0.0027 ---
suitable to 10+ GHz), and PTFE-based laminates (ε\textsubscript{r} ≈
2.2, tan δ ≈ 0.0009 --- used for millimeter-wave circuits).
Controlled-impedance PCB design is essential for signal integrity in
high-speed digital systems (DDR4/5, PCIe, USB 3.x), RF circuits, and any
application where trace lengths approach a significant fraction of the
signal wavelength.

\begin{examplebox}

\textbf{Example 9.5.5:} A 50 Ω microstrip line is to be fabricated on an
FR-4 substrate (ε\textsubscript{r} = 4.3, h = 0.254 mm, t = 0.035 mm
copper). Estimate the required trace width and the effective dielectric
constant. Find the propagation delay per unit length.

\textbf{Solution:}\\
Using the microstrip impedance formula iteratively (or an online
calculator), for Z₀ = 50 Ω on FR-4 with h = 0.254 mm: the trace width is
approximately w ≈ 0.46 mm (18 mils).\\
The ratio w/h = 0.46/0.254 = 1.81.\\
Effective dielectric constant: ε\textsubscript{eff} ≈ (4.3 + 1)/2 + (4.3
- 1)/(2√(1 + 12/1.81)) = 2.65 + 3.3/(2√7.63) = 2.65 + 3.3/5.524 = 2.65 +
0.597 = 3.25.\\
Propagation velocity: v = c/√ε\textsubscript{eff} = 3 × 10⁸/√3.25 = 3 ×
10⁸/1.803 = 1.664 × 10⁸ m/s.\\
Propagation delay: t\textsubscript{pd} = 1/v = 6.01 ns/m = 6.01 ps/mm ≈
153 ps/inch.\\
For a 10 cm trace, the one-way delay is 0.601 ns --- significant for
signals with rise times below \textasciitilde2 ns (clock frequencies
above \textasciitilde500 MHz), where impedance-controlled routing
becomes essential.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-9-5-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch09_microstrip_Z0.png}

\caption{Figure 9.5.5: Microstrip characteristic impedance Z₀ and effective dielectric constant εeff vs trace width ratio W/h for FR-4 (εᵣ = 4.3), Rogers RO4003 (εᵣ = 3.55), and PTFE (εᵣ = 2.2). The W/h = 1.81 point (FR-4, 50 Ω) corresponds to the §9.5.5 example.}

\end{figure}

\subsection{9.5.6 Transmission Line Transients and
TDR}\label{transmission-line-transients-and-tdr}

When a step voltage is applied to a transmission line, the signal
propagates as a traveling wave at velocity v = 1/√(L'C') ≈
c/√ε\textsubscript{eff}, and reflections at impedance discontinuities
create a sequence of forward and backward traveling waves described by
the lattice (bounce) diagram. A source with impedance Z\textsubscript{S}
driving a line of impedance Z₀ initially launches a voltage step V⁺ =
V\textsubscript{S} × Z₀/(Z\textsubscript{S} + Z₀) onto the line. When
this wave arrives at the load after one-way delay t\textsubscript{d} =
l/v, a reflected wave V⁻ = Γ\textsubscript{L}V⁺ travels back, where
Γ\textsubscript{L} = (Z\textsubscript{L} - Z₀)/(Z\textsubscript{L} +
Z₀). The reflected wave then re-reflects at the source with coefficient
Γ\textsubscript{S} = (Z\textsubscript{S} - Z₀)/(Z\textsubscript{S} +
Z₀), and the bouncing continues with diminishing amplitudes until the
line reaches steady state. \textbf{Time-domain reflectometry} (TDR)
exploits this behavior to locate faults and characterize impedance
variations: a fast step (rise time \textless{} 100 ps for
high-resolution instruments) is launched into the line, and the
reflected waveform is displayed versus time, with each impedance
discontinuity appearing as a step or bump at a time corresponding to
twice the electrical distance to the fault. TDR is an essential tool for
signal integrity analysis in high-speed digital design, identifying
impedance mismatches, stubs, vias, connector transitions, and cable
faults with millimeter-level spatial resolution. The characteristic
impedance at any point is computed from the reflection coefficient: Z(t)
= Z₀ × (1 + Γ(t))/(1 - Γ(t)).

\begin{examplebox}

\textbf{Example 9.5.6:} A 1 V step from a 50 Ω source is applied to a 50
Ω coaxial cable (velocity = 2 × 10⁸ m/s, length = 3 m) terminated in a
150 Ω load. Using a lattice diagram, find the voltage at the load at t =
15 ns (immediately after the incident wave arrives), at t = 45 ns (after
the first round trip), and the final steady-state voltage.

\textbf{Solution:}\\
Initial wave: V⁺ = V\textsubscript{S} × Z₀/(Z\textsubscript{S} + Z₀) = 1
× 50/(50 + 50) = 0.5 V.\\
One-way delay: t\textsubscript{d} = l/v = 3/(2 × 10⁸) = 15 ns.\\
Load reflection coefficient: Γ\textsubscript{L} = (150 - 50)/(150 + 50)
= 100/200 = 0.5.\\
Source reflection coefficient: Γ\textsubscript{S} = (50 - 50)/(50 + 50)
= 0 (matched source).\\
At t = 15 ns (wave arrives at load): V\textsubscript{L} = V⁺ +
Γ\textsubscript{L}V⁺ = 0.5 + 0.5 × 0.5 = 0.5 + 0.25 = 0.75 V.\\
The reflected wave of 0.25 V travels back and arrives at the source at t
= 30 ns. Since Γ\textsubscript{S} = 0, no re-reflection occurs --- the
source absorbs the reflected wave completely.\\
At t = 45 ns and beyond, no additional waves arrive at the load. Final
steady-state: V\textsubscript{L} = 0.75 V.\\
Verification by voltage divider: V\textsubscript{L(DC)} =
V\textsubscript{S} × Z\textsubscript{L}/(Z\textsubscript{S} +
Z\textsubscript{L}) = 1 × 150/(50 + 150) = 0.75 V --- confirmed.\\
If the source were mismatched (Γ\textsubscript{S} ≠ 0), additional
bounces would occur, each diminished by Γ\textsubscript{L} ×
Γ\textsubscript{S}, converging geometrically to the same steady state.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-9-5-6}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch09_tdr.png}

\caption{Figure 9.5.6: TDR Lattice Diagram and Voltage Waveforms}

\end{figure}

\subsection{9.5.7 Impedance Matching
Networks}\label{impedance-matching-networks}

Impedance matching transforms a load impedance to the source impedance
(typically 50 Ω) so that maximum power is transferred and reflections
are minimized. The simplest narrowband matching technique is the
\textbf{L-network}, which uses two reactive elements (inductors and/or
capacitors) to transform a real load R\textsubscript{L} to the desired
source resistance R\textsubscript{S}. For R\textsubscript{L} \textless{}
R\textsubscript{S}, the shunt element is placed across the load and the
series element connects to the source; for R\textsubscript{L}
\textgreater{} R\textsubscript{S}, the topology reverses. The design
equations use the quality factor Q =
√(R\textsubscript{high}/R\textsubscript{low} − 1), which also determines
the bandwidth: BW ≈ f₀/Q. The shunt reactance is X\textsubscript{shunt}
= R\textsubscript{high}/Q and the series reactance is
X\textsubscript{series} = QR\textsubscript{low}, with the choice of
inductor or capacitor for each element providing two possible L-network
solutions (high-pass or low-pass form). The \textbf{quarter-wave
transformer} is a transmission line section of length λ/4 with
characteristic impedance Z\textsubscript{T} = √(Z₀Z\textsubscript{L})
that transforms a real load Z\textsubscript{L} to Z₀ at the design
frequency. Its bandwidth is inherently narrow (inversely proportional to
the impedance ratio), but multi-section quarter-wave transformers with
tapered impedances (binomial or Chebyshev) extend the bandwidth. For
broadband matching or complex loads, \textbf{Pi-networks} and
\textbf{T-networks} (three-element topologies) provide an additional
degree of freedom, allowing independent control of Q and transformation
ratio. At microwave frequencies, matching is often performed using
\textbf{open or shorted stubs} --- short transmission line sections that
present a purely reactive impedance at their input, positioned along the
main line to cancel the load's reactive component. Single-stub matching
uses one stub at a calculated distance from the load; double-stub
matching uses two stubs at fixed positions, providing more flexibility
but with a forbidden region of load impedances.

\begin{examplebox}

\textbf{Example 9.5.7:} A 915 MHz RFID reader has a 50 Ω output and must
drive an antenna with input impedance Z\textsubscript{L} = 15 Ω (purely
resistive). Design an L-network match and calculate the matching
bandwidth.

\textbf{Solution:}\\
Since R\textsubscript{L} = 15 Ω \textless{} R\textsubscript{S} = 50 Ω,
the shunt element goes across the load.\\
Q = √(R\textsubscript{high}/R\textsubscript{low} − 1) = √(50/15 − 1) =
√(2.333) = 1.528.\\
Shunt reactance: X\textsubscript{shunt} = R\textsubscript{high}/Q =
50/1.528 = 32.72 Ω.\\
Series reactance: X\textsubscript{series} = Q × R\textsubscript{low} =
1.528 × 15 = 22.92 Ω.\\
\textbf{Low-pass solution} (shunt inductor + series capacitor):
L\textsubscript{shunt} = X\textsubscript{shunt}/(2πf) = 32.72/(2π × 915
× 10⁶) = 5.69 nH. C\textsubscript{series} =
1/(2πfX\textsubscript{series}) = 1/(2π × 915 × 10⁶ × 22.92) = 7.58 pF.\\
\textbf{High-pass solution} (shunt capacitor + series inductor):
C\textsubscript{shunt} = 1/(2πf × 32.72) = 5.32 pF.
L\textsubscript{series} = 22.92/(2π × 915 × 10⁶) = 3.99 nH.\\
Matching bandwidth: BW ≈ f₀/Q = 915/1.528 = 599 MHz.\\
The VSWR stays below 2:1 over approximately ±300 MHz around 915 MHz,
which is more than adequate for the \textasciitilde26 MHz ISM band
(902--928 MHz).\\
The low-pass solution is typically preferred because it provides
harmonic rejection.

\end{examplebox}

\subsection{9.5.8 Coupled Transmission Lines and
Crosstalk}\label{coupled-transmission-lines-and-crosstalk}

When two transmission lines run in close proximity --- adjacent PCB
traces, parallel cable pairs, or neighboring connector pins --- their
electromagnetic fields interact, coupling energy from the driven
(aggressor) line to the quiet (victim) line. This coupling, called
\textbf{crosstalk}, degrades signal integrity by injecting unwanted
noise voltages and currents that can cause false logic transitions,
increase bit error rates, or violate EMI emission limits. Crosstalk
arises from two coupling mechanisms: \textbf{capacitive (electric field)
coupling} through the mutual capacitance C\textsubscript{m} between the
traces, and \textbf{inductive (magnetic field) coupling} through the
mutual inductance L\textsubscript{m} between the current loops. These
mechanisms produce two distinct crosstalk components. \textbf{Near-end
crosstalk (NEXT)} appears at the end of the victim line nearest the
aggressor's source, combining forward-traveling capacitive coupling with
backward-traveling inductive coupling --- both components arrive at the
near end simultaneously, reinforcing each other. \textbf{Far-end
crosstalk (FEXT)} appears at the opposite end of the victim line, where
the capacitive and inductive components travel in the same direction but
with opposite polarity --- in a homogeneous medium (stripline), the two
components cancel perfectly, making FEXT zero, but in an inhomogeneous
medium (microstrip, where ε\textsubscript{eff} ≠ ε\textsubscript{r}),
the velocity difference between even and odd modes prevents perfect
cancellation, producing nonzero FEXT.

The crosstalk coefficients for weakly coupled lines are: NEXT
coefficient K\textsubscript{b} = (C\textsubscript{m}/C₀ +
L\textsubscript{m}/L₀)/4 and FEXT coefficient K\textsubscript{f} =
(C\textsubscript{m}/C₀ − L\textsubscript{m}/L₀)/2, where C₀ and L₀ are
the self-capacitance and self-inductance per unit length,
t\textsubscript{d} is the coupled-region propagation delay, and
t\textsubscript{r} is the signal rise time. NEXT has a maximum voltage
of V\textsubscript{NEXT} = K\textsubscript{b} × V\textsubscript{step}
(saturating when the coupled length exceeds the critical length
l\textsubscript{crit} = t\textsubscript{r}v/2), while FEXT increases
linearly with coupled length: V\textsubscript{FEXT} = K\textsubscript{f}
× V\textsubscript{step} × (t\textsubscript{d}/t\textsubscript{r}).

\textbf{Differential pairs} are a primary technique for reducing
crosstalk susceptibility: two tightly coupled traces carrying equal and
opposite signals (differential mode) reject common-mode noise from
adjacent aggressors because the noise couples equally to both traces and
is cancelled at the differential receiver. The characteristic impedance
of a differential pair is Z\textsubscript{diff} = 2Z₀(1 − k), where Z₀
is the single-ended impedance and k is the coupling coefficient,
typically yielding Z\textsubscript{diff} = 85--100 Ω for standard PCB
designs. Design rules to minimize crosstalk include: maintaining a
separation of ≥ 3h between adjacent single-ended traces (where h is the
height above the ground plane, the ``3W'' rule), using ground guard
traces between sensitive signals, routing differential pairs with
consistent tight coupling, and minimizing parallel run lengths of
dissimilar signals.

\begin{examplebox}

\textbf{Example 9.5.8:} Two 50 Ω microstrip traces on a PCB (h = 0.2 mm
above the ground plane, ε\textsubscript{eff} = 3.2) run parallel with
edge-to-edge spacing s = 0.3 mm for a coupled length of 80 mm. The
aggressor carries a 3.3 V signal with 0.5 ns rise time. The mutual
capacitance is C\textsubscript{m} = 25 pF/m and the mutual inductance is
L\textsubscript{m} = 60 nH/m. The self-capacitance is C₀ = 120 pF/m and
self-inductance is L₀ = 300 nH/m. Calculate (a) the NEXT voltage, (b)
the FEXT voltage, and (c) the minimum spacing needed to reduce NEXT
below 50 mV.

\textbf{Solution:}

(a) NEXT coefficient: K\textsubscript{b} = (C\textsubscript{m}/C₀ +
L\textsubscript{m}/L₀)/4 = (25/120 + 60/300)/4 = (0.2083 + 0.2000)/4 =
0.1021\\
Propagation velocity: v = 1/√(L₀C₀) = 1/√(300 × 10⁻⁹ × 120 × 10⁻¹²) =
1/√(3.6 × 10⁻¹⁷) = 1.667 × 10⁸ m/s\\
Critical length: l\textsubscript{crit} = t\textsubscript{r}v/2 = 0.5 ×
10⁻⁹ × 1.667 × 10⁸ / 2 = 41.7 mm\\
Coupled length (80 mm) \textgreater{} l\textsubscript{crit} (41.7 mm),
so NEXT saturates:\\
V\textsubscript{NEXT} = K\textsubscript{b} × V\textsubscript{step} =
0.1021 × 3.3 = \textbf{337 mV} (10.2\% of signal amplitude)

(b) FEXT coefficient: K\textsubscript{f} = (C\textsubscript{m}/C₀ −
L\textsubscript{m}/L₀)/2 = (0.2083 − 0.2000)/2 = 0.00417\\
Propagation delay for 80 mm: t\textsubscript{d} = 0.08/1.667 × 10⁸ =
0.480 ns\\
V\textsubscript{FEXT} = K\textsubscript{f} × V\textsubscript{step} ×
(t\textsubscript{d}/t\textsubscript{r}) = 0.00417 × 3.3 × (0.480/0.5) =
\textbf{13.2 mV}\\
FEXT is much smaller than NEXT because the capacitive and inductive
components nearly cancel (C\textsubscript{m}/C₀ ≈ L\textsubscript{m}/L₀
in this case).

(c) Crosstalk decreases approximately as (h/(h + s))² for adjacent
microstrip traces. To reduce NEXT from 337 mV to 50 mV requires
K\textsubscript{b,new} = 50/3300 = 0.01515. The ratio
K\textsubscript{b,new}/K\textsubscript{b,old} = 0.01515/0.1021 = 0.148.
Since K\textsubscript{b} scales roughly as (h/(h + s))², and the current
spacing gives (0.2/(0.2 + 0.3))² = 0.16, the new spacing needs (h/(h +
s))² = 0.16 × 0.148 = 0.0237, so h/(h + s) = 0.154, giving s = h(1/0.154
− 1) = 0.2 × 5.49 = \textbf{1.1 mm} (approximately 5.5h spacing,
consistent with the ``3W'' rule where W ≈ 2h for these trace
dimensions).

\end{examplebox}

\section{9.6 Antennas}\label{antennas}

Antennas are the interface between guided waves on transmission lines
and radiated electromagnetic waves in free space. Antenna design
involves balancing radiation efficiency, directional gain, bandwidth,
impedance matching, and physical size --- with the optimal choice
depending on the application, from compact chip antennas in smartphones
to massive dish antennas for deep-space communication. Chapter 16
provides an in-depth treatment of antenna types; this section introduces
the fundamental concepts that connect electromagnetics to antenna
behavior.

\subsection{9.6.1 Antenna Fundamentals}\label{antenna-fundamentals}

An antenna is a transducer that converts guided electromagnetic energy
(on a transmission line or waveguide) into radiated electromagnetic
waves in free space, and vice versa. The radiation pattern describes the
spatial distribution of radiated power as a function of angle, typically
characterized by a main lobe (direction of maximum radiation),
sidelobes, beamwidth, and front-to-back ratio. Antenna gain G expresses
the directivity relative to an isotropic radiator (in dBi) or a
half-wave dipole (in dBd), accounting for the antenna's ability to
concentrate energy in a preferred direction. The effective aperture
A\textsubscript{e} relates the antenna's ability to capture incident
power to its gain: A\textsubscript{e} = Gλ²/(4π). The Friis transmission
equation P\textsubscript{r} = P\textsubscript{t} G\textsubscript{t}
G\textsubscript{r} (λ/(4πd))² relates the received power to the
transmitted power, antenna gains, wavelength, and distance, forming the
basis of link budget calculations in wireless communications.

\begin{examplebox}

\textbf{Example 9.6.1:} A Wi-Fi access point transmits 100 mW (20 dBm)
at 2.4 GHz with an antenna gain of 5 dBi. A laptop 30 m away has a
receive antenna gain of 2 dBi. Find the free-space path loss and the
received power.

\textbf{Solution:}\\
Wavelength: λ = c/f = 3 × 10⁸ / 2.4 × 10⁹ = 0.125 m.\\
Free-space path loss: FSPL = (4πd/λ)² = (4π × 30 / 0.125)² = (3015.9)² =
9.096 × 10⁶.\\
In dB: FSPL = 20log₁₀(4πd/λ) = 20 × log₁₀(3015.9) = 20 × 3.479 = 69.6
dB.\\
Received power (in dB): P\textsubscript{r} = P\textsubscript{t} +
G\textsubscript{t} + G\textsubscript{r} - FSPL = 20 + 5 + 2 - 69.6 =
-42.6 dBm.\\
Converting: P\textsubscript{r} = 10\textsuperscript{-42.6/10} mW = 5.5 ×
10\textsuperscript{-5} mW = \textbf{55 nW}, well above typical Wi-Fi
receiver sensitivity of about −70 dBm (100 pW).

\end{examplebox}

\subsection{9.6.2 Dipole Antennas}\label{dipole-antennas}

The half-wave dipole is the most fundamental resonant antenna,
consisting of two conductive elements each approximately λ/4 in length,
fed at the center. At resonance, a half-wave dipole has an input
impedance of approximately 73 + j42.5 Ω, a gain of 2.15 dBi, and a
toroidal (doughnut-shaped) radiation pattern with maximum radiation
perpendicular to the antenna axis and nulls along the axis. The short
dipole (length \textless\textless{} λ) has a similar radiation pattern
but lower radiation resistance and efficiency. Dipole variants include
the folded dipole (higher impedance, wider bandwidth), the sleeve
dipole, and dipole arrays. Dipole antennas are widely used as reference
antennas, in FM radio reception, and as elements in more complex antenna
arrays.

\begin{examplebox}

\textbf{Example 9.6.2:} Design a half-wave dipole antenna for the FM
broadcast band at 100 MHz. Find the total length of the dipole and its
radiation resistance.

\textbf{Solution:}\\
Wavelength: λ = c/f = 3 × 10⁸ / 100 × 10⁶ = 3.0 m.\\
Half-wave dipole length: L = λ/2 = 3.0 / 2 = 1.5 m (each arm is λ/4 =
0.75 m).\\
In practice, the physical length is shortened by approximately 5\% to
account for end effects: L\textsubscript{practical} ≈ 0.95 × 1.5 = 1.425
m.\\
The radiation resistance at resonance is approximately 73 Ω, and the
gain is 2.15 dBi (1.64 linear).\\
The input impedance is approximately 73 + j42.5 Ω; the reactive part can
be eliminated by slight length adjustment or a matching network.

\end{examplebox}

\subsection{9.6.3 Antenna Arrays}\label{antenna-arrays}

An antenna array combines multiple individual antenna elements with
controlled spacing, amplitude, and phase to achieve radiation
characteristics not possible with a single element. By adjusting the
relative phase of the signals fed to each element, the main beam can be
electronically steered without physically moving the antenna (phased
array). The array factor, which depends on the number of elements,
spacing, and excitation, multiplies the element pattern to produce the
total radiation pattern. Uniform linear arrays with element spacing of
λ/2 and progressive phase shift are the most common configuration, with
the beamwidth inversely proportional to the array length and the number
of elements. Phased arrays are essential in modern radar (simultaneous
tracking of multiple targets), 5G cellular communications (massive MIMO
beamforming), satellite communications, and radio astronomy.

\begin{examplebox}

\textbf{Example 9.6.3:} A uniform linear array of 8 half-wave dipole
elements is spaced at d = λ/2 and operates at 3 GHz. Find the half-power
beamwidth (approximate) and the array directivity improvement over a
single element.

\textbf{Solution:}\\
Wavelength: λ = c/f = 3 × 10⁸ / 3 × 10⁹ = 0.1 m = 10 cm.\\
Element spacing: d = λ/2 = 5 cm.\\
Total array length: L = (N-1) × d = 7 × 0.05 = 0.35 m.\\
For a broadside uniform linear array, the approximate half-power
beamwidth is θ\textsubscript{3dB} ≈ 0.886λ / (Nd) = 0.886 × 0.1 / (8 ×
0.05) = 0.0886 / 0.4 = 0.2215 rad = 12.7°.\\
The directivity of the array is approximately N times that of a single
element: D\textsubscript{array} ≈ N × D\textsubscript{element} = 8 ×
1.64 = 13.12 (11.2 dBi).\\
The array focuses the beam into a narrow 12.7° beam, enabling higher
gain and spatial selectivity.

\end{examplebox}

\subsection{9.6.4 Near-Field and Far-Field
Regions}\label{near-field-and-far-field-regions}

The electromagnetic field surrounding an antenna is divided into
distinct spatial regions with fundamentally different behavior. The
\textbf{reactive near-field} (Fresnel region) extends from the antenna
surface to approximately r \textless{} 0.62√(D³/λ), where D is the
largest antenna dimension; in this region, the fields store energy
reactively (oscillating between electric and magnetic forms each
half-cycle), field strength decays as 1/r² or 1/r³, and the E/H ratio is
not the free-space impedance η₀ --- it can be much higher (for
electrically short dipoles, dominated by the electric field) or much
lower (for small loop antennas, dominated by the magnetic field). The
\textbf{radiating near-field} (Fresnel region) spans from the reactive
boundary to r = 2D²/λ; here, the fields begin to radiate but the angular
pattern varies with distance, making this region unsuitable for
far-field antenna measurements. The \textbf{far-field} (Fraunhofer
region) begins at r \textgreater{} 2D²/λ (and r
\textgreater\textgreater{} λ, r \textgreater\textgreater{} D); in this
region, the wave front is approximately planar, the radiation pattern is
independent of distance, E and H are perpendicular and related by η₀ =
377 Ω, and power density decays as 1/r². The far-field boundary distance
is critical for antenna measurement: a half-wave dipole at 900 MHz (D ≈
0.17 m, λ = 0.33 m) has a far-field boundary of 2D²/λ = 0.17 m --- close
enough for indoor testing. However, a 1 m parabolic dish at 10 GHz (λ =
0.03 m) has 2D²/λ = 67 m, requiring either outdoor test ranges, compact
antenna test ranges (CATR) using a reflector to create a plane wave in a
shorter distance, or near-field scanning with mathematical
transformation to far-field patterns. \textbf{Near-field communication
(NFC)} at 13.56 MHz deliberately operates in the reactive near-field (λ
= 22 m, so all practical distances \textless\textless{} λ), using
magnetic coupling between loop antennas --- the rapid 1/r³ field decay
provides inherent security by limiting communication to
\textasciitilde10 cm range.

\begin{examplebox}

\textbf{Example 9.6.4:} A phased array antenna panel measuring 0.5 m ×
0.5 m operates at 28 GHz (5G mmWave). Calculate the far-field boundary
distance, the reactive near-field extent, and determine the minimum
anechoic chamber length for far-field measurements. Also compare to an
NFC system at 13.56 MHz with a 50 mm × 50 mm loop antenna.

\textbf{Solution:}\\
At 28 GHz: λ = c/f = 3 × 10⁸ / 28 × 10⁹ = 10.71 mm.\\
D = 0.5 m (diagonal of the panel = 0.707 m, but typically the largest
linear dimension is used).\\
Far-field boundary: r\textsubscript{ff} = 2D²/λ = 2 × 0.5² / 0.01071 =
0.5/0.01071 = 46.7 m.\\
Reactive near-field extent: r\textsubscript{reactive} = 0.62√(D³/λ) =
0.62√(0.125/0.01071) = 0.62√(11.67) = 0.62 × 3.416 = 2.12 m.\\
An anechoic chamber for far-field measurement must be at least 47 m long
--- impractical for indoor facilities. A compact antenna test range
(CATR) or planar near-field scanner would be used instead.\\
For the NFC system: λ = 3 × 10⁸ / 13.56 × 10⁶ = 22.12 m. D = 0.05 m.\\
Far-field boundary: 2 × 0.05² / 22.12 = 0.000226 m = 0.23 mm ---
essentially at the antenna surface.\\
Reactive near-field: 0.62√(0.05³/22.12) = 0.62√(5.66 × 10⁻⁶) = 0.62 ×
2.38 × 10⁻³ = 1.47 mm.\\
The entire practical NFC operating range (up to \textasciitilde100 mm)
is deep in the reactive near-field where the magnetic field from the
loop antenna decays as 1/r³, providing the short-range security
characteristic of NFC.\\
At 100 mm, the field is (1.47/100)³ = 3.2 × 10⁻⁶ times weaker than at
the reactive boundary --- a 110 dB natural path loss that limits
eavesdropping range.

\end{examplebox}

\section{9.7 Electromagnetic
Compatibility}\label{electromagnetic-compatibility}

Electromagnetic compatibility (EMC) is the ability of electronic
equipment to function satisfactorily in its electromagnetic environment
without introducing intolerable disturbances to other equipment in that
environment. Every electronic device is both a potential source of
electromagnetic interference (EMI) and a potential victim. EMC
engineering applies the principles of electromagnetics --- shielding,
grounding, filtering, and circuit layout --- to ensure that systems meet
regulatory emission limits (FCC Part 15, CISPR 32) and immunity
requirements (IEC 61000 series). Successful EMC design prevents
conducted and radiated interference from degrading system performance.

\subsection{9.7.1 Shielding
Effectiveness}\label{shielding-effectiveness}

Electromagnetic shielding encloses a sensitive circuit or a radiating
source in a conductive enclosure to attenuate electric and magnetic
fields. The shielding effectiveness (SE) is expressed in dB as the ratio
of field strength without the shield to the field strength with the
shield: SE = 20
log₁₀(E\textsubscript{incident}/E\textsubscript{transmitted}). For a
solid conductive sheet of thickness t, the shielding effectiveness has
three components: absorption loss A = 8.686(t/δ) dB (where δ is the skin
depth), reflection loss R (depends on the impedance mismatch between the
wave and the shield), and a correction for multiple internal reflections
B (significant only when A \textless{} 15 dB). For a plane wave incident
on a good conductor, the reflection loss is approximately R = 168 - 10
log₁₀(fμᵣ/σᵣ) dB, where σᵣ is the conductivity relative to copper. In
practice, shielding effectiveness is limited not by the enclosure walls
but by apertures (slots, seams, ventilation holes, cable penetrations)
--- a slot of length l resonates at λ/2 and can drastically reduce SE.
The rule of thumb is that any aperture longer than λ/20 at the highest
frequency of concern must be treated with EMI gaskets,
waveguide-below-cutoff ventilation panels, or filtered connectors.

\begin{examplebox}

\textbf{Example 9.7.1:} An aluminum enclosure (σ = 3.5 × 10⁷ S/m, μᵣ =
1) with wall thickness t = 1.5 mm must shield against a 100 MHz
interference signal. Calculate the skin depth, absorption loss, and
determine if the enclosure provides adequate shielding (target SE
\textgreater{} 60 dB). Also find the maximum allowable aperture length.

\textbf{Solution:}\\
Skin depth at 100 MHz: δ = 1/√(πfμ₀σ) = 1/√(π × 10⁸ × 4π × 10⁻⁷ × 3.5 ×
10⁷) = 1/√(π × 10⁸ × 43.98) = 1/√(1.381 × 10¹⁰) = 8.51 μm.\\
Absorption loss: A = 8.686 × (t/δ) = 8.686 × (1.5 × 10⁻³ / 8.51 × 10⁻⁶)
= 8.686 × 176.3 = 1531 dB.\\
The absorption loss alone is enormous --- even 0.1 mm of aluminum
provides over 100 dB at 100 MHz.\\
Reflection loss for aluminum at 100 MHz: R ≈ 168 - 10 log₁₀(10⁸ × 1 /
0.604) = 168 - 10 log₁₀(1.656 × 10⁸) = 168 - 82.2 = 85.8 dB.\\
Total SE = A + R = 1531 + 85.8 \textgreater\textgreater{} 60 dB. The
solid walls are not the concern.\\
Maximum aperture: λ = c/f = 3 × 10⁸/10⁸ = 3 m. λ/20 = 150 mm.\\
Any slot, seam, or opening longer than 150 mm will begin to compromise
shielding.\\
At 1 GHz (λ = 30 cm), the limit drops to 15 mm --- highlighting why
high-frequency EMC requires tight seam control and extensive use of
gaskets.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-9-7-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch09_shielding.png}

\caption{Figure 9.7.1: Shielding Effectiveness vs Frequency}

\end{figure}

\subsection{9.7.2 EMI Filtering and Conducted
Emissions}\label{emi-filtering-and-conducted-emissions}

Conducted emissions are electromagnetic interference currents that
travel along power and signal cables, coupling noise from a source (such
as a switching power supply) to other equipment sharing the same power
distribution network or cable bundle. Conducted emissions are regulated
from 150 kHz to 30 MHz (above which radiated emissions dominate) by
standards such as CISPR 32 (multimedia equipment) and FCC Part 15
Subpart B. Conducted noise exists in two modes: \textbf{differential
mode} (noise current flows on the line conductor and returns on the
neutral, in the same path as the desired power current) and
\textbf{common mode} (noise current flows in the same direction on both
line and neutral, returning through the ground conductor or parasitic
capacitance). Common-mode emissions are typically the dominant source of
EMI failures because even small common-mode currents flowing through
long cables produce significant radiated emissions. \textbf{EMI line
filters} suppress conducted emissions using a combination of components:
X-capacitors (line-to-neutral) attenuate differential-mode noise,
Y-capacitors (line-to-ground) attenuate common-mode noise (limited to a
few nF for safety leakage current), and common-mode chokes (coupled
inductors with high impedance to common-mode currents but near-zero
impedance to differential power current) provide the primary common-mode
suppression. A typical single-stage EMI filter provides 20-40 dB of
attenuation; multi-stage filters or additional ferrite cores on cables
extend this to 50-60 dB. On PCBs, decoupling capacitors (100 nF ceramic
close to each IC power pin, plus bulk electrolytics on the board)
suppress high-frequency conducted noise at the source, and proper
grounding (solid ground planes, star-point or single-point grounding for
mixed-signal boards) minimizes ground-coupled interference.

\begin{examplebox}

\textbf{Example 9.7.2:} A switching power supply produces conducted
common-mode noise of 75 dBμV at 1 MHz on its AC input, measured with a
LISN (Line Impedance Stabilization Network). The CISPR 32 Class B
quasi-peak limit at 1 MHz is 46 dBμV. Design an EMI filter to achieve
compliance with 6 dB of margin.

\textbf{Solution:}\\
Required attenuation: 75 - 46 + 6 = 35 dB at 1 MHz.\\
A common-mode choke is the primary component for common-mode
suppression.\\
The choke impedance at 1 MHz must provide 35 dB attenuation across the
50 Ω LISN impedance.\\
Attenuation of an L-filter: A = 20 log₁₀(1 + Z\textsubscript{L}/(2 ×
R\textsubscript{LISN})). For 35 dB: 10\^{}(35/20) = 1 +
Z\textsubscript{L}/100, so 56.23 = 1 + Z\textsubscript{L}/100,
Z\textsubscript{L} = 5523 Ω.\\
At 1 MHz: L\textsubscript{CM} = Z\textsubscript{L}/(2πf) = 5523/(2π ×
10⁶) = 879 μH.\\
A practical common-mode choke of \textasciitilde1 mH (standard value)
provides ≥35 dB at 1 MHz.\\
Adding Y-capacitors of 2.2 nF (each line to ground) provides additional
common-mode attenuation: at 1 MHz, X\textsubscript{C} = 1/(2π × 10⁶ ×
2.2 × 10⁻⁹) = 72.3 Ω.\\
The combined LC filter (1 mH choke + 2.2 nF Y-cap) forms a second-order
filter with resonance at f₀ = 1/(2π√(LC)) = 1/(2π√(10⁻³ × 2.2 × 10⁻⁹)) =
107 kHz, providing -40 dB/decade roll-off above resonance and
approximately 35 + 20 = 55 dB attenuation at 1 MHz --- well beyond the
requirement, allowing margin for component tolerances and aging.

\end{examplebox}

\subsection{9.7.3 PCB Layout for EMC}\label{pcb-layout-for-emc}

Good PCB layout is the first line of defense against both radiated
emissions and susceptibility, and it is far more effective and less
costly than adding external shielding or filtering after the design is
complete. The fundamental principle is \textbf{minimizing loop area} ---
every current loop acts as both a transmitting and receiving antenna,
with radiated emission proportional to the loop area and the square of
the frequency. A continuous \textbf{ground plane} (an entire copper
layer dedicated to the return current) ensures that the return current
flows directly beneath the signal trace (the path of least inductance),
minimizing the loop area to the trace width times the substrate height.
Multi-layer PCB stackups with alternating signal and ground/power planes
(e.g., Sig-GND-PWR-Sig for 4-layer, or Sig-GND-Sig-PWR-GND-Sig for
6-layer) provide low-inductance return paths for every signal.
\textbf{Decoupling capacitors} (100 nF MLCC at each IC power pin, plus
10 μF bulk capacitors per power rail section) suppress high-frequency
supply noise at the source; placement must be as close as possible to
the IC pins, with the capacitor's loop area through the vias to the
power and ground planes minimized. \textbf{Signal routing} rules for EMC
include: keeping high-speed clock traces short and away from board
edges, avoiding routing traces across splits in reference planes (which
forces the return current to detour around the split, creating a large
radiating loop), maintaining controlled impedance for signals with rise
times faster than 2 × t\textsubscript{pd} (where t\textsubscript{pd} is
the trace propagation delay), and using guard traces or ground stitching
vias to isolate sensitive analog sections from noisy digital sections.
\textbf{Connector and cable interface} regions require filtering
(ferrite beads, feed-through capacitors) and ground stitching at the
board edge, since cables are the primary antenna for conducted and
radiated emissions.

\begin{examplebox}

\textbf{Example 9.7.3:} A 4-layer PCB stackup has signal traces on the
top layer, a ground plane on layer 2, a power plane on layer 3, and
signal traces on the bottom layer. The substrate height between the top
signal layer and the ground plane is h = 0.2 mm. A 100 MHz clock trace
is 50 mm long on the top layer. Estimate the loop area formed by the
trace and its return current, and compare it to a 2-layer board where
the return path is 10 mm away from the signal trace.

\textbf{Solution:}\\
4-layer board loop area: A₁ = trace length × substrate height = 50 × 0.2
= 10 mm² = 10 × 10⁻⁶ m².\\
The return current flows in the ground plane directly beneath the trace,
so the loop height is just the 0.2 mm dielectric thickness.\\
2-layer board loop area (return path 10 mm away): A₂ = 50 × 10 = 500 mm²
= 500 × 10⁻⁶ m².\\
Ratio: A₂/A₁ = 500/10 = 50×.\\
Since radiated emission is proportional to loop area, the 2-layer board
radiates 50× more (34 dB worse) than the 4-layer board for the same
clock signal.\\
At 100 MHz (λ = 3 m), both loops are electrically small (loop dimension
\textless\textless{} λ), so the radiated electric field at distance r is
approximately E ∝ f²IA/r, where I is the current.\\
For a 20 mA clock signal on the 4-layer board: the estimated radiated
field at 3 m is E ≈ 1.316 × 10⁻¹⁴ × (10⁸)² × 0.02 × 10 × 10⁻⁶ / 3 = 8.8
μV/m --- below the FCC Class B limit of \textasciitilde100 μV/m at 3
m.\\
The same signal on the 2-layer board would produce \textasciitilde440
μV/m, exceeding the limit by 13 dB.

\end{examplebox}

\subsection{9.7.4 Electrostatic Discharge (ESD)
Protection}\label{electrostatic-discharge-esd-protection}

Electrostatic discharge is the sudden transfer of charge between two
objects at different electrostatic potentials, producing current pulses
with peak amplitudes of amperes to tens of amperes and rise times of
sub-nanosecond to several nanoseconds. ESD is one of the most common
causes of electronic component damage and field failures. The three
standard ESD test models are: the \textbf{Human Body Model (HBM)}, which
simulates a person touching a device (100 pF charged to 2--8 kV,
discharged through 1.5 kΩ, producing \textasciitilde1.3 A peak with
\textasciitilde10 ns rise time); the \textbf{Charged Device Model
(CDM)}, which simulates a charged IC discharging when it contacts a
grounded surface (\textless1 ns rise, 5--15 A peak, most damaging to
gate oxides); and the \textbf{Machine Model (MM)}, which simulates
discharge from equipment (200 pF, 0 Ω, producing higher peak current).
ICs are classified by their ESD withstand voltage (e.g., Class 1A:
\textless250 V HBM, Class 3B: \textgreater8 kV HBM per ANSI/ESDA/JEDEC
JS-001). \textbf{On-chip ESD protection} uses clamp circuits ---
typically a grounded-gate NMOS (ggNMOS) or silicon-controlled rectifier
(SCR) structure --- that shunt the ESD current to ground before it
reaches the protected circuitry. \textbf{Board-level ESD protection} for
I/O ports exposed to human contact (USB, HDMI, Ethernet, touchscreens)
uses TVS (Transient Voltage Suppressor) diodes that clamp the voltage to
a safe level within nanoseconds. Key TVS parameters include breakdown
voltage V\textsubscript{BR}, clamping voltage V\textsubscript{C} at peak
pulse current, junction capacitance (must be low for high-speed data
lines --- \textless1 pF for USB 3.x), and peak pulse power rating.
\textbf{Design practices} to minimize ESD vulnerability include: routing
sensitive traces away from board edges and connectors, providing a
low-impedance ground path from the connector shell to the ground plane,
placing TVS devices as close to the connector as possible, and using
series resistors (22--100 Ω) on sensitive inputs to limit peak current.

\begin{examplebox}

\textbf{Example 9.7.4:} A USB 2.0 data port must survive ±8 kV contact
discharge per IEC 61000-4-2. A TVS diode array with V\textsubscript{BR}
= 6 V, V\textsubscript{C} = 12 V at I\textsubscript{PP} = 8 A, and
C\textsubscript{J} = 0.5 pF per line is selected. The USB transceiver IC
has an absolute maximum voltage rating of 7 V on data pins. Verify that
the TVS protects the IC and assess the signal integrity impact on USB
2.0 (480 Mbps).

\textbf{Solution:}\\
During an 8 kV IEC 61000-4-2 contact discharge, the peak current is
approximately 30 A (per the IEC waveform) with a 0.7--1 ns rise time.\\
The TVS diode must clamp within \textasciitilde1 ns. At 30 A (well above
the specified 8 A), the clamping voltage rises --- using the TVS I-V
curve, V\textsubscript{C} at 30 A is approximately 18--22 V. This
exceeds the IC's 7 V limit.\\
Solution: add a 33 Ω series resistor between the TVS and the IC pin.\\
With the TVS clamping at 18 V and the 33 Ω resistor, the current flowing
into the IC's internal ESD clamp is limited to I = (18 - 7)/33 = 0.33 A,
which is within the IC's internal ESD handling capability (typically 1+
A for HBM-rated devices).\\
Signal integrity: the 33 Ω resistor and 0.5 pF TVS capacitance form a
lowpass filter with f\textsubscript{3dB} = 1/(2πRC) = 1/(2π × 33 × 0.5 ×
10⁻¹²) = 9.65 GHz --- well above the USB 2.0 fundamental frequency of
240 MHz, so signal integrity impact is negligible.\\
For USB 3.x (5 Gbps, fundamental at 2.5 GHz), the 33 Ω resistor would be
too large; a 5--10 Ω resistor with a sub-0.3 pF TVS would be required.

\end{examplebox}

\subsection{9.7.5 Grounding and Bonding for
EMC}\label{grounding-and-bonding-for-emc}

Grounding and bonding are the most fundamental --- and most frequently
misunderstood --- aspects of EMC design. A \textbf{ground} is a
reference conductor to which signal return currents and fault currents
flow; a \textbf{bond} is a low-impedance electrical connection between
two metallic structures, ensuring they remain at the same potential. At
DC and low frequencies, a single-point (star) ground topology minimizes
common-impedance coupling by ensuring that return currents from
different circuits do not share a conductor segment. At high frequencies
(above roughly f \textgreater{} c/(10 × longest ground conductor
length), typically a few MHz), the inductance of long ground wires
dominates over their resistance, and a \textbf{multi-point ground} (mesh
or plane) provides low-impedance return paths by minimizing loop area.
Mixed-signal systems often use a \textbf{hybrid} approach: a
single-point connection between the analog and digital ground domains at
low frequencies (preventing digital return currents from flowing through
the analog ground), transitioning to multi-point bonding through
distributed capacitors at high frequencies. \textbf{Bonding} between
equipment chassis, cable shields, rack frames, and building structural
steel must be low-impedance at the frequencies of concern --- bolted
joints with clean, bare-metal contact surfaces (no paint or anodize in
the contact area) provide bonds below 2.5 mΩ per MIL-STD-188-124B.
Ground loops --- closed conductive paths formed when two grounded points
are connected by both a signal cable shield and the building ground
system --- allow magnetically induced currents to flow, coupling 50/60
Hz hum and transient noise into sensitive circuits. Ground loop
mitigation techniques include differential signaling (rejecting
common-mode noise), galvanic isolation (optocouplers, isolated DC-DC
converters, fiber optics, isolation transformers), and breaking the loop
with a single-point shield ground at the receiver end (for frequencies
below \textasciitilde1 MHz).

\begin{examplebox}

\textbf{Example 9.7.5:} An industrial measurement system connects a
sensor 50 m away to a data acquisition unit. Both are grounded to the
building steel, which has a 2 V potential difference at 60 Hz between
the two ground points. The sensor signal is 10 mV full scale over a
shielded twisted-pair cable with shield resistance of 0.15 Ω. Determine
the ground loop current and the resulting noise at the receiver if the
shield is grounded at both ends. Propose a solution.

\textbf{Solution:}\\
Ground loop current: I\textsubscript{loop} =
V\textsubscript{ground}/R\textsubscript{shield} = 2/0.15 = 13.3 A at 60
Hz.\\
This current flows through the cable shield, inducing a voltage in the
signal conductors via mutual inductance between the shield and the
twisted pair.\\
For a typical shielded cable, the transfer impedance is
Z\textsubscript{T} ≈ 10 mΩ/m at 60 Hz (dominated by shield resistance),
so the induced noise voltage is V\textsubscript{noise} =
I\textsubscript{loop} × Z\textsubscript{T} × length = 13.3 × 0.01 × 50 =
6.65 V.\\
This far exceeds the 10 mV signal --- the measurement is completely
buried in noise.\\
Even if the shield provides 20 dB of additional common-mode rejection,
the noise (0.665 V) still overwhelms the signal by 36 dB.\\
\textbf{Solution:} Use differential signaling with an instrumentation
amplifier (CMRR ≥ 80 dB at 60 Hz) and ground the shield at the receiver
end only, breaking the ground loop.\\
The 2 V ground difference now appears as common-mode voltage on the
signal pair, rejected by the instrumentation amp: V\textsubscript{noise}
= 2 V / 10\textsuperscript{80/20} = 2/10,000 = 0.2 mV = 200 μV, which is
2\% of the 10 mV full-scale signal (34 dB SNR).\\
For better performance, add an isolation amplifier (galvanic isolation)
at the sensor end to completely eliminate the ground loop, reducing
noise to the amplifier's inherent input noise (\textasciitilde1
μV\textsubscript{rms}).

\end{examplebox}

\chapter{Chapter 10}\label{chapter-10}

\chapter{Power Electronics}\label{power-electronics}

Power electronics is the application of solid-state semiconductor
devices to the conversion, control, and conditioning of electric power.
It bridges the gap between power engineering and electronics, using
switching devices such as diodes, transistors, and thyristors to
efficiently convert power between AC and DC forms, regulate voltage and
current levels, and control the speed of electric motors. Power
electronic converters are found in applications ranging from milliwatt
phone chargers to gigawatt HVDC transmission systems, and they are
essential enablers of renewable energy integration, electric vehicles,
and modern industrial automation.

\section{10.1 Switching Devices}\label{switching-devices}

Power semiconductor switches are the core building blocks of all power
electronic converters. The choice of switching device --- diode, MOSFET,
IGBT, thyristor, or wide-bandgap transistor --- is determined by the
application's voltage, current, switching frequency, and efficiency
requirements. Each device type occupies a distinct region in the
voltage/frequency design space, and understanding their characteristics,
loss mechanisms, and gate drive requirements is essential for selecting
the optimal device for a given converter topology.

\subsection{10.1.1 Power Diodes}\label{power-diodes}

Power diodes are two-terminal devices that conduct current in one
direction and block it in the other, serving as the fundamental building
block for rectifier circuits. Unlike signal diodes, power diodes are
designed to handle high forward currents (tens to thousands of amperes)
and high reverse blocking voltages (hundreds to thousands of volts). Key
parameters include forward voltage drop (typically 0.7-1.2 V for
silicon), reverse recovery time (the time required for the diode to
transition from conducting to blocking when reverse biased), and thermal
resistance (which determines heat dissipation requirements).
Fast-recovery diodes minimize reverse recovery losses in high-frequency
switching circuits, while Schottky power diodes offer lower forward
voltage drops and negligible reverse recovery time but are limited to
lower blocking voltages (typically below 200 V). Silicon carbide (SiC)
Schottky diodes combine low forward drop with high voltage ratings and
near-zero reverse recovery, making them increasingly popular in
high-efficiency power converters.

\begin{examplebox}

\textbf{Example 10.1.1:} A silicon power diode has a forward voltage
drop V\textsubscript{F} = 1.0 V and carries a continuous forward current
of I\textsubscript{F} = 25 A. The diode has a reverse recovery time
t\textsubscript{rr} = 50 ns and is used in a circuit where the reverse
voltage is V\textsubscript{R} = 400 V and the switching frequency is
f\textsubscript{sw} = 100 kHz. Estimate the conduction power loss and
the reverse recovery power loss.

\textbf{Solution:}\\
Conduction loss: P\textsubscript{cond} = V\textsubscript{F} ×
I\textsubscript{F} = 1.0 V × 25 A = 25 W.\\
For reverse recovery loss, the recovered charge is approximately
Q\textsubscript{rr} ≈ ½ × I\textsubscript{F} × t\textsubscript{rr} = ½ ×
25 × 50 × 10⁻⁹ = 625 nC.\\
The reverse recovery energy per cycle is E\textsubscript{rr} ≈ ½ ×
Q\textsubscript{rr} × V\textsubscript{R} = ½ × 625 × 10⁻⁹ × 400 = 125
μJ.\\
The reverse recovery power loss is P\textsubscript{rr} =
E\textsubscript{rr} × f\textsubscript{sw} = 125 × 10⁻⁶ × 100 × 10³ =
12.5 W.\\
Total diode power loss ≈ 25 + 12.5 = 37.5 W.

\end{examplebox}

\subsection{10.1.2 MOSFETs}\label{mosfets}

Power MOSFETs (Metal-Oxide-Semiconductor Field-Effect Transistors) are
voltage-controlled switches widely used in power electronics for their
fast switching speeds and ease of gate drive. They conduct current
between drain and source when a sufficient gate-to-source voltage
exceeds the threshold voltage, and they turn off when the gate voltage
is removed. The on-state resistance R\textsubscript{DS(on)} determines
conduction losses and increases with voltage rating, making MOSFETs most
efficient at lower voltages (typically below 600 V). Switching losses
occur during the transitions between on and off states and are
proportional to switching frequency, requiring careful gate drive design
to minimize transition times. Enhancement-mode N-channel MOSFETs are the
dominant type in power electronics, with silicon superjunction devices,
SiC MOSFETs, and GaN HEMTs pushing the boundaries of voltage rating,
switching speed, and efficiency.

\begin{examplebox}

\textbf{Example 10.1.2:} A power MOSFET with R\textsubscript{DS(on)} =
45 mΩ at 25°C is used in a converter switching at f\textsubscript{sw} =
200 kHz. The drain current is 10 A, the bus voltage is 48 V, and the
turn-on and turn-off times are t\textsubscript{on} = 20 ns and
t\textsubscript{off} = 30 ns. The R\textsubscript{DS(on)} temperature
coefficient is +0.4\%/°C and the junction operates at 100°C. Find the
total power loss.

\textbf{Solution:}\\
At 100°C, R\textsubscript{DS(on)} = 45 mΩ × {[}1 + 0.004 × (100 - 25){]}
= 45 mΩ × 1.30 = 58.5 mΩ.\\
Conduction loss: P\textsubscript{cond} = I² × R\textsubscript{DS(on)} =
10² × 0.0585 = 5.85 W.\\
Switching loss: P\textsubscript{sw} = ½ × V × I × (t\textsubscript{on} +
t\textsubscript{off}) × f\textsubscript{sw} = ½ × 48 × 10 × (20 + 30) ×
10⁻⁹ × 200 × 10³ = 2.40 W.\\
Total power loss: P\textsubscript{total} = 5.85 + 2.40 = 8.25 W.

\end{examplebox}

\subsection{10.1.3 IGBTs}\label{igbts}

The Insulated Gate Bipolar Transistor (IGBT) combines the
voltage-controlled gate of a MOSFET with the high current-carrying
capability and low conduction losses of a bipolar transistor. IGBTs are
the preferred switching device for medium to high power applications at
voltages above 600 V, including motor drives, grid-tied inverters,
uninterruptible power supplies, and induction heating. The on-state
voltage drop of an IGBT (typically 1.5--3 V) is relatively independent
of current rating, giving IGBTs an advantage over MOSFETs at higher
voltages where MOSFET R\textsubscript{DS(on)} becomes prohibitively
large. However, IGBTs have a tail current during turn-off (due to stored
minority carriers) that limits their maximum practical switching
frequency to approximately 20--50 kHz. IGBT modules package multiple
devices with antiparallel diodes in standard configurations
(half-bridge, full-bridge, six-pack) for convenient use in converter
topologies.

\begin{examplebox}

\textbf{Example 10.1.3:} An IGBT module has V\textsubscript{CE(sat)} =
2.0 V at rated current I\textsubscript{C} = 150 A, turn-on energy
E\textsubscript{on} = 30 mJ, turn-off energy E\textsubscript{off} = 20
mJ per switching event (at V\textsubscript{DC} = 600 V,
I\textsubscript{C} = 150 A), and it operates at f\textsubscript{sw} = 10
kHz with a duty cycle of 0.5. Calculate the conduction and switching
losses.

\textbf{Solution:}\\
Conduction loss: P\textsubscript{cond} = V\textsubscript{CE(sat)} ×
I\textsubscript{C} × D = 2.0 × 150 × 0.5 = 150 W.\\
Switching loss: P\textsubscript{sw} = (E\textsubscript{on} +
E\textsubscript{off}) × f\textsubscript{sw} = (30 × 10⁻³ + 20 × 10⁻³) ×
10,000 = 0.050 × 10,000 = 500 W.\\
Total IGBT loss: P\textsubscript{total} = 150 + 500 = 650 W.\\
The switching losses dominate at this frequency, illustrating why IGBTs
are typically limited to moderate switching frequencies.

\end{examplebox}

\subsection{10.1.4 Thyristors}\label{thyristors}

Thyristors (Silicon Controlled Rectifiers, or SCRs) are four-layer PNPN
devices that can be triggered into conduction by a gate pulse but remain
latched on until the current falls below the holding current. Once
conducting, the gate loses control and the thyristor can only be turned
off by external circuit conditions that reduce the anode current to zero
(natural commutation in AC circuits or forced commutation using
auxiliary circuits). Thyristors can handle extremely high voltages (up
to 12 kV per device) and currents (up to 6 kA), making them essential in
high-power applications such as HVDC transmission, static VAR
compensators, and large motor drives. The Gate Turn-Off thyristor (GTO)
adds the ability to turn off by applying a negative gate current, while
the Integrated Gate-Commutated Thyristor (IGCT) improves on the GTO with
faster, more reliable turn-off and lower conduction losses.

\begin{examplebox}

\textbf{Example 10.1.4:} A thyristor (SCR) is used in a phase-controlled
rectifier fed from a 480 V\textsubscript{rms} single-phase supply. The
thyristor has a forward voltage drop V\textsubscript{T} = 1.5 V, a
holding current I\textsubscript{H} = 80 mA, and a latching current
I\textsubscript{L} = 250 mA. If the load is purely resistive at R = 10 Ω
and the firing angle is α = 45°, what is the average load current and
the power dissipated in the thyristor?

\textbf{Solution:}\\
Peak supply voltage: V\textsubscript{peak} = 480√2 = 678.8 V.\\
For a single-phase half-wave controlled rectifier with resistive load,
V\textsubscript{dc} = (V\textsubscript{peak} / 2π)(1 + cos α) = (678.8 /
6.283)(1 + cos 45°) = 108.0 × 1.707 = 184.4 V.\\
Average load current: I\textsubscript{dc} = V\textsubscript{dc} / R =
184.4 / 10 = 18.4 A, which far exceeds both I\textsubscript{H} and
I\textsubscript{L}, confirming the thyristor stays latched.\\
Thyristor power dissipation: P\textsubscript{T} ≈ V\textsubscript{T} ×
I\textsubscript{dc} = 1.5 × 18.4 = 27.6 W.

\end{examplebox}

\subsection{10.1.5 Wide-Bandgap Semiconductors (SiC and
GaN)}\label{wide-bandgap-semiconductors-sic-and-gan}

Wide-bandgap (WBG) semiconductors --- primarily silicon carbide (SiC,
bandgap 3.26 eV) and gallium nitride (GaN, bandgap 3.4 eV) --- are
displacing silicon in power electronics applications where higher
efficiency, switching speed, or temperature capability is required.
Compared to silicon (bandgap 1.12 eV), WBG materials have approximately
10× higher critical electric field, enabling devices with thinner drift
regions and dramatically lower on-resistance at a given voltage rating
--- or equivalently, much higher voltage ratings in a compact die.
\textbf{SiC MOSFETs} (available at 650 V to 3.3 kV) offer
R\textsubscript{DS(on)} values 5--10× lower than silicon MOSFETs at the
same voltage and can operate at junction temperatures up to 200°C,
making them the preferred choice for EV traction inverters, solar string
inverters, and fast EV chargers. \textbf{SiC Schottky diodes} eliminate
reverse recovery losses almost entirely, significantly reducing
switching losses in boost PFC stages and bridge rectifiers. \textbf{GaN
HEMTs} (High Electron Mobility Transistors, typically 100--650 V)
leverage the two-dimensional electron gas at the AlGaN/GaN
heterojunction to achieve extremely low on-resistance and parasitic
capacitance, enabling switching frequencies of 1--10 MHz with minimal
losses. GaN devices dominate the compact, high-frequency adapter and
charger market (USB-C PD chargers, laptop adapters) and are gaining
traction in data center power, lidar drivers, and Class-D audio
amplifiers. The primary trade-offs of WBG devices are higher per-device
cost (2--5× silicon) and the need for careful PCB layout and gate drive
design to exploit the fast switching speeds without excessive ringing or
EMI.

\begin{examplebox}

\textbf{Example 10.1.5:} A 650 V silicon superjunction MOSFET has
R\textsubscript{DS(on)} = 99 mΩ and output capacitance
C\textsubscript{oss} = 65 pF. A 650 V SiC MOSFET has
R\textsubscript{DS(on)} = 25 mΩ and C\textsubscript{oss} = 30 pF. Both
are used in a 400 V, 10 A boost PFC stage switching at 100 kHz. Compare
the conduction losses and capacitive switching losses.

\textbf{Solution:}\\
Conduction losses (assuming I\textsubscript{rms} ≈ 7 A):\\
Silicon: P\textsubscript{cond} = 7² × 0.099 = 4.85 W.\\
SiC: P\textsubscript{cond} = 7² × 0.025 = 1.23 W (75\% reduction).\\
Capacitive switching losses: E\textsubscript{oss} =
½C\textsubscript{oss}V² per cycle.\\
Silicon: E\textsubscript{oss} = ½ × 65 × 10⁻¹² × 400² = 5.2 μJ.\\
SiC: E\textsubscript{oss} = ½ × 30 × 10⁻¹² × 400² = 2.4 μJ.\\
At 100 kHz: Silicon: P\textsubscript{oss} = 5.2 × 10⁻⁶ × 10⁵ = 0.52 W.
SiC: P\textsubscript{oss} = 2.4 × 10⁻⁶ × 10⁵ = 0.24 W.\\
Total device losses: Silicon ≈ 5.37 W, SiC ≈ 1.47 W.\\
The SiC device reduces total MOSFET losses by 73\%, enabling higher
efficiency or a smaller heat sink.\\
At 300 kHz switching (feasible with SiC), the inductor and capacitor
sizes shrink proportionally, reducing converter volume.

\end{examplebox}

\subsection{10.1.6 Gate Driver Design}\label{gate-driver-design}

Gate drivers are the interface circuits that translate low-power control
signals into the high-current, precisely timed pulses needed to switch
power MOSFETs and IGBTs on and off. A power MOSFET gate is a capacitive
load (total gate charge Q\textsubscript{g} typically 10--500 nC) that
must be charged and discharged rapidly to minimize switching losses
during the Miller plateau region where the drain voltage transitions.
Peak gate drive currents of 1--10 A are common, requiring dedicated
driver ICs or discrete totem-pole buffer stages. For \textbf{low-side}
switches (source connected to ground), a simple non-isolated gate driver
referenced to the power ground is sufficient. \textbf{High-side}
switches in half-bridge and full-bridge topologies have their source
terminal floating at the switching node voltage, requiring either a
\textbf{bootstrap} circuit or a fully \textbf{isolated} gate driver. A
bootstrap driver uses a capacitor (C\textsubscript{boot}) charged from
the low-voltage supply through a diode during the low-side on-time; when
the high-side switch turns on, the bootstrap capacitor provides gate
drive power referenced to the rising source terminal. The bootstrap
capacitor must be sized to supply the total gate charge plus quiescent
current for the maximum high-side on-time: C\textsubscript{boot} ≥
Q\textsubscript{total} / ΔV\textsubscript{boot}, where
ΔV\textsubscript{boot} is the allowable voltage droop (typically 0.5--1
V). Bootstrap circuits are simple and inexpensive but limited to duty
cycles below \textasciitilde99\% because they require periodic low-side
on-time to recharge. Fully \textbf{isolated gate drivers} use a
transformer, optocoupler, or capacitive isolation barrier to transmit
the gate signal across a galvanic boundary, powered by an isolated DC-DC
converter or integrated isolated supply. They support 100\% duty cycle,
handle high dv/dt transients (50--200 kV/μs common-mode rejection), and
are mandatory for thyristor/IGBT gate drives in medium-voltage
applications. \textbf{Dead time} --- a brief interval (typically 20--500
ns) when both switches in a half-bridge are off --- prevents
shoot-through (simultaneous conduction creating a short circuit across
the DC bus). Dead time is implemented in hardware (resistor-capacitor
networks on the gate drive signal) or in the gate driver IC, and must be
long enough to ensure complete turn-off of one device before the
complementary device turns on, accounting for propagation delay
mismatches and temperature variation. Excessive dead time increases body
diode conduction losses and output distortion in motor drives.

\begin{examplebox}

\textbf{Example 10.1.6:} A half-bridge gate driver uses a bootstrap
circuit to drive the high-side SiC MOSFET. The MOSFET has
Q\textsubscript{g} = 120 nC, the driver IC quiescent current is
I\textsubscript{Q} = 5 mA, the maximum high-side on-time is 9 μs at
f\textsubscript{sw} = 100 kHz, and the allowable bootstrap voltage droop
is ΔV = 0.5 V. The bootstrap diode has V\textsubscript{F} = 0.5 V and
the supply is V\textsubscript{CC} = 15 V. Calculate the minimum
bootstrap capacitance and the effective gate drive voltage.

\textbf{Solution:}\\
Total charge per cycle: Q\textsubscript{total} = Q\textsubscript{g} +
I\textsubscript{Q} × t\textsubscript{on(max)} = 120 × 10⁻⁹ + 5 × 10⁻³ ×
9 × 10⁻⁶ = 120 nC + 45 nC = 165 nC.\\
Minimum bootstrap capacitance: C\textsubscript{boot} =
Q\textsubscript{total} / ΔV = 165 × 10⁻⁹ / 0.5 = 330 nF.\\
Use a standard 470 nF or 1 μF ceramic capacitor for margin.\\
The bootstrap voltage when fully charged: V\textsubscript{boot} =
V\textsubscript{CC} − V\textsubscript{F(diode)} = 15 − 0.5 = 14.5 V.\\
After the high-side on-time, V\textsubscript{boot} droops to 14.5 − (165
× 10⁻⁹ / 470 × 10⁻⁹) = 14.5 − 0.35 = 14.15 V, well above the MOSFET's
minimum gate drive voltage of 10 V.

\end{examplebox}

\section{10.2 Rectifiers}\label{rectifiers}

Rectifiers are the most fundamental power electronic converters,
transforming AC into DC. They range from simple diode bridges in offline
power supplies to high-power thyristor rectifiers in industrial
electrochemical plants and HVDC converter stations. Rectifier design
involves selecting the topology (half-wave, full-wave, multi-pulse),
choosing uncontrolled (diode) or controlled (thyristor) operation,
sizing the output filter to meet ripple requirements, and managing
harmonic currents drawn from the AC source.

\subsection{10.2.1 Single-Phase
Rectifiers}\label{single-phase-rectifiers}

Single-phase rectifiers convert single-phase AC to DC using diodes or
thyristors. The half-wave rectifier uses a single diode and conducts
only during the positive half-cycle, producing a pulsating DC output
with high ripple and a DC voltage of V\textsubscript{dc} =
V\textsubscript{peak}/π. The full-wave bridge rectifier uses four diodes
and conducts during both half-cycles, doubling the DC output to
V\textsubscript{dc} = 2V\textsubscript{peak}/π with reduced ripple at
twice the line frequency. Adding a capacitor filter across the output
smooths the ripple, with larger capacitance yielding lower ripple but
higher peak diode currents. Phase-controlled rectifiers replace diodes
with thyristors, allowing the DC output voltage to be continuously
adjusted from maximum to zero (and negative for full converters) by
varying the firing angle α: V\textsubscript{dc} =
(2V\textsubscript{peak}/π)cos(α).

\begin{examplebox}

\textbf{Example 10.2.1:} A single-phase full-wave bridge rectifier is
fed from a 120 V\textsubscript{rms}, 60 Hz source and supplies a load
requiring 100 V DC. A capacitor filter is used. Calculate the ideal
(no-load) DC output voltage and determine the firing angle α needed if
thyristors are used to regulate the output to exactly 100 V DC.

\textbf{Solution:}\\
V\textsubscript{peak} = 120 × √2 = 169.7 V.\\
Ideal uncontrolled DC output: V\textsubscript{dc} =
2V\textsubscript{peak}/π = 2 × 169.7 / π = 108.0 V.\\
For a fully controlled bridge rectifier to produce V\textsubscript{dc} =
100 V: 100 = (2 × 169.7 / π) cos(α) = 108.0 cos(α).\\
cos(α) = 100/108.0 = 0.926.\\
α = cos⁻¹(0.926) = 22.2°.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-2-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_rectifier.png}

\caption{Figure 10.2.1: Full-Wave Bridge Rectifier}

\end{figure}

\subsection{10.2.2 Three-Phase Rectifiers}\label{three-phase-rectifiers}

Three-phase rectifiers are standard in industrial and high-power
applications because they produce lower output ripple and more efficient
use of the transformer and source. The three-phase half-wave
(three-pulse) rectifier uses three diodes and produces output ripple at
three times the line frequency, with V\textsubscript{dc} =
(3√3/(2π))V\textsubscript{peak}. The three-phase full-wave bridge
(six-pulse) rectifier uses six diodes and produces ripple at six times
the line frequency, with V\textsubscript{dc} =
(3√3/π)V\textsubscript{peak}, yielding smoother DC with only about 4.2\%
ripple. Twelve-pulse and higher-pulse rectifiers use transformer phase
shifting (typically delta-wye combinations) to further reduce harmonics
and ripple. Three-phase controlled rectifiers using thyristors provide
adjustable DC output voltage for applications such as DC motor drives,
electrochemical processes, and HVDC converter stations.

\begin{examplebox}

\textbf{Example 10.2.2:} A three-phase full-wave (six-pulse) diode
bridge rectifier is fed from a 480 V\textsubscript{rms} line-to-line, 60
Hz three-phase source. Calculate the average DC output voltage and the
ripple frequency.

\textbf{Solution:}\\
The peak line-to-line voltage: V\textsubscript{peak} = 480 × √2 = 678.8
V.\\
For a six-pulse diode rectifier: V\textsubscript{dc} = (3/π) ×
V\textsubscript{peak(L-L)} = (3 / 3.1416) × 678.8 = 0.9549 × 678.8 =
648.2 V (alternatively, V\textsubscript{dc} = 3√2/π ×
V\textsubscript{rms(L-L)} = 3 × 1.4142 / 3.1416 × 480 = 1.3505 × 480 =
648.2 V, confirming the result).\\
Ripple frequency: f\textsubscript{ripple} = 6 × f\textsubscript{line} =
6 × 60 = 360 Hz.\\
The peak-to-peak ripple is approximately 4.2\% of V\textsubscript{dc},
or about 27.2 V.

\end{examplebox}

\subsection{10.2.3 Rectifier Harmonics and Input
Filtering}\label{rectifier-harmonics-and-input-filtering}

Non-linear loads such as diode and thyristor rectifiers draw current
from the AC source in pulses rather than sinusoidally, injecting
harmonic currents back into the power system. A single-phase diode
bridge with a capacitor filter draws current only near the peak of the
voltage waveform, producing odd harmonics (3rd, 5th, 7th, \ldots) with a
current THD typically exceeding 100\% and a displacement power factor
near unity but a true power factor of only 0.5-0.65. A six-pulse
three-phase diode bridge produces characteristic harmonics of order h =
6k ± 1 (5th, 7th, 11th, 13th, \ldots) with magnitudes approximately
I\textsubscript{h} ≈ I₁/h, yielding a current THD of about 25-30\%. IEEE
Standard 519 limits the harmonic current distortion that a customer may
inject into the utility system at the point of common coupling (PCC),
with limits depending on the ratio of short-circuit current to load
current (I\textsubscript{SC}/I\textsubscript{L}). \textbf{Passive
harmonic filters} use tuned LC series circuits connected in shunt to
provide a low-impedance path for specific harmonics (typically 5th and
7th), diverting them from the supply. \textbf{Multi-pulse rectifiers}
(12-pulse using delta-wye transformers, 18-pulse, 24-pulse) cancel
lower-order harmonics through phase shifting --- a 12-pulse rectifier
eliminates the 5th and 7th harmonics, reducing THD to approximately
10-12\%. \textbf{Active harmonic filters} inject equal-and-opposite
harmonic currents using a PWM inverter, reducing THD below 5\%
regardless of load conditions.

\begin{examplebox}

\textbf{Example 10.2.3:} A 12-pulse rectifier system uses two six-pulse
bridges fed from a delta-wye and a delta-delta transformer, each
producing 30° of phase shift. The fundamental current drawn by each
bridge is 100 A. Calculate the expected 5th, 7th, 11th, and 13th
harmonic currents at the input, and compare the THD to a single
six-pulse bridge.

\textbf{Solution:}\\
For a single six-pulse bridge, characteristic harmonics: I₅ = 100/5 = 20
A, I₇ = 100/7 = 14.3 A, I₁₁ = 100/11 = 9.1 A, I₁₃ = 100/13 = 7.7 A.\\
Single-bridge THD ≈ √(20² + 14.3² + 9.1² + 7.7² + \ldots) / 100 ≈ √(400
+ 204.5 + 82.8 + 59.3) / 100 ≈ 27.3\% (first four harmonics only).\\
In the 12-pulse system, the 30° phase shift between the two bridges
causes the 5th and 7th harmonics to cancel at the AC supply --- the
negative-sequence 5th harmonic is shifted by 5 × 30° = 150° and the
positive-sequence 7th by 7 × 30° = 210° through the delta-wye
transformer, and the resulting primary currents sum to zero for both
orders.\\
The 11th and 13th harmonics add in phase: I₁₁ = 2 × (100/11) = 18.2 A,
I₁₃ = 2 × (100/13) = 15.4 A, with fundamental I₁ = 2 × 100 = 200 A.\\
12-pulse THD ≈ √(18.2² + 15.4²) / 200 = √(331.2 + 237.2) / 200 = 23.8 /
200 = 11.9\%.\\
The 12-pulse arrangement reduces THD from \textasciitilde27\% to
\textasciitilde12\%, eliminating the dominant 5th and 7th harmonics that
are most difficult to filter.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-2-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_harmonics.png}

\caption{Figure 10.2.3: Rectifier Harmonic Spectrum: 6-Pulse vs 12-Pulse}

\end{figure}

\section{10.3 DC-DC Converters}\label{dc-dc-converters}

DC-DC converters change one DC voltage level to another with high
efficiency using switching techniques rather than the resistive voltage
division of linear regulators. The basic non-isolated topologies ---
buck, boost, and buck-boost --- form the foundation from which dozens of
specialized topologies are derived. Isolated converters add a
transformer for galvanic isolation and voltage scaling. The choice of
topology depends on the input/output voltage ratio, power level,
isolation requirements, and performance targets for efficiency, size,
and transient response.

\subsection{10.3.1 Buck Converter}\label{buck-converter}

The buck (step-down) converter reduces a higher DC input voltage to a
lower DC output voltage with high efficiency. It operates by rapidly
switching the input voltage across an inductor using a transistor
(typically a MOSFET) and a freewheeling diode, with the inductor and
output capacitor averaging the switched waveform into a smooth DC
output. The output voltage is controlled by the duty cycle D (the
fraction of the switching period the transistor is on):
V\textsubscript{out} = D × V\textsubscript{in}, where 0 \textless{} D
\textless{} 1. In continuous conduction mode (CCM), the inductor current
never reaches zero during a switching cycle, and the output ripple is
determined by the inductance, capacitance, and switching frequency.
Synchronous buck converters replace the freewheeling diode with a second
MOSFET to reduce conduction losses, achieving efficiencies above 95\% in
modern designs.

\begin{examplebox}

\textbf{Example 10.3.1:} A buck converter operates from
V\textsubscript{in} = 24 V and must produce V\textsubscript{out} = 5 V
at I\textsubscript{out} = 3 A. The switching frequency is
f\textsubscript{sw} = 500 kHz. Determine the duty cycle, and calculate
the minimum inductance required to maintain continuous conduction mode
(CCM) assuming a ripple current of 30\% of the output current.

\textbf{Solution:}\\
Duty cycle: D = V\textsubscript{out} / V\textsubscript{in} = 5 / 24 =
0.2083 (20.83\%).\\
The peak-to-peak inductor ripple current: ΔI\textsubscript{L} = 0.30 ×
I\textsubscript{out} = 0.30 × 3 = 0.9 A.\\
For a buck converter: ΔI\textsubscript{L} = (V\textsubscript{in} -
V\textsubscript{out}) × D / (L × f\textsubscript{sw}).\\
Solving for L: L = (V\textsubscript{in} - V\textsubscript{out}) × D /
(ΔI\textsubscript{L} × f\textsubscript{sw}) = (24 - 5) × 0.2083 / (0.9 ×
500,000) = 3.958 / 450,000 = 8.8 μH.\\
Use a standard value of 10 μH to ensure CCM operation with margin.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-3-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_buck.png}

\caption{Figure 10.3.1: Buck Converter Inductor Current}

\end{figure}

\subsection{10.3.2 Boost Converter}\label{boost-converter}

The boost (step-up) converter increases a lower DC input voltage to a
higher DC output voltage. During the on-time, the switch connects the
inductor across the input, storing energy in its magnetic field; during
the off-time, the inductor voltage adds to the input voltage and
transfers energy through the diode to the output capacitor. The ideal
voltage conversion ratio is V\textsubscript{out} =
V\textsubscript{in}/(1 - D), where D is the duty cycle, allowing
theoretically unlimited voltage gain as D approaches 1. In practice,
parasitic resistances limit the achievable voltage gain to approximately
4-5× before efficiency degrades significantly. Boost converters are used
in power factor correction front ends, battery-powered systems that
require higher voltage rails, solar maximum power point trackers (MPPT),
and LED drivers.

\begin{examplebox}

\textbf{Example 10.3.2:} A boost converter must step up a solar panel
voltage of V\textsubscript{in} = 18 V to V\textsubscript{out} = 48 V for
a battery charging application. The load current is 2 A, and the
switching frequency is f\textsubscript{sw} = 150 kHz. Determine the duty
cycle and the input current.

\textbf{Solution:}\\
Duty cycle: V\textsubscript{out} = V\textsubscript{in} / (1 - D), so 1 -
D = V\textsubscript{in} / V\textsubscript{out} = 18 / 48 = 0.375, giving
D = 0.625 (62.5\%).\\
Assuming an ideal (lossless) converter, input power equals output power:
P\textsubscript{out} = V\textsubscript{out} × I\textsubscript{out} = 48
× 2 = 96 W.\\
I\textsubscript{in} = P\textsubscript{out} / V\textsubscript{in} = 96 /
18 = 5.33 A.\\
Alternatively, I\textsubscript{in} = I\textsubscript{out} / (1 - D) = 2
/ 0.375 = 5.33 A, confirming the result.\\
The inductor must carry the full 5.33 A input current continuously.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-3-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_boost.png}

\caption{Figure 10.3.2: Boost Converter Inductor Current}

\end{figure}

\subsection{10.3.3 Buck-Boost Converter}\label{buck-boost-converter}

The buck-boost converter can produce an output voltage that is either
higher or lower than the input voltage, with the output polarity
inverted relative to the input. When the switch is on, the inductor
charges from the input; when the switch is off, the inductor discharges
into the output through the diode. The ideal voltage conversion ratio is
V\textsubscript{out} = -V\textsubscript{in} × D/(1 - D), where the
negative sign indicates polarity inversion. The Ćuk converter, SEPIC
(Single-Ended Primary-Inductor Converter), and ZETA converter are
related topologies that provide non-inverted buck-boost operation using
two inductors (or a coupled inductor) and a series capacitor for energy
transfer. Four-switch (H-bridge) buck-boost converters avoid polarity
inversion and provide seamless transitions between buck and boost modes,
commonly used in battery management systems where the battery voltage
may be above or below the required output.

\begin{examplebox}

\textbf{Example 10.3.3:} An inverting buck-boost converter operates from
V\textsubscript{in} = 12 V with a duty cycle D = 0.4. Calculate the
output voltage. If the duty cycle is then increased to D = 0.7, what is
the new output voltage?

\textbf{Solution:}\\
For an ideal inverting buck-boost converter: V\textsubscript{out} =
-V\textsubscript{in} × D / (1 - D).\\
At D = 0.4: V\textsubscript{out} = -12 × 0.4 / (1 - 0.4) = -12 × 0.4 /
0.6 = -12 × 0.667 = -8.0 V (buck mode,
\textbar V\textsubscript{out}\textbar{} \textless{}
V\textsubscript{in}).\\
At D = 0.7: V\textsubscript{out} = -12 × 0.7 / (1 - 0.7) = -12 × 0.7 /
0.3 = -12 × 2.333 = -28.0 V (boost mode,
\textbar V\textsubscript{out}\textbar{} \textgreater{}
V\textsubscript{in}).\\
This demonstrates the topology's ability to produce outputs both below
and above the input magnitude.

\end{examplebox}

\subsection{10.3.4 Isolated Converters}\label{isolated-converters}

Isolated DC-DC converters use a transformer to provide galvanic
isolation between input and output, enabling voltage scaling through the
turns ratio and meeting safety requirements. The flyback converter is
the simplest isolated topology, derived from the buck-boost converter
with the inductor replaced by a coupled inductor (flyback transformer),
widely used in low-power applications (up to \textasciitilde150 W) such
as phone chargers and standby power supplies. The forward converter is
derived from the buck converter and uses a true transformer with
simultaneous energy transfer, suitable for power levels up to several
hundred watts. For higher power levels (500 W to several kilowatts), the
half-bridge and full-bridge converters drive the transformer with an AC
square wave and use a secondary-side rectifier and filter. Phase-shifted
full-bridge converters achieve zero-voltage switching (ZVS) to reduce
switching losses, and LLC resonant converters use a resonant tank
circuit to achieve both ZVS and zero-current switching (ZCS) for high
efficiency across a wide load range.

\begin{examplebox}

\textbf{Example 10.3.4:} A flyback converter operates from
V\textsubscript{in} = 375 V DC (from a PFC front end) and must produce
V\textsubscript{out} = 12 V at I\textsubscript{out} = 3 A. The
transformer turns ratio is N\textsubscript{p}:N\textsubscript{s} = 20:1,
the maximum duty cycle is D\textsubscript{max} = 0.45, and the switching
frequency is f\textsubscript{sw} = 100 kHz. Verify that the turns ratio
is suitable and calculate the peak primary current.

\textbf{Solution:}\\
For a flyback converter in CCM, the output voltage is:
V\textsubscript{out} = V\textsubscript{in} ×
(N\textsubscript{s}/N\textsubscript{p}) × D / (1 - D).\\
At D = D\textsubscript{max}: V\textsubscript{out} = 375 × (1/20) × 0.45
/ (1 - 0.45) = 375 × 0.05 × 0.818 = 15.3 V.\\
This exceeds 12 V, confirming the turns ratio provides adequate
margin.\\
For V\textsubscript{out} = 12 V: 12 = 375 × 0.05 × D / (1 - D), so D /
(1 - D) = 12 / 18.75 = 0.64, giving D = 0.39.\\
Output power: P\textsubscript{out} = 12 × 3 = 36 W. Assuming 90\%
efficiency, P\textsubscript{in} = 36 / 0.90 = 40 W.\\
Average primary current: I\textsubscript{p(avg)} = P\textsubscript{in} /
V\textsubscript{in} = 40 / 375 = 0.107 A.\\
Peak primary current (CCM, assuming 40\% ripple):
I\textsubscript{p(peak)} ≈ I\textsubscript{p(avg)} / D + ΔI/2 ≈ 0.107 /
0.39 × (1 + 0.20) ≈ 0.329 A.

\end{examplebox}

\subsection{10.3.5 Resonant Converters}\label{resonant-converters}

Resonant converters use the interaction between inductors and capacitors
(an LC resonant tank) to shape the voltage and current waveforms at the
switching devices, enabling zero-voltage switching (ZVS) or zero-current
switching (ZCS) to dramatically reduce switching losses. By switching
when either the voltage across or the current through the device is
zero, the V × I overlap that causes switching losses in hard-switched
converters is eliminated, allowing operation at much higher frequencies
(500 kHz to several MHz) with high efficiency. The \textbf{LLC resonant
converter} is the most widely used resonant topology, employing a
resonant network of two inductors (L\textsubscript{r},
L\textsubscript{m}) and one capacitor (C\textsubscript{r}) between a
half-bridge or full-bridge switching stage and a transformer. The LLC
converter achieves ZVS for the primary switches across the entire load
range, provides inherent short-circuit protection, and has high
efficiency at the resonant frequency where the gain is unity. Frequency
modulation (varying f\textsubscript{sw} relative to the resonant
frequency f\textsubscript{r} =
1/(2π√(L\textsubscript{r}C\textsubscript{r}))) controls the output
voltage. Below resonance the converter operates in ZCS mode for the
secondary rectifiers; above resonance it maintains primary ZVS but with
increasing circulating current. LLC converters dominate in server power
supplies, telecom rectifiers, TV power supplies, and EV on-board
chargers, typically achieving 95--97\% peak efficiency.

\begin{examplebox}

\textbf{Example 10.3.5:} An LLC resonant converter has
L\textsubscript{r} = 50 μH, C\textsubscript{r} = 10 nF, and magnetizing
inductance L\textsubscript{m} = 250 μH. The transformer turns ratio is
16:1, V\textsubscript{in} = 400 V (from PFC), and V\textsubscript{out} =
12 V. Calculate the series resonant frequency f\textsubscript{r}, the
ratio L\textsubscript{m}/L\textsubscript{r}, and verify the output
voltage at the resonant frequency.

\textbf{Solution:}\\
Series resonant frequency: f\textsubscript{r} =
1/(2π√(L\textsubscript{r}C\textsubscript{r})) = 1/(2π√(50 × 10⁻⁶ × 10 ×
10⁻⁹)) = 1/(2π√(500 × 10⁻¹⁵)).\\
Recalculating: √(50 × 10⁻⁶ × 10 × 10⁻⁹) = √(5 × 10⁻¹³) = 7.071 × 10⁻⁷.\\
f\textsubscript{r} = 1/(2π × 7.071 × 10⁻⁷) = 1/(4.443 × 10⁻⁶) = 225
kHz.\\
Inductance ratio: L\textsubscript{m}/L\textsubscript{r} = 250/50 = 5 (a
typical value; higher ratios narrow the frequency range but improve
efficiency).\\
At the resonant frequency, the LLC gain for a half-bridge is
approximately 1.0, so V\textsubscript{out} = (V\textsubscript{in}/2) ×
(N\textsubscript{s}/N\textsubscript{p}) × gain = (400/2) × (1/16) × 1.0
= 200 × 0.0625 = 12.5 V.\\
This is close to the 12 V target; the switching frequency will operate
slightly above 225 kHz to reduce the gain to exactly 12/12.5 = 0.96.

\end{examplebox}

\subsection{10.3.6 Converter Control: Voltage Mode and Current
Mode}\label{converter-control-voltage-mode-and-current-mode}

Switching converters require closed-loop feedback control to maintain a
regulated output voltage despite variations in input voltage and load
current. \textbf{Voltage mode control} (VMC) senses the output voltage,
compares it to a reference, and adjusts the duty cycle through an error
amplifier and PWM comparator. The control loop is a single voltage
feedback loop with a Type II or Type III compensator designed to provide
adequate phase margin (typically 45--60°) and crossover frequency
(typically f\textsubscript{sw}/10 to f\textsubscript{sw}/5). VMC is
simple to implement but has slower transient response because load
current changes must first appear as output voltage deviations before
the loop corrects. \textbf{Current mode control} (CMC) adds an inner
current loop that senses the inductor current and compares it to the
output of the voltage error amplifier, effectively turning the power
stage into a voltage-controlled current source. Peak current mode
control terminates the on-time when the sensed inductor current reaches
the control voltage, providing cycle-by-cycle current limiting, inherent
current sharing in parallel converters, and simplified compensator
design (the power stage appears as a single-pole system). CMC requires
slope compensation to prevent subharmonic oscillation at duty cycles
above 50\% --- a fixed ramp signal is added to the sensed current signal
to ensure stability. Average current mode control senses the average
inductor current rather than the peak, providing more accurate current
regulation and better noise immunity, and is the standard method for
boost PFC converters. Modern digital control implementations use ADCs
and digital compensators (PID with anti-windup) running on DSPs or
dedicated power management ICs, enabling adaptive tuning, nonlinear
control, and predictive algorithms that improve transient response
beyond what analog loops achieve.

\begin{examplebox}

\textbf{Example 10.3.6:} A buck converter with V\textsubscript{in} = 12
V, V\textsubscript{out} = 3.3 V, L = 4.7 μH, C = 100 μF (ESR = 15 mΩ),
and f\textsubscript{sw} = 500 kHz uses peak current mode control.
Calculate the duty cycle, the slope compensation ramp needed to prevent
subharmonic oscillation, and the inductor current downslope.

\textbf{Solution:}\\
Duty cycle: D = V\textsubscript{out}/V\textsubscript{in} = 3.3/12 =
0.275 (27.5\%).\\
Since D \textless{} 0.5, subharmonic oscillation is not a concern at
this operating point, but slope compensation is still good practice for
robustness.\\
Inductor current upslope: m₁ = (V\textsubscript{in} -
V\textsubscript{out})/L = (12 - 3.3)/(4.7 × 10⁻⁶) = 1.851 A/μs.\\
Inductor current downslope: m₂ = V\textsubscript{out}/L = 3.3/(4.7 ×
10⁻⁶) = 0.702 A/μs.\\
The minimum slope compensation to guarantee stability at all duty cycles
is S\textsubscript{e} ≥ m₂/2 = 0.702/2 = 0.351 A/μs.\\
Converting to a voltage ramp across a 50 mΩ sense resistor: the
compensation ramp rate is 0.351 × 0.050 = 17.6 mV/μs, or 17.6 mV/μs × 2
μs (switching period) = 35.1 mV peak ramp added per cycle.

\end{examplebox}

\section{10.4 Inverters}\label{inverters}

Inverters perform the reverse function of rectifiers, converting DC
power to AC at a controlled frequency and amplitude. Modern inverters
use pulse-width modulation to synthesize high-quality sinusoidal outputs
with low harmonic distortion. They are the enabling technology for
variable-speed motor drives, grid-tied renewable energy systems,
uninterruptible power supplies, and electric vehicle powertrains.

\subsection{10.4.1 Single-Phase Inverters}\label{single-phase-inverters}

Single-phase inverters convert DC to single-phase AC using a full-bridge
(H-bridge) of four switching devices that alternately connect the load
to the positive and negative DC bus. Square-wave inverters produce a
simple ±V\textsubscript{dc} output but contain significant low-order
harmonics that are difficult to filter. Pulse Width Modulation (PWM)
inverters switch at high frequency (typically 10-100 kHz) and vary the
pulse widths within each half-cycle to synthesize a sinusoidal output
with harmonics pushed to high frequencies where they are easily filtered
by small inductors and capacitors. Sinusoidal PWM (SPWM) compares a
sinusoidal reference to a triangular carrier to generate the switching
pattern, with the output fundamental voltage controlled by the
modulation index m\textsubscript{a} =
V\textsubscript{reference}/V\textsubscript{carrier}. Single-phase
inverters are used in residential solar inverters, uninterruptible power
supplies (UPS), and small variable-frequency drives.

\begin{examplebox}

\textbf{Example 10.4.1:} A single-phase full-bridge inverter operates
from a DC bus voltage of V\textsubscript{dc} = 400 V with sinusoidal
PWM. The modulation index is m\textsubscript{a} = 0.85 and the switching
frequency is f\textsubscript{sw} = 20 kHz. Calculate the fundamental RMS
output voltage and the frequency of the lowest-order harmonics in the
output.

\textbf{Solution:}\\
For a single-phase SPWM inverter, the peak fundamental output voltage
is: V₁\textsubscript{(peak)} = m\textsubscript{a} × V\textsubscript{dc}
= 0.85 × 400 = 340 V.\\
The fundamental RMS voltage: V₁\textsubscript{(rms)} = 340 / √2 = 240.4
V.\\
The switching harmonics in SPWM appear as sidebands around multiples of
the switching frequency.\\
The lowest significant harmonics are at frequencies f\textsubscript{sw}
± f₁, 2f\textsubscript{sw} ± f₁, etc.\\
For a 60 Hz fundamental: first harmonic cluster is at 20,000 ± 60 Hz,
i.e., 19,940 Hz and 20,060 Hz.\\
These high-frequency components are easily filtered by a small LC output
filter.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-4-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_spwm.png}

\caption{Figure 10.4.1: SPWM Inverter Output}

\end{figure}

\subsection{10.4.2 Three-Phase Inverters}\label{three-phase-inverters}

Three-phase inverters use six switching devices (three half-bridge legs)
to produce three-phase AC from a DC source and are the standard topology
for industrial motor drives, grid-tied solar and wind inverters, and
electric vehicle traction drives. Six-step (120° or 180° conduction)
switching produces a quasi-square-wave output with low-order harmonics
(5th, 7th, 11th, 13th). Space Vector PWM (SVPWM) is the preferred
modulation technique in modern three-phase inverters, providing
approximately 15.5\% higher DC bus utilization than SPWM and lower
harmonic distortion. Multilevel inverters (neutral-point-clamped, flying
capacitor, and cascaded H-bridge topologies) synthesize the output
waveform using multiple voltage levels, reducing harmonic content and
dv/dt stress on the switching devices while enabling operation at higher
voltages than individual device ratings would allow. Output LC or LCL
filters attenuate the switching-frequency harmonics to meet grid
connection standards such as IEEE 1547 and IEC 61000-3-12.

\begin{examplebox}

\textbf{Example 10.4.2:} A three-phase inverter operates from a
V\textsubscript{dc} = 650 V DC bus using space vector PWM (SVPWM).
Calculate the maximum fundamental line-to-line RMS output voltage.
Compare this to the output achievable with standard SPWM.

\textbf{Solution:}\\
With SVPWM, the maximum peak fundamental phase voltage is
V\textsubscript{phase(peak)} = V\textsubscript{dc} / √3 = 650 / 1.732 =
375.3 V.\\
The maximum line-to-line RMS voltage: V\textsubscript{LL(rms)} =
V\textsubscript{phase(peak)} × √3 / √2 = 375.3 × 1.732 / 1.414 = 375.3 ×
1.225 = 459.7 V.\\
With standard SPWM (m\textsubscript{a} = 1.0):
V\textsubscript{phase(peak)} = V\textsubscript{dc} / 2 = 325 V.
V\textsubscript{LL(rms)} = 325 × √3 / √2 = 325 × 1.225 = 398.1 V.\\
The improvement: 459.7 / 398.1 = 1.155, confirming the 15.5\% higher DC
bus utilization of SVPWM over SPWM.

\end{examplebox}

\subsection{10.4.3 Multilevel Inverters}\label{multilevel-inverters}

Multilevel inverters synthesize the output voltage waveform using three
or more discrete voltage levels, reducing the harmonic content and dv/dt
stress on the load compared to conventional two-level inverters. By
approximating the sinusoidal output with a staircase of smaller voltage
steps, each switching transition involves a fraction of the total DC bus
voltage, reducing electromagnetic interference, output filter
requirements, and insulation stress on motor windings. The three main
multilevel topologies are: \textbf{Neutral-Point-Clamped (NPC)}
inverters, which use clamping diodes to produce three or more voltage
levels from a split DC bus with series capacitors; \textbf{Flying
Capacitor} inverters, which use floating capacitors charged to fractions
of the DC bus voltage to create intermediate levels; and
\textbf{Cascaded H-Bridge (CHB)} inverters, which connect multiple
single-phase H-bridge modules in series per phase, each with its own
isolated DC source. A three-level NPC inverter (the most common) uses
four switches per phase leg and produces output voltage levels of
+V\textsubscript{dc}/2, 0, and -V\textsubscript{dc}/2, effectively
halving the dv/dt per switching event and eliminating the need for
output dv/dt filters in many motor drive applications. Five-level and
seven-level topologies further reduce harmonics but increase component
count and control complexity. Modular multilevel converters (MMC) --- a
variant of the CHB approach using dozens to hundreds of submodules per
arm --- are the dominant topology for HVDC voltage-source converters and
STATCOM applications, handling voltages up to ±525 kV with individual
submodule voltages of only 1.5-2.5 kV.

\begin{examplebox}

\textbf{Example 10.4.3:} A three-level NPC inverter operates from a DC
bus of V\textsubscript{dc} = 800 V (±400 V, with a midpoint). Compare
the voltage step size and output THD to a two-level inverter at the same
bus voltage, both using SPWM at f\textsubscript{sw} = 5 kHz with a 60 Hz
fundamental.

\textbf{Solution:}\\
Two-level inverter: each switching transition steps between +400 V and
-400 V, a step of 800 V. The output phase voltage toggles between
+V\textsubscript{dc}/2 = +400 V and -V\textsubscript{dc}/2 = -400 V.\\
dv/dt per transition = 800 V / t\textsubscript{rise}. For a typical 100
ns rise time: dv/dt = 800 / 100 × 10⁻⁹ = 8 kV/μs.\\
Three-level NPC: each transition steps between adjacent levels (0 to
+400 V, or 0 to -400 V), a step of 400 V --- half the two-level value.
dv/dt = 400 / 100 × 10⁻⁹ = 4 kV/μs (50\% reduction).\\
The three-level output has an effective switching frequency of 2 ×
f\textsubscript{sw} = 10 kHz as seen by the load (each phase produces
two switching events per carrier cycle), pushing the lowest harmonic
cluster to 10 kHz ± 60 Hz instead of 5 kHz ± 60 Hz.\\
The weighted THD of the three-level output is typically 40-50\% lower
than the two-level output at the same switching frequency, or
equivalently, the three-level inverter can achieve the same THD at half
the switching frequency, reducing switching losses by 50\%.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-4-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_multilevel.png}

\caption{Figure 10.4.3: Multilevel Inverter: 2-Level vs 3-Level NPC}

\end{figure}

\section{10.5 AC-AC Converters}\label{ac-ac-converters}

AC-AC converters change the voltage, frequency, or both of an AC power
source without an intermediate DC stage (or with a minimal one).
Phase-controlled AC voltage controllers adjust the RMS voltage delivered
to a load, while cycloconverters and matrix converters provide frequency
conversion for specialized motor drive and power conditioning
applications.

\subsection{10.5.1 AC Voltage Controllers}\label{ac-voltage-controllers}

AC voltage controllers regulate the RMS value of the AC output voltage
by controlling the conduction angle of thyristors or triacs connected in
series with the load. Phase-angle control delays the firing of the
thyristors by an angle α each half-cycle, reducing the RMS output
voltage according to V\textsubscript{out} = V\textsubscript{in} × √((π -
α + sin(2α)/2)/π) for resistive loads. Common applications include
lighting dimmers, heating controls, and soft starters for induction
motors that limit the starting current by gradually increasing the
voltage. The primary disadvantage of phase-angle control is the
generation of low-order harmonics and poor power factor at reduced
output voltages. Integral cycle control (burst firing) is an alternative
that switches complete half-cycles on and off, producing no additional
harmonics but introducing sub-harmonic flicker that limits its use to
loads with long thermal time constants such as ovens and heaters.

\begin{examplebox}

\textbf{Example 10.5.1:} A single-phase AC voltage controller with
back-to-back thyristors supplies a 10 Ω resistive heating load from a
240 V\textsubscript{rms}, 50 Hz source. The firing angle is set to α =
90°. Calculate the RMS output voltage and the power delivered to the
load.

\textbf{Solution:}\\
For a resistive load with phase-angle control: V\textsubscript{out(rms)}
= V\textsubscript{in} × √{[}(π - α + sin(2α)/2) / π{]}.\\
With α = 90° = π/2 radians: sin(2 × 90°) = sin(180°) = 0.\\
V\textsubscript{out(rms)} = 240 × √{[}(π - π/2 + 0) / π{]} = 240 ×
√{[}0.5{]} = 240 × 0.707 = 169.7 V.\\
Power delivered: P = V\textsubscript{out(rms)}² / R = (169.7)² / 10 =
28,798 / 10 = 2,880 W.\\
This is exactly 50\% of the full power (240²/10 = 5,760 W), which makes
sense since exactly half the waveform is conducted at α = 90°.

\end{examplebox}

\subsection{10.5.2 Cycloconverters}\label{cycloconverters}

A cycloconverter converts AC at one frequency directly to AC at a
different (typically lower) frequency without an intermediate DC link,
using naturally commutated thyristors. It synthesizes the output
waveform by selecting segments of the input voltage waveform, with the
output frequency limited to approximately one-third of the input
frequency for acceptable output quality. Three-phase to single-phase
cycloconverters use two back-to-back controlled rectifier bridges (one
for positive and one for negative output half-cycles), while three-phase
to three-phase configurations use six bridges. Cycloconverters are used
in high-power, low-speed motor drives (cement mills, mine hoists, ship
propulsion) where their ability to handle megawatt-level power without
high-frequency switching is advantageous. Modern matrix converters offer
a more compact alternative by providing bidirectional AC-AC conversion
with controllable output frequency and amplitude using bidirectional
switch arrays without energy storage elements.

\begin{examplebox}

\textbf{Example 10.5.2:} A three-phase to single-phase cycloconverter is
fed from a 60 Hz, 480 V\textsubscript{rms} supply and must produce a 15
Hz output for a low-speed cement mill drive. Verify this output
frequency is achievable and determine the maximum output voltage.

\textbf{Solution:}\\
The maximum recommended output frequency for a cycloconverter is
f\textsubscript{out(max)} ≈ f\textsubscript{in} / 3 = 60 / 3 = 20 Hz.
Since 15 Hz \textless{} 20 Hz, this frequency is achievable with
acceptable waveform quality.\\
The maximum output voltage of a cycloconverter equals the maximum DC
output of the constituent controlled rectifier bridges.\\
For a three-phase fully controlled bridge: V\textsubscript{dc(max)} =
(3/π) × V\textsubscript{peak(L-L)} = 0.9549 × 678.8 = 648.2 V (average
DC output at firing angle α = 0°).\\
The RMS output voltage at maximum is approximately
V\textsubscript{out(rms)} ≈ V\textsubscript{dc(max)} / √2 = 648.2 /
1.414 ≈ 458.4 V.\\
In practice, the output is limited to about 75--80\% of the input
voltage due to commutation overlap, yielding approximately
V\textsubscript{out} ≈ 0.75 × 480 = 360 V\textsubscript{rms}.

\end{examplebox}

\subsection{10.5.3 Matrix Converters}\label{matrix-converters}

A matrix converter is a direct AC-to-AC power converter that connects
each output phase to any input phase through a matrix of bidirectional
switches, providing frequency and voltage conversion without any
intermediate DC energy storage (no DC link capacitor or inductor). For a
three-phase to three-phase matrix converter, nine bidirectional switches
arranged in a 3×3 matrix connect three input phases to three output
phases. Each bidirectional switch is typically realized with two
back-to-back IGBTs or MOSFETs with antiparallel diodes (or with
reverse-blocking IGBTs that eliminate the need for series diodes). The
space vector modulation algorithm selects switch states to synthesize
the desired output voltage and frequency while simultaneously
controlling the input current to be sinusoidal with a controllable
displacement power factor. The maximum voltage transfer ratio is limited
to q\textsubscript{max} = √3/2 ≈ 0.866 (86.6\% of the input voltage)
without overmodulation, which is a fundamental limitation compared to
back-to-back voltage source converters that can achieve unity or higher
voltage ratios. Key advantages of matrix converters include: sinusoidal
input and output currents, controllable input power factor (can operate
at unity or leading/lagging), compact size due to elimination of bulky
DC link capacitors, inherent four-quadrant operation (regeneration
capability), and theoretically unlimited output frequency range.
Practical challenges include the need for a clamp circuit to protect
against overvoltage during commutation, a complex four-step commutation
strategy to avoid short-circuiting input phases or open-circuiting
inductive loads, and sensitivity to input voltage disturbances. Matrix
converters are used in aerospace drives (weight-critical applications),
compressor drives, and wind energy systems where bidirectional power
flow and compact size are valued.

\begin{examplebox}

\textbf{Example 10.5.3:} A three-phase matrix converter is fed from a
400 V\textsubscript{rms} line-to-line, 50 Hz source and must supply a 30
Hz, three-phase output to an induction motor rated at 15 kW. Calculate
the maximum output line-to-line voltage, the output line current, and
verify the input line current assuming unity input displacement power
factor and 97\% converter efficiency.

\textbf{Solution:}\\
Maximum output voltage: V\textsubscript{out(LL)} = q\textsubscript{max}
× V\textsubscript{in(LL)} = 0.866 × 400 = 346.4 V\textsubscript{rms}.\\
Output line current at rated power: I\textsubscript{out} = P/(√3 ×
V\textsubscript{out(LL)}) = 15,000/(1.732 × 346.4) = 15,000/599.9 = 25.0
A.\\
Input power (accounting for 97\% efficiency): P\textsubscript{in} =
P\textsubscript{out}/η = 15,000/0.97 = 15,464 W.\\
Input line current: I\textsubscript{in} = P\textsubscript{in}/(√3 ×
V\textsubscript{in(LL)} × cos φ) = 15,464/(1.732 × 400 × 1.0) =
15,464/692.8 = 22.3 A.\\
The input current (22.3 A) is lower than the output current (25.0 A)
because the input voltage is higher than the output voltage --- the
converter steps down voltage and correspondingly steps up current,
conserving power.

\end{examplebox}

\section{10.6 Thermal Management}\label{thermal-management}

Every watt of power lost in a switching converter is dissipated as heat,
and the resulting temperature rise must be managed to keep semiconductor
junctions within their safe operating limits. Thermal design uses an
electrical analog --- thermal resistance (°C/W) models the path from the
junction through the package, thermal interface, heat sink, and
ultimately to the ambient environment. Proper thermal management is
often the factor that limits converter power density and determines
physical size.

\subsection{10.6.1 Power Losses}\label{power-losses}

Power losses in switching converters consist of conduction losses and
switching losses in the semiconductor devices, core losses and copper
losses in magnetic components, and resistive losses in conductors and
interconnects. Conduction losses in MOSFETs are P\textsubscript{cond} =
I\textsubscript{rms}² × R\textsubscript{DS(on)}, which increases with
temperature due to the positive temperature coefficient of MOSFET
on-resistance. Switching losses occur during the transition between on
and off states when both voltage across and current through the device
are simultaneously non-zero: P\textsubscript{sw} = ½ × V × I ×
(t\textsubscript{rise} + t\textsubscript{fall}) × f\textsubscript{sw}.
In IGBTs, additional tail current losses occur during turn-off. Gate
drive losses, reverse recovery losses in diodes, and dead-time-related
losses contribute to overall switching losses. Accurate loss estimation
is essential for thermal design, efficiency optimization, and selection
of the appropriate switching frequency.

\begin{examplebox}

\textbf{Example 10.6.1:} A MOSFET in a buck converter has
R\textsubscript{DS(on)} = 30 mΩ and carries an RMS current of 8 A. The
converter switches at f\textsubscript{sw} = 300 kHz, with
V\textsubscript{DS} = 48 V, I\textsubscript{D} = 10 A (at switching
instants), t\textsubscript{rise} = 15 ns, and t\textsubscript{fall} = 25
ns. The gate charge is Q\textsubscript{g} = 30 nC and the gate drive
voltage is V\textsubscript{gs} = 10 V. Calculate total MOSFET losses.

\textbf{Solution:}\\
Conduction loss: P\textsubscript{cond} = I\textsubscript{rms}² ×
R\textsubscript{DS(on)} = 8² × 0.030 = 1.92 W.\\
Switching loss: P\textsubscript{sw} = ½ × V\textsubscript{DS} ×
I\textsubscript{D} × (t\textsubscript{rise} + t\textsubscript{fall}) ×
f\textsubscript{sw} = ½ × 48 × 10 × (15 + 25) × 10⁻⁹ × 300 × 10³ = ½ ×
48 × 10 × 40 × 10⁻⁹ × 3 × 10⁵ = 2.88 W.\\
Gate drive loss: P\textsubscript{gate} = Q\textsubscript{g} ×
V\textsubscript{gs} × f\textsubscript{sw} = 30 × 10⁻⁹ × 10 × 300 × 10³ =
0.09 W.\\
Total MOSFET loss: P\textsubscript{total} = 1.92 + 2.88 + 0.09 = 4.89 W.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-6-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_power_losses.png}

\caption{Figure 10.6.1: MOSFET Power Losses vs Switching Frequency}

\end{figure}

\subsection{10.6.2 Heat Sinks and Cooling}\label{heat-sinks-and-cooling}

Semiconductor devices must be kept within their rated junction
temperature (typically 125-175°C) to ensure reliable operation and
adequate lifetime. The thermal path from junction to ambient is modeled
as a series of thermal resistances: R\textsubscript{θJC} (junction to
case) + R\textsubscript{θCS} (case to heat sink) + R\textsubscript{θSA}
(heat sink to ambient), with the total temperature rise ΔT =
P\textsubscript{loss} × (R\textsubscript{θJC} + R\textsubscript{θCS} +
R\textsubscript{θSA}). Heat sinks are passive or active thermal
management devices that increase the surface area for heat dissipation
to the surrounding air. Natural convection heat sinks rely on
buoyancy-driven airflow and are suitable for low to moderate power
dissipation, while forced-air cooling using fans can reduce thermal
resistance by a factor of 3-10. For high-power-density applications,
liquid cooling (cold plates with water or water-glycol mixtures)
provides thermal resistances an order of magnitude lower than air
cooling, enabling compact designs in electric vehicle inverters, data
center power supplies, and high-power industrial drives.

\begin{examplebox}

\textbf{Example 10.6.2:} An IGBT module dissipates P\textsubscript{loss}
= 200 W. The thermal resistances are R\textsubscript{θJC} = 0.15 °C/W
(junction to case), R\textsubscript{θCS} = 0.05 °C/W (case to heat sink,
with thermal compound), and R\textsubscript{θSA} = 0.25 °C/W (heat sink
to ambient). The ambient temperature is T\textsubscript{A} = 40°C and
the maximum junction temperature is T\textsubscript{J(max)} = 150°C.
Determine whether the thermal design is adequate.

\textbf{Solution:}\\
Total thermal resistance: R\textsubscript{θJA} = R\textsubscript{θJC} +
R\textsubscript{θCS} + R\textsubscript{θSA} = 0.15 + 0.05 + 0.25 = 0.45
°C/W.\\
Temperature rise: ΔT = P\textsubscript{loss} × R\textsubscript{θJA} =
200 × 0.45 = 90°C.\\
Junction temperature: T\textsubscript{J} = T\textsubscript{A} + ΔT = 40
+ 90 = 130°C.\\
Since T\textsubscript{J} = 130°C \textless{} T\textsubscript{J(max)} =
150°C, the design is adequate with a 20°C margin.\\
The heat sink surface temperature: T\textsubscript{HS} =
T\textsubscript{A} + P\textsubscript{loss} × R\textsubscript{θSA} = 40 +
200 × 0.25 = 90°C.

\end{examplebox}

\subsection{10.6.3 Thermal Interface Materials and Liquid
Cooling}\label{thermal-interface-materials-and-liquid-cooling}

The thermal interface between a semiconductor package and its heat sink
is a critical link in the thermal chain, and the choice of thermal
interface material (TIM) directly impacts junction temperature and
converter reliability. Without a TIM, microscopic surface roughness
leaves air gaps (thermal conductivity \textasciitilde0.025 W/m·K) that
create high thermal resistance between the two mating surfaces.
\textbf{Thermal grease} (silicone-based with metal oxide or ceramic
fillers) fills these gaps and provides thermal conductivity of 1--5
W/m·K with thin bond lines (25--75 μm), achieving R\textsubscript{θCS}
values of 0.05--0.2 °C/W for typical power module footprints.
\textbf{Phase-change materials} (PCMs) are solid at room temperature but
soften at operating temperatures (typically 50--60°C), flowing into
surface irregularities like grease but with the handling convenience of
a solid pad; they offer conductivity of 3--5 W/m·K. \textbf{Thermal
pads} (silicone elastomer with ceramic filler) provide electrical
isolation and gap-filling capability with conductivity of 1--6 W/m·K,
but their greater thickness (0.25--2 mm) results in higher thermal
resistance than grease. \textbf{Solder} or \textbf{sintered silver} TIMs
provide the lowest thermal resistance (conductivity 50--250 W/m·K) and
are used for die-attach in power modules; sintered silver interfaces
achieve R\textsubscript{θ} values 5--10× lower than thermal grease. For
high-power-density converters dissipating hundreds of watts to kilowatts
per device --- such as EV traction inverters, data center power shelves,
and MW-class industrial drives --- \textbf{liquid cooling} with cold
plates replaces air-cooled heat sinks. A cold plate is a thermally
conductive metal block (aluminum or copper) with internal channels
through which a coolant (water, water-glycol mixture, or dielectric
fluid) flows, removing heat by forced convection. Liquid-cooled cold
plates achieve thermal resistances of 0.01--0.05 °C/W --- an order of
magnitude lower than forced-air heat sinks --- enabling power densities
above 50 W/cm². The coolant loop includes a pump, reservoir, radiator or
chiller, and temperature/flow sensors. Pin-fin and microchannel cold
plate designs maximize the wetted surface area within the plate, with
microchannel designs achieving heat transfer coefficients above 10,000
W/m²·K but at higher pressure drop. Two-phase cooling (using boiling
coolant) and jet impingement are emerging approaches for next-generation
power electronics exceeding 200 W/cm² power density.

\begin{examplebox}

\textbf{Example 10.6.3:} A SiC power module dissipates 400 W and is
mounted on a liquid-cooled cold plate. The thermal interface uses
thermal grease with conductivity k\textsubscript{TIM} = 3.5 W/m·K and
bond-line thickness t = 50 μm over a 40 mm × 50 mm contact area. The
cold plate has R\textsubscript{θ(plate-to-coolant)} = 0.02 °C/W, and the
coolant inlet temperature is 25°C. The module's R\textsubscript{θJC} =
0.08 °C/W. Calculate the junction temperature and compare to an
air-cooled design with R\textsubscript{θSA} = 0.15 °C/W.

\textbf{Solution:}\\
TIM thermal resistance: R\textsubscript{θCS} = t/(k\textsubscript{TIM} ×
A) = (50 × 10⁻⁶)/(3.5 × 0.040 × 0.050) = 50 × 10⁻⁶ / (7.0 × 10⁻³) =
0.00714 °C/W.\\
\textbf{Liquid-cooled:} Total R\textsubscript{θ} = R\textsubscript{θJC}
+ R\textsubscript{θCS} + R\textsubscript{θ(plate)} = 0.08 + 0.007 + 0.02
= 0.107 °C/W. T\textsubscript{J} = 25 + 400 × 0.107 = 25 + 42.8 =
67.8°C.\\
\textbf{Air-cooled:} Total R\textsubscript{θ} = R\textsubscript{θJC} +
R\textsubscript{θCS} + R\textsubscript{θSA} = 0.08 + 0.007 + 0.15 =
0.237 °C/W. T\textsubscript{J} = 40 + 400 × 0.237 = 40 + 94.8 = 134.8°C
(using 40°C ambient for air-cooled).\\
The liquid-cooled design runs 67°C cooler, keeping the junction at
67.8°C versus 134.8°C --- well within the SiC module's 175°C rating with
over 100°C of thermal margin, enabling higher power or a smaller module.

\end{examplebox}

\subsection{10.6.4 EMI and Filtering in Power
Converters}\label{emi-and-filtering-in-power-converters}

Switching power converters are inherent sources of electromagnetic
interference (EMI) because their operation depends on rapidly changing
voltages and currents. The steep dv/dt and di/dt transitions during
switching events generate broadband noise that propagates as
\textbf{conducted emissions} through the power lines (150 kHz -- 30 MHz)
and as \textbf{radiated emissions} from PCB traces, cables, and
component leads (30 MHz -- 1 GHz). International standards --- CISPR 32
(multimedia equipment), CISPR 11 (industrial, scientific, medical), FCC
Part 15 (USA), and EN 55032 (EU) --- impose strict limits on both
conducted and radiated emissions to prevent interference with other
equipment. Conducted emissions are measured with a Line Impedance
Stabilization Network (LISN) that presents a defined 50 Ω impedance to
the equipment under test, separating the emission measurement from the
utility supply. Emissions are categorized as \textbf{differential mode}
(DM) noise flowing in opposite directions on the line and neutral
conductors, and \textbf{common mode} (CM) noise flowing in the same
direction on both conductors and returning through the ground. DM noise
is generated by the pulsating input current of the converter and is
filtered by series inductors and parallel capacitors (X-capacitors,
typically 0.1--2.2 μF film type) placed across the line and neutral. CM
noise arises from parasitic capacitive coupling between switching nodes
and the grounded heat sink or chassis, and is filtered by common-mode
chokes (coupled inductors that present high impedance to CM current but
low impedance to DM current) and Y-capacitors (typically 1--4.7 nF
ceramic, limited by safety leakage current requirements) connected from
each line to ground. A well-designed EMI filter typically uses a
two-stage π or T network with both CM and DM filtering elements,
achieving 40--80 dB of attenuation in the 150 kHz -- 30 MHz band. PCB
layout is critical for EMI performance: minimizing the high-di/dt loop
area (the ``hot loop'' between the switching device, freewheeling
diode/synchronous rectifier, and input capacitor) reduces radiated
emissions, while a solid ground plane provides a low-impedance return
path and shielding. Snubber circuits (RC networks across switching
devices) dampen voltage ringing caused by parasitic inductance and
device capacitance, reducing high-frequency spectral content.

\begin{examplebox}

\textbf{Example 10.6.4:} A 200 W flyback converter operating at
f\textsubscript{sw} = 100 kHz fails conducted emission testing per CISPR
32 Class B, exceeding the quasi-peak limit by 18 dB at the fundamental
switching frequency (100 kHz) and by 12 dB at the third harmonic (300
kHz). Design an input EMI filter to achieve compliance with at least 6
dB of margin.

\textbf{Solution:}\\
Required attenuation at 100 kHz: 18 + 6 = 24 dB. At 300 kHz: 12 + 6 = 18
dB.\\
A single-stage LC filter has a roll-off of −40 dB/decade above its
corner frequency. For 24 dB of attenuation at 100 kHz, the corner
frequency must be below 100 kHz.\\
Using a second-order LC filter: attenuation A = (f/f₀)² at frequencies
well above f₀. 24 dB = 10\textsuperscript{24/20} = 15.85×.\\
f₀ = f/√A = 100 kHz / √15.85 = 100 / 3.98 = 25.1 kHz.\\
Choose L\textsubscript{DM} = 100 μH (DM inductor) and calculate C: f₀ =
1/(2π√(LC)), so C = 1/(4π²f₀²L) = 1/(4π² × (25,100)² × 100 × 10⁻⁶) =
1/(4 × 9.87 × 6.3 × 10⁸ × 10⁻⁴) = 1/(2.49 × 10⁶) = 0.40 μF.\\
Use a 0.47 μF X2 film capacitor.\\
Verify at 300 kHz: attenuation = (300/25.1)² = (11.95)² = 142.8 = 43.1
dB ≫ 18 dB required.\\
Add a common-mode choke (10 mH, rated for line current) and two 2.2 nF
Y-capacitors for CM filtering.\\
Total filter: CM choke → X-cap (0.47 μF) → DM inductor (100 μH) → second
X-cap (0.47 μF), providing both CM and DM attenuation with 6+ dB margin.

\end{examplebox}

\section{10.7 Power Factor Correction}\label{power-factor-correction-1}

Power factor correction (PFC) ensures that equipment connected to the AC
mains draws current in phase with the voltage and with low harmonic
content, minimizing reactive power demand and complying with
international harmonic standards (IEC 61000-3-2, EN 61000-3-2). Without
PFC, a typical offline power supply with a diode bridge and capacitor
filter draws current only at the peaks of the AC voltage, resulting in
high peak-to-average current ratios, a power factor as low as 0.5--0.65,
and total harmonic distortion (THD) exceeding 100\%. Active PFC circuits
shape the input current to follow the input voltage waveform, achieving
power factors above 0.99 and THD below 5\%.

\subsection{10.7.1 Active PFC Topologies}\label{active-pfc-topologies}

The \textbf{boost PFC} converter is the most widely used active PFC
topology, operating in continuous conduction mode (CCM) with average
current mode control. A boost stage is placed between the diode bridge
rectifier and the DC bus capacitor, with a controller that forces the
inductor current to track the rectified sinusoidal input voltage shape.
The output voltage (typically 380--400 V DC for universal-input designs)
must be higher than the peak input voltage (peak of 265
V\textsubscript{rms} × √2 = 375 V for worldwide mains). The duty cycle
varies throughout the AC cycle to maintain sinusoidal current draw at
each instant. \textbf{Critical conduction mode} (CrCM, or transition
mode) PFC operates at the boundary between CCM and DCM with variable
switching frequency, simplifying the control loop and achieving natural
ZVS of the boost diode. CrCM is common in power levels from 75 W to 300
W (LED drivers, small adapters). \textbf{Interleaved PFC} uses two or
more boost stages operated with phase-shifted switching to reduce input
current ripple, output voltage ripple, and component stress, and is used
in server power supplies and EV chargers above 1 kW. \textbf{Bridgeless
PFC} topologies (totem-pole, dual-boost) eliminate the input diode
bridge, reducing conduction losses by one diode drop per half-cycle and
improving efficiency by 0.5--1\%, enabled by GaN or SiC devices that can
handle bidirectional current.

\begin{examplebox}

\textbf{Example 10.7.1:} A boost PFC converter operates from a 230
V\textsubscript{rms} input (50 Hz) and produces a 400 V DC output at 500
W. The switching frequency is 65 kHz and the boost inductor is 500 μH.
Calculate the peak input current, the duty cycle at the peak of the AC
input, and the inductor current ripple at that point.

\textbf{Solution:}\\
Input current (assuming PF ≈ 1.0): I\textsubscript{in(rms)} = P /
V\textsubscript{in(rms)} = 500 / 230 = 2.174 A\textsubscript{rms}.\\
Peak input current: I\textsubscript{in(peak)} = I\textsubscript{in(rms)}
× √2 = 2.174 × 1.414 = 3.074 A.\\
Peak input voltage: V\textsubscript{in(peak)} = 230 × √2 = 325.3 V.\\
Duty cycle at the peak of the AC input: D = 1 -
V\textsubscript{in}/V\textsubscript{out} = 1 - 325.3/400 = 1 - 0.8133 =
0.1867 (18.7\%).\\
This is the minimum duty cycle in the AC cycle; at the zero crossings, D
approaches 1.0.\\
Inductor current ripple at the peak: ΔI\textsubscript{L} =
V\textsubscript{in(peak)} × D / (L × f\textsubscript{sw}) = 325.3 ×
0.1867 / (500 × 10⁻⁶ × 65 × 10³) = 60.74 / 32.5 = 1.869
A\textsubscript{pp}.\\
The ripple ratio is ΔI\textsubscript{L} / I\textsubscript{peak} = 1.869
/ 3.074 = 60.8\%, which is higher than desired for CCM operation.\\
A larger inductor (e.g., 1 mH) would halve the ripple to 30\%, or
increasing the switching frequency to 130 kHz would achieve the same
reduction.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-7-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_pfc.png}

\caption{Figure 10.7.1: Active PFC Current Shaping}

\end{figure}

\subsection{10.7.2 Bridgeless PFC
Topologies}\label{bridgeless-pfc-topologies}

Bridgeless PFC topologies eliminate the input diode bridge rectifier,
removing two diode forward-voltage drops from the current path and
improving overall converter efficiency by 0.5-1.5 percentage points ---
a significant gain in high-efficiency server, telecom, and EV charger
power supplies targeting 80 PLUS Titanium (96\%+ efficiency) or
equivalent standards. The \textbf{totem-pole bridgeless PFC} is the most
popular topology, using two active switches (typically GaN HEMTs) in a
half-bridge configuration that directly switches the AC line voltage.
During the positive half-cycle, one switch operates as the boost switch
(high-frequency PWM) while the other acts as the synchronous rectifier;
their roles reverse during the negative half-cycle. A second pair of
low-frequency switches (silicon MOSFETs or diodes) commutates at the
line frequency to steer current during each half-cycle. The totem-pole
topology requires devices capable of reverse conduction with low
recovery charge --- GaN HEMTs are ideal because they have zero reverse
recovery loss (the 2DEG channel conducts in reverse without minority
carrier storage). SiC MOSFETs can also be used but their body diode has
a small reverse recovery charge that must be managed. The
\textbf{dual-boost bridgeless PFC} uses two boost inductors and two
active switches, with each switch handling one half-cycle; it maintains
the same ground reference between input and output but requires two
inductors. Bridgeless topologies require careful common-mode noise
management because the output DC bus is no longer referenced to the AC
neutral through the diode bridge, creating high dv/dt common-mode
voltages that couple through parasitic capacitances. Dedicated
common-mode EMI filtering (Y-capacitors, common-mode chokes) is
essential.

\begin{examplebox}

\textbf{Example 10.7.2:} A 3 kW totem-pole bridgeless PFC converter uses
GaN HEMTs with R\textsubscript{DS(on)} = 50 mΩ (including package) and
low-frequency silicon MOSFETs with R\textsubscript{DS(on)} = 8 mΩ. The
input is 230 V\textsubscript{rms} and the output is 400 V DC. Compare
the conduction losses to a conventional boost PFC using a diode bridge
with V\textsubscript{F} = 0.9 V per diode and a silicon MOSFET with
R\textsubscript{DS(on)} = 50 mΩ.

\textbf{Solution:}\\
Input current: I\textsubscript{in(rms)} = P / V\textsubscript{in} = 3000
/ 230 = 13.04 A.\\
\textbf{Conventional boost PFC:} Diode bridge loss (two diodes conduct
at any time): P\textsubscript{bridge} = 2 × V\textsubscript{F} ×
I\textsubscript{avg} = 2 × 0.9 × (13.04 × 2√2/π) = 2 × 0.9 × 11.73 =
21.1 W (using average rectified current).\\
Boost MOSFET conduction loss: the MOSFET RMS current ≈
I\textsubscript{in(rms)} × √D\textsubscript{avg}. With average duty ≈
0.42 for 230 V / 400 V: I\textsubscript{Q(rms)} ≈ 13.04 × √0.42 = 8.45
A. P\textsubscript{Q} = 8.45² × 0.050 = 3.57 W.\\
Total conduction: 21.1 + 3.57 = 24.7 W.\\
\textbf{Totem-pole bridgeless PFC:} High-frequency GaN switch
conduction: P\textsubscript{GaN} = I\textsubscript{Q(rms)}² ×
R\textsubscript{DS(on)} = 8.45² × 0.050 = 3.57 W.\\
Synchronous rectifier GaN (complementary duty): I\textsubscript{SR(rms)}
≈ 13.04 × √(1 - 0.42) = 13.04 × 0.762 = 9.93 A. P\textsubscript{SR} =
9.93² × 0.050 = 4.93 W.\\
Low-frequency Si MOSFETs: P\textsubscript{LF} = 13.04² × 0.008 = 1.36
W.\\
Total conduction: 3.57 + 4.93 + 1.36 = 9.86 W.\\
The bridgeless topology reduces conduction losses from 24.7 W to 9.86 W
--- a 60\% reduction (14.8 W saved), improving full-load efficiency by
14.8/3000 = 0.49 percentage points.\\
At lighter loads where diode drops dominate, the improvement is even
more pronounced.

\end{examplebox}

\subsection{10.7.3 Power Supply Protection
Circuits}\label{power-supply-protection-circuits}

Robust protection circuits are essential in power electronic converters
to safeguard both the converter and the load from damage during fault
conditions, startup transients, and abnormal operating events.
\textbf{Overvoltage protection (OVP)} monitors the output voltage and
shuts down the converter (or clamps the output with a crowbar circuit)
if the voltage exceeds a safe threshold --- typically 110--120\% of the
nominal output. In a crowbar OVP circuit, a thyristor fires when a
zener-referenced comparator detects an overvoltage, short-circuiting the
output and blowing a fuse or triggering the upstream breaker; this is a
last-resort protection used in critical loads like server motherboards
where sustained overvoltage is more destructive than a momentary outage.
Active OVP in the controller IC reduces the duty cycle or disables
switching when the feedback voltage exceeds an internal threshold.
\textbf{Overcurrent protection (OCP)} limits the output current to
prevent damage from short circuits or overloads. In peak current mode
control, OCP is inherent --- a cycle-by-cycle current limit clamps the
peak inductor current within one switching period (microseconds). Hiccup
mode protection detects a sustained overcurrent condition, shuts down
the converter for a cooldown period (typically 100 ms -- 1 s), then
attempts a restart; this cycle repeats until the fault clears, limiting
average power dissipation during a short circuit to safe levels.
\textbf{Soft start} gradually ramps the converter's duty cycle or
reference voltage over a controlled interval (typically 5--50 ms) after
enable, preventing the inrush current surge that would otherwise occur
when charging the output capacitor from zero. Without soft start, the
instantaneous current into a discharged output capacitor can be many
times the rated load current, stressing the switching devices and
triggering OCP. Soft start is implemented by slowly ramping an internal
voltage reference or by using a capacitor on a dedicated SS pin that
charges through an internal current source. \textbf{Inrush current
limiting} addresses the surge current at initial power-on when bulk
input capacitors charge through the AC mains. A
negative-temperature-coefficient (NTC) thermistor in series with the
input presents high resistance when cold (limiting inrush to 10--20 A),
then self-heats to low resistance (0.5--2 Ω) during steady-state
operation. For higher-power supplies (\textgreater500 W), an active
inrush limiter uses a relay or MOSFET to bypass a current-limiting
resistor after the capacitors have charged, avoiding the continuous
power dissipation of an NTC. \textbf{Undervoltage lockout (UVLO)}
prevents the converter from operating when the input voltage is too low
to sustain proper regulation, avoiding undefined or destructive
behavior. UVLO circuits have hysteresis (typically 1--3 V) to prevent
oscillation at the turn-on threshold.

\begin{examplebox}

\textbf{Example 10.7.3:} A 48 V, 20 A power supply has a 2,000 μF output
capacitor bank and uses soft start with a 10 ms ramp time. The
converter's OCP threshold is set at 25 A. Without soft start, the
initial duty cycle would step to the steady-state value immediately.
Estimate the peak inrush current without soft start (assuming the
converter output impedance during startup is dominated by the MOSFET
R\textsubscript{DS(on)} = 15 mΩ) and verify that the soft-start ramp
keeps the current below the OCP limit.

\textbf{Solution:}\\
\textbf{Without soft start:} If the duty cycle steps immediately to the
steady-state value, the converter tries to charge the 2,000 μF capacitor
from 0 V to 48 V as fast as the inductor and switch allow. The peak
current is limited only by the inductor slew rate and OCP; in practice,
the current slams into the OCP limit of 25 A on the first switching
cycle, triggering hiccup-mode protection and delaying startup.\\
\textbf{With soft start (10 ms ramp):} The output voltage ramps
approximately linearly: dV/dt = 48 V / 10 ms = 4,800 V/s.\\
The capacitor charging current: I\textsubscript{cap} = C × dV/dt = 2,000
× 10⁻⁶ × 4,800 = 9.6 A.\\
Adding the steady-state load current that develops as
V\textsubscript{out} ramps (load current is small initially when
V\textsubscript{out} is low), the peak current occurs near the end of
the ramp: I\textsubscript{peak} ≈ I\textsubscript{cap} +
I\textsubscript{load} ≈ 9.6 + 20 = 29.6 A, which still exceeds 25 A
OCP.\\
Increasing the soft-start time to 20 ms: I\textsubscript{cap} = 2,000 ×
10⁻⁶ × (48/0.020) = 4.8 A. I\textsubscript{peak} ≈ 4.8 + 20 = 24.8 A,
just under the 25 A OCP limit.\\
Use 25 ms for adequate margin: I\textsubscript{cap} = 3.84 A,
I\textsubscript{peak} ≈ 23.8 A with 1.2 A margin below OCP.

\end{examplebox}

\section{10.8 Battery Management
Systems}\label{battery-management-systems}

Battery management systems (BMS) monitor, protect, and optimize
rechargeable battery packs used in electric vehicles, grid energy
storage, UPS systems, and portable electronics. A BMS measures
individual cell voltages, pack current, and temperatures to prevent
operation outside safe limits and to maximize the usable capacity and
lifetime of the battery. Modern lithium-ion cells can deliver
exceptional energy density and cycle life but are intolerant of
overcharge, over-discharge, and excessive temperature --- conditions
that cause irreversible capacity loss, thermal runaway, or fire. The BMS
is the critical safety and performance layer between the battery cells
and the power electronic converter that charges or discharges them.

\subsection{10.8.1 Battery Cell
Characteristics}\label{battery-cell-characteristics}

A rechargeable battery cell converts chemical energy to electrical
energy through reversible electrochemical reactions. The key parameters
are nominal voltage (determined by cell chemistry), capacity (in
amp-hours, the total charge the cell can deliver), energy density (Wh/kg
or Wh/L), C-rate (discharge current normalized to capacity --- 1C fully
discharges the cell in one hour), and cycle life (number of
charge-discharge cycles before capacity drops to 80\% of initial).
Lithium-ion cells dominate modern applications with chemistries
including LFP (LiFePO₄, 3.2 V nominal, long cycle life, excellent
safety), NMC (LiNiMnCoO₂, 3.7 V, high energy density), NCA (LiNiCoAlO₂,
3.6 V, highest energy density, used in EVs), and LTO (Li₄Ti₅O₁₂, 2.4 V,
fastest charging, extreme cycle life). The open-circuit voltage (OCV)
varies with state of charge following a chemistry-dependent curve, and
internal resistance increases with age and low temperature.

\begin{examplebox}

\textbf{Example 10.8.1:} A battery pack for an electric vehicle uses 96
series-connected NMC cells (3.7 V nominal, 50 Ah each). Determine (a)
the nominal pack voltage, (b) the energy capacity in kWh, (c) the
maximum continuous discharge current at 3C, and (d) the pack internal
resistance if each cell has 2 mΩ internal resistance.

\textbf{Solution:}

(a) V\textsubscript{pack} = 96 × 3.7 = \textbf{355.2 V}

(b) Energy = V\textsubscript{pack} × Capacity = 355.2 × 50 = 17,760 Wh =
\textbf{17.76 kWh}

(c) Maximum current at 3C: I\textsubscript{max} = 3 × 50 = \textbf{150
A}

(d) Series cells add resistance: R\textsubscript{pack} = 96 × 0.002 =
\textbf{0.192 Ω}. At 150 A discharge, the voltage drop across internal
resistance is I × R = 150 × 0.192 = 28.8 V, reducing the terminal
voltage to 355.2 − 28.8 = \textbf{326.4 V} under load.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-8-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_bms_discharge.png}

\caption{Figure 10.8.1: 96s NMC Pack Voltage vs SOC}

\end{figure}

\subsection{10.8.2 Cell Balancing}\label{cell-balancing}

In a series-connected battery pack, manufacturing variations and aging
differences cause individual cells to diverge in capacity and state of
charge over repeated cycles. Without balancing, the weakest cell limits
the entire pack --- it reaches the discharge cutoff voltage first
(reducing usable capacity) and the charge voltage limit first
(preventing full charge of other cells). Cell balancing equalizes the
charge across all cells, recovering the capacity lost to cell mismatch.
\textbf{Passive balancing} dissipates excess energy from higher-charged
cells through bleed resistors --- it is simple and inexpensive but
wastes energy as heat. \textbf{Active balancing} transfers charge from
higher-charged cells to lower-charged cells using switched-capacitor,
transformer-coupled, or inductor-based circuits --- it is more efficient
but adds cost and complexity.

\begin{examplebox}

\textbf{Example 10.8.2:} A 12-series lithium-ion pack has cells ranging
from 3.95 V to 4.18 V at end of charge. The BMS uses passive balancing
with 33 Ω bleed resistors. Determine (a) the balancing current for the
highest cell, (b) the power dissipated per balancing resistor, (c) the
time to balance a 50 mAh charge difference, and (d) the total energy
wasted during balancing.

\textbf{Solution:}

(a) Balancing current: I\textsubscript{bal} = V\textsubscript{cell}/R =
4.18/33 = \textbf{126.7 mA}

(b) Power per resistor: P = V²/R = 4.18²/33 = 17.47/33 = \textbf{0.529
W}

(c) Time to balance 50 mAh: t = Q/I = 0.050/0.1267 = 0.3946 hours =
\textbf{23.7 minutes}

(d) Energy wasted: E = P × t = 0.529 × 0.3946 = 0.209 Wh per cell. For
all cells requiring balancing (worst case, 11 cells):
E\textsubscript{total} = 11 × 0.209 = \textbf{2.30 Wh}. This is small
compared to a typical EV pack capacity (e.g., the 17.76 kWh pack from
Example 10.8.1) --- about 0.013\% of that reference pack.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-8-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_bms_balancing.png}

\caption{Figure 10.8.2: Passive Cell Balancing Convergence}

\end{figure}

\subsection{10.8.3 State of Charge
Estimation}\label{state-of-charge-estimation}

State of charge (SOC) is the ratio of remaining charge to full capacity,
expressed as a percentage: SOC =
Q\textsubscript{remaining}/Q\textsubscript{full} × 100\%. Accurate SOC
estimation is critical for range prediction in EVs, power management in
grid storage, and preventing over-discharge. \textbf{Coulomb counting}
integrates the measured current over time: SOC(t) = SOC(t₀) −
(1/Q\textsubscript{full}) ∫I dt. This method is simple but accumulates
drift errors from current sensor offset and requires periodic
recalibration. \textbf{OCV-based estimation} maps the measured
open-circuit voltage to SOC using the cell's OCV-SOC lookup table, but
requires the cell to be at rest (no current flow) for an accurate
reading. \textbf{Kalman filter} methods combine coulomb counting and
voltage measurements in a model-based estimator that corrects for drift,
providing the most accurate SOC under dynamic load conditions. State of
health (SOH) tracks the degradation of maximum capacity over the
battery's lifetime: SOH =
Q\textsubscript{full,current}/Q\textsubscript{full,new} × 100\%.

\begin{examplebox}

\textbf{Example 10.8.3:} A 100 Ah battery pack starts at SOC = 85\%. A
current sensor with ±0.5\% accuracy measures the discharge. After
delivering 60 Ah of charge (by coulomb counting), determine (a) the
estimated SOC, (b) the worst-case SOC error from sensor drift after 60
Ah, and (c) the SOC uncertainty range.

\textbf{Solution:}

(a) SOC = 85\% − (60/100) × 100\% = 85\% − 60\% = \textbf{25\%}

(b) Current sensor error over 60 Ah: ΔQ = 0.005 × 60 = \textbf{0.30 Ah}.
SOC error = 0.30/100 × 100\% = \textbf{0.30\%}

(c) SOC range: 25\% ± 0.30\%, or \textbf{24.7\% to 25.3\%}. This is a
relatively small error for a single discharge, but over many partial
cycles without OCV recalibration, the cumulative drift can reach several
percent.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-8-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_bms_soc.png}

\caption{Figure 10.8.3: SOC Estimation with Coulomb Counting Drift}

\end{figure}

\subsection{10.8.4 BMS Thermal Management}\label{bms-thermal-management}

Battery cells must operate within a safe temperature window ---
typically 0°C to 45°C for charging and −20°C to 60°C for discharging.
Temperatures above 60°C accelerate degradation and risk thermal runaway
in lithium-ion cells, while temperatures below 0°C dramatically increase
internal resistance and can cause lithium plating during charging
(permanent damage). The BMS monitors cell temperatures using thermistors
or RTDs distributed throughout the pack and controls the thermal
management system --- which may include liquid cooling (glycol loops),
air cooling (fans and ducts), or heating elements (PTC heaters for
cold-weather operation). Temperature gradients across the pack cause
uneven aging; the BMS may derate charge/discharge current or activate
additional cooling to maintain cell-to-cell temperature uniformity
within 3--5°C.

\begin{examplebox}

\textbf{Example 10.8.4:} A battery pack generates 800 W of heat at full
discharge rate. The liquid cooling system uses a glycol-water mixture
with a flow rate of 6 L/min and a specific heat of 3.4 kJ/(kg·°C). The
coolant density is 1.05 kg/L. Determine (a) the coolant temperature rise
through the pack, (b) the required inlet temperature to keep cells below
40°C with a 5°C thermal resistance between coolant and cell surface, and
(c) the maximum allowable thermal resistance per cell for a 96-cell pack
dissipating equal heat.

\textbf{Solution:}

(a) Mass flow rate: ṁ = 6 × 1.05 = 6.3 kg/min = 0.105 kg/s\\
ΔT = Q̇/(ṁ × c\textsubscript{p}) = 800/(0.105 × 3,400) = 800/357 =
\textbf{2.24°C}

(b) Cell surface temperature must be ≤ 40°C. With 5°C thermal resistance
from coolant to cell:\\
T\textsubscript{coolant,max} = 40 − 5 = 35°C. Inlet temperature:
T\textsubscript{inlet} = 35 − 2.24 = \textbf{32.76°C} (the outlet
reaches 35°C).

(c) Heat per cell: Q̇\textsubscript{cell} = 800/96 = 8.33 W\\
Maximum thermal resistance per cell: R\textsubscript{θ} =
ΔT/Q̇\textsubscript{cell} = 5/8.33 = \textbf{0.60 °C/W}

\end{examplebox}

\subsection{10.8.5 Battery Protection and Fault
Detection}\label{battery-protection-and-fault-detection}

The BMS protection layer prevents the battery from operating outside its
safe operating area (SOA) by monitoring voltage, current, and
temperature in real time. \textbf{Overvoltage protection} disconnects
the charger when any cell exceeds the maximum charge voltage (4.20 V for
NMC/NCA, 3.65 V for LFP) to prevent lithium plating, electrolyte
decomposition, and thermal runaway. \textbf{Undervoltage protection}
disconnects the load when any cell drops below the minimum discharge
voltage (typically 2.5--3.0 V) to prevent copper dissolution from the
anode current collector, which causes permanent internal short circuits
on subsequent charging. \textbf{Overcurrent protection} limits discharge
current to the cell's maximum C-rate and charge current to the
manufacturer's specified maximum, using current-sense resistors or
Hall-effect sensors feeding the BMS controller. \textbf{Temperature
protection} restricts charging below 0°C (or reduces charge current to
C/10) and shuts down the pack above the maximum operating temperature.
The BMS uses contactors (high-voltage relays) or power MOSFETs to
disconnect the pack from the load or charger within milliseconds of
detecting a fault. Advanced BMS designs also perform \textbf{insulation
monitoring} on high-voltage packs (\textgreater60 V) to detect ground
faults, and \textbf{short-circuit detection} using di/dt sensing to
differentiate a hard short from a normal transient.

\begin{examplebox}

\textbf{Example 10.8.5:} A 400 V, 100 Ah EV battery pack uses a 0.5 mΩ
current-sense resistor and a BMS with a 10-bit ADC referenced to 50 mV
full-scale. The pack has overvoltage, undervoltage, and overcurrent
protection. Determine (a) the ADC current resolution, (b) the maximum
measurable current, (c) the OVP and UVP thresholds for a 96-series NMC
pack, and (d) the energy that must be safely dissipated if the pack is
disconnected at maximum current.

\textbf{Solution:}

(a) ADC resolution: LSB = 50 mV / 2¹⁰ = 50 mV / 1024 = 48.8 μV\\
Current resolution: ΔI = LSB / R\textsubscript{sense} = 48.8 × 10⁻⁶ /
0.5 × 10⁻³ = \textbf{97.7 mA}

(b) Maximum measurable current: I\textsubscript{max} =
V\textsubscript{FS} / R\textsubscript{sense} = 0.050 / 0.0005 =
\textbf{100 A} (1C rate for this pack)

(c) OVP threshold: 96 × 4.20 V = \textbf{403.2 V} (per-cell monitoring
triggers at 4.20 V on any cell)\\
UVP threshold: 96 × 2.50 V = \textbf{240 V} (per-cell monitoring
triggers at 2.50 V on any cell)

(d) Inductive energy in the wiring and contactors at disconnection
(assuming 10 μH total circuit inductance at 100 A):\\
E = ½LI² = 0.5 × 10 × 10⁻⁶ × 100² = \textbf{0.05 J}. This is small; the
main concern is the arc energy across the contactor contacts, which is
managed by arc suppression circuits (snubber RC networks or varistors
across the contactor).

\end{examplebox}

\section{10.9 Battery Energy Storage
Systems}\label{battery-energy-storage-systems}

Battery energy storage systems (BESS) integrate battery packs, power
conversion systems (PCS), thermal management, and control software into
grid-connected installations ranging from kilowatt-scale commercial
systems to gigawatt-hour utility plants. BESS enables the electrical
grid to store surplus energy and dispatch it on demand --- replacing
peaking gas turbines, firming variable renewable generation, providing
ancillary services such as frequency regulation, and deferring
transmission and distribution upgrades. While §10.8 addresses cell-level
battery management, this section covers the system-level engineering:
architecture, power conversion, grid services, sizing methodology, and
economic analysis. Lithium-ion technology (particularly LFP for
stationary applications) dominates the market due to its declining cost,
long cycle life, and high round-trip efficiency, though flow batteries
and sodium-ion are emerging for long-duration applications.

\subsection{10.9.1 BESS Architecture and
Components}\label{bess-architecture-and-components}

A utility-scale BESS is typically deployed in standardized 20-foot or
40-foot shipping containers, each housing multiple battery racks, a DC
bus, and local environmental controls. Each rack contains battery
modules connected in series to achieve the target DC bus voltage
(typically 600--1,500 V DC), with a rack-level BMS monitoring module
voltages and temperatures. Multiple racks connect in parallel to form a
DC string feeding the power conversion system (PCS). The PCS is a
bidirectional DC-AC inverter that interfaces the battery to the AC grid
through a step-up transformer. Supporting systems include an energy
management system (EMS) that dispatches charge/discharge commands, HVAC
for thermal control, fire detection and suppression (typically
clean-agent or aerosol systems), and a site controller that communicates
with the grid operator via SCADA or IEEE 2030.5.

\begin{examplebox}

\textbf{Example 10.9.1:} A utility requires a 50 MW / 200 MWh (4-hour
duration) BESS using LFP cells rated at 3.2 V nominal and 280 Ah. Each
battery module contains 16 series cells (51.2 V module voltage). Each
rack contains 10 series modules (512 V DC bus). Determine (a) the energy
per rack, (b) the number of racks required, (c) the total cell count,
and (d) the number of 5 MW PCS inverters needed.

\textbf{Solution:}

(a) Energy per rack: E\textsubscript{rack} = V\textsubscript{rack} × C =
512 × 280 = 143,360 Wh = \textbf{143.36 kWh}

(b) Number of racks: N\textsubscript{racks} = 200,000 / 143.36 = 1,395.1
→ \textbf{1,396 racks} (round up)

(c) Cells per rack = 16 × 10 = 160 cells. Total cells = 1,396 × 160 =
\textbf{223,360 cells}

(d) Number of 5 MW PCS units: N\textsubscript{PCS} = 50 / 5 = \textbf{10
inverters} (each rated 5 MW, paired with \textasciitilde140 racks)

\end{examplebox}

\subsection{10.9.2 Power Conversion
Systems}\label{power-conversion-systems}

The power conversion system (PCS) is the bidirectional interface between
the DC battery bus and the AC grid. During discharge, the PCS operates
as an inverter converting DC to AC; during charge, it operates as a
rectifier converting AC to DC. Modern BESS inverters use three-phase,
multilevel (typically 3-level NPC or T-type) IGBT or SiC MOSFET
topologies with switching frequencies of 2--20 kHz and efficiencies of
95--99\% at rated power. The PCS must handle rapid transitions between
charge and discharge modes, support four-quadrant operation (active and
reactive power in both directions), and comply with grid codes for power
quality, fault ride-through, and anti-islanding. AC-coupled BESS
connects to the grid through a dedicated inverter and transformer, while
DC-coupled solar+storage shares a single inverter with the PV array,
reducing hardware cost but limiting independent dispatch.

\begin{examplebox}

\textbf{Example 10.9.2:} A 10 MW / 40 MWh BESS has a PCS with 96.5\%
one-way inverter efficiency and 1.2\% auxiliary power consumption
(cooling, BMS, controls) relative to throughput. The system operates 365
cycles per year at 80\% depth of discharge. Determine (a) the round-trip
efficiency, (b) the annual energy throughput, (c) the annual energy
losses, and (d) the annual auxiliary energy consumption.

\textbf{Solution:}

(a) Round-trip efficiency: η\textsubscript{RT} = η\textsubscript{inv}² ×
(1 − aux)² = 0.965² × (1 − 0.012)² = 0.9312 × 0.9761 = \textbf{90.9\%}

(b) Annual energy throughput: E\textsubscript{annual} = 40 × 0.80 × 365
= \textbf{11,680 MWh} (discharge side)

(c) Energy losses: E\textsubscript{loss} = E\textsubscript{annual} × (1
− η\textsubscript{RT}) / η\textsubscript{RT} = 11,680 × (1 − 0.909) /
0.909 = 11,680 × 0.1001 = \textbf{1,169 MWh/year} (energy input exceeds
output by this amount)

(d) Auxiliary consumption: E\textsubscript{aux} = 11,680 × 2 × 0.012 =
\textbf{280 MWh/year} (applied to both charge and discharge throughput,
hence the factor of 2)

\end{examplebox}

\subsection{10.9.3 BESS Control and Grid
Services}\label{bess-control-and-grid-services}

A BESS can provide multiple grid services by rapidly adjusting its power
output. \textbf{Frequency regulation} responds to grid frequency
deviations by injecting or absorbing power according to a droop
characteristic: ΔP/P\textsubscript{rated} = −Δf/(f\textsubscript{nom} ×
R), where R is the droop setting (typically 3--5\%) and Δf is the
frequency deviation from nominal. The BESS response time (milliseconds)
is far faster than conventional generators (seconds to minutes), making
it highly effective for primary frequency response. \textbf{Voltage
support} provides reactive power (VAR) to maintain local bus voltage
within limits. \textbf{Peak shaving} discharges during high-demand
periods to reduce a facility's peak demand charge. \textbf{Renewable
smoothing} absorbs rapid PV or wind fluctuations to limit ramp rates
seen by the grid. \textbf{Arbitrage} charges during low-price hours and
discharges during high-price hours, capturing the price spread. Revenue
stacking --- combining multiple services --- is critical for BESS
economics.

\begin{examplebox}

\textbf{Example 10.9.3:} A 20 MW BESS provides primary frequency
regulation with a 4\% droop setting and ±0.036 Hz deadband around 60 Hz.
Determine (a) the power output for a sustained frequency drop to 59.85
Hz, (b) the power output for a frequency rise to 60.10 Hz, and (c) the
energy dispatched during a 15-minute event where the average frequency
deviation is −0.15 Hz.

\textbf{Solution:}

(a) Δf = 60 − 59.85 = 0.15 Hz. Subtract deadband: Δf\textsubscript{eff}
= 0.15 − 0.036 = 0.114 Hz.\\
ΔP = P\textsubscript{rated} × Δf\textsubscript{eff} /
(f\textsubscript{nom} × R) = 20 × 0.114 / (60 × 0.04) = 20 × 0.114 / 2.4
= \textbf{0.95 MW} (discharge, injecting power to support frequency)

(b) Δf = 60.10 − 60 = 0.10 Hz. Δf\textsubscript{eff} = 0.10 − 0.036 =
0.064 Hz.\\
ΔP = 20 × 0.064 / 2.4 = \textbf{0.533 MW} (charge, absorbing power to
reduce frequency)

(c) For −0.15 Hz average deviation: Δf\textsubscript{eff} = 0.15 − 0.036
= 0.114 Hz.\\
Average power: P\textsubscript{avg} = 0.95 MW. Energy over 15 min: E =
0.95 × 15/60 = \textbf{0.238 MWh}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-9-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_bess_droop.png}

\caption{Figure 10.9.3: BESS Frequency Regulation Droop Response}

\end{figure}

\subsection{10.9.4 BESS Sizing and
Duration}\label{bess-sizing-and-duration}

BESS sizing requires matching power rating (MW) and energy capacity
(MWh) to the target application. The duration (hours) = energy/power
determines how long the system can sustain rated output. \textbf{Peak
shaving} requires analyzing the facility's load profile to identify the
magnitude and duration of demand peaks above a target threshold --- the
BESS must store enough energy to cover the area between the peak and the
threshold. \textbf{Renewable firming} sizes the battery to absorb
surplus generation and fill generation shortfalls over a defined window.
\textbf{Duration selection} depends on the application: 0.5--1 hour for
frequency regulation, 2--4 hours for peak shaving and arbitrage, and
4--12+ hours for renewable firming and capacity replacement. Oversizing
by 10--20\% accounts for degradation over the project life and ensures
the system meets its performance guarantee at end of warranty.

\begin{examplebox}

\textbf{Example 10.9.4:} A commercial facility has a monthly peak demand
of 5.0 MW, but demand exceeds 3.5 MW for only 4 hours per day (peak
profile approximated as a trapezoid peaking at 5.0 MW). The utility
demand charge is \$18/kW-month. Determine (a) the BESS power rating to
shave the peak to 3.5 MW, (b) the minimum energy capacity required, (c)
the monthly demand charge savings, and (d) the recommended nameplate
capacity with a 15\% degradation margin.

\textbf{Solution:}

(a) Required BESS power: P\textsubscript{BESS} = 5.0 − 3.5 = \textbf{1.5
MW}

(b) Energy required: The peak above 3.5 MW over 4 hours forms
approximately a triangle with peak excess of 1.5 MW. Energy = ½ × 1.5 ×
4 = \textbf{3.0 MWh}

(c) Monthly demand charge savings: ΔD = (5.0 − 3.5) × \$18 = 1.5 × 18 =
\textbf{\$27,000/month} (\$324,000/year)

(d) Nameplate capacity with margin: E\textsubscript{nameplate} = 3.0 /
(1 − 0.15) = 3.0 / 0.85 = \textbf{3.53 MWh} (specify 3.5 MWh or 4.0 MWh
depending on available module sizes)

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-9-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_bess_peak_shaving.png}

\caption{Figure 10.9.4: BESS Peak Shaving Load Profile}

\end{figure}

\subsection{10.9.5 BESS Economics and
Degradation}\label{bess-economics-and-degradation}

BESS economics are evaluated using the \textbf{levelized cost of storage
(LCOS)}, which amortizes all costs over the lifetime energy throughput:
LCOS = (Capital + PW of O\&M + PW of Augmentation) / PW of Lifetime
Energy Discharged. Capital cost is dominated by battery cells
(\$100--\$250/kWh at the pack level for LFP) plus the PCS, transformer,
balance of plant, and EPC, bringing total installed cost to
\$200--\$500/kWh depending on scale and duration. \textbf{Capacity
degradation} from cycling follows an approximately linear model:
capacity retention = 1 − (throughput × degradation rate), where
degradation rate is typically 0.01--0.03\% per full equivalent cycle for
LFP. Calendar aging adds 1--2\% per year independent of cycling. When
cumulative degradation reaches the performance guarantee limit
(typically 70--80\% of initial capacity after 10--20 years),
\textbf{augmentation} adds new modules to restore capacity, extending
system life. Revenue must exceed LCOS for the project to be viable;
revenue stacking across multiple services (arbitrage + regulation +
capacity payments) typically yields \$80--\$200/MWh of throughput.

\begin{examplebox}

\textbf{Example 10.9.5:} A 100 MWh LFP BESS has an installed cost of
\$280/kWh, 15-year project life, 1 cycle/day at 80\% DOD, 92\%
round-trip efficiency, 2.5\% capacity fade per year (combined cycling
and calendar), and O\&M of \$6/MWh of throughput. Using a discount rate
of 8\%, determine (a) the total lifetime energy discharged
(undiscounted), (b) the LCOS (simplified, without augmentation), and (c)
whether the project is viable with stacked revenue of \$140/MWh.

\textbf{Solution:}

(a) Annual discharge: E\textsubscript{yr} = 100 × 0.80 × 365 = 29,200
MWh (year 1). With 2.5\%/year degradation, average annual capacity over
15 years ≈ 100 × (1 − 0.025 × 7.5) = 81.25 MWh effective. Average annual
discharge = 81.25 × 0.80 × 365 = 23,725 MWh. Total lifetime: 23,725 × 15
= \textbf{355,875 MWh}

(b) Capital: 100,000 × \$280 = \$28,000,000. Annual O\&M: 23,725 × \$6 =
\$142,350/year. PW of O\&M (P/A, 8\%, 15) = \$142,350 × 8.5595 =
\$1,218,497. LCOS = (\$28,000,000 + \$1,218,497) / 355,875 =
\$29,218,497 / 355,875 = \textbf{\$82.1/MWh}

(c) Revenue of \$140/MWh exceeds LCOS of \$82.1/MWh by \$57.9/MWh,
yielding an annual profit margin of 23,725 × \$57.9 =
\textbf{\$1,373,678/year}. The project is \textbf{viable}.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-9-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_bess_degradation.png}

\caption{Figure 10.9.5: BESS Capacity Degradation and LCOS}

\end{figure}

\section{10.10 Battery Charging}\label{battery-charging}

Battery charging is the controlled process of restoring energy to an
electrochemical cell by forcing current through it in the reverse
direction of discharge. The charger must regulate voltage, current, and
temperature to maximize charge acceptance while preventing damage from
overcharging, excessive heat, or lithium plating. Different battery
chemistries require different charging algorithms --- lithium-ion uses
\textbf{constant-current/constant-voltage (CC/CV)}, lead-acid uses a
three-stage bulk/absorption/float profile, and NiMH relies on
\textbf{−ΔV detection} to identify full charge. Modern charger design
spans from milliwatt USB-powered circuits to megawatt DC fast-charging
stations, incorporating power factor correction, galvanic isolation,
bidirectional power flow (V2G), and wireless energy transfer. The power
electronics topologies, control strategies, and thermal management
techniques used in charging systems draw on nearly every topic in this
chapter.

\subsection{10.10.1 CC/CV Charging Profile and Charge
Termination}\label{cccv-charging-profile-and-charge-termination}

The \textbf{constant-current/constant-voltage (CC/CV)} algorithm is the
standard charging method for lithium-ion batteries. During the
\textbf{CC phase}, the charger supplies a fixed current (typically 0.5C
to 1C, where C is the cell's rated capacity) while the cell voltage
rises from its discharged state toward the \textbf{charge cutoff
voltage} (4.20 V for NMC/NCA, 3.65 V for LFP). Once the cell reaches the
cutoff voltage, the charger transitions to the \textbf{CV phase},
holding the voltage constant while the current tapers exponentially as
the cell approaches full charge. \textbf{Charge termination} occurs when
the current drops below a threshold (typically C/20 to C/50), indicating
that the cell can no longer accept significant charge at the applied
voltage. The CC phase typically delivers 60--80\% of the cell's capacity
in a relatively short time, while the CV phase completes the remaining
20--40\% more slowly. \textbf{Coulombic efficiency} --- the ratio of
charge extracted during discharge to charge inserted during charge ---
is 99.5--99.9\% for healthy lithium-ion cells but decreases with aging
and low-temperature operation, serving as a sensitive indicator of side
reactions such as SEI growth and lithium plating. For lead-acid
batteries, the three-stage charging profile consists of a \textbf{bulk}
CC phase to \textasciitilde80\% SOC, an \textbf{absorption} CV phase at
14.4--14.8 V (for a 12 V battery) to reach 100\%, and a \textbf{float}
stage at 13.2--13.6 V to maintain full charge without overcharging. NiMH
cells use a \textbf{−ΔV/Δt} termination method that detects the slight
voltage drop (5--10 mV) that occurs when the cell reaches full charge
and exothermic oxygen recombination begins.

\begin{examplebox}

\textbf{Example 10.10.1:} A 21700 NMC lithium-ion cell has a rated
capacity of 5.0 Ah and is charged using a CC/CV algorithm with a CC rate
of 0.5C (2.5 A) and a charge cutoff voltage of 4.20 V. The cell starts
at 3.0 V (fully discharged) and reaches 4.20 V after 1.6 hours of CC
charging. During the CV phase, the current decays exponentially with a
time constant τ = 0.4 hours, and charge is terminated when the current
drops to C/20 (0.25 A). (a) Calculate the charge delivered during the CC
phase. (b) Determine the time to reach charge termination after the CV
phase begins. (c) Calculate the charge delivered during the CV phase.
(d) If the cell delivers 4.90 Ah on the subsequent discharge, what is
the coulombic efficiency?

\textbf{Solution:}

(a) Charge in CC phase: Q\textsubscript{CC} = I\textsubscript{CC} ×
t\textsubscript{CC} = 2.5 A × 1.6 h = \textbf{4.00 Ah} (80\% of rated
capacity)

(b) CV phase current decays as I(t) = 2.5 × e\textsuperscript{−t/0.4}.
Termination when I = 0.25 A:\\
0.25 = 2.5 × e\textsuperscript{−t/0.4} → e\textsuperscript{−t/0.4} = 0.1
→ t = −0.4 × ln(0.1) = 0.4 × 2.303 = \textbf{0.92 hours} (55 minutes)

(c) Charge in CV phase: Q\textsubscript{CV} = ∫₀\textsuperscript{0.92}
2.5 × e\textsuperscript{−t/0.4} dt = 2.5 × 0.4 × (1 −
e\textsuperscript{−0.92/0.4}) = 1.0 × (1 − 0.1) = \textbf{0.90 Ah}

(d) Total charge in: Q\textsubscript{in} = 4.00 + 0.90 = 4.90 Ah. Charge
out: Q\textsubscript{out} = 4.90 Ah.\\
Coulombic efficiency: η\textsubscript{C} = Q\textsubscript{out} /
Q\textsubscript{in} = 4.90 / 4.90 = \textbf{100.0\%} --- this idealized
result indicates negligible side reactions; in practice,
η\textsubscript{C} ≈ 99.5--99.9\% due to minor SEI growth.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-10-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_cccv_charging.png}

\caption{Figure 10.10.1: CC/CV Charging Profile}

\end{figure}

\subsection{10.10.2 Charger Topologies: On-Board and Off-Board
AC/DC}\label{charger-topologies-on-board-and-off-board-acdc}

An AC/DC battery charger converts grid-frequency AC power into regulated
DC power at the voltage and current required by the battery. The typical
architecture is a \textbf{two-stage design}: a front-end \textbf{power
factor correction (PFC)} stage that converts AC to a regulated DC bus
(typically 400 V) with near-unity power factor, followed by an isolated
\textbf{DC-DC converter} stage that steps the voltage down to the
battery level and provides galvanic isolation for safety. The PFC stage
commonly uses a boost converter topology (see §10.7), while the DC-DC
stage favors resonant topologies --- the \textbf{LLC resonant converter}
achieves zero-voltage switching (ZVS) across the full load range with
96--98\% efficiency and is the dominant topology for chargers above 1
kW. For bidirectional chargers supporting \textbf{vehicle-to-grid (V2G)}
operation, the \textbf{CLLC resonant converter} provides symmetric
bidirectional power flow by adding a second resonant capacitor.
\textbf{On-board chargers (OBCs)} are integrated into the electric
vehicle and are typically rated at 3.3--22 kW for Level 1/Level 2 AC
charging, constrained by weight, volume, and cooling capacity.
\textbf{Off-board chargers} (DC fast-charging stations) bypass the OBC
entirely, connecting directly to the battery through the vehicle's DC
charging inlet, and are rated at 50--350 kW or higher. GaN transistors
are increasingly replacing silicon MOSFETs in OBC designs at power
levels up to 22 kW, enabling switching frequencies above 500 kHz that
shrink magnetic components by 50--70\%. The \textbf{USB Power Delivery
(USB-PD)} standard enables up to 240 W charging over a USB-C cable with
programmable voltage levels (5/9/15/20/28/36/48 V), governed by digital
negotiation between the source and sink.

\begin{examplebox}

\textbf{Example 10.10.2:} A 3.3 kW on-board charger has a PFC stage with
97\% efficiency and an LLC DC-DC stage with 96\% efficiency. The charger
converts 240 V\textsubscript{rms} single-phase AC to a 400 V nominal
battery pack. (a) Calculate the overall charger efficiency. (b)
Determine the AC input current at full load. (c) Calculate the total
power dissipated as heat. (d) If the charger enclosure has a thermal
resistance of 0.8°C/W to ambient at 35°C, estimate the maximum internal
temperature.

\textbf{Solution:}

(a) Overall efficiency: η\textsubscript{total} = η\textsubscript{PFC} ×
η\textsubscript{DC-DC} = 0.97 × 0.96 = \textbf{93.1\%}

(b) AC input power: P\textsubscript{in} = P\textsubscript{out} /
η\textsubscript{total} = 3,300 / 0.931 = 3,544 W.\\
AC input current: I\textsubscript{AC} = P\textsubscript{in} /
V\textsubscript{AC} = 3,544 / 240 = \textbf{14.8 A}

(c) Total heat dissipated: P\textsubscript{loss} = P\textsubscript{in} −
P\textsubscript{out} = 3,544 − 3,300 = \textbf{244 W}

(d) Temperature rise: ΔT = P\textsubscript{loss} × R\textsubscript{θ} =
244 × 0.8 = 195°C.\\
T\textsubscript{max} = 35 + 195 = \textbf{230°C} --- this is far too
high for enclosed operation, indicating that the 0.8°C/W thermal
resistance is inadequate. A liquid-cooled or fan-cooled design with
R\textsubscript{θ} ≤ 0.15°C/W would keep the internal temperature below
72°C, which is within the safe operating range for power semiconductors.

\end{examplebox}

\subsection{10.10.3 EV Charging Levels and
Standards}\label{ev-charging-levels-and-standards}

Electric vehicle charging infrastructure is categorized into
\textbf{levels} that define the power delivery capability and connection
type. \textbf{Level 1} uses a standard 120 V/15 A household outlet (NEMA
5-15) through a portable \textbf{EVSE (Electric Vehicle Supply
Equipment)} cord set, delivering 1.4--1.9 kW and adding approximately
5--8 km of range per hour --- suitable for overnight charging of plug-in
hybrids. \textbf{Level 2} uses a dedicated 208--240 V circuit with a
permanently installed EVSE, delivering 3.3--19.2 kW (typical
residential: 7.7 kW on a 40 A circuit) and adding 20--100 km of range
per hour. Both Level 1 and Level 2 supply AC power to the vehicle's
on-board charger. \textbf{DC fast charging (DCFC)} bypasses the OBC and
supplies DC power directly to the battery at 50--350 kW (with 800 V
architectures enabling up to 500 kW), adding 200--500 km of range in
15--30 minutes. The \textbf{SAE J1772} standard defines the Level
1/Level 2 AC connector and \textbf{pilot signal} --- a 1 kHz PWM square
wave on the control pilot (CP) pin whose duty cycle communicates the
maximum available current from the EVSE to the vehicle. The
\textbf{Combined Charging System (CCS)} adds two DC pins below the J1772
connector for DCFC up to 350 kW. \textbf{CHAdeMO} is a competing DC
fast-charging standard (up to 400 kW) using CAN bus communication,
developed in Japan. The \textbf{North American Charging Standard
(NACS)}, originally Tesla's proprietary connector, was adopted as SAE
J3400 and supports both AC and DC charging through a single compact
connector rated to 1 MW. The \textbf{Megawatt Charging System (MCS)},
standardized as SAE J3068, targets heavy-duty commercial vehicles with
charging power up to 3.75 MW at 1,250 V / 3,000 A.

\begin{examplebox}

\textbf{Example 10.10.3:} A battery electric vehicle has a 75 kWh usable
battery capacity and arrives at a charging station with 10\% state of
charge. Determine the time to charge to 80\% SOC using (a) Level 1 at
1.4 kW, (b) Level 2 at 7.7 kW, (c) DCFC at 150 kW (assuming constant
power up to 80\% SOC), and (d) the minimum EVSE circuit breaker rating
for a Level 2 EVSE on a 240 V circuit delivering 7.7 kW, applying the
NEC 125\% continuous load rule.

\textbf{Solution:}

(a) Energy required: E = 75 × (0.80 − 0.10) = 75 × 0.70 = 52.5 kWh.\\
Level 1 time: t = 52.5 / 1.4 = \textbf{37.5 hours}

(b) Level 2 time: t = 52.5 / 7.7 = \textbf{6.8 hours}

(c) DCFC time: t = 52.5 / 150 = 0.35 hours = \textbf{21 minutes}

(d) EVSE current: I = 7,700 / 240 = 32.1 A. NEC continuous load (125\%):
I\textsubscript{CB} = 32.1 × 1.25 = 40.1 A → \textbf{40 A circuit
breaker} (standard size per NEC 240.6(A)), requiring 8 AWG copper
conductors (ampacity 50 A at 75°C from NEC Table 310.16)

\end{examplebox}

\subsection{10.10.4 Fast Charging and Thermal
Considerations}\label{fast-charging-and-thermal-considerations}

\textbf{Fast charging} at rates above 1C generates significant heat
within the cell from \textbf{I²R losses} in the internal resistance,
which includes ionic resistance of the electrolyte, interfacial
charge-transfer resistance, and electronic resistance of the current
collectors and tabs. For a cell with internal resistance
R\textsubscript{int}, the instantaneous heat generation rate is
approximately Q̇ = I²R\textsubscript{int} + I × T ×
(dV\textsubscript{OCV}/dT), where the second term accounts for
reversible entropic heating (which can be exothermic or endothermic
depending on SOC). At low temperatures (below 10°C), the electrolyte
viscosity increases dramatically, raising ionic resistance and reducing
lithium-ion diffusivity in the graphite anode. If the charging rate
exceeds the anode's ability to intercalate lithium ions, metallic
lithium deposits on the anode surface --- a process called
\textbf{lithium plating} --- which permanently reduces capacity,
increases internal resistance, and in severe cases creates dendrites
that can cause internal short circuits. The safe \textbf{charge
acceptance window} narrows at low temperatures: a cell that safely
accepts 2C at 25°C may be limited to 0.3C at 0°C. Battery
\textbf{pre-conditioning} heats the pack to 15--25°C before fast
charging using PTC heaters, waste heat from the motor inverter, or
resistive heating of the cells themselves by applying high-frequency AC
current. \textbf{Pulse charging} protocols alternate short high-current
pulses (5--10 seconds) with rest periods (1--3 seconds), allowing
lithium-ion concentration gradients to relax and reducing the risk of
plating compared to continuous CC charging at the same average rate.
Charge rate optimization algorithms use \textbf{electrochemical
impedance spectroscopy (EIS)} feedback or physics-based models to
continuously adjust the charging current based on real-time cell
temperature, voltage, and estimated anode potential.

\begin{examplebox}

\textbf{Example 10.10.4:} A prismatic LFP cell has a capacity of 280 Ah,
internal resistance of 0.6 mΩ, and is charged at 1C (280 A). (a)
Calculate the I²R heat generation rate. (b) If the cell has a mass of
5.5 kg and specific heat capacity of 1,100 J/(kg·°C), estimate the
adiabatic temperature rise after 20 minutes of CC charging. (c) At 5°C
ambient, the internal resistance increases to 1.5 mΩ. Calculate the new
heat generation rate. (d) If the maximum safe cell temperature is 45°C
and the cell starts at 5°C, determine the maximum continuous charge time
at 1C before thermal limits are reached (adiabatic conditions, using the
5°C resistance value).

\textbf{Solution:}

(a) Heat generation at 25°C: Q̇ = I² × R\textsubscript{int} = 280² ×
0.0006 = 78,400 × 0.0006 = \textbf{47.04 W}

(b) Energy dissipated in 20 min: E = 47.04 × 20 × 60 = 56,448 J.\\
Temperature rise: ΔT = E / (m × c\textsubscript{p}) = 56,448 / (5.5 ×
1,100) = 56,448 / 6,050 = \textbf{9.3°C}

(c) At 5°C: Q̇ = 280² × 0.0015 = 78,400 × 0.0015 = \textbf{117.6 W} (2.5×
higher than at 25°C)

(d) Allowable temperature rise: ΔT\textsubscript{max} = 45 − 5 = 40°C.\\
Energy budget: E\textsubscript{max} = m × c\textsubscript{p} ×
ΔT\textsubscript{max} = 5.5 × 1,100 × 40 = 242,000 J.\\
Maximum charge time: t = E\textsubscript{max} / Q̇ = 242,000 / 117.6 =
2,058 s = \textbf{34.3 minutes} --- after which the cell must either
stop charging or reduce current. In practice, active cooling extends
this limit significantly.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-10-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_fast_charging_thermal.png}

\caption{Figure 10.10.4: Fast Charging Thermal Analysis}

\end{figure}

\subsection{10.10.5 Wireless and Inductive
Charging}\label{wireless-and-inductive-charging}

\textbf{Wireless power transfer (WPT)} for battery charging uses
\textbf{resonant inductive coupling} between a transmitter coil
(embedded in a charging pad or road surface) and a receiver coil
(mounted on the underside of the device or vehicle). The transmitter
drives the primary coil at a resonant frequency (typically 85 kHz for EV
charging per SAE J2954, or 100--205 kHz for Qi consumer devices),
creating an alternating magnetic field that induces a voltage in the
receiver coil through mutual inductance M = k√(L₁L₂), where k is the
\textbf{coupling coefficient} (0.1--0.3 for loosely coupled EV systems,
0.5--0.8 for tightly coupled consumer devices). To maximize power
transfer efficiency at the resonant frequency, \textbf{compensation
networks} --- series-series (SS), series-parallel (SP), LCC, or
double-sided LCC --- are added to both coils to cancel reactive
impedance and create a resonant condition. The \textbf{SS compensation}
topology places a capacitor in series with each coil, tuned so that the
capacitive reactance equals the inductive reactance at the operating
frequency: C = 1/(ω²L). System efficiency depends on the quality factor
Q of each coil (Q = ωL/R, typically 200--500 for well-designed Litz-wire
coils), the coupling coefficient, and the compensation network losses,
with practical WPT systems achieving 85--93\% DC-to-DC efficiency. The
\textbf{Qi standard} (Wireless Power Consortium) defines wireless
charging for consumer electronics at power levels from 5 W (baseline) to
15 W (extended power profile), using inductive coupling at 100--205 kHz
with in-band communication between receiver and transmitter for power
control. \textbf{SAE J2954} standardizes wireless EV charging at power
levels of WPT1 (3.7 kW), WPT2 (7.7 kW), WPT3 (11 kW), and WPT4 (22 kW)
at 85 kHz, specifying ground clearance classes (100--250 mm) and
alignment tolerances. \textbf{Foreign object detection (FOD)} is
critical for safety --- metallic objects on the charging pad can absorb
energy and overheat; FOD systems use auxiliary sensing coils, quality
factor monitoring, or thermal sensors to detect foreign objects and shut
down the transmitter.

\begin{examplebox}

\textbf{Example 10.10.5:} A wireless EV charging system operates at 85
kHz with a transmitter coil inductance L₁ = 200 μH, receiver coil
inductance L₂ = 250 μH, and coupling coefficient k = 0.20. The system
uses SS compensation. (a) Calculate the mutual inductance. (b) Determine
the series compensation capacitors for both coils. (c) If each coil has
an AC resistance of 0.15 Ω, calculate the quality factor of each coil.
(d) Estimate the maximum achievable efficiency using
η\textsubscript{max} = (k²Q₁Q₂) / (1 + √(1 + k²Q₁Q₂))².

\textbf{Solution:}

(a) Mutual inductance: M = k × √(L₁ × L₂) = 0.20 × √(200 × 10⁻⁶ × 250 ×
10⁻⁶) = 0.20 × √(5.0 × 10⁻⁸) = 0.20 × 2.236 × 10⁻⁴ = \textbf{44.7 μH}

(b) Angular frequency: ω = 2π × 85,000 = 534,071 rad/s.\\
C₁ = 1/(ω²L₁) = 1/(2.852 × 10¹¹ × 200 × 10⁻⁶) = 1/(5.704 × 10⁷) =
\textbf{17.5 nF}\\
C₂ = 1/(ω²L₂) = 1/(2.852 × 10¹¹ × 250 × 10⁻⁶) = 1/(7.130 × 10⁷) =
\textbf{14.0 nF}

(c) Q₁ = ωL₁/R₁ = 534,071 × 200 × 10⁻⁶ / 0.15 = 106.8 / 0.15 =
\textbf{712}\\
Q₂ = ωL₂/R₂ = 534,071 × 250 × 10⁻⁶ / 0.15 = 133.5 / 0.15 = \textbf{890}

(d) Product: k²Q₁Q₂ = 0.04 × 712 × 890 = 0.04 × 633,680 = 25,347.\\
η\textsubscript{max} = 25,347 / (1 + √(1 + 25,347))² = 25,347 / (1 +
159.2)² = 25,347 / (160.2)² = 25,347 / 25,664 = \textbf{98.8\%} --- this
theoretical maximum assumes lossless compensation networks and
electronics; practical system DC-to-DC efficiency is 85--93\% after
accounting for inverter, rectifier, and compensation network losses.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-10-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_wireless_charging_efficiency.png}

\caption{Figure 10.10.5: Wireless Charging Efficiency vs Coupling Coefficient}

\end{figure}

\section{10.11 Supercapacitors}\label{supercapacitors}

Supercapacitors --- also called \textbf{ultracapacitors} or
\textbf{electrochemical double-layer capacitors (EDLC)} --- occupy the
performance space between conventional electrolytic capacitors and
rechargeable batteries, offering capacitances from a few farads to
thousands of farads. Their energy density (1--15 Wh/kg) is far below
that of lithium-ion batteries (100--250 Wh/kg), but their specific power
(500--10,000 W/kg) greatly exceeds battery capability, and their cycle
life of 500,000+ cycles dwarfs the 500--2,000 cycles of Li-ion cells.
Supercapacitors store energy electrostatically --- not chemically ---
enabling sub-second charge/discharge capability, wide operating
temperature ranges (−40 °C to +65 °C), and no risk of thermal runaway.
They are widely deployed in regenerative energy recovery for transit
vehicles, peak power buffering for industrial drives, uninterruptible
power supplies, automotive start-stop systems, and hybrid configurations
that pair a battery (high energy) with a supercapacitor (high power).

\subsection{10.11.1 EDLC Fundamentals}\label{edlc-fundamentals}

An EDLC cell stores charge at the \textbf{electrochemical double layer}
--- the molecular interface between a high-surface-area carbon electrode
and an electrolyte. When a voltage is applied, electrolyte ions are
adsorbed onto the electrode surface, forming two layers of opposite
charge separated by a distance d of roughly 0.3--1 nm. The resulting
capacitance follows the standard parallel-plate formula C = εᵣε₀A/d, but
because d is so small and the electrode surface area A so large
(1,000--3,000 m²/g for activated carbon), capacitances per unit mass are
orders of magnitude higher than in conventional capacitors. Each cell
consists of two such electrodes separated by an ion-permeable membrane;
the cell capacitance equals half the single-electrode capacitance
because the two double layers are in series.

Key operating parameters include: - \textbf{Specific capacitance}:
100--300 F/g for activated carbon electrodes - \textbf{Cell voltage}:
limited to 2.5--2.7 V for organic electrolytes, 1.0--1.2 V for aqueous
electrolytes - \textbf{ESR} (equivalent series resistance): 1--50 mΩ,
which limits peak current and introduces voltage droop -
\textbf{Self-discharge}: time constant of hours to days (far faster than
batteries) - \textbf{Cycle life}: \textgreater{} 500,000 full
charge/discharge cycles with \textless{} 20\% capacitance fade

Energy stored in a supercapacitor is E = ½CV², and a key design
consideration is that not all stored energy is recoverable ---
discharging from V\textsubscript{max} to V\textsubscript{max}/2 delivers
75\% of the total energy, but the terminal voltage halves
simultaneously.

\begin{examplebox}

\textbf{Example 10.11.1:} A symmetric EDLC cell uses two activated
carbon electrodes, each with a specific surface area of 1,500 m²/g and a
mass of 5 g. The double-layer capacitance per unit area is 20 μF/cm².
(a) Calculate the electrode capacitance. (b) Calculate the cell
capacitance. (c) If the cell is charged to 2.7 V, how much energy is
stored?

\textbf{Solution:}

(a) Total electrode surface area = 1,500 m²/g × 5 g = 7,500 m² = 7,500 ×
(100 cm)²/m² = 7.5 × 10⁷ cm².\\
Electrode capacitance: C\textsubscript{electrode} = 20 × 10⁻⁶ F/cm² ×
7.5 × 10⁷ cm² = \textbf{1,500 F}

(b) Two double layers in series (one per electrode):
C\textsubscript{cell} = C\textsubscript{electrode}/2 = 1,500/2 =
\textbf{750 F}

(c) E = ½ × C\textsubscript{cell} × V² = ½ × 750 × (2.7)² = ½ × 750 ×
7.29 = \textbf{2,734 J (0.759 Wh)}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-11-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_supercap_edlc_energy.png}

\caption{Figure 10.11.1: EDLC Energy Storage vs Voltage — Usable 75\% and Electrolyte Comparison}

\end{figure}

\subsection{10.11.2 Pseudocapacitors and Hybrid
Supercapacitors}\label{pseudocapacitors-and-hybrid-supercapacitors}

\textbf{Pseudocapacitors} augment double-layer capacitance with
\textbf{Faradaic charge storage} --- reversible electrochemical
reactions (surface redox, intercalation, or underpotential deposition)
that occur at the electrode surface rather than in the bulk, as in a
battery. Common pseudocapacitive materials include RuO₂ (ruthenium
dioxide, high performance but expensive), MnO₂ (manganese dioxide, low
cost), and conducting polymers such as polyaniline. Because charge is
stored both electrostatically and electrochemically, pseudocapacitors
achieve 2--5× higher energy density than EDLC at the cost of slightly
reduced cycle life and slower response.

\textbf{Lithium-ion capacitors (LICs)} are a prominent hybrid technology
combining a pre-lithiated graphite anode (which stores charge like a
Li-ion battery) with an activated carbon cathode (which stores charge
like an EDLC). The asymmetric design raises the cell voltage to 2.2--3.8
V and triples the energy density versus conventional EDLC, while
retaining much of the power advantage. LICs target applications --- such
as regenerative braking, elevator energy recovery, and industrial UPS
--- where batteries lack peak-power capability but standard EDLC lack
sufficient energy density.

A \textbf{Ragone plot} (specific power vs specific energy on a log-log
scale) is the standard tool for comparing energy storage technologies
and identifying the region each occupies.

\begin{examplebox}

\textbf{Example 10.11.2:} A 350 F EDLC cell (V\textsubscript{max} = 2.7
V, mass = 60 g) is compared to a lithium-ion battery cell (specific
energy = 150 Wh/kg, specific power = 400 W/kg, mass = 100 g). (a)
Calculate the energy stored in each device. (b) Calculate the specific
energy of the EDLC. (c) By what factor does the Li-ion cell exceed the
EDLC in specific energy?

\textbf{Solution:}

(a) EDLC: E = ½ × 350 × (2.7)² = ½ × 350 × 7.29 = \textbf{1,275.75 J =
0.354 Wh}\\
Li-ion battery: E = 150 Wh/kg × 0.100 kg = \textbf{15.0 Wh}

(b) EDLC specific energy = 0.354 Wh / 0.060 kg = \textbf{5.9 Wh/kg}

(c) Ratio = 150 Wh/kg ÷ 5.9 Wh/kg = \textbf{25.4×} --- the Li-ion cell
stores about 25 times more energy per kilogram; however, the EDLC can
deliver its energy in a fraction of a second, whereas the battery is
rate-limited by ion diffusion.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-11-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_supercap_ragone.png}

\caption{Figure 10.11.2: Ragone Plot — Specific Power vs Specific Energy for Energy Storage Technologies}

\end{figure}

\subsection{10.11.3 Equivalent Circuit, ESR, and
Charge/Discharge}\label{equivalent-circuit-esr-and-chargedischarge}

The practical supercapacitor equivalent circuit is a \textbf{series RC
model}: an ideal capacitor C, a series \textbf{equivalent series
resistance (ESR)}, and a parallel leakage resistance
R\textsubscript{leak} (typically 100 kΩ--1 MΩ, governing self-discharge
rate). The ESR, dominated by electrode contact resistance and
electrolyte resistance, limits peak power and causes a voltage step at
the start of charge or discharge.

During \textbf{constant-current discharge} at current I from initial
voltage V₀:

V\textsubscript{C}(t) = V₀ − (I/C) × t (capacitor voltage, linear ramp)

V\textsubscript{terminal}(t) = V\textsubscript{C}(t) − I × ESR (terminal
voltage, shifted down by I × ESR)

The maximum power deliverable to a matched load is P\textsubscript{max}
= V₀²/(4 × ESR), which highlights that lower ESR directly enables higher
peak power. Unlike batteries, which maintain a relatively flat discharge
voltage, the supercapacitor terminal voltage drops linearly from V₀ to 0
V, requiring a DC-DC converter in most applications to regulate the
output voltage as the supercapacitor discharges.

\begin{examplebox}

\textbf{Example 10.11.3:} A 10 F supercapacitor module has ESR = 50 mΩ
and is charged to V₀ = 16.2 V (6 cells × 2.7 V). (a) If the module is
discharged at a constant 20 A, find the initial terminal voltage. (b)
How long until the capacitor voltage falls to 8.1 V (half of initial)?
(c) What fraction of total stored energy has been extracted at that
point? (d) What is the maximum power available from this module?

\textbf{Solution:}

(a) V\textsubscript{terminal}(0) = V₀ − I × ESR = 16.2 − 20 × 0.050 =
16.2 − 1.0 = \textbf{15.2 V}

(b) V\textsubscript{C}(t) = 16.2 − (20/10) × t = 16.2 − 2t. Setting
V\textsubscript{C} = 8.1:\\
8.1 = 16.2 − 2t → t = (16.2 − 8.1)/2 = \textbf{4.05 s}

(c) E\textsubscript{total} = ½ × 10 × 16.2² = 1,312.2 J.
E\textsubscript{remaining} = ½ × 10 × 8.1² = 328.1 J.\\
Fraction extracted = (1,312.2 − 328.1)/1,312.2 = 984.1/1,312.2 =
\textbf{75\%} --- discharging to V\textsubscript{max}/2 always extracts
exactly 75\% of stored energy.

(d) P\textsubscript{max} = V₀²/(4 × ESR) = 16.2²/(4 × 0.050) =
262.44/0.200 = \textbf{1,312 W}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-11-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_supercap_discharge.png}

\caption{Figure 10.11.3: Supercapacitor Constant-Current Discharge Voltage Profile}

\end{figure}

\subsection{10.11.4 Series-Parallel Bank
Design}\label{series-parallel-bank-design}

Supercapacitors are combined in \textbf{series} to increase voltage
rating, in \textbf{parallel} to increase capacitance and energy, or in
series-parallel combinations to meet both requirements. For
n\textsubscript{s} cells in series with n\textsubscript{p} parallel
strings:

\begin{itemize}
\tightlist
\item
  V\textsubscript{bank} = n\textsubscript{s} × V\textsubscript{cell}
\item
  C\textsubscript{bank} = n\textsubscript{p} × C\textsubscript{cell} /
  n\textsubscript{s}
\item
  E\textsubscript{bank} = ½ × C\textsubscript{bank} ×
  V\textsubscript{bank}²
\end{itemize}

\textbf{Cell voltage balancing} is essential for series-connected cells
because manufacturing variation in capacitance (±20\%) and leakage
current causes unequal voltage distribution. \textbf{Passive balancing}
uses a resistor (typically 100--1,000 Ω) shunted across each cell; while
simple, it continuously draws leakage current and reduces efficiency.
\textbf{Active balancing} uses a switched-capacitor or DC-DC converter
topology to shuffle charge between cells, improving efficiency and
reducing voltage imbalance to under 10 mV. ESR also adds in series
across the string, so total module ESR = n\textsubscript{s} ×
ESR\textsubscript{cell}/n\textsubscript{p}.

\begin{examplebox}

\textbf{Example 10.11.4:} A supercapacitor energy storage module must
deliver at least 100 Wh at a nominal bus voltage of 48 V using cells
rated at 2.7 V, 3,000 F each. (a) Determine the minimum number of series
cells to meet the voltage requirement. (b) Calculate the string
capacitance and energy per string. (c) Determine the number of parallel
strings needed. (d) Verify total stored energy.

\textbf{Solution:}

(a) Cells per string: n\textsubscript{s} = ⌈48 / 2.7⌉ = ⌈17.78⌉ =
\textbf{18 cells}; V\textsubscript{string} = 18 × 2.7 = 48.6 V

(b) C\textsubscript{string} = 3,000 / 18 = \textbf{166.7 F}\\
E\textsubscript{string} = ½ × 166.7 × (48.6)² = ½ × 166.7 × 2,361.96 =
\textbf{196,869 J = 54.7 Wh}

(c) Parallel strings: n\textsubscript{p} = ⌈100 / 54.7⌉ = ⌈1.83⌉ =
\textbf{2 strings}

(d) C\textsubscript{bank} = 2 × 166.7 = 333.4 F; E\textsubscript{bank} =
½ × 333.4 × (48.6)² = 393,739 J = \textbf{109.4 Wh} ✓ (exceeds 100 Wh
requirement)

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-11-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_supercap_bank_design.png}

\caption{Figure 10.11.4: Series-Parallel Bank Design — Voltage, Capacitance, and Energy vs Series Cell Count}

\end{figure}

\subsection{10.11.5 Applications: Regenerative Braking and Peak Power
Buffering}\label{applications-regenerative-braking-and-peak-power-buffering}

Supercapacitors excel in \textbf{transient energy applications} where
energy must be absorbed or delivered in seconds rather than minutes. Key
industrial applications include:

\begin{itemize}
\tightlist
\item
  \textbf{Regenerative braking} in trains, trams, and hybrid buses:
  capturing several hundred kilojoules during braking and returning it
  during acceleration
\item
  \textbf{Peak power buffering} in cranes, elevators, and industrial
  presses: reducing peak current demand from the utility grid and
  shrinking transformer ratings
\item
  \textbf{UPS and ride-through}: bridging the gap during generator
  startup (typically 10--30 s) for data centers and medical equipment
\item
  \textbf{Start-stop automotive systems}: replacing or augmenting
  lead-acid batteries for engine restart
\end{itemize}

In a \textbf{hybrid battery-supercapacitor system}, the supercapacitor
handles fast transients (\textless{} 10 s) while the battery supplies
the sustained load. This hybrid topology reduces battery peak current,
extends battery cycle life by 2--4×, and improves overall system
efficiency. The split is governed by the \textbf{energy management
strategy} --- typically rule-based (frequency splitting) or
model-predictive control.

\begin{examplebox}

\textbf{Example 10.11.5:} A light rail vehicle recovers 40 kJ of kinetic
energy during a 5-second braking event. A supercapacitor bank operates
between V\textsubscript{max} = 200 V and V\textsubscript{min} = 100 V
(discharging to half voltage to extract 75\% of stored energy). (a) Size
the required capacitance. (b) Calculate the average charging current
during braking. (c) Verify the energy extracted when the bank is
subsequently discharged from 200 V to 100 V.

\textbf{Solution:}

(a) Usable energy: E\textsubscript{usable} = ½C(V\textsubscript{max}² −
V\textsubscript{min}²) = ½ × C × (200² − 100²) = ½ × C × 30,000 =
15,000C\\
Setting E\textsubscript{usable} = 40,000 J: C = 40,000/15,000 =
\textbf{2.67 F}

(b) Average power during braking: P = 40,000/5 = 8,000 W.\\
Average current: I\textsubscript{avg} ≈ P/V\textsubscript{avg} =
8,000/150 = \textbf{53.3 A} (V\textsubscript{avg} ≈ (200+100)/2 = 150 V
during charging)

(c) E\textsubscript{extracted} = ½ × 2.67 × (200² − 100²) = ½ × 2.67 ×
30,000 = \textbf{40,050 J ≈ 40 kJ} ✓

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-11-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_supercap_regen.png}

\caption{Figure 10.11.5: Regenerative Braking Cycle — Voltage, Current, and Power for a Light Rail Tram}

\end{figure}

\section{10.12 Solar Photovoltaic
Systems}\label{solar-photovoltaic-systems}

Solar photovoltaic (PV) systems convert sunlight directly into
electricity using the \textbf{photovoltaic effect} --- the generation of
electron-hole pairs when photons with sufficient energy are absorbed by
a semiconductor junction. Power electronics is indispensable at every
stage of the energy chain: a \textbf{DC-DC converter} with maximum power
point tracking (MPPT) extracts the most available power from the array
as irradiance and temperature shift continuously, and a \textbf{DC-AC
inverter} conditions the output for grid injection, AC loads, or battery
storage. A PV array behaves as a current source with a nonlinear I-V
characteristic whose peak power point moves with every change in
operating conditions, making MPPT essential for capturing 97--99\% of
available energy. Grid-tied inverters must satisfy strict
anti-islanding, harmonic distortion, and power quality requirements
under IEEE 1547 and UL 1741, while off-grid systems add charge
controllers, battery banks, and backup generators for energy autonomy.
Solar PV is now among the lowest-cost electricity sources globally, and
the power electronics covered throughout this chapter --- boost
converters (§10.3.2), three-phase inverters (§10.4.2), battery
management (§10.8), and energy storage (§10.9) --- underlies both
utility-scale gigawatt arrays and small rooftop installations.

\subsection{10.12.1 PV Cell Characteristics and the I-V
Curve}\label{pv-cell-characteristics-and-the-i-v-curve}

A photovoltaic cell is a large-area p-n junction operated under
illumination. Incident photons with energy exceeding the semiconductor
bandgap generate electron-hole pairs; the built-in junction field
separates the carriers, producing a photocurrent I\textsubscript{ph}
proportional to irradiance G (W/m²). The cell I-V characteristic is
described by the \textbf{single-diode model}:

I = I\textsubscript{ph} − I₀(e\textsuperscript{V/(n·VT)} − 1)

where I₀ is the reverse saturation current, n is the diode ideality
factor (1.0--1.5), and V\textsubscript{T} = kT/q ≈ 25.85 mV at 25 °C.
Three parameters define the curve:

\begin{itemize}
\tightlist
\item
  \textbf{Short-circuit current} I\textsubscript{sc}: current at V = 0;
  scales nearly linearly with irradiance G
\item
  \textbf{Open-circuit voltage} V\textsubscript{oc}: voltage at I = 0;
  decreases \textasciitilde0.3 \%/°C for silicon; increases
  logarithmically with irradiance
\item
  \textbf{Maximum power point (MPP)}: (V\textsubscript{mp},
  I\textsubscript{mp}) where P = V × I is maximized
\end{itemize}

The \textbf{fill factor} FF = (V\textsubscript{mp} ×
I\textsubscript{mp}) / (V\textsubscript{oc} × I\textsubscript{sc})
measures curve ``squareness''; commercial silicon cells achieve FF =
0.75--0.85. Cell \textbf{efficiency} η = P\textsubscript{max} / (G ×
A\textsubscript{cell}) is typically 18--24\% for monocrystalline silicon
at standard test conditions (STC: G = 1,000 W/m², T\textsubscript{cell}
= 25 °C, AM 1.5 spectrum). A 60-cell series module multiplies
V\textsubscript{oc} and V\textsubscript{mp} by 60 while leaving
I\textsubscript{sc} unchanged.

\begin{examplebox}

\textbf{Example 10.12.1:} A 156 mm × 156 mm monocrystalline silicon PV
cell (area = 0.0243 m²) has STC parameters: I\textsubscript{sc} = 9.0 A,
V\textsubscript{oc} = 0.650 V, I\textsubscript{mp} = 8.5 A,
V\textsubscript{mp} = 0.540 V. (a) Calculate the fill factor. (b)
Calculate P\textsubscript{max}. (c) Calculate cell efficiency at STC (G
= 1,000 W/m²). (d) At 65 °C, V\textsubscript{oc} decreases at −2.3 mV/°C
from 25 °C. Calculate the new V\textsubscript{oc} and the percentage
drop.

\textbf{Solution:}

(a) FF = (V\textsubscript{mp} × I\textsubscript{mp}) /
(V\textsubscript{oc} × I\textsubscript{sc}) = (0.540 × 8.5) / (0.650 ×
9.0) = 4.590 / 5.850 = \textbf{0.785 (78.5\%)}

(b) P\textsubscript{max} = V\textsubscript{mp} × I\textsubscript{mp} =
0.540 × 8.5 = \textbf{4.59 W}

(c) η = P\textsubscript{max} / (G × A) = 4.59 / (1,000 × 0.0243) = 4.59
/ 24.3 = \textbf{18.9\%}

(d) ΔT = 65 − 25 = 40 °C; ΔV\textsubscript{oc} = −2.3 × 10⁻³ × 40 =
−0.092 V

V\textsubscript{oc}(65 °C) = 0.650 − 0.092 = \textbf{0.558 V} --- a
14.2\% reduction, demonstrating why PV output falls significantly on hot
days even at constant irradiance.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-10-12-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch10_pv_iv_curves.png}

\caption{Figure 10.12.1: PV Module I-V and P-V Curves — Effect of Irradiance at 25 °C}

\end{figure}

\subsection{10.12.2 Maximum Power Point Tracking
(MPPT)}\label{maximum-power-point-tracking-mppt}

A PV module's I-V curve shifts with every change in irradiance and cell
temperature, moving the MPP to a new (V\textsubscript{mp},
I\textsubscript{mp}) coordinate. Without active tracking, a converter
operating at a fixed duty cycle rarely coincides with the MPP, typically
losing 10--30\% of available energy. MPPT continuously adjusts the
converter operating point to maximize P = V × I.

The most widely deployed algorithm is \textbf{Perturb-and-Observe
(P\&O)}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Measure V and I; compute P = V × I.
\item
  Perturb voltage by a small step ΔV (typically 0.5--1 \% of
  V\textsubscript{mp}).
\item
  Measure new P′. If P′ \textgreater{} P, continue in the same
  direction; if P′ \textless{} P, reverse direction.
\item
  Repeat at each control cycle (10--100 ms).
\end{enumerate}

P\&O is simple but oscillates with amplitude ΔV around the MPP in steady
state. The \textbf{Incremental Conductance (InC)} method eliminates
steady-state oscillation by using the analytical MPP condition dP/dV =
0, which yields I + V × dI/dV = 0, or equivalently dI/dV = −I/V at the
MPP. MPPT efficiency --- the ratio of harvested energy to available MPP
energy --- typically reaches 97--99.5 \%. In microinverters and
multi-string systems, each module or string has its own MPPT,
eliminating losses from module-level mismatch.

\begin{examplebox}

\textbf{Example 10.12.2:} A PV module has V\textsubscript{oc} = 45 V,
I\textsubscript{sc} = 9.0 A, V\textsubscript{mp} = 36 V,
I\textsubscript{mp} = 8.5 A. A boost converter MPPT stage steps up from
V\textsubscript{pv} to a 400 V DC bus with 96\% efficiency. (a)
Calculate module power at MPP. (b) Calculate the boost converter duty
cycle at MPP (ideal). (c) Calculate DC bus power delivered. (d) A P\&O
algorithm starts at V = 34.0 V with P = 289 W, then steps to V = 34.5 V
and measures P = 294 W. State the direction of the next perturbation.

\textbf{Solution:}

(a) P\textsubscript{mp} = V\textsubscript{mp} × I\textsubscript{mp} = 36
× 8.5 = \textbf{306 W}

(b) Ideal boost: V\textsubscript{out} = V\textsubscript{in} / (1 − D) →
1 − D = 36 / 400 = 0.090 → D = \textbf{0.910 (91.0\%)}

(c) P\textsubscript{dc} = P\textsubscript{mp} × η = 306 × 0.96 =
\textbf{293.8 W}

(d) ΔP = 294 − 289 = +5 W \textgreater{} 0 with ΔV = +0.5 V → power
increased with a voltage increase → \textbf{perturb in the same
direction (increase V further toward the MPP)}.

\end{examplebox}

\subsection{10.12.3 Grid-Tied PV
Inverters}\label{grid-tied-pv-inverters}

A \textbf{grid-tied inverter} synchronizes PV power to the utility grid,
injecting current in phase with the grid voltage to achieve unity power
factor. Two primary topologies exist:

\begin{itemize}
\tightlist
\item
  \textbf{Single-stage}: a DC-AC inverter with built-in MPPT directly
  converts PV DC to AC; simpler, fewer components, but the DC bus
  voltage must stay within the inverter's MPPT window at all times
\item
  \textbf{Two-stage}: a DC-DC MPPT stage followed by a DC-AC stage;
  decouples the PV array voltage from the inverter bus, enabling a wider
  PV operating range and higher overall efficiency
\end{itemize}

Grid synchronization uses a \textbf{phase-locked loop (PLL)} to track
grid frequency and phase, ensuring injected current is in phase with the
grid voltage. \textbf{Anti-islanding protection} is mandatory under IEEE
1547: if the utility goes offline, the inverter must detect the
condition and cease energizing the local circuit within 2 seconds,
preventing shock hazards for utility workers. Detection methods include
passive schemes (over/underfrequency, over/undervoltage) and active
schemes (frequency shift, reactive power injection).

Key standards: \textbf{IEEE 1547} (interconnection and
interoperability), \textbf{UL 1741} (inverter safety), \textbf{NEC
Article 690} (PV system wiring and protection). Modern inverters also
support reactive power injection for grid voltage support, low-voltage
ride-through (LVRT), and remote curtailment.

\begin{examplebox}

\textbf{Example 10.12.3:} A single-phase grid-tied PV inverter connects
to a 240 V\textsubscript{rms} / 60 Hz grid with a 400 V DC bus. The
inverter outputs 3.0 kW at unity power factor with a 16 kHz switching
frequency. (a) Calculate peak grid voltage. (b) Calculate RMS output
current. (c) Calculate the SPWM modulation index m =
V̂\textsubscript{AC}/V\textsubscript{DC}. (d) Calculate the number of
switching cycles in the 2-second anti-islanding detection window.

\textbf{Solution:}

(a) V̂\textsubscript{AC} = 240 × √2 = \textbf{339.4 V}

(b) I\textsubscript{rms} = P / V\textsubscript{rms} = 3,000 / 240 =
\textbf{12.5 A}

(c) m = V̂\textsubscript{AC} / V\textsubscript{DC} = 339.4 / 400 =
\textbf{0.849}

(d) N\textsubscript{cycles} = f\textsubscript{sw} × t = 16,000 × 2 =
\textbf{32,000 switching cycles}

\end{examplebox}

\subsection{10.12.4 Off-Grid and Hybrid PV
Systems}\label{off-grid-and-hybrid-pv-systems}

An \textbf{off-grid (stand-alone) PV system} operates without utility
connection, supplying all loads from PV generation and battery storage.
The main components are:

\begin{itemize}
\tightlist
\item
  \textbf{PV array}: sized to meet daily load energy plus system losses
\item
  \textbf{Charge controller}: regulates charging to prevent overcharge
  and overdischarge; \textbf{PWM controllers} connect the array directly
  to the battery (simple, lower cost, but less efficient when
  V\textsubscript{pv} \textgreater{} V\textsubscript{battery});
  \textbf{MPPT charge controllers} use a DC-DC converter to
  independently track the array MPP, extracting 10--30\% more energy
\item
  \textbf{Battery bank}: provides autonomy during nights and
  low-irradiance periods; typically 1--5 days of storage; lead-acid
  (50\% usable DoD) or lithium iron phosphate (80--90\% usable DoD)
\item
  \textbf{Inverter/charger}: converts battery DC to AC loads; typically
  includes a transfer switch for optional AC generator backup
\end{itemize}

A \textbf{hybrid system} adds a diesel or propane generator as backup,
operated only when PV generation and battery state of charge cannot meet
the load. System sizing begins with daily load energy (Wh/day),
determines battery capacity from autonomy days and allowable DoD, then
sizes the PV array to restore the battery within one average peak-sun
day.

\begin{examplebox}

\textbf{Example 10.12.4:} An off-grid cabin has a daily load of 1.2 kWh
at a 24 V bus. The system must provide 3 days of autonomy with AGM
lead-acid batteries (50\% maximum DoD). Peak sun hours = 5 h/day; system
efficiency from PV array to load = 80\%. (a) Calculate minimum battery
capacity in Ah. (b) Calculate minimum PV array peak power. (c) If
modules have V\textsubscript{mp} = 36 V and an MPPT charge controller
steps down to 24 V, calculate the required array I\textsubscript{mp}.

\textbf{Solution:}

(a) Autonomy energy = 3 × 1,200 = 3,600 Wh. At 50\% DoD, total battery
energy needed = 3,600 / 0.50 = 7,200 Wh.

Capacity = 7,200 / 24 = \textbf{300 Ah}

(b) E\textsubscript{pv} = 1,200 / 0.80 = 1,500 Wh/day;
P\textsubscript{pv} = 1,500 / 5 = \textbf{300 W} (peak array power)

(c) I\textsubscript{mp} = P\textsubscript{pv} / V\textsubscript{mp} =
300 / 36 = \textbf{8.33 A} --- the MPPT controller draws this current at
36 V and delivers equivalent power at 24 V to the battery (less
converter losses).

\end{examplebox}

\subsection{10.12.5 PV Array Wiring, Shading, and
Protection}\label{pv-array-wiring-shading-and-protection}

\textbf{String configuration} combines modules in series and parallel to
meet inverter input requirements. N\textsubscript{s} modules in series
yield a string voltage of N\textsubscript{s} × V\textsubscript{module};
N\textsubscript{p} parallel strings give total array current of
N\textsubscript{p} × I\textsubscript{string}. String voltage must fall
within the inverter's MPPT window at all temperatures: at low
temperature (high V\textsubscript{oc}) the string must not exceed the
inverter's maximum DC input voltage; at high temperature (low
V\textsubscript{mp}) the string must remain above the MPPT minimum.

\textbf{Partial shading} is a critical design issue: one shaded cell in
a series string restricts the current of all cells in that string,
causing severe power loss and potentially damaging hot spots.
\textbf{Bypass diodes} --- typically one per 18--20 cells, or three per
60-cell module --- allow current to flow around a shaded cell group,
confining the loss to the affected bypass zone. Without bypass diodes, a
single shaded cell could eliminate nearly all of the string's output;
with bypass diodes, only the shaded zone (one-third of a module in a
three-diode design) is sacrificed.

Additional NEC Article 690 protection requirements include:

\begin{itemize}
\tightlist
\item
  \textbf{Arc Fault Circuit Interrupter (AFCI)} --- detects series and
  parallel arcs in DC wiring (NEC 690.11)
\item
  \textbf{Rapid Shutdown System (RSS)} --- reduces rooftop conductor
  voltage within 30 seconds to protect first responders (NEC 690.12)
\item
  \textbf{Overcurrent protection} --- string fuses or breakers required
  when three or more strings are paralleled
\end{itemize}

\begin{examplebox}

\textbf{Example 10.12.5:} A PV string has 20 series-connected modules,
each rated: V\textsubscript{oc} = 45 V, I\textsubscript{sc} = 9.5 A,
V\textsubscript{mp} = 37 V, I\textsubscript{mp} = 9.0 A. Each module has
3 bypass diodes protecting 20 cells each. (a) Calculate string
V\textsubscript{oc} and string P\textsubscript{mp} at full irradiance.
(b) One module falls fully into shade, activating its bypass diodes.
Calculate the new string power. (c) Without bypass diodes the shaded
module limits string current to 1.0 A. Estimate the power loss.

\textbf{Solution:}

(a) String V\textsubscript{oc} = 20 × 45 = \textbf{900 V}; String
P\textsubscript{mp} = (20 × 37) × 9.0 = 740 × 9.0 = \textbf{6,660 W
(6.66 kW)}

(b) With bypass diodes, the shaded module is bypassed: current remains
at I\textsubscript{mp} = 9.0 A; the shaded module contributes ≈ 0 V and
0 W.

V\textsubscript{string} = 19 × 37 = 703 V; P\textsubscript{shaded} = 703
× 9.0 = \textbf{6,327 W} --- a loss of 333 W (5.0\%), equal to exactly
one module's output.

(c) Without bypass diodes, string current is limited to 1.0 A.

P\textsubscript{no-bypass} = 740 × 1.0 = 740 W; loss = 6,660 − 740 =
\textbf{5,920 W (88.9\%)} --- one shaded module eliminates nearly 90\%
of string output, demonstrating why bypass diodes are mandatory in
series strings.

\end{examplebox}

\chapter{Chapter 11}\label{chapter-11}

\chapter{Instrumentation and
Measurement}\label{instrumentation-and-measurement}

Instrumentation and measurement is the branch of electrical engineering
concerned with the accurate sensing, acquisition, and analysis of
physical quantities such as voltage, current, resistance, temperature,
pressure, and frequency. It encompasses the design of sensors and
transducers that convert physical phenomena into electrical signals, the
signal conditioning circuits that amplify, filter, and convert those
signals, and the measurement instruments and data acquisition systems
that display, record, and analyze the results. Precise measurement is
fundamental to all engineering disciplines --- without the ability to
accurately quantify a parameter, it cannot be controlled, optimized, or
verified.

\section{11.1 Measurement Fundamentals}\label{measurement-fundamentals}

Every measurement system is characterized by how faithfully it
represents the true value of the quantity being measured. Measurement
fundamentals encompass the concepts of accuracy, precision, resolution,
error analysis, calibration, and signal-to-noise ratio --- the tools
engineers use to quantify measurement quality, identify error sources,
and establish confidence in their results. Understanding these
fundamentals is prerequisite to selecting the right sensor, instrument,
or data acquisition system for a given application.

\subsection{11.1.1 Accuracy, Precision, and
Resolution}\label{accuracy-precision-and-resolution}

Accuracy describes how close a measurement is to the true value of the
quantity being measured, while precision describes the repeatability or
consistency of measurements under the same conditions. A measurement
system can be precise without being accurate (consistent but offset from
the true value) or accurate on average without being precise (scattered
around the true value). Resolution is the smallest change in the
measured quantity that the instrument can detect, determined by the
number of bits in a digital system (e.g., a 12-bit ADC with a 10 V range
has a resolution of 10/4096 ≈ 2.44 mV). Measurement uncertainty is the
quantitative expression of doubt about a measurement result, combining
systematic errors (bias) and random errors (noise), and is typically
reported as an expanded uncertainty with a stated confidence level
(e.g., ±0.5\% at 95\% confidence).

\begin{examplebox}

\textbf{Example 11.1.1:} A 16-bit ADC has an input range of 0-5 V. A
voltage source is measured 10 times, yielding readings (in volts):
3.3021, 3.3018, 3.3025, 3.3019, 3.3022, 3.3020, 3.3023, 3.3017, 3.3024,
3.3021. The true voltage is 3.3050 V. Determine the resolution,
accuracy, and precision.

\textbf{Solution:}\\
Resolution = full-scale range / 2ᴺ = 5 / 2¹⁶ = 5 / 65,536 = 76.3 μV per
count.\\
Mean of measurements: x̄ = (sum of all values) / 10 = 33.021 / 10 =
3.3021 V.\\
Accuracy (systematic error): \textbar3.3050 - 3.3021\textbar{} = 2.9 mV,
or (2.9 / 3.3050) × 100 = 0.088\% of reading.\\
Precision (standard deviation): s = √{[}Σ(x\textsubscript{i} - x̄)² /
(N-1){]}.\\
The deviations from the mean are: 0, -0.3, +0.4, -0.2, +0.1, -0.1, +0.2,
-0.4, +0.3, 0 mV.\\
s = √{[}(0 + 0.09 + 0.16 + 0.04 + 0.01 + 0.01 + 0.04 + 0.16 + 0.09 + 0)
× 10⁻⁶ / 9{]} = √{[}0.0667 × 10⁻⁶{]} = 0.258 mV.\\
The instrument is precise (small spread) but has a 2.9 mV systematic
offset requiring calibration.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-11-1-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch11_accuracy_precision.png}

\caption{Figure 11.1.1: Accuracy vs Precision: Target Analogy}

\end{figure}

\subsection{11.1.2 Error and Calibration}\label{error-and-calibration}

Measurement errors are classified as systematic (consistent bias that
affects all measurements equally) or random (statistical variations that
cause scatter around a mean value). Common sources of systematic error
include instrument offset, gain error, nonlinearity, loading effects
(where the measurement instrument alters the quantity being measured),
and environmental influences such as temperature drift. Calibration is
the process of comparing an instrument's readings against a known
reference standard and adjusting or documenting the corrections needed
to minimize systematic error. Traceability ensures that calibrations are
linked through an unbroken chain of comparisons to national or
international measurement standards (such as those maintained by NIST or
PTB). Regular calibration intervals and proper documentation are
essential for maintaining measurement confidence and meeting quality
standards such as ISO 17025.

\begin{examplebox}

\textbf{Example 11.1.2:} A voltmeter is calibrated against a precision
reference standard at five points. The reference values and meter
readings are: 1.000 V reads 1.003 V, 2.000 V reads 2.005 V, 3.000 V
reads 3.008 V, 4.000 V reads 4.010 V, 5.000 V reads 5.013 V. Determine
the gain error and offset error assuming a linear error model.

\textbf{Solution:}\\
Using a linear error model: V\textsubscript{reading} = G ×
V\textsubscript{true} + V\textsubscript{offset}, where G is the gain and
V\textsubscript{offset} is the offset.\\
Using the first and last calibration points: G = (5.013 - 1.003) /
(5.000 - 1.000) = 4.010 / 4.000 = 1.00250.\\
V\textsubscript{offset} = V\textsubscript{reading} - G ×
V\textsubscript{true} = 1.003 - 1.00250 × 1.000 = 1.003 - 1.00250 = 0.50
mV.\\
Gain error = (G - 1) × 100\% = 0.250\%.\\
Verification at 3.000 V: predicted reading = 1.00250 × 3.000 + 0.00050 =
3.0080 V, actual reading = 3.008 V -- confirming the linear model.\\
Corrected measurement: V\textsubscript{true} = (V\textsubscript{reading}
- 0.00050) / 1.00250.

\end{examplebox}

\subsection{11.1.3 Signal-to-Noise Ratio}\label{signal-to-noise-ratio}

The Signal-to-Noise Ratio (SNR) quantifies the strength of the desired
signal relative to the background noise, expressed in decibels: SNR(dB)
= 20log₁₀(V\textsubscript{signal}/V\textsubscript{noise}) for voltage
measurements, or equivalently
10log₁₀(P\textsubscript{signal}/P\textsubscript{noise}) for power. A
higher SNR indicates a cleaner measurement with less noise corruption.
Common noise sources in measurement systems include thermal noise
(Johnson-Nyquist noise, proportional to √(4kTRΔf)), flicker noise (1/f
noise, dominant at low frequencies), quantization noise (inherent in
analog-to-digital conversion), and electromagnetic interference (EMI)
from external sources. Techniques for improving SNR include shielding
and grounding, differential measurements to reject common-mode noise,
filtering to limit bandwidth to the frequency range of interest, signal
averaging to reduce random noise by √N (where N is the number of
averages), and lock-in amplification to extract signals buried deep in
noise.

\begin{examplebox}

\textbf{Example 11.1.3:} A thermocouple signal of 5
mV\textsubscript{rms} is measured through a sensor with 50 kΩ source
resistance at 25°C using an amplifier with 100 kHz bandwidth. Calculate
the thermal noise voltage and the SNR. How many signal averages are
needed to achieve 60 dB SNR?

\textbf{Solution:}\\
Thermal noise voltage: V\textsubscript{n} = √(4kTRΔf) = √(4 × 1.381 ×
10⁻²³ × 298 × 50,000 × 100,000) = √(4 × 1.381 × 10⁻²³ × 1.49 × 10¹²) =
√(82.3 × 10⁻¹²) = 9.07 μV\textsubscript{rms}.\\
SNR = 20log₁₀(V\textsubscript{signal} / V\textsubscript{noise}) =
20log₁₀(5 × 10⁻³ / 9.07 × 10⁻⁶) = 20log₁₀(551.3) = 20 × 2.741 = 54.8
dB.\\
To achieve 60 dB: improvement needed = 60 - 54.8 = 5.2 dB, corresponding
to a voltage ratio improvement of 10\^{}(5.2/20) = 1.82×.\\
Since averaging improves SNR by √N: √N = 1.82, so N = 3.3 -- round up to
N = 4 averages.

\end{examplebox}

\subsection{11.1.4 Measurement
Uncertainty}\label{measurement-uncertainty}

Measurement uncertainty quantifies the range of values within which the
true value of a measurand is expected to lie, following the
internationally accepted framework defined by the Guide to the
Expression of Uncertainty in Measurement (GUM, ISO/IEC 98-3).
\textbf{Type A uncertainty} is evaluated by statistical methods ---
repeated measurements yield a mean and standard deviation, and the
standard uncertainty is u\textsubscript{A} = s/√N, where s is the sample
standard deviation and N is the number of observations. \textbf{Type B
uncertainty} is evaluated by non-statistical methods --- manufacturer
specifications, calibration certificates, environmental estimates, and
engineering judgment --- and is converted to a standard uncertainty by
dividing the stated tolerance by an appropriate coverage factor (e.g.,
÷√3 for a rectangular distribution, ÷2 for a normal distribution at
95\%). The \textbf{combined standard uncertainty} u\textsubscript{c} is
calculated by the root-sum-of-squares (RSS) of all individual
uncertainty components: u\textsubscript{c} = √(u₁² + u₂² + \ldots{} +
u\textsubscript{n}²), assuming uncorrelated inputs. The \textbf{expanded
uncertainty} U = k × u\textsubscript{c} applies a coverage factor k
(typically k = 2 for 95\% confidence or k = 3 for 99.7\%) to define the
interval within which the measurand lies with the stated probability.
Proper uncertainty analysis is required for ISO 17025 accredited
laboratories and is essential for determining measurement capability,
pass/fail conformance decisions (guard banding), and calibration
hierarchy.

\begin{examplebox}

\textbf{Example 11.1.4:} A calibrated thermometer measures 85.3°C. The
uncertainty budget includes: (1) repeatability from 6 measurements with
standard deviation s = 0.12°C, (2) calibration certificate uncertainty
of ±0.15°C at k = 2, (3) resolution of 0.1°C (digital display), and (4)
drift since last calibration estimated as ±0.08°C (rectangular
distribution). Calculate the combined standard uncertainty and the
expanded uncertainty at 95\% confidence.

\textbf{Solution:}\\
Type A: u₁ = s/√N = 0.12/√6 = 0.049°C.\\
Type B components: calibration u₂ = 0.15/2 = 0.075°C (convert from k = 2
to standard uncertainty).\\
Resolution u₃ = 0.1/(2√3) = 0.029°C (half the resolution, rectangular
distribution).\\
Drift u₄ = 0.08/√3 = 0.046°C (rectangular distribution).\\
Combined standard uncertainty: u\textsubscript{c} = √(0.049² + 0.075² +
0.029² + 0.046²) = √(0.00240 + 0.00563 + 0.00084 + 0.00212) = √(0.01099)
= 0.105°C.\\
Expanded uncertainty at 95\% (k = 2): U = 2 × 0.105 = 0.21°C.\\
The measurement result is reported as 85.3 ± 0.2°C (k = 2, 95\%
confidence).\\
The calibration certificate is the dominant uncertainty contributor
(51\% of variance), suggesting that upgrading to a lower-uncertainty
reference standard would most effectively improve the overall
measurement.

\end{examplebox}

\subsection{11.1.5 Measurement Bridges}\label{measurement-bridges}

A measurement bridge is a circuit that determines an unknown impedance
by balancing it against known reference impedances, achieving
extraordinary accuracy because the measurement is based on a null (zero)
condition rather than on absolute voltage or current readings. The
\textbf{Wheatstone bridge} is the most fundamental form: four resistors
arranged in a diamond with a voltage source across one diagonal and a
null detector (galvanometer) across the other. At balance,
R\textsubscript{unknown} = R₂ × R₃ / R₁, and the detector reads zero
regardless of source voltage variations --- a key advantage over direct
measurement. The \textbf{Kelvin double bridge} extends the Wheatstone
principle to measure very low resistances (micro-ohms to milli-ohms) by
adding a second set of ratio arms that eliminates errors from lead and
contact resistance, essential for measuring shunt resistors, busbar
connections, and superconductor joints. For AC impedance measurement,
the \textbf{Wien bridge} measures capacitance and dissipation factor by
balancing a capacitive arm against resistive references at a specific
frequency, while the \textbf{Maxwell bridge} (also called the
Maxwell-Wien bridge) measures inductance and Q factor by balancing an
inductive arm against a capacitive reference --- avoiding the need for a
standard inductor, which is difficult to construct with known parasitic
resistance. The \textbf{Schering bridge} is optimized for measuring
capacitance and dielectric loss in high-voltage insulation systems, and
is the standard method for assessing transformer, cable, and bushing
insulation condition. Modern bridge instruments automate the balancing
process digitally, but the underlying null-balance principle remains the
foundation of precision impedance measurement.

\begin{examplebox}

\textbf{Example 11.1.5:} A Wheatstone bridge is used to measure an
unknown resistance. The bridge has R₁ = 1,000 Ω, R₂ = 10,000 Ω (decade
box), and the standard arm R₃ is adjusted to 4,728 Ω for a null reading
on the galvanometer. Calculate R\textsubscript{unknown}. If the detector
sensitivity is 5 μA/mV of bridge imbalance and the minimum detectable
current is 0.1 μA with a 10 V excitation, estimate the measurement
resolution.

\textbf{Solution:}\\
At balance: R\textsubscript{x} = R₂ × R₃ / R₁ = 10,000 × 4,728 / 1,000 =
47,280 Ω = 47.28 kΩ.\\
The ratio R₂/R₁ = 10,000/1,000 = 10 is the bridge multiplier, extending
the range of the decade box by 10×.\\
For resolution, the minimum detectable imbalance voltage:
V\textsubscript{min} = I\textsubscript{min} / sensitivity = 0.1 μA / 5
μA/mV = 0.02 mV.\\
Near balance the sensitivity is dV/dR\textsubscript{x} =
V\textsubscript{ex} × R₃ / (R₃ + R\textsubscript{x})², the exact bridge
sensitivity at the operating point.\\
With R₃ = 4,728 Ω and R\textsubscript{x} = 47,280 Ω:
dV/dR\textsubscript{x} = 10 × 4,728 / (52,008)² = 47,280 / (2.705 × 10⁹)
= 0.01748 mV/Ω.\\
Minimum detectable resistance change: ΔR = V\textsubscript{min} /
(dV/dR\textsubscript{x}) = 0.02 / 0.01748 = 1.14 Ω.\\
Resolution as a fraction of R\textsubscript{x}: 1.14 / 47,280 = 24.1 ppm
--- demonstrating the exceptional precision achievable with null-balance
measurements.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-11-1-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch11_wheatstone_bridge.png}

\caption{Figure 11.1.5: Wheatstone Bridge Response}

\end{figure}

\subsection{11.1.6 Grounding and Shielding in Measurement
Systems}\label{grounding-and-shielding-in-measurement-systems}

Grounding and shielding are the primary defenses against noise,
interference, and ground-loop errors in precision measurement systems. A
ground loop forms whenever two or more points in a measurement circuit
are connected to ground at different physical locations, and a potential
difference exists between those ground points --- even millivolts of
ground potential difference can overwhelm microvolt-level sensor
signals. Proper grounding topology, cable shielding, and isolation
techniques are essential for achieving the full accuracy of any
instrumentation system, particularly when measuring low-level signals
from thermocouples, strain gauges, and biomedical electrodes in
electrically noisy industrial or laboratory environments.

\textbf{Single-point grounding} connects all circuit returns to one
common ground point (a star topology), eliminating ground loops by
ensuring no current flows between ground connections. This approach
works well at low frequencies (DC to \textasciitilde1 MHz) where cable
lengths are short relative to the wavelength. \textbf{Multi-point
grounding} connects each subsystem to the nearest low-impedance ground
plane and is necessary at high frequencies (\textgreater1 MHz) where
lead inductance in long single-point ground wires creates significant
impedance --- RF and high-speed digital systems universally use
multi-point grounding to a solid ground plane. \textbf{Hybrid grounding}
uses single-point topology at low frequencies and transitions to
multi-point at high frequencies via capacitors that bypass the
single-point connection above a crossover frequency.

\textbf{Cable shielding} intercepts electromagnetic interference before
it couples into signal conductors. Braided copper shields provide
70--95\% optical coverage and excellent low-frequency magnetic shielding
due to their low DC resistance, while aluminum foil shields provide
100\% coverage against electric fields but higher resistance that limits
low-frequency performance --- many high-quality cables combine both
(foil + braid). The shield must be grounded, and the grounding method is
critical: grounding the shield at one end only (the instrument end)
prevents shield current from flowing and is preferred for low-frequency
measurements, while grounding at both ends provides better
high-frequency shielding but allows ground-loop currents to flow through
the shield. A \textbf{drain wire} in foil-shielded cables provides a
convenient low-resistance termination point for the foil shield.
\textbf{Driven shields} (guard shields) use an amplifier to actively
drive the cable shield to the same potential as the signal conductor,
eliminating the cable capacitance effect (since there is no voltage
across it) and dramatically improving the common-mode rejection ratio at
high source impedances --- this technique is standard in
electrometer-grade instruments measuring picoampere currents through
gigaohm source impedances.

Common-mode rejection (CMR) is the ability of a differential measurement
system to reject voltages that appear equally on both input leads
relative to ground. An instrumentation amplifier with 100 dB CMRR can
reject 100,000:1, but imbalances in source impedance, cable capacitance,
or shield connections degrade the effective CMRR. \textbf{Isolation} ---
using transformer-coupled, optically-coupled, or capacitively-coupled
amplifiers --- provides the ultimate ground-loop solution by completely
breaking the galvanic path between the sensor and the measurement
system, achieving isolation-mode rejection ratios of 140--160 dB at DC
and common-mode voltage ratings of 1,000--5,000 V\textsubscript{rms}.

\begin{examplebox}

\textbf{Example 11.1.6:} A thermocouple (source impedance
Z\textsubscript{s} = 50 Ω) is connected to a data acquisition system 30
m away. The ground potential difference between the sensor location and
the DAQ system is V\textsubscript{gnd} = 2.5 V at 60 Hz. The shielded
cable has a shield resistance of R\textsubscript{shield} = 0.15 Ω and
the shield is grounded at both ends. The DAQ input has CMRR = 90 dB.
Calculate the ground-loop current through the shield, the error voltage
induced in the signal conductors, and the total measurement error on a 5
mV thermocouple signal. Then determine the error if the shield is
grounded at one end only.

\textbf{Solution:}\\
Ground-loop current through shield (grounded at both ends):
I\textsubscript{loop} = V\textsubscript{gnd} / R\textsubscript{shield} =
2.5 / 0.15 = 16.7 A.\\
This large current flowing through the shield generates a magnetic field
that couples into the signal conductors. The mutual inductance coupling
with a typical twisted-pair cable inside the shield induces
approximately V\textsubscript{induced} ≈ M × dI/dt. For a 60 Hz
sinusoidal current, dI/dt = 2π × 60 × 16.7 = 6,283 A/s. With typical
mutual coupling of M ≈ 0.1 μH/m over 30 m: V\textsubscript{induced} =
0.1 × 10⁻⁶ × 30 × 6,283 = 18.8 mV.\\
Additionally, the CMRR-limited error from the 2.5 V common-mode voltage:
V\textsubscript{cm\_error} = V\textsubscript{gnd} /
10\textsuperscript{CMRR/20} = 2.5 / 10\textsuperscript{90/20} = 2.5 /
31,623 = 79 μV.\\
Total error voltage: 18.8 mV + 0.079 mV ≈ 18.9 mV --- nearly 4× the 5 mV
thermocouple signal, rendering the measurement useless.\\
With shield grounded at one end only: no shield current flows
(I\textsubscript{loop} = 0), so no magnetically induced error. The
common-mode voltage still appears on both signal leads, but the
differential error is limited to the CMRR contribution:
V\textsubscript{error} = 79 μV, which is 79/5000 × 100 = 1.6\% of the
signal --- much improved.\\
Using a fully isolated input (160 dB IMRR) would reduce the error to 2.5
/ 10⁸ = 25 nV, achieving 0.0005\% error.

\end{examplebox}

\section{11.2 Sensors and Transducers}\label{sensors-and-transducers}

Sensors and transducers are the front end of any measurement system,
converting physical quantities --- temperature, strain, pressure,
position, acceleration, magnetic field, and current --- into electrical
signals that can be conditioned, digitized, and analyzed. A sensor
detects the physical phenomenon, while a transducer converts it into a
proportional electrical output (voltage, current, resistance change, or
charge). The selection of a sensor involves trade-offs among
sensitivity, range, linearity, bandwidth, environmental ruggedness, and
cost, and the sensor's characteristics directly determine the achievable
accuracy and resolution of the overall measurement system.

\subsection{11.2.1 Temperature Sensors}\label{temperature-sensors}

Temperature is one of the most commonly measured physical quantities in
engineering. Thermocouples generate a voltage proportional to the
temperature difference between two junctions of dissimilar metals
(Seebeck effect), covering wide temperature ranges (-200°C to +2300°C
depending on type) with types K, J, T, and E being the most common.
Resistance Temperature Detectors (RTDs) use the predictable change in
resistance of a pure metal (typically platinum, Pt100 or Pt1000) with
temperature, offering high accuracy (±0.1°C) and excellent long-term
stability. Thermistors are ceramic semiconductor devices with a large
negative (NTC) or positive (PTC) temperature coefficient of resistance,
providing high sensitivity over a narrow range. Integrated circuit
temperature sensors (such as the LM35 and TMP36) provide a linear
voltage output proportional to temperature with built-in signal
conditioning, simplifying interfacing with microcontrollers.

\begin{examplebox}

\textbf{Example 11.2.1:} A Pt100 RTD (R₀ = 100 Ω at 0°C, α = 0.00385
Ω/Ω/°C) is used to measure furnace temperature. The measured resistance
is 247.1 Ω. Using the linear approximation R(T) = R₀(1 + αT), calculate
the temperature. A Type K thermocouple at the same location reads 10.57
mV (reference junction at 0°C). Using the approximate sensitivity of 41
μV/°C, what temperature does the thermocouple indicate?

\textbf{Solution:}\\
For the Pt100: R(T) = R₀(1 + αT), so 247.1 = 100(1 + 0.00385T).\\
2.471 = 1 + 0.00385T.\\
T = 1.471 / 0.00385 = 382.1°C.\\
For the Type K thermocouple: T = V / sensitivity = 10.57 × 10⁻³ / 41 ×
10⁻⁶ = 257.8°C.\\
The significant discrepancy (382°C vs.~258°C) suggests the linear
thermocouple approximation is too crude at this temperature; using the
Type K thermocouple tables, 10.57 mV actually corresponds to
approximately 260°C.\\
This illustrates why RTDs provide superior accuracy and why thermocouple
linearization tables or polynomial corrections are essential for precise
measurements.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-11-2-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch11_thermocouple.png}

\caption{Figure 11.2.1: Thermocouple Voltage vs Temperature}

\end{figure}

\subsection{11.2.2 Strain and Force
Sensors}\label{strain-and-force-sensors}

Strain gauges measure mechanical deformation by detecting the change in
electrical resistance of a conductor or semiconductor element bonded to
the surface under test. A metallic foil strain gauge has a gauge factor
(ratio of fractional resistance change to strain) of approximately 2,
while semiconductor strain gauges achieve gauge factors of 100-200 for
much greater sensitivity. The Wheatstone bridge is the standard circuit
for measuring strain gauge resistance changes, with quarter-bridge,
half-bridge, and full-bridge configurations offering increasing
sensitivity and temperature compensation. Load cells are force
transducers constructed from strain gauges bonded to a precisely
machined elastic element (bending beam, shear beam, or compression
column), calibrated to produce an output voltage proportional to the
applied force or weight. Piezoelectric sensors generate an electric
charge proportional to applied mechanical stress and are used for
measuring dynamic forces, pressure, and acceleration.

\begin{examplebox}

\textbf{Example 11.2.2:} A 350 Ω metallic foil strain gauge with a gauge
factor GF = 2.1 is bonded to a steel beam (Young's modulus E = 200 GPa).
It is connected in a quarter-bridge Wheatstone configuration with an
excitation voltage of V\textsubscript{ex} = 5 V. Under load, the bridge
output voltage is measured as V\textsubscript{out} = 1.8 mV. Calculate
the strain and the stress in the beam.

\textbf{Solution:}\\
For a quarter-bridge Wheatstone configuration: V\textsubscript{out} =
(GF × ε / 4) × V\textsubscript{ex}, where ε is the strain.\\
Solving for strain: ε = 4 × V\textsubscript{out} / (GF ×
V\textsubscript{ex}) = 4 × 1.8 × 10⁻³ / (2.1 × 5) = 7.2 × 10⁻³ / 10.5 =
685.7 × 10⁻⁶ = 685.7 με.\\
Stress: σ = E × ε = 200 × 10⁹ × 685.7 × 10⁻⁶ = 137.1 × 10⁶ Pa = 137.1
MPa.\\
Resistance change in the gauge: ΔR = GF × ε × R = 2.1 × 685.7 × 10⁻⁶ ×
350 = 0.504 Ω (a change of only 0.144\%).

\end{examplebox}

\subsection{11.2.3 Pressure Sensors}\label{pressure-sensors}

Pressure sensors convert fluid or gas pressure into an electrical signal
using various transduction mechanisms. Piezoresistive pressure sensors
use a silicon diaphragm with implanted or diffused strain gauges that
change resistance under pressure-induced deformation, offering good
linearity and compatibility with MEMS fabrication. Capacitive pressure
sensors detect the change in capacitance as pressure deflects a
diaphragm relative to a fixed electrode, providing high sensitivity and
low power consumption. Pressure ranges span from sub-pascal
(micromanometers) to hundreds of megapascals (industrial hydraulic
systems), with gauge pressure (referenced to atmosphere), absolute
pressure (referenced to vacuum), and differential pressure (between two
ports) configurations. MEMS pressure sensors have enabled miniaturized,
low-cost devices found in automotive tire pressure monitors, altimeters,
weather stations, and medical ventilators.

\begin{examplebox}

\textbf{Example 11.2.3:} A capacitive pressure sensor has a circular
diaphragm of diameter 2 mm and a gap of 5 μm at zero pressure. The
dielectric is air (ε\textsubscript{r} = 1). Calculate the zero-pressure
capacitance and the capacitance at a pressure that deflects the
diaphragm center by 1 μm (assume parallel-plate approximation with the
average gap).

\textbf{Solution:}\\
Plate area: A = π × (d/2)² = π × (1 × 10⁻³)² = 3.1416 × 10⁻⁶ m².\\
Zero-pressure capacitance: C₀ = ε₀ × A / g₀ = 8.854 × 10⁻¹² × 3.1416 ×
10⁻⁶ / 5 × 10⁻⁶ = 27.82 × 10⁻¹⁸ / 5 × 10⁻⁶ = 5.56 pF.\\
For a uniform diaphragm, the average deflection is approximately 1/3 of
the center deflection for clamped circular plates, so the average gap
reduction is about 1/3 × 1 μm = 0.333 μm.\\
New average gap: g = 5.0 - 0.333 = 4.667 μm.\\
New capacitance: C = ε₀A / g = 8.854 × 10⁻¹² × 3.1416 × 10⁻⁶ / 4.667 ×
10⁻⁶ = 5.96 pF.\\
Capacitance change: ΔC = 5.96 - 5.56 = 0.40 pF (7.2\% change), which is
readily detectable with a capacitance-to-digital converter IC.

\end{examplebox}

\subsection{11.2.4 Proximity and Position
Sensors}\label{proximity-and-position-sensors}

Proximity sensors detect the presence or distance of an object without
physical contact. Inductive proximity sensors detect metallic objects by
sensing changes in an oscillating electromagnetic field, with typical
ranges of 1-50 mm. Capacitive proximity sensors detect changes in
capacitance caused by nearby objects (metallic or non-metallic), making
them suitable for level sensing in tanks and detecting materials through
non-metallic barriers. Optical proximity sensors (photoelectric sensors)
use emitted and reflected light beams with through-beam,
retro-reflective, and diffuse-reflective configurations for detection
ranges from millimeters to tens of meters. Linear Variable Differential
Transformers (LVDTs) measure linear displacement with high accuracy
(±0.1\% of full range) using a movable ferromagnetic core within a
transformer, providing virtually infinite resolution since the output is
a continuous analog signal. Rotary encoders measure angular position
using optical or magnetic sensing, available as incremental (producing
pulses per revolution) or absolute (providing a unique digital code for
each angular position) types.

\begin{examplebox}

\textbf{Example 11.2.4:} An LVDT has a sensitivity of 25 mV/mm with an
excitation of 3 V\textsubscript{rms} at 5 kHz. The LVDT has a linear
range of ±10 mm. If the signal conditioning electronics have a noise
floor of 0.5 mV\textsubscript{rms}, what is the maximum measurable
displacement, the resolution limited by noise, and the position accuracy
if the LVDT nonlinearity is ±0.1\% of full range?

\textbf{Solution:}\\
Maximum displacement: ±10 mm (linear range).\\
Maximum output voltage: V\textsubscript{max} = 25 mV/mm × 10 mm = 250
mV.\\
Resolution (limited by noise floor): Δx = V\textsubscript{noise} /
sensitivity = 0.5 mV / 25 mV/mm = 0.020 mm = 20 μm.\\
Nonlinearity error: ±0.1\% of full range = ±0.001 × 10 mm = ±0.010 mm =
±10 μm.\\
Total position accuracy (RSS of noise-limited resolution and
nonlinearity): ±√(20² + 10²) = ±√(400 + 100) = ±√500 = ±22.4 μm.\\
Dynamic range: 20 mm / 0.020 mm = 1000:1, or 20log₁₀(1000) = 60 dB.

\end{examplebox}

\subsection{11.2.5 Accelerometers and
Gyroscopes}\label{accelerometers-and-gyroscopes}

Accelerometers measure acceleration (change in velocity) along one or
more axes, while gyroscopes measure angular velocity (rate of rotation).
\textbf{MEMS accelerometers} use a micromachined proof mass suspended by
spring-like flexures; acceleration displaces the proof mass relative to
the substrate, and the displacement is detected capacitively or
piezoresistively. Typical specifications include measurement range (±2 g
to ±200 g), sensitivity (mV/g or LSB/g for digital output), noise
density (μg/√Hz), and bandwidth (DC to several kHz). \textbf{MEMS
gyroscopes} use a vibrating structure (tuning fork or ring) and detect
the Coriolis force that acts on the vibrating mass when rotated,
producing a signal proportional to angular velocity. Inertial
Measurement Units (IMUs) combine 3-axis accelerometers and 3-axis
gyroscopes (6-DOF) --- often with a 3-axis magnetometer (9-DOF) --- in a
single package for motion tracking, navigation, and stabilization.
Applications include smartphone orientation, drone flight control,
automotive stability systems (ESC), seismic monitoring, and industrial
vibration analysis.

\begin{examplebox}

\textbf{Example 11.2.5:} A MEMS accelerometer has a sensitivity of 1000
LSB/g, a 16-bit ADC output, a noise density of 100 μg/√Hz, and a
measurement bandwidth of 500 Hz. Calculate the noise floor in
mg\textsubscript{rms} and the dynamic range.

\textbf{Solution:}\\
Total noise: a\textsubscript{noise} = noise density × √BW = 100 × 10⁻⁶ ×
√500 = 100 × 10⁻⁶ × 22.36 = 2.236 × 10⁻³ g = 2.24
mg\textsubscript{rms}.\\
Full-scale range for a ±16 g device (using 16-bit output): 32 g.\\
Dynamic range: DR = 20 × log₁₀(full-scale / noise) = 20 × log₁₀(32 /
2.24 × 10⁻³) = 20 × log₁₀(14,286) = 20 × 4.155 = 83.1 dB.\\
The noise floor of 2.24 mg means the sensor can resolve accelerations as
small as \textasciitilde7 mg (3σ) with 99.7\% confidence, sufficient for
tilt sensing (where 1° of tilt produces \textasciitilde17.5 mg) but not
for seismology (which requires μg-level resolution with sub-Hz
bandwidth).

\end{examplebox}

\subsection{11.2.6 Magnetic Field Sensors}\label{magnetic-field-sensors}

Magnetic field sensors detect the presence, strength, and direction of
magnetic fields. \textbf{Hall effect sensors} are the most widely used
type, producing a voltage proportional to the magnetic flux density
perpendicular to the current-carrying semiconductor element:
V\textsubscript{H} = K\textsubscript{H} × I × B, where
K\textsubscript{H} is the Hall coefficient. Linear Hall sensors provide
an analog output proportional to field strength (typical sensitivity
1--5 mV/mT), while Hall switches provide a digital output that changes
state when the field exceeds a threshold --- widely used for position
sensing, current measurement, and brushless motor commutation.
\textbf{Magnetoresistive sensors} (AMR, GMR, TMR) exploit the change in
electrical resistance caused by an external magnetic field, offering
higher sensitivity than Hall sensors (nT range for TMR) and are used in
compasses, biomedical detection, and hard disk read heads.
\textbf{Fluxgate magnetometers} measure DC and low-frequency magnetic
fields with very high sensitivity (sub-nT) by detecting the asymmetric
saturation of a ferromagnetic core driven by an AC excitation, and are
used in geophysical surveys, spacecraft attitude determination, and
military applications.

\begin{examplebox}

\textbf{Example 11.2.6:} A linear Hall effect sensor with sensitivity of
2.5 mV/mT and a quiescent output of 2.5 V (at B = 0) is used to measure
the magnetic field from a permanent magnet. The sensor output reads
3.125 V. Calculate the magnetic field and determine the sensor's
suitability for measuring Earth's magnetic field (\textasciitilde50 μT).

\textbf{Solution:}\\
Voltage change from quiescent: ΔV = 3.125 - 2.5 = 0.625 V.\\
Magnetic field: B = ΔV / sensitivity = 0.625 / (2.5 × 10⁻³) = 250 mT =
0.25 T.\\
This is a strong field typical of proximity to a permanent magnet.\\
For Earth's field (50 μT = 0.05 mT): the expected output would be ΔV =
2.5 × 10⁻³ × 0.05 = 0.125 mV --- far below the sensor's typical noise
and offset voltage (several mV).\\
A Hall sensor is not suitable for measuring Earth's field; a
magnetoresistive (AMR/TMR) sensor with nT sensitivity or a fluxgate
magnetometer would be required.

\end{examplebox}

\subsection{11.2.7 Current Sensors}\label{current-sensors}

Current sensors measure electric current without breaking the circuit
(non-invasive) or with minimal insertion loss. \textbf{Current
transformers} (CTs) use electromagnetic coupling to measure AC current:
the primary is the conductor carrying the current to be measured, and
the secondary winding produces a scaled-down current proportional to the
turns ratio (e.g., a 100:5 CT transforms 100 A primary into 5 A
secondary). CTs are passive, isolated, and used extensively in power
metering and protective relaying. \textbf{Hall effect current sensors}
place a Hall element in the gap of a magnetic core surrounding the
conductor, measuring both AC and DC current with typical accuracy of
1--3\%. Closed-loop (null-balance) Hall sensors use a feedback winding
to cancel the core flux, achieving accuracy of 0.1--0.5\% with bandwidth
from DC to 100+ kHz. \textbf{Rogowski coils} are flexible, air-core
coils wrapped around a conductor that output a voltage proportional to
di/dt; the signal is integrated to recover the current waveform.
Rogowski coils are lightweight, have no magnetic saturation (linear over
enormous current ranges), and are ideal for measuring large transient
currents and fault currents. \textbf{Shunt resistors} are the simplest
current sensors --- a precision low-value resistor inserted in the
circuit produces a voltage proportional to current (V = IR), but they
lack isolation and introduce insertion loss.

\begin{examplebox}

\textbf{Example 11.2.7:} A closed-loop Hall effect current sensor with a
rated primary current of 50 A, an output sensitivity of 40 mV/A, and
accuracy of ±0.5\% is used to monitor a motor drive. The sensor output
reads 1.280 V. Calculate the measured current and the measurement
uncertainty. Compare the insertion loss to a 10 mΩ shunt resistor at the
same current.

\textbf{Solution:}\\
Measured current: I = V\textsubscript{out} / sensitivity = 1.280 / 0.040
= 32.0 A.\\
Measurement uncertainty: ±0.5\% × 32.0 = ±0.16 A, so the current is 32.0
± 0.16 A.\\
The Hall sensor has essentially zero insertion loss (the conductor
passes through the core aperture).\\
For a 10 mΩ shunt at 32.0 A: voltage drop = I × R = 32.0 × 0.010 = 0.32
V.\\
Power dissipation = I²R = 32.0² × 0.010 = 10.24 W.\\
The shunt dissipates over 10 W of heat and drops 0.32 V from the supply
--- significant in a power circuit.\\
The Hall sensor provides galvanic isolation with negligible insertion
loss, which is why it is preferred for high-current measurement.

\end{examplebox}

\subsection{11.2.8 Optical and Infrared
Sensors}\label{optical-and-infrared-sensors}

Optical sensors convert light intensity, wavelength, or modulation into
electrical signals, enabling non-contact measurement of temperature,
position, chemical composition, and physical phenomena.
\textbf{Pyrometers} (infrared thermometers) measure the thermal
radiation emitted by an object to determine its surface temperature
without contact, using the Stefan-Boltzmann law (total radiated power ∝
T⁴) or the Planck radiation law (spectral distribution). Single-color
pyrometers measure total IR intensity in a band (typically 8--14 μm for
low temperatures or 1--5 μm for high temperatures) and require known
emissivity, while two-color (ratio) pyrometers compare intensity at two
wavelengths to cancel the emissivity dependence --- essential for
measuring metals, molten glass, and surfaces with uncertain or varying
emissivity. Temperature ranges span from −50°C (long-wave IR) to over
3000°C (short-wave for steel mills and furnaces). \textbf{Fiber optic
sensors} use changes in the light propagating through an optical fiber
to measure strain, temperature, pressure, or acceleration. Fiber Bragg
Grating (FBG) sensors reflect a narrow wavelength band (Bragg wavelength
λ\textsubscript{B} = 2nΛ, where n is the effective index and Λ is the
grating period) that shifts with strain (\textasciitilde1.2 pm/με) and
temperature (\textasciitilde10 pm/°C), enabling multiplexing of dozens
of sensors along a single fiber. Distributed sensing techniques such as
Brillouin Optical Time-Domain Reflectometry (BOTDR) measure strain and
temperature continuously along the entire fiber length (up to 50 km)
with spatial resolution of 0.5--2 m, making them ideal for structural
health monitoring of bridges, pipelines, and dams. \textbf{Photoelectric
sensors} in industrial automation use emitter-receiver pairs
(through-beam, retro-reflective, or diffuse) with modulated LED or laser
sources, and \textbf{color sensors} detect reflected spectral signatures
for sorting and quality inspection.

\begin{examplebox}

\textbf{Example 11.2.8:} A ratio pyrometer measures thermal radiation
from a steel billet at two wavelengths: λ₁ = 0.9 μm and λ₂ = 1.6 μm. The
detected intensity ratio is I(λ₁)/I(λ₂) = 0.180. Using the Wien
approximation I(λ) ∝ ε λ⁻⁵ exp(−c₂/(λT)) where c₂ = 14,388 μm·K,
calculate the billet temperature. Show why the ratio method eliminates
the need to know emissivity.

\textbf{Solution:}\\
Taking the ratio: I(λ₁)/I(λ₂) = (ε₁/ε₂) × (λ₂/λ₁)⁵ × exp{[}−c₂/T × (1/λ₁
− 1/λ₂){]}.\\
For a gray body (ε₁ = ε₂), the emissivity cancels: 0.180 = (1.6/0.9)⁵ ×
exp{[}−14,388/T × (1/0.9 − 1/1.6){]}.\\
Compute (1.6/0.9)⁵ = (1.778)⁵ = 17.77.\\
Exponent factor: 1/0.9 − 1/1.6 = 1.111 − 0.625 = 0.4861 μm⁻¹.\\
So 0.180 = 17.77 × exp(−14,388 × 0.4861/T) = 17.77 × exp(−6994/T).\\
Solving: 0.180/17.77 = 0.01013 = exp(−6994/T).\\
ln(0.01013) = −4.593 = −6994/T.\\
T = 6994/4.593 = 1523 K = 1250°C --- a typical rolling mill temperature
for a steel billet.\\
The key advantage is that ε cancels in the ratio, so the measurement is
independent of surface oxidation, roughness, or viewing angle.

\end{examplebox}

\subsection{11.2.9 Flow Sensors}\label{flow-sensors}

Flow sensors measure the volumetric or mass flow rate of liquids and
gases in pipes, ducts, and open channels --- a critical measurement in
process control, HVAC, water treatment, oil and gas, and biomedical
applications. \textbf{Electromagnetic flow meters} (mag meters) apply
Faraday's law: a conductive fluid flowing through a magnetic field
generates a voltage V = B × D × v̄, where B is the magnetic flux density,
D is the pipe diameter, and v̄ is the average fluid velocity. Mag meters
have no moving parts, produce no pressure drop, handle slurries and
corrosive fluids, and are accurate to ±0.2--0.5\%, but require a minimum
fluid conductivity of \textasciitilde5 μS/cm, excluding hydrocarbons and
pure water. \textbf{Ultrasonic flow meters} use transit-time or Doppler
techniques. Transit-time meters measure the difference in propagation
time of ultrasonic pulses sent upstream and downstream through the
fluid: Δt = 2 × L × v̄ × cos θ / c², where L is the path length and θ is
the beam angle. They are non-invasive (clamp-on versions mount outside
the pipe), handle clean liquids, and achieve ±0.5--1\% accuracy.
\textbf{Coriolis flow meters} measure mass flow directly by vibrating a
U-shaped or straight tube at its resonant frequency; the Coriolis force
induced by mass flow through the vibrating tube causes a phase shift
between the inlet and outlet that is proportional to mass flow rate.
Coriolis meters are the most accurate flow technology (±0.1\% of
reading), simultaneously measure density and temperature, and are the
standard for custody transfer of hydrocarbons. \textbf{Vortex flow
meters} detect the frequency of vortices shed alternately from a bluff
body (shedder bar) placed in the flow stream; the shedding frequency f =
St × v̄ / d is proportional to velocity, where St is the Strouhal number
(\textasciitilde0.27) and d is the shedder width. \textbf{Differential
pressure} flow meters (orifice plates, Venturi tubes, flow nozzles)
infer velocity from the pressure drop across a constriction using
Bernoulli's principle: Q = C\textsubscript{d} × A₂ × √(2ΔP / ρ), where
C\textsubscript{d} is the discharge coefficient --- the oldest and still
most widely installed flow technology in industrial plants.

\begin{examplebox}

\textbf{Example 11.2.9:} An electromagnetic flow meter is installed on a
150 mm (6-inch) diameter pipe carrying water (conductivity 450 μS/cm).
The magnetic field is B = 0.05 T, and the measured electrode voltage is
2.35 mV. Calculate the average flow velocity and the volumetric flow
rate in m³/h. Then, for a separate higher-flow operating condition on
the same pipe, an orifice plate (β = d/D = 0.6, C\textsubscript{d} =
0.61) measures ΔP = 18.5 kPa --- calculate that flow rate to compare
sensor technologies.

\textbf{Solution:}\\
Mag meter (low-flow condition): v̄ = V / (B × D) = 2.35 × 10⁻³ / (0.05 ×
0.150) = 2.35 × 10⁻³ / 7.5 × 10⁻³ = 0.3133 m/s.\\
Pipe area: A = π/4 × (0.150)² = 0.01767 m².\\
Volumetric flow: Q = v̄ × A = 0.3133 × 0.01767 = 5.536 × 10⁻³ m³/s =
19.93 m³/h.\\
Orifice plate (high-flow condition, ΔP = 18.5 kPa): orifice area A₂ =
π/4 × (β × D)² = π/4 × (0.090)² = 6.362 × 10⁻³ m².\\
Q = C\textsubscript{d} × A₂ × √(2ΔP/ρ) = 0.61 × 6.362 × 10⁻³ × √(2 ×
18,500 / 1000) = 3.881 × 10⁻³ × √37.0 = 3.881 × 10⁻³ × 6.083 = 23.61 ×
10⁻³ m³/s = 85.0 m³/h.\\
The two sensors are operating at different flow conditions (19.93 vs
85.0 m³/h), illustrating the measurement range of each technology on the
same pipe geometry.\\
The mag meter's advantage is zero pressure drop and no moving parts; the
orifice plate permanently reduces pressure by approximately 60\% of the
measured ΔP (11.1 kPa), wasting pumping energy.

\end{examplebox}

\subsection{11.2.10 Chemical and Gas
Sensors}\label{chemical-and-gas-sensors}

Chemical and gas sensors detect the presence and concentration of
specific chemical species in air, water, or other media, enabling
environmental monitoring, industrial safety, process control, and
emissions compliance. These sensors face unique challenges compared to
physical sensors --- they must be selective to the target analyte amid a
complex mixture of background gases, they are subject to drift and
poisoning over their operational lifetime, and they often require
periodic calibration against known reference gases. The diversity of
chemical sensing mechanisms reflects the wide range of target species
and application requirements, from parts-per-billion detection of toxic
gases in semiconductor fabrication to percent-level oxygen monitoring in
confined spaces.

\textbf{Electrochemical sensors} use a chemical reaction at an
electrode-electrolyte interface to generate a current proportional to
the target gas concentration. A typical three-electrode cell consists of
a sensing (working) electrode, a counter electrode, and a reference
electrode separated by an electrolyte (often a liquid acid or polymer
gel). The target gas diffuses through a membrane to the sensing
electrode, where it is oxidized or reduced, producing a current in the
nanoampere to microampere range that is linearly proportional to
concentration over 3-4 decades of range. Electrochemical sensors are the
industry standard for toxic gas detection (CO, H₂S, NO₂, Cl₂, SO₂) in
portable safety monitors, offering good selectivity, low power
consumption, and moderate cost, with typical lifetimes of 2--3 years
before electrolyte depletion requires replacement.

\textbf{Metal oxide semiconductor (MOS) gas sensors} use a heated tin
dioxide (SnO₂) or tungsten trioxide (WO₃) sensing element whose
electrical conductance changes when target gas molecules adsorb on the
surface and react with pre-adsorbed oxygen ions. The sensor requires a
heater (typically 200--400°C) to activate the surface reactions,
consuming 100--800 mW --- a significant disadvantage for battery-powered
applications. MOS sensors offer very high sensitivity (sub-ppm for some
gases) and long operational life (5--10 years), but suffer from poor
selectivity (responding to a broad range of reducing gases) and
cross-sensitivity to humidity. Selectivity can be improved by using
arrays of sensors with different oxide compositions and operating
temperatures, combined with pattern recognition algorithms (electronic
nose).

\textbf{Nondispersive infrared (NDIR) sensors} exploit the
characteristic infrared absorption bands of gas molecules to measure
concentration. The sensor passes broadband IR radiation through a gas
sample cell and measures the attenuation at the target gas absorption
wavelength using a narrowband optical filter and a thermopile or
pyroelectric detector. A reference channel at a non-absorbing wavelength
compensates for source aging and optical contamination. NDIR sensors are
the gold standard for CO₂ measurement (absorption at 4.26 μm), and are
also used for CO (4.67 μm), CH₄ (3.31 μm), and hydrocarbons. They offer
excellent selectivity (each gas has a unique absorption fingerprint), no
consumable components, and operational lifetimes exceeding 10 years, but
are larger and more expensive than electrochemical or MOS sensors.

\textbf{Photoionization detectors (PIDs)} use a high-energy UV lamp
(typically 10.6 eV) to ionize gas molecules in a sample chamber,
generating a current between collection electrodes that is proportional
to the total concentration of ionizable volatile organic compounds
(VOCs). PIDs respond to a wide range of organic vapors (benzene,
toluene, xylene, solvents) with ppb-level sensitivity and fast response
(\textless3 seconds), making them essential for environmental site
assessment, industrial hygiene, and hazmat response. However, they
provide a total VOC reading rather than identifying individual
compounds. \textbf{Catalytic bead sensors} (pellistors) detect
combustible gases by measuring the heat released when gas oxidizes on a
catalyst-coated bead, with the resistance change of an embedded platinum
wire measured by a Wheatstone bridge; they are used for LEL (lower
explosive limit) monitoring of methane, propane, and hydrogen in oil and
gas, mining, and confined-space entry.

\textbf{Cross-sensitivity} is the response of a sensor to gases other
than the target analyte --- for example, an electrochemical CO sensor
may also respond to H₂S or NO₂, requiring correction factors or scrubber
filters. Calibration requires periodic exposure to a certified reference
gas (span gas) at a known concentration, typically every 6--12 months,
along with a zero-gas (purified air) check to verify baseline. Multi-gas
monitors combine several sensing technologies (electrochemical for toxic
gases, catalytic bead for combustibles, NDIR for CO₂, and galvanic cell
for O₂) in a single handheld instrument for confined-space entry
compliance with OSHA regulations.

\begin{examplebox}

\textbf{Example 11.2.10:} An electrochemical CO sensor has a sensitivity
of 55 nA/ppm with a linear range of 0--500 ppm. The sensor is calibrated
at 100 ppm CO (span gas) and produces an output of 5.38 μA. During field
use, the sensor output is 2.12 μA. The sensor has a known
cross-sensitivity to H₂ of 12\% (i.e., 100 ppm H₂ produces the same
response as 12 ppm CO). If the environment contains an estimated 50 ppm
H₂ background, calculate the indicated CO concentration, the H₂
interference, and the corrected CO concentration.

\textbf{Solution:}\\
Calibration check: at 100 ppm CO, expected output = 100 × 55 nA/ppm =
5,500 nA = 5.50 μA.\\
Actual calibration output: 5.38 μA. Calibration factor: CF = 5.50/5.38 =
1.022 (sensor reads 2.2\% low).\\
Indicated CO concentration from field reading:
CO\textsubscript{indicated} = I\textsubscript{field} / sensitivity =
2,120 nA / 55 nA/ppm = 38.5 ppm.\\
Apply calibration correction: CO\textsubscript{corrected} = 38.5 × 1.022
= 39.4 ppm.\\
H₂ cross-sensitivity interference: 50 ppm H₂ × 12\% = 6.0 ppm
CO-equivalent.\\
True CO concentration: CO\textsubscript{true} = 39.4 − 6.0 = 33.4 ppm.\\
The H₂ interference accounts for 15\% of the calibration-corrected CO
reading --- a significant error if uncorrected. In practice, multi-gas
instruments with both CO and H₂ sensors can apply automatic
cross-sensitivity compensation. The corrected reading of 33.4 ppm is
below the OSHA 8-hour TWA limit of 50 ppm, so the environment is within
permissible exposure limits for CO.

\end{examplebox}

\section{11.3 Signal Conditioning}\label{signal-conditioning}

Signal conditioning is the intermediate stage between the raw sensor
output and the data acquisition system, preparing the signal for
accurate digitization. Conditioning circuits amplify low-level sensor
signals to match the ADC input range, filter out noise and unwanted
frequency components, provide galvanic isolation for safety and
ground-loop rejection, and linearize nonlinear sensor outputs. Proper
signal conditioning is critical because errors introduced at this stage
--- offset drift, gain error, insufficient filtering, or inadequate
isolation --- propagate through the entire measurement chain and cannot
be corrected by downstream digital processing.

\subsection{11.3.1 Amplification}\label{amplification}

Signal conditioning amplifiers scale low-level sensor outputs to voltage
ranges suitable for data acquisition systems. Instrumentation amplifiers
are precision differential amplifiers with high common-mode rejection
ratio (CMRR, typically 80-120 dB), high input impedance (\textgreater10⁹
Ω), and adjustable gain set by a single external resistor, making them
ideal for amplifying small differential signals from bridges and
thermocouples in the presence of large common-mode voltages.
Programmable gain amplifiers (PGAs) allow the gain to be digitally
selected, enabling a single data acquisition channel to accommodate
sensors with different output ranges. Charge amplifiers convert the
charge output of piezoelectric sensors into a proportional voltage,
using a high-impedance feedback capacitor around an operational
amplifier. Key specifications include gain accuracy, gain drift with
temperature, bandwidth, input offset voltage, input bias current, and
noise spectral density.

\begin{examplebox}

\textbf{Example 11.3.1:} An instrumentation amplifier with a gain of G =
500 and CMRR = 100 dB amplifies a 2 mV thermocouple signal. The
thermocouple wires pick up a 60 Hz common-mode noise voltage of
V\textsubscript{cm} = 1.5 V. Calculate the desired output signal, the
common-mode error at the output, and the signal-to-error ratio.

\textbf{Solution:}\\
Desired output: V\textsubscript{out(signal)} = G × V\textsubscript{diff}
= 500 × 2 mV = 1.000 V.\\
CMRR = 100 dB = 10\^{}(100/20) = 100,000.\\
Common-mode rejection means the amplifier converts a fraction of
V\textsubscript{cm} to a differential error:
V\textsubscript{error(input)} = V\textsubscript{cm} / CMRR = 1.5 /
100,000 = 15 μV.\\
Error at the output: V\textsubscript{error(output)} = G ×
V\textsubscript{error(input)} = 500 × 15 μV = 7.5 mV.\\
Signal-to-error ratio: V\textsubscript{out(signal)} /
V\textsubscript{error(output)} = 1.000 / 0.0075 = 133.3, or
20log₁₀(133.3) = 42.5 dB.\\
The error is 0.75\% of the output signal -- acceptable for many
industrial measurements but may require additional 60 Hz notch filtering
for higher-precision applications.

\end{examplebox}

\subsection{11.3.2 Filtering}\label{filtering}

Analog filters in signal conditioning remove unwanted frequency
components before digitization. Anti-aliasing filters (lowpass) are
mandatory before an ADC to attenuate frequencies above the Nyquist
frequency (f\textsubscript{s}/2) and prevent aliasing distortion. Active
filters using operational amplifiers implement lowpass, highpass,
bandpass, and notch (band-reject) responses with standard topologies
including Sallen-Key, Multiple Feedback (MFB), and state-variable
configurations. The Butterworth response provides maximally flat
passband magnitude, the Chebyshev response allows passband ripple for a
steeper transition, and the Bessel response provides maximally flat
group delay (linear phase) for waveform preservation. Notch filters at
50/60 Hz are commonly used to reject power line interference in
low-frequency measurement systems.

\begin{examplebox}

\textbf{Example 11.3.2:} A data acquisition system samples a sensor
signal with a maximum frequency of interest of 500 Hz. Design a
second-order Butterworth anti-aliasing lowpass filter by specifying the
cutoff frequency if the ADC sample rate is 5 kS/s, and calculate the
attenuation at the Nyquist frequency.

\textbf{Solution:}\\
Nyquist frequency: f\textsubscript{N} = f\textsubscript{s} / 2 = 5000 /
2 = 2500 Hz.\\
The anti-aliasing filter must attenuate signals at and above
f\textsubscript{N} sufficiently (typically \textgreater{} 40 dB).\\
Set the filter cutoff frequency at f\textsubscript{c} = 1 kHz (providing
a flat passband well above 500 Hz with roll-off beginning before
Nyquist).\\
For a 2nd-order Butterworth filter, the roll-off is -40 dB/decade.\\
Frequency ratio at Nyquist: f\textsubscript{N} / f\textsubscript{c} =
2500 / 1000 = 2.5.\\
Butterworth magnitude response: \textbar H(f)\textbar{} = 1 / √(1 +
(f/f\textsubscript{c})²ⁿ) = 1 / √(1 + 2.5⁴) = 1 / √(1 + 39.06) = 1 /
√40.06 = 1 / 6.33 = 0.158.\\
Attenuation = 20log₁₀(0.158) = -16.0 dB.\\
This is insufficient; a 4th-order Butterworth would give: 1 / √(1 +
2.5⁸) = 1 / √(1 + 1526) = 1 / 39.1 = 0.0256, or -31.8 dB.\\
For \textgreater{} 40 dB, use a 6th-order filter or increase the
sampling rate.

\end{examplebox}

\subsection{11.3.3 Isolation}\label{isolation}

Signal isolation provides a galvanic barrier between the sensor or field
wiring and the measurement system, protecting equipment and personnel
from high voltages, breaking ground loops that cause measurement errors,
and preventing noise coupling between different parts of the system.
Optocouplers use an LED and photodetector across the isolation barrier
to transmit analog or digital signals, with isolation ratings typically
from 1.5 kV to 5 kV. Capacitive isolation and magnetic
(transformer-based) isolation are used in modern digital isolators and
isolated amplifiers, offering higher bandwidth and lower power
consumption than optocouplers. Isolated power supplies (using small
transformers or piezoelectric converters) provide the power needed on
the isolated side of the barrier. Isolation is essential in industrial
measurement systems, medical instrumentation (patient safety), and
high-voltage power system monitoring.

\begin{examplebox}

\textbf{Example 11.3.3:} A current sensor monitors a 480 V power bus.
The sensor output is 0-5 V and must be isolated before connecting to a
ground-referenced DAQ system. An isolated amplifier with 2500
V\textsubscript{rms} isolation rating, 0.05\% gain error, ±10 μV/°C
offset drift, and 100 kHz bandwidth is selected. If the operating
temperature varies by 50°C from calibration, calculate the total
measurement error on a 2.5 V signal.

\textbf{Solution:}\\
Gain error contribution: 0.05\% × 2.5 V = 1.25 mV.\\
Offset drift error: ±10 μV/°C × 50°C = ±500 μV = ±0.5 mV.\\
Total worst-case error: ±(1.25 + 0.5) = ±1.75 mV.\\
Percent of signal: ±1.75 / 2500 × 100 = ±0.070\%.\\
RSS error (assuming uncorrelated): ±√(1.25² + 0.5²) = ±√(1.5625 + 0.25)
= ±√1.8125 = ±1.35 mV, or ±0.054\% of the 2.5 V signal.\\
The isolation barrier provides safety against the 480 V bus while
maintaining measurement accuracy well within 0.1\%.

\end{examplebox}

\subsection{11.3.4 Linearization}\label{linearization}

Many sensors have inherently nonlinear transfer characteristics ---
thermocouples, thermistors, photodetectors, and pressure sensors all
produce outputs that are not strictly proportional to the measured
quantity over their full range. Linearization corrects these
nonlinearities to produce an output that accurately represents the
physical variable. \textbf{Analog linearization} uses hardware
techniques such as logarithmic amplifiers, diode networks, or feedback
configurations that shape the transfer function (e.g., a thermistor in
one arm of a Wheatstone bridge with appropriate resistor values can
partially linearize the response). \textbf{Lookup table linearization}
stores a table of sensor output vs.~true value pairs in firmware and
uses interpolation (linear or cubic spline) to convert each reading ---
this is the most common approach in microcontroller-based systems
because it handles arbitrary nonlinearities and is easily updated for
different sensor calibrations. \textbf{Polynomial linearization} fits a
polynomial equation to the sensor characteristic (e.g., the ITS-90
thermocouple reference functions use polynomials of order 8-14) and
computes the corrected value algebraically. The Steinhart-Hart equation
for thermistors, 1/T = A + B·ln(R) + C·(ln(R))³, is a widely used
three-parameter model that provides ±0.01°C accuracy over a 100°C span
with just three calibration points.

\begin{examplebox}

\textbf{Example 11.3.4:} An NTC thermistor has the following calibration
data: R₁ = 27,445 Ω at T₁ = 0°C (273.15 K), R₂ = 10,000 Ω at T₂ = 25°C
(298.15 K), R₃ = 4,160 Ω at T₃ = 50°C (323.15 K). Using the
Steinhart-Hart equation 1/T = A + B·ln(R) + C·(ln(R))³, determine the
coefficients and calculate the temperature when R = 6,530 Ω.

\textbf{Solution:}\\
Set up three equations using the calibration data.\\
ln(R₁) = ln(27,445) = 10.2199, ln(R₂) = ln(10,000) = 9.2103, ln(R₃) =
ln(4,160) = 8.3333.\\
The three simultaneous equations:\\
1/273.15 = A + 10.2199B + (10.2199)³C → 3.6610 × 10⁻³ = A + 10.2199B +
1067.4C.\\
1/298.15 = A + 9.2103B + (9.2103)³C → 3.3540 × 10⁻³ = A + 9.2103B +
781.3C.\\
1/323.15 = A + 8.3333B + (8.3333)³C → 3.0946 × 10⁻³ = A + 8.3333B +
578.7C.\\
Solving the system: A = 8.404 × 10⁻⁴, B = 2.596 × 10⁻⁴, C = 1.570 ×
10⁻⁷.\\
For R = 6,530 Ω: ln(6,530) = 8.7842.\\
1/T = 8.404 × 10⁻⁴ + 2.596 × 10⁻⁴ × 8.7842 + 1.570 × 10⁻⁷ × (8.7842)³ =
8.404 × 10⁻⁴ + 2.280 × 10⁻³ + 1.064 × 10⁻⁴ = 3.227 × 10⁻³.\\
T = 1 / 3.227 × 10⁻³ = 309.9 K = 36.7°C.\\
Without linearization (using a simple linear interpolation between 25°C
and 50°C): T ≈ 25 + 25 × (10,000 - 6,530) / (10,000 - 4,160) = 25 + 25 ×
0.594 = 39.9°C --- a 3.2°C error demonstrating the importance of proper
linearization.

\end{examplebox}

\subsection{11.3.5 Analog-to-Digital Converter
Selection}\label{analog-to-digital-converter-selection}

Selecting the right ADC architecture is critical for matching the
measurement system's requirements for resolution, speed, accuracy, and
power consumption. \textbf{Successive Approximation Register (SAR) ADCs}
use a binary search algorithm with a DAC and comparator, achieving
12--20 bit resolution at sample rates from 10 kS/s to 10+ MS/s with low
power consumption --- they are the dominant choice for multiplexed data
acquisition, sensor interfaces, and battery-powered instruments.
\textbf{Delta-Sigma (Σ-Δ) ADCs} use oversampling (typically 64× to 256×
the Nyquist rate) and noise shaping to push quantization noise out of
the band of interest, followed by a digital decimation filter, achieving
16--32 bit resolution but at lower effective sample rates (typically 10
S/s to 100 kS/s) --- ideal for precision DC and low-frequency
measurements such as weigh scales, temperature, and strain gauge
bridges. \textbf{Pipeline ADCs} use a cascaded chain of low-resolution
stages (1.5--3.5 bits each) with interstage residue amplification,
achieving 8--16 bit resolution at sample rates from 10 MS/s to 1+ GS/s
--- suited for oscilloscopes, communications receivers, and waveform
capture. Key selection parameters include effective number of bits (ENOB
= (SINAD − 1.76) / 6.02), integral nonlinearity (INL), differential
nonlinearity (DNL), input bandwidth, latency, and power dissipation per
conversion. Modern integrated Σ-Δ ADCs often include a programmable gain
amplifier, excitation current sources, and digital filter --- providing
a nearly complete signal conditioning front end in a single chip.

\begin{examplebox}

\textbf{Example 11.3.5:} A precision weigh scale requires 0.001\%
accuracy over a ±20 mV full-scale range from a strain gauge bridge, with
a measurement bandwidth of 10 Hz. Compare the minimum resolution
requirements and select the appropriate ADC architecture. The system
operates from a 3.3 V supply with a 500 μA power budget.

\textbf{Solution:}\\
Required resolution: 0.001\% of full scale = 0.001\% × 40 mV = 0.4 μV.\\
Number of bits: 2ᴺ = full-scale / resolution = 40 × 10⁻³ / 0.4 × 10⁻⁶ =
100,000.\\
N = log₂(100,000) = 16.6 bits minimum --- round up to 18 bits practical
(with noise margin).\\
Nyquist rate: 2 × 10 Hz = 20 S/s minimum.\\
A SAR ADC at 18 bits could work but would require an external low-noise
PGA and anti-aliasing filter, consuming significant board space and
power.\\
A 24-bit Σ-Δ ADC (e.g., with 128× oversampling at 2,560 S/s, decimated
to 20 S/s) provides: effective resolution at 10 Hz BW ≈ 20+ noise-free
bits, integrated PGA (gains of 1--128), built-in digital sinc filter
that rejects 50/60 Hz, and typical power consumption of 200--500 μA at
3.3 V.\\
A pipeline ADC is entirely inappropriate --- far too fast (minimum
\textasciitilde10 MS/s) and insufficient resolution (typically 12--14
bits).\\
\textbf{Selection: 24-bit Σ-Δ ADC} --- provides the required resolution,
built-in signal conditioning, excellent 50/60 Hz rejection, and power
consumption within the 500 μA budget.

\end{examplebox}

\section{11.4 Measurement Instruments}\label{measurement-instruments}

Measurement instruments are the tools engineers use to observe,
quantify, and analyze electrical signals and circuit behavior. The four
most common bench instruments --- the digital multimeter, oscilloscope,
spectrum analyzer, and function generator --- each provide a different
view of the signal: the DMM measures steady-state magnitude, the
oscilloscope shows the time-domain waveform, the spectrum analyzer
reveals the frequency-domain content, and the function generator
provides controlled stimulus signals. Modern instruments are
increasingly digital, offering deep memory, advanced triggering,
automated measurements, remote control via GPIB/USB/LAN, and
protocol-aware decoding for serial buses.

\subsection{11.4.1 Digital Multimeter
(DMM)}\label{digital-multimeter-dmm}

The digital multimeter is the most widely used general-purpose
measurement instrument, capable of measuring DC and AC voltage, DC and
AC current, and resistance, with many models adding capacitance,
frequency, temperature, and diode test functions. A DMM operates by
converting the quantity being measured into a DC voltage proportional to
its value, then digitizing it with an integrating ADC (typically
dual-slope or multi-slope) that provides high resolution and excellent
rejection of power line frequency interference. Resolution is specified
in digits (e.g., a 6½-digit DMM can display values from 0 to 1,999,999,
providing approximately 1 μV resolution on the 2 V range). Bench DMMs
offer higher accuracy (0.001-0.01\%), better resolution (6½ to 8½
digits), and more measurement functions than handheld models (typically
3½ to 4½ digits with 0.1-0.5\% accuracy). Input impedance is a critical
specification: 10 MΩ is standard for most DMMs, while high-impedance
(\textgreater10 GΩ) inputs are necessary for measuring high-impedance
circuits without loading errors.

\begin{examplebox}

\textbf{Example 11.4.1:} A 6½-digit DMM on the 10 V range (input
impedance 10 MΩ) is used to measure the open-circuit voltage of a sensor
with an output impedance of 100 kΩ. The true sensor voltage is 8.500 V.
Calculate the displayed reading and the loading error.

\textbf{Solution:}\\
The DMM input impedance forms a voltage divider with the sensor output
impedance.\\
Displayed voltage: V\textsubscript{measured} = V\textsubscript{true} ×
R\textsubscript{DMM} / (R\textsubscript{source} + R\textsubscript{DMM})
= 8.500 × 10,000,000 / (100,000 + 10,000,000) = 8.500 × 10⁷ / 10.1 × 10⁶
= 8.500 × 0.99010 = 8.4158 V.\\
Loading error: ΔV = 8.500 - 8.4158 = 0.0842 V.\\
Percent error: 0.0842 / 8.500 × 100 = 0.99\%.\\
This is significant for a precision instrument.\\
Resolution: 10 V / 1,999,999 counts = 5.0 μV per count, so the DMM
itself is far more accurate than the loading error.\\
Using a high-impedance (\textgreater10 GΩ) DMM would reduce the loading
error to \textless{} 0.001\%.

\end{examplebox}

\subsection{11.4.2 Oscilloscope}\label{oscilloscope}

An oscilloscope displays voltage as a function of time, providing a
visual representation of signal waveforms that reveals amplitude,
frequency, rise time, noise, distortion, and timing relationships
between multiple signals. Modern digital storage oscilloscopes (DSOs)
sample the input signal using a high-speed ADC (8-12 bit resolution),
store the digitized waveform in memory, and display it on a screen with
measurement cursors and automatic measurements. Key specifications
include bandwidth (the frequency at which the measured amplitude drops
to -3 dB, typically 50 MHz to over 100 GHz), sample rate (typically
1-100+ GS/s, must be at least 2.5-5× the bandwidth for accurate waveform
reconstruction), memory depth (determines the time window that can be
captured at full sample rate), and number of channels (typically 2-8).
Triggering systems (edge, pulse width, logic, protocol) ensure stable
display of repetitive waveforms and capture of specific events.
Mixed-signal oscilloscopes (MSOs) add digital logic inputs for
simultaneous analog and digital signal analysis, and protocol-aware
triggering and decoding for serial buses (SPI, I2C, UART, CAN).

\begin{examplebox}

\textbf{Example 11.4.2:} A digital oscilloscope has a bandwidth of 200
MHz and a sample rate of 1 GS/s. The memory depth is 10 Mpoints. A pulse
signal with a rise time of 2 ns must be measured. Determine whether the
oscilloscope bandwidth is adequate, the time window at full sample rate,
and the maximum time window at reduced sample rate.

\textbf{Solution:}\\
For accurate rise time measurement, the oscilloscope bandwidth should
satisfy: BW ≥ 0.35 / t\textsubscript{rise(actual)}.\\
However, the measured rise time is: t\textsubscript{rise(measured)} =
√(t\textsubscript{rise(signal)}² + t\textsubscript{rise(scope)}²), where
t\textsubscript{rise(scope)} = 0.35 / BW = 0.35 / 200 × 10⁶ = 1.75 ns.\\
Measured rise time: t\textsubscript{rise(measured)} = √(2² + 1.75²) =
√(4 + 3.0625) = √7.0625 = 2.66 ns.\\
The scope significantly affects the measurement (33\% error).\\
A 500 MHz scope would give t\textsubscript{rise(scope)} = 0.7 ns and
t\textsubscript{rise(measured)} = √(4 + 0.49) = 2.12 ns (6\% error) --
much better.\\
Time window at full sample rate: T = memory depth / sample rate = 10 ×
10⁶ / 1 × 10⁹ = 10 ms.

\end{examplebox}

\subsection{11.4.3 Spectrum Analyzer}\label{spectrum-analyzer}

A spectrum analyzer displays signal amplitude as a function of
frequency, providing a frequency-domain view complementary to the
oscilloscope's time-domain display. Swept-tuned spectrum analyzers use a
superheterodyne receiver architecture that mixes the input signal with a
swept local oscillator and measures the output of a narrowband
intermediate-frequency (IF) filter, scanning across the frequency range
to build up the spectrum display. FFT-based spectrum analyzers digitize
a block of the input signal and compute the frequency spectrum using the
Fast Fourier Transform, offering faster measurement speed and the
ability to capture transient spectral events. Key specifications include
frequency range (DC to 50+ GHz), resolution bandwidth (RBW, the minimum
frequency separation between two signals that can be resolved), dynamic
range (the range from the noise floor to the maximum input level without
distortion, typically 80-120 dB), and phase noise (which determines the
ability to measure signals close to a strong carrier). Spectrum
analyzers are essential for RF design, EMC testing, wireless
communications, and vibration analysis.

\begin{examplebox}

\textbf{Example 11.4.3:} A spectrum analyzer with a noise floor of -110
dBm (in 1 kHz RBW) is used to measure the second harmonic distortion of
an amplifier. The fundamental output at 100 MHz is -5 dBm, and the
second harmonic at 200 MHz reads -52 dBm, both measured with RBW = 10
kHz. Calculate the second harmonic distortion and the dynamic range
margin above the noise floor.

\textbf{Solution:}\\
Second harmonic distortion: HD₂ = P\textsubscript{2nd} -
P\textsubscript{fundamental} = -52 - (-5) = -47 dBc (47 dB below the
carrier).\\
In percentage: HD₂ = 10\^{}(-47/20) × 100\% = 0.00447 × 100\% =
0.447\%.\\
Noise floor correction for the measurement RBW: noise floor at 10 kHz
RBW = -110 + 10log₁₀(10,000/1000) = -110 + 10 = -100 dBm.\\
Signal-to-noise margin for the harmonic measurement: -52 - (-100) = 48
dB above the noise floor, confirming the harmonic measurement is valid
and well above the noise.\\
The maximum measurable dynamic range for this carrier level: -5 - (-100)
= 95 dB.

\end{examplebox}

\subsection{11.4.4 Function Generator}\label{function-generator}

A function generator produces standard waveforms (sine, square,
triangle, sawtooth, pulse) at selectable frequencies and amplitudes for
testing and characterizing electronic circuits and systems. Modern
arbitrary waveform generators (AWGs) can produce any user-defined
waveform loaded from a digital memory, enabling generation of complex
modulated signals, protocol test patterns, and real-world signal
replicas. Key specifications include frequency range (typically DC to
tens of MHz for general-purpose units, GHz for RF signal generators),
amplitude range and resolution, waveform fidelity (harmonic distortion,
typically -40 to -70 dBc for sine waves), and output impedance
(typically 50 Ω). Frequency accuracy and stability are determined by the
internal clock reference (crystal oscillator or optional external
reference input), with high-stability OCXO references providing
parts-per-billion accuracy. Modulation capabilities (AM, FM, PM, PWM,
sweep, burst) allow function generators to serve as stimulus sources for
communications, control system, and sensor testing.

\begin{examplebox}

\textbf{Example 11.4.4:} A function generator with a 50 Ω output
impedance is set to produce a 1 MHz sine wave at 2 V\textsubscript{pp}
into a 50 Ω load. The generator's specified harmonic distortion is -55
dBc. Calculate the RMS fundamental voltage across the load, the power
delivered to the load, and the amplitude of the largest harmonic.

\textbf{Solution:}\\
The problem specifies 2 V\textsubscript{pp} into the 50 Ω load, so
V\textsubscript{load(pp)} = 2 V\textsubscript{pp}.\\
V\textsubscript{load(rms)} = V\textsubscript{load(pp)} / (2√2) = 2 /
2.828 = 0.707 V\textsubscript{rms}.\\
Power into 50 Ω load: P = V\textsubscript{rms}² / R = 0.707² / 50 =
0.500 / 50 = 10.0 mW = +10.0 dBm.\\
Harmonic level: -55 dBc means the harmonic is 55 dB below the
fundamental.\\
Harmonic amplitude: V\textsubscript{harmonic} =
V\textsubscript{fundamental} × 10\^{}(-55/20) = 0.707 × 1.778 × 10⁻³ =
1.26 mV\textsubscript{rms}.

\end{examplebox}

\subsection{11.4.5 Power Analyzer}\label{power-analyzer}

A power analyzer is a specialized instrument designed to accurately
measure electrical power and energy in AC and DC systems, including real
power (W), reactive power (var), apparent power (VA), power factor,
harmonic content, and efficiency. Unlike a DMM or oscilloscope that
measures voltage and current independently, a power analyzer
simultaneously samples voltage and current at high speed (typically 1-5
MS/s per channel) and computes power quantities using digital signal
processing, correctly handling non-sinusoidal waveforms, phase shifts,
and harmonic distortion. Modern power analyzers provide 3-7 power input
channels for single-phase, three-phase (3-wire and 4-wire), and
multi-stage efficiency measurements (e.g., simultaneously measuring
input AC power, DC bus, and output to a motor). Key specifications
include basic power accuracy (typically 0.01-0.1\%), measurement
bandwidth (DC to 1-5 MHz for capturing switching converter harmonics),
and harmonic analysis capability (THD and individual harmonics to the
50th or 100th order per IEC 61000-4-7). Power analyzers are essential
for motor drive efficiency testing, power supply compliance testing (80
PLUS, Energy Star), IEC 62301 standby power measurement, and power
quality audits.

\begin{examplebox}

\textbf{Example 11.4.5:} A power analyzer measures a single-phase motor
drive with the following results: V\textsubscript{rms} = 230.5 V,
I\textsubscript{rms} = 4.82 A, real power P = 845 W, and total harmonic
distortion of the current THD\textsubscript{I} = 38\%. Calculate the
apparent power, power factor, displacement power factor, and distortion
power factor.

\textbf{Solution:}\\
Apparent power: S = V\textsubscript{rms} × I\textsubscript{rms} = 230.5
× 4.82 = 1,111.0 VA.\\
Power factor (total): PF = P / S = 845 / 1,111.0 = 0.761.\\
For non-sinusoidal currents, the total power factor is the product of
displacement power factor (cos φ₁, due to phase shift of the
fundamental) and distortion power factor (due to harmonics): PF = DPF ×
DstPF.\\
The distortion power factor relates to THD: DstPF = 1 / √(1 + THD²) = 1
/ √(1 + 0.38²) = 1 / √1.1444 = 1 / 1.0698 = 0.935.\\
Displacement power factor: DPF = PF / DstPF = 0.761 / 0.935 = 0.814,
corresponding to a phase angle of cos⁻¹(0.814) = 35.5° between
fundamental voltage and current.\\
The motor drive has acceptable displacement power factor but the 38\%
current THD significantly degrades the overall power factor and may
require harmonic filtering to meet IEEE 519 limits.

\end{examplebox}

\subsection{11.4.6 LCR Meter and Impedance
Analyzer}\label{lcr-meter-and-impedance-analyzer}

An LCR meter measures the inductance (L), capacitance (C), and
resistance (R) of passive components, along with derived quantities such
as impedance magnitude \textbar Z\textbar, phase angle θ, dissipation
factor (D = tan δ), quality factor (Q = 1/D), and equivalent series
resistance (ESR). The instrument applies a sinusoidal test signal
(typically 0.1--10 V\textsubscript{rms} at frequencies from 20 Hz to 1+
MHz) to the device under test and simultaneously measures the voltage
across and current through it, computing impedance as Z = V/I =
\textbar Z\textbar∠θ. From Z, the meter extracts series or parallel
equivalent circuit parameters: for a capacitor, C\textsubscript{s} =
−1/(ωX\textsubscript{s}) and ESR = R\textsubscript{s} in series mode, or
C\textsubscript{p} = −B\textsubscript{p}/ω and R\textsubscript{p} =
1/G\textsubscript{p} in parallel mode. \textbf{Four-terminal (Kelvin)
sensing} eliminates lead resistance errors by using separate force and
sense connections, essential for measuring low impedances (\textless10
Ω). \textbf{Impedance analyzers} extend LCR meter capability to broader
frequency ranges (1 Hz to 120+ MHz or even GHz with network analyzer
techniques), enabling characterization of component behavior across
frequency --- revealing self-resonant frequencies of capacitors and
inductors, parasitic effects, and material properties. Applications
include incoming component inspection, PCB parasitic extraction,
magnetic core characterization, and electrochemical impedance
spectroscopy (EIS) for battery and corrosion analysis.

\begin{examplebox}

\textbf{Example 11.4.6:} A 100 μF aluminum electrolytic capacitor is
measured on an LCR meter at 100 kHz with a 1 V\textsubscript{rms} test
signal. The meter reads \textbar Z\textbar{} = 0.185 Ω and θ = −59.2°.
Calculate the ESR, the actual capacitance at 100 kHz, the dissipation
factor D, and the quality factor Q. Compare the ESR to the
manufacturer's specification of 0.10 Ω maximum.

\textbf{Solution:}\\
Extract series equivalent components from Z = R\textsubscript{s} +
jX\textsubscript{s}.\\
R\textsubscript{s} (ESR) = \textbar Z\textbar{} × cos θ = 0.185 ×
cos(−59.2°) = 0.185 × 0.5120 = 0.0947 Ω.\\
X\textsubscript{s} = \textbar Z\textbar{} × sin θ = 0.185 × sin(−59.2°)
= 0.185 × (−0.8590) = −0.1589 Ω.\\
Capacitance: C\textsubscript{s} = −1/(ωX\textsubscript{s}) = −1/(2π ×
100,000 × (−0.1589)) = 1/(99,874) = 10.01 μF.\\
The capacitance has dropped from 100 μF (at 120 Hz) to \textasciitilde10
μF at 100 kHz --- a 10× reduction typical of aluminum electrolytics,
which lose effective capacitance above a few kHz due to internal
inductance and dielectric loss.\\
Dissipation factor: D = tan δ =
R\textsubscript{s}/\textbar X\textsubscript{s}\textbar{} = 0.0947/0.1589
= 0.596.\\
Quality factor: Q = 1/D = 1.68.\\
The ESR of 0.0947 Ω is within the 0.10 Ω specification.\\
This measurement demonstrates why LCR meters must test at the
application frequency --- a 120 Hz measurement would show the full 100
μF but would not reveal the high-frequency ESR and capacitance roll-off
critical for switching power supply decoupling.

\end{examplebox}

\subsection{11.4.7 Frequency Counter and Time Interval
Analyzer}\label{frequency-counter-and-time-interval-analyzer}

A frequency counter measures the frequency of a periodic signal by
counting the number of zero-crossings (or trigger-level crossings)
within a precisely timed gate interval. In the \textbf{direct count}
method, an internal reference oscillator defines the gate time (e.g., 1
s) and the counter tallies input cycles: frequency = count / gate time,
with a resolution of ±1 count (±1 Hz for a 1 s gate). The
\textbf{reciprocal counting} method instead measures the period of N
input cycles using a high-speed internal clock (typically 200 MHz--10
GHz with interpolation), then computes frequency as f = N / (measured
period), achieving resolution proportional to measurement time
regardless of the input frequency --- critical for measuring low
frequencies where direct counting yields poor resolution. Modern
\textbf{universal counters} combine both techniques and add time
interval measurement (measuring the elapsed time between start and stop
trigger events with resolution down to \textasciitilde20 ps single-shot,
improving to sub-picosecond with averaging), totalize counting, phase
measurement, and pulse width measurement. The accuracy of all frequency
counter measurements ultimately depends on the timebase reference: a
standard TCXO provides ±1 ppm stability, an OCXO provides ±0.01 ppm, and
a \textbf{GPS-disciplined oscillator (GPSDO)} or rubidium reference
provides ±0.001 ppb (10⁻¹²) long-term accuracy traceable to UTC ---
enabling measurements with 12+ digits of resolution. Frequency counters
are essential for calibrating oscillators, characterizing clock jitter,
verifying RF transmitter frequencies, and production testing of
timing-critical components.

\begin{examplebox}

\textbf{Example 11.4.7:} A reciprocal frequency counter with a 10 GHz
internal timebase measures a 60 Hz power line signal using a gate time
of 100 ms. A second measurement is made using the direct count method
with a 1 s gate. Compare the frequency resolution of each method. If the
timebase is a GPSDO with 1 × 10⁻¹¹ stability, what is the absolute
frequency accuracy for a 10.000 000 MHz measurement with a 1 s gate?

\textbf{Solution:}\\
\textbf{Reciprocal method} (100 ms gate): During 100 ms, approximately 6
cycles of the 60 Hz signal occur.\\
The internal clock at 10 GHz counts 10⁹ ticks per 100 ms period.\\
Period of 6 cycles = 6/60 = 0.1 s, measured with resolution of 1/(10 ×
10⁹) = 100 ps.\\
Period resolution per cycle: 100 ps / 6 = 16.7 ps.\\
Frequency resolution: Δf/f = Δt/t = 100 × 10⁻¹² / 0.1 = 10⁻⁹, so Δf = 60
× 10⁻⁹ = 60 nHz --- 9 digits of resolution.\\
\textbf{Direct count method} (1 s gate): Count = 60. Resolution = ±1
count / 1 s = ±1 Hz. Relative resolution = 1/60 = 1.7\%, only 1.8
digits.\\
The reciprocal method is 10⁷× better.\\
\textbf{Absolute accuracy} for 10 MHz with GPSDO: uncertainty = f ×
stability = 10⁷ × 10⁻¹¹ = 10⁻⁴ Hz = 0.1 mHz.\\
The measurement reads 10,000,000.000 0 ± 0.000 1 Hz --- 11 significant
digits, traceable to the GPS satellite constellation's atomic clocks.

\end{examplebox}

\subsection{11.4.8 Vector Network Analyzer
(VNA)}\label{vector-network-analyzer-vna}

A vector network analyzer measures the complex (magnitude and phase)
scattering parameters (S-parameters) of RF and microwave devices, fully
characterizing how a device reflects and transmits signals as a function
of frequency. The VNA operates by sending a known stimulus signal into
the device under test (DUT) through precision test ports and measuring
the reflected and transmitted waves using directional couplers and
coherent receivers. For a two-port device, the four S-parameters are:
S₁₁ (input reflection coefficient / return loss), S₂₁ (forward
transmission / insertion loss or gain), S₁₂ (reverse transmission /
isolation), and S₂₂ (output reflection coefficient). Each parameter is a
complex number with magnitude (in dB) and phase (in degrees), enabling
the VNA to display results as return loss, insertion loss, VSWR,
impedance on a Smith chart, group delay, and time-domain reflectometry
(TDR) via inverse FFT. Modern VNAs cover frequencies from 5 Hz to 110+
GHz (with waveguide extensions to 1.5 THz), with dynamic range of
100--140 dB, and typically offer 2 or 4 test ports. \textbf{Calibration}
is critical to VNA accuracy: the SOLT (Short-Open-Load-Thru) and TRL
(Thru-Reflect-Line) calibration methods use known standards to
mathematically remove systematic errors from the measurement ports,
cables, and adapters --- moving the reference plane to the DUT
connectors. The VNA is indispensable for characterizing filters,
amplifiers, antennas, cables, connectors, PCB transmission lines, and
any component where impedance matching and frequency response are
critical. Applications extend beyond RF to materials characterization
(dielectric constant measurement), biomedical sensing, and semiconductor
device modeling.

\begin{examplebox}

\textbf{Example 11.4.8:} A VNA measures a bandpass filter from 800 MHz
to 1200 MHz. At the center frequency of 1000 MHz, S₂₁ = -1.2 dB ∠-45°
and S₁₁ = -18 dB ∠+135°. Calculate the insertion loss, return loss, VSWR
at the input port, the fraction of power reflected, and the fraction of
power transmitted through the filter.

\textbf{Solution:}\\
Insertion loss = -S₂₁ = 1.2 dB.\\
Return loss = -S₁₁ = 18 dB.\\
Input reflection coefficient magnitude: \textbar Γ\textbar{} =
10\textsuperscript{S₁₁/20} = 10\textsuperscript{-18/20} =
10\textsuperscript{-0.9} = 0.1259.\\
VSWR = (1 + \textbar Γ\textbar) / (1 - \textbar Γ\textbar) = (1 +
0.1259) / (1 - 0.1259) = 1.1259 / 0.8741 = 1.288:1.\\
Power reflected: \textbar Γ\textbar² = 0.1259² = 0.01585 = 1.585\% of
incident power.\\
Power transmitted: \textbar S₂₁\textbar² =
10\textsuperscript{S₂₁(dB)/10} = 10\textsuperscript{-1.2/10} =
10\textsuperscript{-0.12} = 0.7586 = 75.86\%.\\
Power absorbed/dissipated in the filter: 1 - \textbar S₁₁\textbar² -
\textbar S₂₁\textbar² = 1 - 0.01585 - 0.7586 = 0.2256 = 22.56\%.\\
The filter has good input matching (VSWR \textless{} 1.3) but dissipates
nearly a quarter of the input power --- suggesting resistive losses in
the filter elements or substrate.\\
At the band edges (800 and 1200 MHz), S₂₁ drops to -25 dB (0.316\% power
transmission), providing 23.8 dB of out-of-band rejection.

\end{examplebox}

\subsection{11.4.9 Thermal Imaging
Cameras}\label{thermal-imaging-cameras}

Thermal imaging cameras detect infrared radiation emitted by objects and
convert it into a visible image (thermogram) that maps surface
temperature across the field of view, enabling non-contact temperature
measurement of entire scenes rather than single points. Every object
above absolute zero emits infrared radiation according to the Planck
radiation law, with the peak wavelength and total radiated power
determined by its temperature and surface emissivity. Thermal cameras
are indispensable in electrical maintenance --- detecting hotspots on
switchgear, loose connections, overloaded conductors, and failing
transformer bushings before they cause outages or fires --- as well as
in building diagnostics, mechanical equipment monitoring, process
control, and security and surveillance applications.

Two primary detector technologies dominate thermal imaging.
\textbf{Uncooled microbolometer arrays} use a grid of vanadium oxide
(VOx) or amorphous silicon (a-Si) elements suspended on micro-bridges
that absorb incident IR radiation, causing a temperature rise that
changes the element's electrical resistance. Microbolometers operate at
ambient temperature (no cryogenic cooling), are compact and relatively
inexpensive, and achieve noise equivalent temperature difference (NETD)
values of 30--80 mK at f/1 optics. Standard resolutions range from 160 ×
120 to 640 × 480 pixels, with high-end models reaching 1024 × 768. They
operate in the long-wave infrared (LWIR) band, 8--14 μm, which coincides
with an atmospheric transmission window and the peak emission wavelength
of objects near ambient temperature (\textasciitilde10 μm at 300 K per
Wien's displacement law). \textbf{Cooled detector arrays} use photon
detectors --- typically indium antimonide (InSb) for the mid-wave
infrared (MWIR, 3--5 μm) band or mercury cadmium telluride (MCT/HgCdTe)
for MWIR or LWIR --- cooled to cryogenic temperatures (typically 77 K
using a Stirling-cycle cooler or liquid nitrogen) to suppress thermal
noise. Cooled detectors achieve NETD values of 15--25 mK with higher
sensitivity, faster response times (\textless1 ms vs.~\textasciitilde10
ms for microbolometers), and larger format arrays (up to 1280 × 1024 or
higher), but are significantly more expensive, bulkier, and require
periodic cooler maintenance.

\textbf{NETD (Noise Equivalent Temperature Difference)} is the key
performance metric for thermal cameras --- it represents the smallest
temperature difference the camera can resolve, defined as the target
temperature change that produces a signal-to-noise ratio of 1. A camera
with 50 mK NETD can distinguish temperature differences as small as
0.05°C under ideal conditions. In practice, the minimum resolvable
temperature difference depends on spatial averaging, frame integration,
and the temperature contrast between the target and background.

\textbf{Spectral band selection} affects measurement capability: LWIR
(8--14 μm) cameras provide the best performance for objects near ambient
temperature and are less affected by solar reflections, making them
ideal for outdoor electrical inspections during daylight. MWIR (3--5 μm)
cameras offer higher spatial resolution for a given aperture size
(shorter wavelength allows smaller diffraction-limited spot size) and
better performance at elevated temperatures (\textgreater300°C), making
them preferred for furnace monitoring, gas detection (many gases have
absorption bands in the 3--5 μm region), and military/aerospace
applications.

\textbf{Emissivity correction} is essential for accurate temperature
measurement. Real surfaces emit less radiation than an ideal blackbody
at the same temperature, with the ratio defined as emissivity ε (ranging
from 0 to 1). Most non-metallic surfaces have ε = 0.85--0.95, while
polished metals can have ε as low as 0.02--0.10. An uncorrected
measurement of a low-emissivity surface will significantly underestimate
the actual temperature because the camera receives less radiation than
expected. Modern cameras allow the user to set ε, reflected apparent
temperature (to compensate for ambient radiation reflected off low-ε
surfaces), atmospheric temperature, humidity, and distance to correct
for transmission losses.

\textbf{Spatial resolution} is defined by the instantaneous field of
view (IFOV), which is the angular subtense of a single detector pixel
--- typically 1--3 mrad for standard lenses. The measurement spot size
at a given distance is: spot diameter = IFOV × distance. For accurate
temperature measurement, the target must fill at least 3 × 3 pixels (the
``spot size ratio'' or ``distance-to-spot-size ratio'' D:S). A camera
with 1.4 mrad IFOV viewing a target at 5 m has a pixel footprint of 7
mm, requiring the target to be at least 21 mm across for a valid
temperature measurement. Applications in electrical maintenance include
scanning distribution panels for overloaded breakers (ΔT \textgreater{}
10°C above adjacent phases indicates a problem), inspecting overhead
transmission connections for resistance heating, locating underground
cable faults via surface temperature anomalies, and verifying the
thermal performance of heat sinks and cooling systems. Infrared
thermography programs following NFPA 70B and NETA MTS standards
recommend annual thermographic surveys of all electrical distribution
equipment rated above 600 V.

\begin{examplebox}

\textbf{Example 11.4.9:} A thermal imaging camera with NETD = 50 mK and
LWIR (8--14 μm) spectral band measures a bolted bus connection in a
switchgear panel. The camera settings are ε = 0.95 (oxidized copper),
and the reflected apparent temperature is 25°C. The camera reads an
apparent temperature of 78°C on the suspect connection, while an
adjacent identical connection reads 42°C. The actual emissivity of the
suspect connection is ε = 0.70 (partially cleaned/polished surface from
recent maintenance). Calculate the corrected temperature of the suspect
connection and determine the severity of the hotspot according to NETA
guidelines.

\textbf{Solution:}\\
The camera computes temperature assuming ε = 0.95. The total radiation
received by the camera from the target is: W\textsubscript{total} =
ε\textsubscript{actual} × σT⁴\textsubscript{actual} + (1 −
ε\textsubscript{actual}) × σT⁴\textsubscript{reflected}.\\
The camera interprets this as: W\textsubscript{total} =
ε\textsubscript{set} × σT⁴\textsubscript{apparent} + (1 −
ε\textsubscript{set}) × σT⁴\textsubscript{reflected}.\\
Setting these equal: ε\textsubscript{set} × T⁴\textsubscript{apparent} +
(1 − ε\textsubscript{set}) × T⁴\textsubscript{reflected} =
ε\textsubscript{actual} × T⁴\textsubscript{actual} + (1 −
ε\textsubscript{actual}) × T⁴\textsubscript{reflected}.\\
Converting to Kelvin: T\textsubscript{apparent} = 78 + 273.15 = 351.15
K, T\textsubscript{reflected} = 25 + 273.15 = 298.15 K.\\
Left side: 0.95 × (351.15)⁴ + 0.05 × (298.15)⁴ = 0.95 × 1.519 × 10¹⁰ +
0.05 × 7.906 × 10⁹ = 1.443 × 10¹⁰ + 3.953 × 10⁸ = 1.483 × 10¹⁰.\\
Solving for T\textsubscript{actual}: ε\textsubscript{actual} ×
T⁴\textsubscript{actual} = 1.483 × 10¹⁰ − (1 − 0.70) × (298.15)⁴ = 1.483
× 10¹⁰ − 0.30 × 7.906 × 10⁹ = 1.483 × 10¹⁰ − 2.372 × 10⁹ = 1.246 ×
10¹⁰.\\
T⁴\textsubscript{actual} = 1.246 × 10¹⁰ / 0.70 = 1.780 × 10¹⁰.\\
T\textsubscript{actual} = (1.780 × 10¹⁰)\textsuperscript{1/4} = 365.3 K
= 92.2°C.\\
The corrected temperature is 92.2°C --- significantly higher than the
78°C apparent reading due to the lower-than-assumed emissivity.\\
Temperature rise above the reference connection: ΔT = 92.2 − 42 =
50.2°C.\\
Per NETA MTS severity criteria: ΔT \textgreater{} 40°C above a similar
component under similar loading is classified as \textbf{immediate
action required} (the most severe category), indicating a
high-resistance connection that should be de-energized and repaired
immediately to prevent equipment failure or fire.\\
This example demonstrates why accurate emissivity settings are critical
--- the 0.25 difference in emissivity (0.95 assumed vs.~0.70 actual)
caused a 14.2°C underestimate that could have led to an incorrect
severity classification.

\end{examplebox}

\section{11.5 Data Acquisition}\label{data-acquisition}

Data acquisition (DAQ) bridges the gap between the analog world of
sensors and the digital world of computers, converting continuous
physical signals into discrete digital data that can be processed,
stored, and analyzed by software. A DAQ system encompasses the entire
signal chain from the analog front end (multiplexing, sampling, and
quantization) through digital communication to the host computer,
including the software that configures the hardware, displays real-time
data, and logs measurements for later analysis. The performance of a DAQ
system is defined by its channel count, sampling rate, resolution,
accuracy, and the ability to synchronize measurements across channels
and with external events.

\subsection{11.5.1 Sampling and
Quantization}\label{sampling-and-quantization}

Data acquisition systems convert analog sensor signals into digital data
for processing, storage, and analysis by a computer. The
analog-to-digital converter (ADC) performs two operations: sampling
(capturing the instantaneous value of the analog signal at discrete time
intervals) and quantization (mapping each sample to the nearest digital
code from a finite set of levels). The sampling rate must satisfy the
Nyquist criterion (f\textsubscript{s} \textgreater{}
2f\textsubscript{max}) to avoid aliasing, and practical systems sample
at 5--10× the maximum signal frequency to ease anti-aliasing filter
requirements. ADC resolution (typically 12--24 bits for data
acquisition) determines the smallest detectable signal change: an N-bit
ADC divides the full-scale range into 2ᴺ levels. Common ADC
architectures for data acquisition include successive approximation
(SAR, 12-18 bit, up to several MS/s), delta-sigma (Σ-Δ, 16-24 bit,
excellent noise rejection but lower speed), and pipeline (12-16 bit,
high speed for waveform capture).

\begin{examplebox}

\textbf{Example 11.5.1:} A 14-bit SAR ADC with a ±10 V bipolar input
range samples a vibration sensor at f\textsubscript{s} = 50 kS/s. The
signal of interest has frequencies up to 2 kHz. Calculate the ADC
resolution (LSB), the ideal signal-to-noise-and-distortion ratio
(SINAD), and the required anti-aliasing filter cutoff.

\textbf{Solution:}\\
Full-scale range: 20 V (from -10 to +10 V).\\
Resolution (LSB): 20 V / 2¹⁴ = 20 / 16,384 = 1.221 mV.\\
Ideal SINAD for an N-bit ADC: SINAD = 6.02N + 1.76 dB = 6.02 × 14 + 1.76
= 84.28 + 1.76 = 86.04 dB.\\
Nyquist frequency: f\textsubscript{N} = f\textsubscript{s} / 2 = 25
kHz.\\
The anti-aliasing filter cutoff should be set between the maximum signal
frequency and the Nyquist frequency.\\
A practical choice: f\textsubscript{c} ≈ 5 kHz (2.5× the signal
bandwidth), providing a flat passband to 2 kHz and a 5× frequency margin
to Nyquist for filter roll-off (just over 2.3 octaves).\\
A 4th-order Butterworth at 5 kHz gives -80 dB/decade × log₁₀(25/5) = -80
× 0.699 = -55.9 dB attenuation at Nyquist --- a factor of
\textasciitilde625× reduction of any out-of-band signal.

\end{examplebox}

\subsection{11.5.2 Data Acquisition
Systems}\label{data-acquisition-systems}

A complete data acquisition (DAQ) system integrates multiplexing, signal
conditioning, ADC conversion, timing, and digital communication into a
coordinated measurement platform. Multiplexed systems use an analog
multiplexer to sequentially connect multiple sensor channels to a shared
ADC, reducing cost at the expense of simultaneous sampling capability.
Simultaneous sampling systems provide a dedicated sample-and-hold
circuit and ADC for each channel, essential when phase relationships
between channels must be preserved (e.g., vibration analysis, power
measurements). Timing and triggering control the start of acquisition,
sample rate, and synchronization with external events or other
instruments. Common DAQ interfaces include USB, PCI/PCIe, and Ethernet,
with industrial systems using fieldbus protocols (Modbus, PROFIBUS,
EtherCAT) to distribute measurement points across a facility. Software
frameworks such as LabVIEW, MATLAB Data Acquisition Toolbox, and Python
libraries (nidaqmx, pydaq) provide configuration, real-time display,
logging, and analysis of acquired data.

\begin{examplebox}

\textbf{Example 11.5.2:} A 16-channel data acquisition system uses a
multiplexed 16-bit ADC with a maximum throughput of 250 kS/s. Each
channel requires a settling time of 2 μs after the multiplexer switches.
The signals of interest have a maximum frequency of 1 kHz on all
channels. Determine the maximum per-channel sample rate and whether
simultaneous sampling is needed.

\textbf{Solution:}\\
Total time per conversion including settling: t\textsubscript{ch} =
1/250,000 + 2 × 10⁻⁶ = 4.0 μs + 2.0 μs = 6.0 μs per channel.\\
Cycle time for all 16 channels: t\textsubscript{cycle} = 16 × 6.0 μs =
96 μs.\\
Maximum per-channel sample rate: f\textsubscript{ch} = 1 /
t\textsubscript{cycle} = 1 / 96 × 10⁻⁶ = 10,417 S/s ≈ 10.4 kS/s per
channel.\\
This is more than 5× the 1 kHz signal bandwidth, satisfying Nyquist with
margin.\\
Phase error between first and last channel: Δt = 15 × 6.0 μs = 90 μs.\\
At 1 kHz: phase skew = 360° × f × Δt = 360° × 1000 × 90 × 10⁻⁶ =
32.4°.\\
This significant phase skew means simultaneous sampling (dedicated S/H
per channel) is required if phase relationships between channels must be
preserved.

\end{examplebox}

\subsection{11.5.3 Data Logging and
Storage}\label{data-logging-and-storage}

Data logging is the process of recording measurement data over time for
later retrieval and analysis, ranging from simple standalone loggers
that record a single parameter to enterprise-class systems that
continuously capture thousands of channels across an entire facility.
\textbf{Standalone data loggers} are battery-powered devices with
built-in sensors (or sensor inputs), onboard memory (typically 1-64 MB
flash), and a real-time clock that timestamp each sample --- common for
environmental monitoring, cold-chain compliance, and long-term field
deployments lasting weeks to months. \textbf{PC-based logging} uses DAQ
hardware connected to a computer running logging software, offering
higher channel counts, faster sample rates, and real-time display but
requiring continuous PC operation and power. Storage capacity planning
requires calculating the data rate: bytes per second = (channels ×
sample rate × bytes per sample) + timestamp overhead. File formats
include CSV (human-readable, large), TDMS (NI Technical Data Management
Streaming, compact with metadata), HDF5 (hierarchical, widely used in
science), and proprietary binary formats optimized for specific
instruments. For long-duration logging at high sample rates, circular
buffer (ring buffer) operation overwrites the oldest data when memory is
full, ensuring the most recent data is always captured. Industrial data
historians (such as OSIsoft PI or InfluxDB) provide time-series
databases optimized for storing and querying billions of timestamped
measurements with compression ratios of 10:1 to 50:1.

\begin{examplebox}

\textbf{Example 11.5.3:} A 32-channel vibration monitoring system logs
data continuously from accelerometers sampled at 10 kS/s per channel
with 16-bit (2-byte) resolution. Each sample is timestamped with a
4-byte UNIX timestamp per scan (one timestamp for all 32 channels).
Calculate the raw data rate in MB/hour, the storage required for 30 days
of continuous logging, and the minimum write speed required for the
storage medium.

\textbf{Solution:}\\
Data per scan (all 32 channels): 32 channels × 2 bytes = 64 bytes + 4
bytes timestamp = 68 bytes per scan.\\
Scans per second: 10,000.\\
Raw data rate: 68 × 10,000 = 680,000 bytes/s = 680 kB/s = 0.680 MB/s.\\
Per hour: 0.680 × 3,600 = 2,448 MB/hour ≈ 2.45 GB/hour.\\
Per day: 2.45 × 24 = 58.8 GB/day.\\
For 30 days: 58.8 × 30 = 1,764 GB ≈ 1.76 TB.\\
A 2 TB SSD would provide sufficient capacity with margin.\\
Minimum sustained write speed: 680 kB/s = 0.68 MB/s --- easily met by
any modern SSD (typical sustained write \textgreater{} 200 MB/s) or even
a quality SD card.\\
With typical 10:1 compression (using lossless algorithms on the
redundant sensor data): effective storage ≈ 176 GB for 30 days, fitting
on a single 256 GB drive.

\end{examplebox}

\subsection{11.5.4 Automated Test and Remote Instrument
Control}\label{automated-test-and-remote-instrument-control}

Automated test systems use software to configure instruments, execute
measurement sequences, collect data, and make pass/fail decisions
without operator intervention, enabling high-throughput production
testing, regression testing, and complex multi-instrument
characterization. The \textbf{IEEE 488 (GPIB)} bus was the original
standard for instrument communication (1 MB/s, 15 devices per bus, cable
lengths to 20 m), and while still widely installed, it has been
supplemented by \textbf{USB-TMC} (Test and Measurement Class, uses
standard USB with GPIB-like semantics), \textbf{LXI} (LAN eXtensions for
Instrumentation, using Ethernet/TCP-IP for high-speed, long-distance
control), and \textbf{PXI} (PCI eXtensions for Instrumentation, a
modular rack-based platform with shared high-speed backplane for tightly
integrated ATE systems). \textbf{SCPI} (Standard Commands for
Programmable Instruments) defines a standardized ASCII command syntax
across all interfaces --- a command like \texttt{MEAS:VOLT:DC?} reads a
DC voltage measurement on any SCPI-compliant DMM regardless of
manufacturer. The \textbf{VISA} (Virtual Instrument Software
Architecture) library provides a unified API that abstracts the physical
interface, allowing the same program code to control instruments over
GPIB, USB, LAN, or serial by changing only the resource address string
(e.g., \texttt{GPIB0::22::INSTR} or
\texttt{TCPIP::192.168.1.50::INSTR}). Programming environments include
LabVIEW (graphical, widely used in test engineering), MATLAB Instrument
Control Toolbox, and Python with PyVISA --- the latter providing a
lightweight, open-source alternative:
\texttt{import\ pyvisa;\ rm\ =\ pyvisa.ResourceManager();\ dmm\ =\ rm.open\_resource(\textquotesingle{}TCPIP::192.168.1.50::INSTR\textquotesingle{});\ print(dmm.query(\textquotesingle{}MEAS:VOLT:DC?\textquotesingle{}))}.
\textbf{Automated test equipment (ATE)} for production integrates
switching matrices (to route signals between DUT pins and instruments),
stimulus sources, measurement instruments, and a test executive that
sequences test steps, collects results, computes pass/fail limits, and
generates test reports with statistical yield analysis.

\begin{examplebox}

\textbf{Example 11.5.4:} A production test station must measure DC
voltage, AC voltage, resistance, and frequency on a circuit board at 8
test points using a DMM and a frequency counter, both controlled via
LAN/LXI. Each measurement takes 150 ms (instrument settling +
measurement + data transfer). The test sequence requires 8 DC voltage, 4
AC voltage, 4 resistance, and 2 frequency measurements per board.
Calculate the total test time per board and the maximum throughput in
boards per hour. If parallel testing of 4 boards is implemented using a
switching matrix, what is the new throughput?

\textbf{Solution:}\\
Total measurements per board: 8 + 4 + 4 + 2 = 18 measurements.\\
Test time per board: 18 × 150 ms = 2.7 s.\\
Add 0.5 s for board handler settling and communication overhead: total =
3.2 s per board.\\
Throughput: 3600/3.2 = 1,125 boards/hour.\\
With parallel testing of 4 boards: the switching matrix routes each test
point from one of 4 boards to the instruments in sequence.\\
Total measurements: 18 × 4 = 72.\\
Test time for 4 boards: 72 × 150 ms + 0.5 s = 10.8 + 0.5 = 11.3 s.\\
Per-board time: 11.3/4 = 2.825 s.\\
Throughput: 3600/2.825 × (4/4) --- wait, the 4 boards are tested
sequentially through the mux, not truly in parallel.\\
Actual throughput: 4 boards per 11.3 s = 1,274 boards/hour --- only a
13\% improvement because the instruments are the bottleneck.\\
True parallel testing requires duplicating the instruments: 4 DMMs and 4
counters testing simultaneously would give 4 × 1,125 = 4,500
boards/hour, but at 4× the instrument cost.\\
A better approach: overlap handler time with test time using a conveyor
and dual-site fixturing, achieving \textasciitilde1,800 boards/hour with
a single instrument set.

\end{examplebox}

\chapter{Chapter 12}\label{chapter-12}

\chapter{Electric Motors}\label{electric-motors}

Electric motors convert electrical energy into mechanical energy through
the interaction of magnetic fields and current-carrying conductors. They
are the most common source of mechanical power in modern industry,
transportation, and consumer products, collectively consuming
approximately 45\% of global electricity generation. Motor selection
depends on the application requirements for speed, torque, efficiency,
control precision, size, cost, and operating environment, with motor
types ranging from simple DC machines to sophisticated synchronous and
stepper motors driven by advanced power electronics.

\section{12.1 DC Motors}\label{dc-motors}

DC motors produce torque by passing current through conductors immersed
in a magnetic field, following the Lorentz force law (F = I × L × B).
They offer inherently simple speed control --- varying the applied
voltage changes the speed, while varying the current changes the torque
--- making them the earliest motors used for variable-speed
applications. The two main categories are brushed DC motors, which use a
mechanical commutator to switch current direction in the rotor windings,
and brushless DC (BLDC) motors, which use electronic commutation to
energize fixed stator windings around a permanent magnet rotor.

\subsection{12.1.1 Brushed DC Motors}\label{brushed-dc-motors}

Brushed DC motors use a wound rotor (armature) that rotates within a
stationary magnetic field produced by permanent magnets or field
windings. Current is delivered to the rotating armature through carbon
brushes that make sliding contact with a segmented commutator, which
mechanically reverses the current direction in each coil as it rotates
to maintain continuous torque production. The speed of a brushed DC
motor is proportional to the applied voltage minus the back-EMF (V =
E\textsubscript{back} + I\textsubscript{a} × R\textsubscript{a}), and
the torque is proportional to the armature current (τ =
K\textsubscript{t} × I\textsubscript{a}), making speed and torque
control straightforward by varying the supply voltage. Brushed DC motors
are simple, inexpensive, and provide excellent low-speed torque, but the
brushes and commutator introduce friction, electrical noise (arcing),
and require periodic maintenance due to wear. Series-wound, shunt-wound,
and compound-wound configurations provide different speed-torque
characteristics suited to various applications such as automotive
starters (series), machine tools (shunt), and elevators (compound).

\begin{examplebox}

\textbf{Example 12.1.1:} A shunt-wound DC motor has the following
nameplate data: V\textsubscript{supply} = 240 V, R\textsubscript{a} =
0.5 Ω (armature resistance), and the motor constant K = 1.2 V/(rad/s).
At no load, the motor draws I\textsubscript{a} = 2 A. Under full load,
the armature current is I\textsubscript{a} = 40 A. Calculate the no-load
speed, full-load speed, and speed regulation.

\textbf{Solution:}\\
No-load: Back-EMF: E\textsubscript{back} = V - I\textsubscript{a} ×
R\textsubscript{a} = 240 - 2 × 0.5 = 239 V.\\
No-load speed: ω\textsubscript{NL} = E\textsubscript{back} / K = 239 /
1.2 = 199.2 rad/s = 199.2 × 60/(2π) = 1,902 RPM.\\
Full-load: E\textsubscript{back} = 240 - 40 × 0.5 = 220 V.\\
Full-load speed: ω\textsubscript{FL} = 220 / 1.2 = 183.3 rad/s = 1,751
RPM.\\
Speed regulation: SR = (ω\textsubscript{NL} - ω\textsubscript{FL}) /
ω\textsubscript{FL} × 100\% = (199.2 - 183.3) / 183.3 × 100\% =
8.64\%.\\
Full-load torque: τ = K × I\textsubscript{a} = 1.2 × 40 = 48.0 N·m.

\end{examplebox}

\subsection{12.1.2 Brushless DC Motors
(BLDC)}\label{brushless-dc-motors-bldc}

Brushless DC motors eliminate the mechanical commutator by placing
permanent magnets on the rotor and the stator windings on the stationary
frame, using electronic commutation (via transistor switching) to
energize the appropriate stator phases as the rotor turns. Hall effect
sensors or back-EMF sensing (sensorless control) detect the rotor
position and determine the commutation timing. BLDC motors offer higher
efficiency (85-95\%), longer life (no brush wear), lower electrical
noise, and higher power density compared to brushed DC motors. The
trapezoidal back-EMF waveform distinguishes BLDC motors from permanent
magnet synchronous motors (which have sinusoidal back-EMF), and they are
typically driven with six-step (trapezoidal) commutation from a
three-phase inverter. Applications include computer fans, hard disk
drives, drone propellers, electric bicycles, and industrial servo
systems where high reliability and compact size are required.

\begin{examplebox}

\textbf{Example 12.1.2:} A BLDC motor has 8 poles, a torque constant
K\textsubscript{t} = 0.15 N·m/A, a back-EMF constant K\textsubscript{e}
= 0.15 V/(rad/s), and a phase resistance of R\textsubscript{ph} = 0.8 Ω.
The DC bus voltage is 48 V, and the motor drives a load requiring 2 N·m
at 1,700 RPM. Calculate the required phase current, the back-EMF, and
the motor efficiency (neglecting switching and iron losses).

\textbf{Solution:}\\
Speed in rad/s: ω = 1700 × 2π/60 = 178.0 rad/s.\\
Required phase current: I = τ / K\textsubscript{t} = 2.0 / 0.15 = 13.33
A.\\
Back-EMF (line-to-line): E\textsubscript{back} = K\textsubscript{e} × ω
= 0.15 × 178.0 = 26.7 V.\\
Verify voltage equation (two phases conducting, total resistance
2R\textsubscript{ph} = 1.6 Ω): V\textsubscript{bus} =
E\textsubscript{back} + I × 2R\textsubscript{ph} = 26.7 + 13.33 × 1.6 =
26.7 + 21.3 = 48.0 V ✓.\\
Mechanical output power: P\textsubscript{mech} = τ × ω = 2.0 × 178.0 =
356.0 W.\\
Copper losses (three phases, two conducting at any time in trapezoidal
commutation): P\textsubscript{copper} = 2 × I² × R\textsubscript{ph} = 2
× 13.33² × 0.8 = 2 × 142.1 = 284.2 W.\\
Input power: P\textsubscript{in} = P\textsubscript{mech} +
P\textsubscript{copper} = 356.0 + 284.2 = 640.2 W.\\
Efficiency: η = 356.0 / 640.2 × 100\% = 55.6\%.\\
The relatively low efficiency reflects the high copper losses at this
load current; efficiency improves significantly at lighter loads where
I²R losses are smaller relative to mechanical output.

\end{examplebox}

\subsection{12.1.3 Universal Motors}\label{universal-motors}

Universal motors are series-wound DC motors designed to operate on both
AC and DC supplies, making them one of the few motor types that can run
directly from single-phase household mains without a rectifier or
inverter. In a series motor, the field winding and armature winding
carry the same current, so when the AC supply reverses polarity, both
the field flux and the armature current reverse simultaneously,
producing torque in the same direction throughout the cycle. Universal
motors achieve very high speeds (up to 20,000-30,000 RPM) and high
power-to-weight ratios, making them the dominant motor for handheld
power tools (drills, grinders, circular saws, routers), vacuum cleaners,
blenders, and hair dryers. Their speed can be controlled simply with a
triac-based phase-angle controller, providing variable speed from
near-zero to maximum RPM. The main disadvantages are the brush and
commutator wear (limiting lifespan to a few hundred hours of continuous
operation), high audible noise, radio frequency interference (RFI) from
commutator arcing, and reduced efficiency (typically 50-70\%) compared
to brushless alternatives. In many consumer applications, brushless DC
motors with electronic controllers are increasingly replacing universal
motors due to longer life, lower noise, and higher efficiency.

\begin{examplebox}

\textbf{Example 12.1.3:} A universal motor rated at 120 V, 12 A, 20,000
RPM is used in a router. The armature resistance is R\textsubscript{a} =
0.8 Ω and the series field resistance is R\textsubscript{f} = 0.4 Ω.
Calculate the back-EMF at rated speed, the copper losses, the motor
output power (assuming total losses are 35\% of input), and the torque.

\textbf{Solution:}\\
Total winding resistance: R\textsubscript{total} = R\textsubscript{a} +
R\textsubscript{f} = 0.8 + 0.4 = 1.2 Ω.\\
Back-EMF: E\textsubscript{back} = V - I × R\textsubscript{total} = 120 -
12 × 1.2 = 120 - 14.4 = 105.6 V.\\
Input power: P\textsubscript{in} = V × I = 120 × 12 = 1,440 W.\\
Copper losses: P\textsubscript{Cu} = I² × R\textsubscript{total} = 144 ×
1.2 = 172.8 W.\\
Output power (65\% of input): P\textsubscript{out} = 0.65 × 1,440 = 936
W = 1.25 HP.\\
Remaining losses (core, friction, windage): P\textsubscript{other} =
1,440 - 936 - 172.8 = 331.2 W.\\
Speed in rad/s: ω = 20,000 × 2π/60 = 2,094 rad/s.\\
Output torque: τ = P\textsubscript{out} / ω = 936 / 2,094 = 0.447 N·m.\\
The high speed and relatively low torque are characteristic of universal
motors --- they develop useful mechanical power through high rotational
speed rather than high torque.

\end{examplebox}

\section{12.2 AC Motors}\label{ac-motors}

AC motors are driven by alternating current and rely on rotating
magnetic fields produced by poly-phase or single-phase stator windings.
The three-phase induction motor dominates industrial applications due to
its rugged, maintenance-free construction, while synchronous motors
serve applications requiring precise speed control or power factor
correction. Single-phase motors fill the residential and
light-commercial niche where three-phase power is unavailable, and
reluctance motors offer a magnet-free alternative with competitive
efficiency for certain variable-speed applications.

\subsection{12.2.1 Induction Motors}\label{induction-motors}

The induction motor (also called an asynchronous motor) is the most
widely used electric motor in industry due to its rugged construction,
low cost, and minimal maintenance requirements. The stator carries
three-phase windings that produce a rotating magnetic field at
synchronous speed n\textsubscript{s} = 120f/P, where f is the supply
frequency and P is the number of poles. The rotating field induces
currents in the rotor conductors (either a squirrel-cage of aluminum or
copper bars, or wound rotor with slip rings), and the interaction
between the induced rotor currents and the stator field produces torque.
The rotor must always turn slower than the synchronous speed for
induction to occur; this speed difference is quantified by slip: s =
(n\textsubscript{s} - n\textsubscript{r})/n\textsubscript{s}, with
typical full-load slip of 2--5\% for standard machines. The torque-speed
characteristic features a starting torque, a maximum (breakdown) torque,
and a nearly linear operating region near synchronous speed where the
motor runs during normal loaded operation.

\begin{examplebox}

\textbf{Example 12.2.1:} A 4-pole, three-phase induction motor is
connected to a 60 Hz supply. At full load, the motor speed is measured
at 1,740 RPM. The motor delivers 15 HP of mechanical power. Calculate
the synchronous speed, slip, rotor electrical frequency, and full-load
torque.

\textbf{Solution:}\\
Synchronous speed: n\textsubscript{s} = 120f / P = 120 × 60 / 4 = 1,800
RPM.\\
Slip: s = (n\textsubscript{s} - n\textsubscript{r}) / n\textsubscript{s}
= (1800 - 1740) / 1800 = 60 / 1800 = 0.0333 (3.33\%).\\
Rotor electrical frequency: f\textsubscript{r} = s × f = 0.0333 × 60 =
2.0 Hz.\\
Mechanical power: P\textsubscript{mech} = 15 HP × 746 W/HP = 11,190 W.\\
Rotor speed in rad/s: ω\textsubscript{r} = 1740 × 2π/60 = 182.2 rad/s.\\
Full-load torque: τ = P\textsubscript{mech} / ω\textsubscript{r} =
11,190 / 182.2 = 61.4 N·m.

\end{examplebox}

\subsection{12.2.2 Synchronous Motors}\label{synchronous-motors}

Synchronous motors operate at exactly synchronous speed
(n\textsubscript{s} = 120f/P) regardless of load, maintaining a fixed
relationship between rotor position and the rotating stator field. The
rotor is magnetized either by DC field windings fed through slip rings
(wound-rotor type) or by permanent magnets (PM synchronous motors), and
it locks in step with the rotating stator field. Synchronous motors can
operate at unity or leading power factor by adjusting the field
excitation (overexcited operation), making them useful for power factor
correction in industrial plants. Permanent magnet synchronous motors
(PMSMs) offer the highest efficiency and power density of any motor type
and are the preferred choice for electric vehicle traction drives,
industrial servo systems, and high-performance applications. Starting a
synchronous motor requires special provisions since it has no starting
torque at standstill -- methods include variable frequency drives (most
common), damper (amortisseur) windings that provide induction motor
starting torque, or an auxiliary starting motor.

\begin{examplebox}

\textbf{Example 12.2.2:} A 6-pole, three-phase synchronous motor
operates at 50 Hz. The motor is rated at 500 kW with an efficiency of
95\% and is running at unity power factor. The plant also has a 300 kVAR
inductive load from induction motors. Calculate the motor speed, the
line current at 4160 V, and the required excitation adjustment to
correct the entire plant power factor to unity.

\textbf{Solution:}\\
Synchronous speed: n\textsubscript{s} = 120f / P = 120 × 50 / 6 = 1,000
RPM.\\
Input power at rated load: P\textsubscript{in} = P\textsubscript{out} /
η = 500 / 0.95 = 526.3 kW.\\
At unity power factor: S = P = 526.3 kVA.\\
Line current: I\textsubscript{L} = S / (√3 × V\textsubscript{LL}) =
526,300 / (1.732 × 4160) = 526,300 / 7,205 = 73.0 A.\\
To correct the plant power factor to unity, the synchronous motor must
supply 300 kVAR of leading reactive power.\\
Required motor apparent power: S\textsubscript{motor} =
√(P\textsubscript{in}² + Q²) = √(526.3² + 300²) = √(277,012 + 90,000) =
√367,012 = 605.8 kVA.\\
New motor power factor: cos(φ) = 526.3 / 605.8 = 0.869 leading.\\
New motor line current: I\textsubscript{L} = 605,800 / (1.732 × 4160) =
84.1 A.\\
The field excitation must be increased (overexcited) to generate the
required leading reactive power.

\end{examplebox}

\subsection{12.2.3 Single-Phase Motors}\label{single-phase-motors}

Single-phase motors operate from standard single-phase AC power and are
used in residential and light commercial applications where three-phase
power is unavailable. A single-phase stator winding produces a pulsating
rather than rotating magnetic field, so auxiliary means are required to
create the phase shift needed for starting torque. Split-phase motors
use an auxiliary winding with higher resistance to create a phase
displacement, providing moderate starting torque for fans and blowers.
Capacitor-start motors add a series capacitor to the auxiliary winding
for improved starting torque (belt-driven equipment, compressors), and
capacitor-start-capacitor-run motors use two capacitors for both high
starting torque and improved running efficiency. Shaded-pole motors use
a copper shading band on a portion of each stator pole to create a small
phase shift, providing low starting torque at minimal cost for small
fans, timers, and light-duty applications. Permanent split-capacitor
(PSC) motors use a single run capacitor for both starting and running,
offering quiet operation and multiple speed capability for HVAC blowers
and fans.

\begin{examplebox}

\textbf{Example 12.2.3:} A capacitor-start single-phase induction motor
operates at 120 V, 60 Hz. The main winding has impedance
Z\textsubscript{m} = 6 + j8 Ω, and the auxiliary (start) winding has
impedance Z\textsubscript{aux} = 12 + j5 Ω. A start capacitor is in
series with the auxiliary winding. Calculate the capacitance needed to
place the auxiliary winding current exactly 90° ahead of the main
winding current for maximum starting torque.

\textbf{Solution:}\\
Main winding impedance angle: φ\textsubscript{m} = tan⁻¹(8/6) =
tan⁻¹(1.333) = 53.1°.\\
For the auxiliary current to lead the main current by 90°, the auxiliary
impedance angle must be: φ\textsubscript{aux} = 53.1° - 90° = -36.9°
(capacitive).\\
The auxiliary winding alone has: Z\textsubscript{aux} = 12 + j5 Ω.\\
Adding a series capacitor with reactance X\textsubscript{C}:
Z\textsubscript{total} = 12 + j(5 - X\textsubscript{C}).\\
For φ\textsubscript{aux} = -36.9°: tan(-36.9°) = (5 -
X\textsubscript{C}) / 12.\\
-0.750 = (5 - X\textsubscript{C}) / 12.\\
5 - X\textsubscript{C} = -9.00.\\
X\textsubscript{C} = 14.00 Ω.\\
Capacitance: C = 1 / (2πfX\textsubscript{C}) = 1 / (2π × 60 × 14.00) = 1
/ 5,278 = 189.5 μF.\\
A standard 200 μF start capacitor would be selected.

\end{examplebox}

\subsection{12.2.4 Reluctance Motors}\label{reluctance-motors}

Reluctance motors produce torque by exploiting the tendency of a
ferromagnetic rotor to align with the stator magnetic field to minimize
the magnetic circuit reluctance. The switched reluctance motor (SRM) has
salient poles on both the stator and rotor with concentrated windings on
the stator poles and no windings or magnets on the rotor, making it the
simplest and most robust motor construction. Each stator phase is
energized sequentially by a power electronic converter as the rotor
poles approach alignment, producing torque pulses that drive continuous
rotation. The synchronous reluctance motor (SynRM) uses a conventional
distributed stator winding (identical to an induction motor stator) with
a specially designed rotor that has flux barriers punched into the
laminations to create a high saliency ratio
(L\textsubscript{d}/L\textsubscript{q}), and it operates at synchronous
speed when driven by a VFD. SynRM motors achieve IE4 (super-premium) or
IE5 efficiency levels without rare-earth permanent magnets, making them
attractive for industrial pumps, fans, and compressors where magnet cost
and supply-chain concerns are factors.

\begin{examplebox}

\textbf{Example 12.2.4:} A 4-pole synchronous reluctance motor operates
from a 60 Hz VFD supply. The motor has a d-axis inductance
L\textsubscript{d} = 120 mH and a q-axis inductance L\textsubscript{q} =
20 mH. The rated stator current is 10 A. Calculate the synchronous
speed, the saliency ratio, and the maximum reluctance torque per phase
using the torque equation τ = (3/2) × (P/2) × (L\textsubscript{d} -
L\textsubscript{q}) × I\textsubscript{d} × I\textsubscript{q}, where the
maximum torque occurs at I\textsubscript{d} = I\textsubscript{q} =
I\textsubscript{s}/√2.

\textbf{Solution:}\\
Synchronous speed: n\textsubscript{s} = 120f / P = 120 × 60 / 4 = 1,800
RPM.\\
Saliency ratio: ξ = L\textsubscript{d} / L\textsubscript{q} = 120 / 20 =
6.0.\\
For maximum torque: I\textsubscript{d} = I\textsubscript{q} =
I\textsubscript{s} / √2 = 10 / 1.414 = 7.07 A.\\
Maximum torque: τ = (3/2) × (P/2) × (L\textsubscript{d} -
L\textsubscript{q}) × I\textsubscript{d} × I\textsubscript{q} = 1.5 × 2
× (0.120 - 0.020) × 7.07 × 7.07 = 1.5 × 2 × 0.100 × 50.0 = 15.0 N·m.\\
Mechanical power at rated speed: P\textsubscript{mech} = τ × ω = 15.0 ×
(1800 × 2π/60) = 15.0 × 188.5 = 2,827 W = 2.83 kW.

\end{examplebox}

\subsection{12.2.5 Linear Motors}\label{linear-motors}

A linear motor produces force and motion in a straight line rather than
rotational torque, effectively an ``unrolled'' version of a conventional
rotary motor. The \textbf{linear induction motor (LIM)} consists of a
flat stator (primary) with three-phase windings that produce a traveling
magnetic field, and a conductive plate or rail (secondary, typically
aluminum backed by steel) in which eddy currents are induced --- the
interaction between the traveling field and the induced currents
produces a thrust force along the direction of travel. The synchronous
speed of the traveling field is v\textsubscript{s} =
2τ\textsubscript{p}f, where τ\textsubscript{p} is the pole pitch and f
is the supply frequency. The \textbf{linear synchronous motor (LSM)}
uses either permanent magnets or electromagnets on the moving part (or
the track) to lock in step with the stator's traveling field, providing
higher efficiency and force density than LIMs. Linear motors eliminate
mechanical transmission elements (gearboxes, ball screws, belts,
rack-and-pinion), achieving zero backlash, very high speeds
(\textgreater500 km/h for maglev trains), and sub-micrometer positioning
accuracy in precision applications. \textbf{Applications} include
magnetic levitation (maglev) trains (Shanghai Transrapid at 431 km/h,
SCMaglev at 603 km/h), semiconductor lithography stages (nanometer-level
positioning), baggage handling and people movers (airport transit),
roller coaster launch systems, and high-speed pick-and-place machines.
The main design challenges are the large air gap (compared to rotary
motors), end effects that reduce thrust at the edges of the primary, and
the need for linear position feedback (linear encoders or laser
interferometers) for closed-loop control.

\begin{examplebox}

\textbf{Example 12.2.5:} A linear synchronous motor for a semiconductor
wafer stage has a pole pitch of τ\textsubscript{p} = 24 mm, a peak force
constant of K\textsubscript{f} = 180 N/A, a moving mass of 12 kg, and a
linear encoder with 1 nm resolution. The stage must accelerate at 50
m/s² to a peak velocity of 2 m/s. Calculate the thrust force required
for acceleration, the peak current, and the electrical frequency at peak
velocity.

\textbf{Solution:}\\
Thrust force for acceleration: F = ma = 12 × 50 = 600 N.\\
Adding 20 N for friction and cable drag: F\textsubscript{total} = 620
N.\\
Peak current: I = F\textsubscript{total}/K\textsubscript{f} = 620/180 =
3.44 A.\\
Electrical frequency at peak velocity: f = v/(2τ\textsubscript{p}) =
2.0/(2 × 0.024) = 41.7 Hz.\\
Acceleration time to peak velocity: t = v/a = 2.0/50 = 40 ms.\\
Distance during acceleration: d = ½at² = ½ × 50 × 0.04² = 0.04 m = 40
mm.\\
At constant velocity (2 m/s), the continuous thrust needed is only
\textasciitilde20 N (friction), requiring I = 20/180 = 0.11 A ---
demonstrating that linear motors for positioning are dominated by
acceleration forces, not steady-state loads.\\
The 1 nm encoder resolution provides position feedback far finer than
the \textasciitilde10 nm positioning accuracy achievable by the servo
controller.

\end{examplebox}

\subsection{12.2.6 Wound-Rotor Induction
Motors}\label{wound-rotor-induction-motors}

A wound-rotor induction motor replaces the squirrel-cage rotor with a
three-phase winding connected to external circuits through slip rings
and brushes, providing direct access to the rotor circuit for speed and
torque control. By inserting external resistance in series with the
rotor windings, the motor's torque-speed characteristic is reshaped:
increasing rotor resistance shifts the maximum (breakdown) torque to a
lower speed without changing its magnitude, allowing full breakdown
torque to be available at standstill for heavy starting loads. This
makes wound-rotor motors ideal for \textbf{crane and hoist applications}
where high starting torque at low speed is essential, \textbf{large
compressors and mills} where smooth, high-torque starting reduces
mechanical stress, and \textbf{slip-energy recovery systems} (Scherbius
drives) where the rotor slip power is recovered and fed back to the
supply through a power electronic converter rather than wasted as heat
in resistors. The rotor current at any slip s is I₂ = sE₂ /
√(R₂\textsubscript{total}² + (sX₂)²), where E₂ is the standstill rotor
EMF, R₂\textsubscript{total} is the rotor resistance plus external
resistance, and X₂ is the rotor leakage reactance. The slip at maximum
torque shifts proportionally to the total rotor resistance:
s\textsubscript{max} = R₂\textsubscript{total} / X₂, while the breakdown
torque remains constant: T\textsubscript{max} = 3V₁² /
(2ω\textsubscript{s}(X₁ + X₂)), independent of rotor resistance. Modern
applications increasingly replace external resistor banks with
rotor-side converters that provide stepless speed control and
regenerative braking capability, combining the starting advantages of
wound-rotor motors with the efficiency of electronic control.

\begin{examplebox}

\textbf{Example 12.2.6:} A 6-pole, 60 Hz wound-rotor induction motor has
a standstill rotor EMF of E₂ = 200 V (line-to-line), rotor resistance R₂
= 0.3 Ω per phase, and rotor leakage reactance X₂ = 1.5 Ω per phase.
Calculate the slip at maximum torque with no external resistance, then
determine the external resistance per phase needed to achieve maximum
torque at standstill (s = 1) for a heavy crane lift.

\textbf{Solution:}\\
Synchronous speed: n\textsubscript{s} = 120 × 60 / 6 = 1,200 RPM.\\
Slip at maximum torque (no external resistance): s\textsubscript{max} =
R₂/X₂ = 0.3/1.5 = 0.2 (20\%).\\
Speed at max torque: n = n\textsubscript{s}(1 − s\textsubscript{max}) =
1,200 × 0.8 = 960 RPM.\\
For maximum torque at standstill (s = 1): s\textsubscript{max} =
R₂\textsubscript{total}/X₂ = 1, so R₂\textsubscript{total} = X₂ = 1.5 Ω
per phase.\\
External resistance needed: R\textsubscript{ext} =
R₂\textsubscript{total} − R₂ = 1.5 − 0.3 = 1.2 Ω per phase.\\
Rotor current at starting with external resistance: I₂ = E₂/(√3 ×
√(R₂\textsubscript{total}² + X₂²)) = 200/(1.732 × √(1.5² + 1.5²)) =
200/(1.732 × 2.121) = 200/3.674 = 54.4 A per phase.\\
Without external resistance, starting current would be: I₂ = 200/(1.732
× √(0.3² + 1.5²)) = 200/(1.732 × 1.530) = 75.5 A --- higher current but
lower starting torque.\\
The external resistance reduces starting current by 28\% while
increasing starting torque to the maximum possible value.\\
During the lift, the resistors are progressively shorted out in steps as
the motor accelerates, until at full speed all external resistance is
bypassed and the motor runs as a standard induction motor.

\end{examplebox}

\section{12.3 Stepper Motors}\label{stepper-motors}

Stepper motors are a class of brushless DC motor designed for precise,
incremental position control. Unlike continuous-rotation motors that are
characterized by speed and torque, stepper motors are defined by their
step angle, holding torque, and dynamic torque-speed curve. They operate
in open-loop mode without position feedback, relying on the discrete
nature of their steps to maintain positional accuracy, which makes them
simpler and less expensive than closed-loop servo systems for
moderate-precision applications.

\subsection{12.3.1 Types and Operation}\label{types-and-operation}

Stepper motors are brushless DC motors that divide a full rotation into
a large number of discrete, equal steps, enabling precise open-loop
position control without feedback sensors. Permanent magnet steppers use
a permanent magnet rotor and produce relatively low torque at low cost,
suitable for light-duty positioning. Variable reluctance steppers use a
soft iron rotor with salient poles that align with the energized stator
poles to minimize reluctance, offering fast response but lower torque.
Hybrid stepper motors combine both principles --- a permanent magnet
rotor with fine teeth on its surface --- providing the highest step
resolution (typically 200 steps/revolution or 1.8° per step) and the
best torque characteristics. When a stator phase is energized, the rotor
moves to align with the resulting magnetic field; sequentially
energizing phases causes the rotor to advance one step at a time.

\begin{examplebox}

\textbf{Example 12.3.1:} A hybrid stepper motor has 200 steps per
revolution and a rated phase current of 2.0 A. The holding torque is
specified as 1.8 N·m, and the detent torque is 0.12 N·m. If the motor
must rotate exactly 36°, determine the number of full steps required,
the step angle, and the maximum load torque that can be applied without
losing steps (assume a safety margin of 50\%).

\textbf{Solution:}\\
Step angle: θ\textsubscript{step} = 360° / 200 = 1.8° per step.\\
Steps for 36° rotation: N = 36° / 1.8° = 20 full steps.\\
The pull-out torque (dynamic) decreases with speed, but at low speed it
approaches the holding torque.\\
With a 50\% safety margin, maximum load torque:
τ\textsubscript{load(max)} = 0.50 × τ\textsubscript{holding} = 0.50 ×
1.8 = 0.90 N·m.\\
Position accuracy (open-loop): typical non-cumulative error is ±5\% of
one step = ±0.05 × 1.8° = ±0.09°.\\
After 20 steps, the worst-case cumulative position error remains ±0.09°
since the error is non-cumulative for a properly loaded stepper motor.

\end{examplebox}

\subsection{12.3.2 Drive Modes}\label{drive-modes}

Full-step mode energizes one or two phases at a time, advancing the
motor one full step per commutation event (typically 1.8° for a 200-step
motor). Half-step mode alternates between one-phase and two-phase
energization, doubling the number of steps per revolution to 400 (0.9°
per step) with improved smoothness at the cost of slightly unequal
torque between half-step positions. Microstepping uses sinusoidal
current waveforms to subdivide each full step into smaller increments
(typically 4, 8, 16, 32, 64, or 256 microsteps per full step),
dramatically improving motion smoothness, reducing vibration and
resonance, and enabling step resolutions of 0.007° or finer.
Microstepping requires a chopper-type current-regulated driver that
precisely controls the current amplitude in each winding according to a
sinusoidal profile. Common stepper driver ICs (such as the A4988,
DRV8825, and TMC2209) integrate the current regulation, microstepping
sequencer, and protection functions into a single package.

\begin{examplebox}

\textbf{Example 12.3.2:} A stepper motor with 200 full steps/revolution
is driven with 16× microstepping. The motor drives a lead screw with a
pitch of 2 mm/revolution. Calculate the linear resolution per microstep,
the pulse frequency needed for a linear speed of 50 mm/s, and the number
of pulses for a 25.4 mm (1 inch) move.

\textbf{Solution:}\\
Microsteps per revolution: 200 × 16 = 3,200 microsteps/rev.\\
Linear distance per microstep: d = pitch / microsteps per rev = 2 mm /
3,200 = 0.000625 mm = 0.625 μm per microstep.\\
Revolutions per second for 50 mm/s: n = 50 mm/s / 2 mm/rev = 25 rev/s.\\
Pulse frequency: f\textsubscript{pulse} = 25 rev/s × 3,200 pulses/rev =
80,000 Hz = 80 kHz.\\
Pulses for 25.4 mm: N = 25.4 / 0.000625 = 40,640 pulses.\\
Travel time at 50 mm/s: t = 25.4 / 50 = 0.508 s.\\
Verification: 40,640 / 80,000 = 0.508 s -- confirmed.

\end{examplebox}

\subsection{12.3.3 Applications}\label{applications}

Stepper motors are widely used in applications requiring precise,
repeatable positioning without the cost and complexity of closed-loop
servo systems. CNC machines and 3D printers use stepper motors on each
axis to position the tool or print head with sub-millimeter accuracy.
Textile machines, pick-and-place equipment, and automated pipetting
systems rely on steppers for accurate, programmable motion profiles.
Camera focus and zoom mechanisms, robotic joints, and antenna
positioners use steppers for their ability to hold position with full
torque when stationary (holding torque). The main limitations of stepper
motors are reduced torque at high speeds (due to back-EMF and
inductance), the potential for missed steps under excessive load (since
there is no position feedback in open-loop operation), and audible noise
and vibration at certain step rates (resonance), which microstepping and
proper driver tuning help mitigate.

\begin{examplebox}

\textbf{Example 12.3.3:} A 3D printer uses a NEMA 17 stepper motor
(1.8°/step, holding torque 0.44 N·m) to drive the X-axis via a GT2
timing belt with a 20-tooth pulley (2 mm belt pitch). The print head
mass is 0.3 kg and the desired maximum acceleration is 3,000 mm/s².
Calculate the linear resolution in full-step mode, the force and torque
required for acceleration, and whether the motor has adequate torque.

\textbf{Solution:}\\
Pulley circumference: C = 20 teeth × 2 mm/tooth = 40 mm/rev.\\
Linear distance per step: d = 40 mm / 200 steps = 0.200 mm per step (200
μm resolution).\\
Force for acceleration: F = m × a = 0.3 × 3.0 = 0.9 N.\\
Add friction (estimate 0.5 N): F\textsubscript{total} ≈ 1.4 N.\\
Torque at motor: τ = F\textsubscript{total} × r\textsubscript{pulley} =
1.4 × (40 / 2π) / 1000 = 1.4 × 6.366 × 10⁻³ = 8.9 × 10⁻³ N·m = 8.9
mN·m.\\
Maximum speed: typical 150 mm/s = 150/40 = 3.75 rev/s = 750 steps/s.\\
At this speed, available torque is typically 50--70\% of holding torque:
τ\textsubscript{available} ≈ 0.6 × 0.44 = 0.264 N·m, far exceeding the
required 8.9 mN·m.\\
The motor is more than adequate.

\end{examplebox}

\subsection{12.3.4 Stepper Motor Resonance and Torque
Curves}\label{stepper-motor-resonance-and-torque-curves}

Stepper motors exhibit speed-dependent torque characteristics and
resonance phenomena that are critical to reliable operation. The
\textbf{pull-in torque curve} defines the maximum load torque at which
the motor can start and synchronize without missing steps at a given
step rate --- it decreases with increasing speed because the windings
have limited time to reach full current during each step (due to the L/R
electrical time constant). The \textbf{pull-out torque curve} defines
the maximum load torque the motor can sustain while running at a given
speed --- it is always higher than the pull-in torque because the rotor
has momentum. Between these curves is a ``slew range'' where the motor
can run but cannot start directly; it must be ramped up from a lower
speed. \textbf{Mid-band resonance} occurs at a characteristic speed
(typically 100--400 full steps/s for NEMA 17/23 motors) where the rotor
oscillation frequency matches the motor's natural mechanical resonance
f\textsubscript{n} = (1/2π)√(K\textsubscript{h}/J), where
K\textsubscript{h} is the holding torque stiffness and J is the total
moment of inertia. At resonance, the rotor oscillates violently, causing
missed steps, excessive vibration, and audible noise. Mitigation
strategies include: microstepping (distributes the energy impulses more
smoothly), adding external damping (viscous dampers), avoiding the
resonant speed range in the acceleration profile, increasing the rotor
inertia (adding a flywheel, which shifts resonance to a lower
frequency), and using advanced driver features such as StealthChop (TMC
drivers) that shape the current waveform for quiet operation. The
motor's \textbf{detent torque} (cogging torque when unpowered) also
contributes to vibration in variable-reluctance and hybrid steppers.

\begin{examplebox}

\textbf{Example 12.3.4:} A NEMA 23 hybrid stepper motor has a rotor
inertia of J\textsubscript{rotor} = 300 g·cm² (3.0 × 10⁻⁵ kg·m²), a
holding torque of 1.9 N·m, and drives a load with a reflected inertia of
J\textsubscript{load} = 200 g·cm² (2.0 × 10⁻⁵ kg·m²). The step angle is
1.8°. Estimate the natural resonant frequency and the corresponding step
rate. If the pull-out torque at 1,000 steps/s is 0.8 N·m, determine the
maximum continuous load torque at that speed with a 50\% safety margin.

\textbf{Solution:}\\
Total inertia: J\textsubscript{total} = J\textsubscript{rotor} +
J\textsubscript{load} = 3.0 × 10⁻⁵ + 2.0 × 10⁻⁵ = 5.0 × 10⁻⁵ kg·m².\\
Holding torque stiffness: K\textsubscript{h} = T\textsubscript{hold} /
θ\textsubscript{step} = 1.9 / (1.8 × π/180) = 1.9 / 0.03142 = 60.5
N·m/rad.\\
Natural frequency: f\textsubscript{n} = (1/2π)√(K\textsubscript{h}/J) =
(1/2π)√(60.5 / 5.0 × 10⁻⁵) = (1/2π)√(1.21 × 10⁶) = (1/2π) × 1100 = 175
Hz.\\
Resonant step rate: 175 full steps/s (since each step excites the
resonance).\\
At 1.8°/step: resonant speed = 175 × 1.8 / 360 × 60 = 52.5 RPM.\\
The acceleration profile should ramp quickly through the 150--200
steps/s region.\\
Maximum continuous load at 1,000 steps/s: T\textsubscript{max} = 0.50 ×
0.8 = 0.4 N·m.\\
The speed at 1,000 steps/s is 1000 × 1.8 / 360 × 60 = 300 RPM.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-12-3-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch12_stepper_torque.png}

\caption{Figure 12.3.4: Stepper Motor Torque vs Speed}

\end{figure}

\section{12.4 Motor Control}\label{motor-control}

Motor control encompasses the power electronic circuits and control
algorithms used to start, stop, regulate speed, and control torque of
electric motors. The choice of control method depends on the motor type,
the application's performance requirements, and cost constraints.
Variable frequency drives (VFDs) provide full speed control for AC
motors, servo systems deliver precise position and velocity tracking for
high-performance motion applications, and soft starters offer a
cost-effective solution for reducing inrush current during motor
starting.

\subsection{12.4.1 Variable Frequency Drives
(VFD)}\label{variable-frequency-drives-vfd}

Variable Frequency Drives control the speed of AC motors by converting
fixed-frequency mains power to variable-frequency, variable-voltage
output. A typical VFD consists of a rectifier (AC to DC), a DC bus with
filter capacitors, and a three-phase PWM inverter that synthesizes the
variable-frequency AC output. The motor speed is controlled by varying
the output frequency, and the voltage is adjusted proportionally to
maintain constant flux (V/f ratio) for consistent torque throughout the
speed range. Modern VFDs implement vector control (field-oriented
control, or FOC) algorithms that independently control the
torque-producing and flux-producing components of the stator current,
enabling precise torque and speed control rivaling DC drives. VFDs
reduce energy consumption by 20--50\% in variable-torque applications
(fans, pumps, compressors) compared to throttling or damper control, and
they provide soft starting, regenerative braking, and multiple motor
protection functions.

\begin{examplebox}

\textbf{Example 12.4.1:} A 4-pole, 460 V, 60 Hz induction motor rated at
50 HP drives a centrifugal pump. The motor must be operated at 45 Hz to
reduce flow. Using constant V/f control, calculate the new operating
speed, the voltage applied by the VFD, and the approximate power savings
(pump power varies as the cube of speed).

\textbf{Solution:}\\
Base speed at 60 Hz: n\textsubscript{s} = 120 × 60 / 4 = 1,800 RPM.\\
New synchronous speed at 45 Hz: n\textsubscript{s(new)} = 120 × 45 / 4 =
1,350 RPM.\\
Constant V/f ratio: V/f = 460/60 = 7.667 V/Hz.\\
New voltage: V\textsubscript{new} = 7.667 × 45 = 345.0 V.\\
Speed ratio: n\textsubscript{new}/n\textsubscript{base} ≈ 1350/1800 =
0.75.\\
Power ratio for a centrifugal pump (affinity law):
P\textsubscript{new}/P\textsubscript{base} =
(n\textsubscript{new}/n\textsubscript{base})³ = 0.75³ = 0.4219.\\
New power: P\textsubscript{new} = 50 × 0.4219 = 21.1 HP.\\
Power savings: 50 - 21.1 = 28.9 HP (57.8\% reduction).\\
Energy cost savings at \$0.10/kWh running 8,000 hrs/yr: Savings = 28.9 ×
0.746 × 8000 × 0.10 = \$17,248/yr.

\end{examplebox}

\subsection{12.4.2 Servo Systems}\label{servo-systems}

A servo system is a closed-loop motor control system that uses position,
velocity, and/or current feedback to precisely track a commanded
trajectory. The system typically consists of a servo motor (BLDC or
PMSM), a position/velocity feedback device (encoder or resolver), a
servo drive (current-regulated inverter with control algorithms), and a
motion controller that generates the desired trajectory. The control
loop hierarchy includes an inner current loop (fastest, typically 10-20
kHz bandwidth), a velocity loop (intermediate, 100-500 Hz bandwidth),
and a position loop (outermost, 10-100 Hz bandwidth), each tuned using
PID or advanced control algorithms. Servo systems provide high dynamic
response, precise positioning (sub-micrometer in precision
applications), and the ability to follow complex multi-axis coordinated
motion profiles. Applications include CNC machining, robotics,
semiconductor manufacturing, packaging machinery, and any application
requiring accurate, responsive motion control.

\begin{examplebox}

\textbf{Example 12.4.2:} A servo motor with a 2,500-line incremental
encoder (quadrature decoded) drives a ball screw with a 5 mm pitch
through a 3:1 gear reduction. The required positioning accuracy is ±5
μm. Determine the encoder resolution in counts per revolution, the
linear resolution, and whether the system meets the accuracy
requirement.

\textbf{Solution:}\\
Quadrature decoding multiplies the encoder lines by 4: counts/rev =
2,500 × 4 = 10,000 counts/rev at the motor shaft.\\
With 3:1 gear reduction, counts per revolution at the ball screw: 10,000
× 3 = 30,000 counts/rev (at the output).\\
Linear resolution per count: d = ball screw pitch / counts per screw rev
= 5 mm / 30,000 = 0.000167 mm = 0.167 μm per count.\\
Since 0.167 μm \textless\textless{} ±5 μm, the encoder resolution is far
finer than the required accuracy.\\
The positioning accuracy will be limited by mechanical factors (ball
screw backlash, typically 5-20 μm; thermal expansion; bearing play)
rather than encoder resolution.\\
With a preloaded ball screw (zero backlash) and proper servo tuning, the
±5 μm target is achievable.

\end{examplebox}

\subsection{12.4.3 Soft Starters}\label{soft-starters}

Soft starters limit the inrush current and mechanical stress during the
starting of AC induction motors by gradually ramping the applied voltage
from a reduced level to full voltage over a programmable time period.
They use back-to-back thyristors (SCRs) in each phase to control the
voltage applied to the motor by varying the firing angle, similar to a
phase-controlled AC voltage controller. During starting, the reduced
voltage limits the current to typically 2--4× the full-load current,
compared to 6--8× for direct-on-line (DOL) starting. Soft starters also
provide controlled deceleration (soft stop) by gradually reducing the
voltage, which is beneficial for pump applications where sudden stopping
causes water hammer. While less expensive and simpler than VFDs, soft
starters do not provide continuous speed control -- they are used only
during starting and stopping, with the motor running at full speed
during normal operation.

\begin{examplebox}

\textbf{Example 12.4.3:} A 100 HP, 460 V, 3-phase induction motor has a
full-load current of I\textsubscript{FL} = 124 A and a DOL starting
current of 6× I\textsubscript{FL}. A soft starter is configured to limit
starting current to 3× I\textsubscript{FL} with a ramp time of 10
seconds. Calculate the DOL inrush current, the soft-start limited
current, and the initial voltage applied by the soft starter.

\textbf{Solution:}\\
DOL starting current: I\textsubscript{start(DOL)} = 6 ×
I\textsubscript{FL} = 6 × 124 = 744 A.\\
Soft-start limited current: I\textsubscript{start(soft)} = 3 ×
I\textsubscript{FL} = 3 × 124 = 372 A.\\
Since motor starting current is approximately proportional to applied
voltage, the initial voltage ratio: V\textsubscript{initial} /
V\textsubscript{rated} = I\textsubscript{start(soft)} /
I\textsubscript{start(DOL)} = 372 / 744 = 0.50.\\
Initial voltage: V\textsubscript{initial} = 0.50 × 460 = 230 V.\\
The soft starter ramps the voltage from 230 V to 460 V over 10
seconds.\\
Starting torque reduction: since torque is proportional to voltage
squared, the initial torque is (0.50)² = 0.25 or 25\% of DOL starting
torque.\\
This is adequate for centrifugal pumps and fans (which require low
starting torque) but may be insufficient for high-inertia or
loaded-start applications.

\end{examplebox}

\subsection{12.4.4 Regenerative Braking}\label{regenerative-braking}

Regenerative braking occurs when a motor operates as a generator,
converting the kinetic energy of the load back into electrical energy to
decelerate the system. In a VFD-driven application, regeneration happens
when the motor speed exceeds the synchronous speed set by the drive (the
load is driving the motor), causing power to flow from the motor back to
the DC bus. Standard VFDs cannot return energy to the AC mains because
their front-end diode rectifiers are unidirectional, so a braking
resistor on the DC bus dissipates the regenerated energy as heat. Active
front-end (AFE) VFDs replace the diode rectifier with an IGBT-based
converter that can return power to the grid, achieving true
four-quadrant operation (motoring and braking in both directions).
Electric vehicles use regenerative braking extensively, recovering
10--30\% of the energy that would otherwise be lost as heat in friction
brakes, with the recovered energy stored in the battery. The braking
torque available from regeneration depends on the generator back-EMF,
the DC bus voltage limits, and the power electronics current rating.

\begin{examplebox}

\textbf{Example 12.4.4:} An electric vehicle with a mass of 1,800 kg is
traveling at 80 km/h (22.2 m/s) and decelerates to 20 km/h (5.56 m/s)
using regenerative braking. The motor/generator efficiency during
regeneration is 88\%, and the battery charging efficiency is 95\%.
Calculate the kinetic energy recovered, the energy stored in the
battery, and the average regenerative braking power if the deceleration
takes 8 seconds.

\textbf{Solution:}\\
Initial kinetic energy: KE₁ = ½mv² = 0.5 × 1800 × 22.2² = 0.5 × 1800 ×
492.84 = 443,556 J = 443.6 kJ.\\
Final kinetic energy: KE₂ = 0.5 × 1800 × 5.56² = 0.5 × 1800 × 30.9 =
27,810 J = 27.8 kJ.\\
Energy available for recovery: ΔKE = 443,556 - 27,822 = 415,734 J =
415.7 kJ.\\
Energy stored in battery: E\textsubscript{stored} = ΔKE ×
η\textsubscript{motor} × η\textsubscript{battery} = 415.7 × 0.88 × 0.95
= 347.6 kJ.\\
Recovery efficiency: η\textsubscript{total} = 347.6 / 415.7 = 83.6\%.\\
Average regenerative braking power: P\textsubscript{avg} = ΔKE / t =
415,700 / 8 = 51,963 W ≈ 52.0 kW.\\
Average braking force: F = P\textsubscript{avg} / v\textsubscript{avg} =
52,000 / ((22.2 + 5.56)/2) = 52,000 / 13.89 = 3,744 N.

\end{examplebox}

\subsection{12.4.5 Field-Oriented Control
(FOC)}\label{field-oriented-control-foc}

Field-oriented control (FOC), also called vector control, is an advanced
motor control technique that decouples the torque-producing and
flux-producing components of the stator current, enabling independent
control of motor torque and flux similar to a separately excited DC
motor. In an AC induction or synchronous motor, the stator current
vector is resolved into two orthogonal components in a rotating
reference frame aligned with the rotor flux: the d-axis (direct)
component I\textsubscript{d} controls the rotor flux magnitude, and the
q-axis (quadrature) component I\textsubscript{q} controls the torque.
This decomposition requires knowledge of the rotor flux angle, obtained
either from a shaft encoder (direct or sensored FOC) or estimated from
the motor voltage and current measurements using an observer algorithm
(indirect or sensorless FOC). The Park transform converts three-phase
stator quantities (abc) to the two-axis rotating frame (dq) through the
intermediate Clarke transform (abc → αβ), and inverse transforms convert
the dq-frame voltage commands back to three-phase PWM duty cycles for
the inverter. FOC achieves fast dynamic torque response
(millisecond-level step changes), smooth low-speed operation down to
zero speed, and near-optimal efficiency by maintaining the flux at its
rated value during normal operation and reducing it during light loads
(flux weakening). It is the standard control method for high-performance
drives in electric vehicles, industrial robots, machine tools, and
elevator systems.

\begin{examplebox}

\textbf{Example 12.4.5:} A 4-pole (P = 4), 3-phase PMSM has the
following parameters: rated torque T\textsubscript{rated} = 12 N·m,
torque constant K\textsubscript{t} = 1.5 N·m/A, rated flux linkage
λ\textsubscript{m} = 0.25 Wb, stator resistance R\textsubscript{s} = 0.5
Ω, d-axis inductance L\textsubscript{d} = 8 mH, q-axis inductance
L\textsubscript{q} = 12 mH, and the motor operates at 1,500 RPM. Using
FOC with I\textsubscript{d} = 0 control (simplified --- for a true IPM
motor, MTPA shifts I\textsubscript{d} negative, but I\textsubscript{d} =
0 is used here for clarity), calculate the required q-axis current, the
stator voltage magnitude, and the inverter DC bus voltage needed.

\textbf{Solution:}\\
Required q-axis current for rated torque: I\textsubscript{q} =
T\textsubscript{rated} / K\textsubscript{t} = 12 / 1.5 = 8.0 A.\\
With I\textsubscript{d} = 0, the stator current magnitude is:
I\textsubscript{s} = √(I\textsubscript{d}² + I\textsubscript{q}²) = √(0
+ 64) = 8.0 A.\\
Electrical speed: ω\textsubscript{e} = (P/2) × ω\textsubscript{m}. For a
4-pole motor (P = 4): ω\textsubscript{m} = 1500 × 2π/60 = 157.1 rad/s,
ω\textsubscript{e} = 2 × 157.1 = 314.2 rad/s.\\
Voltage equations in the dq frame:\\
V\textsubscript{d} = R\textsubscript{s} × I\textsubscript{d} -
ω\textsubscript{e} × L\textsubscript{q} × I\textsubscript{q} = 0.5 × 0 -
314.2 × 0.012 × 8.0 = -30.2 V.\\
V\textsubscript{q} = R\textsubscript{s} × I\textsubscript{q} +
ω\textsubscript{e} × L\textsubscript{d} × I\textsubscript{d} +
ω\textsubscript{e} × λ\textsubscript{m} = 0.5 × 8.0 + 0 + 314.2 × 0.25 =
4.0 + 78.6 = 82.6 V.\\
Stator voltage magnitude: V\textsubscript{s} = √(V\textsubscript{d}² +
V\textsubscript{q}²) = √(912.0 + 6,822.8) = √7,734.8 = 87.9 V (phase
peak).\\
Minimum DC bus voltage (for space vector PWM): V\textsubscript{DC} = √3
× V\textsubscript{s} = √3 × 87.9 = 152.3 V.\\
A 160 V or higher DC bus is required.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-12-4-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch12_foc_vectors.png}

\caption{Figure 12.4.5: FOC Vector Diagram}

\end{figure}

\subsection{12.4.6 Direct Torque Control
(DTC)}\label{direct-torque-control-dtc}

Direct torque control (DTC) is an alternative to field-oriented control
that directly controls the motor's stator flux magnitude and
electromagnetic torque without requiring a rotor position sensor or
coordinate transformations (Park/Clarke). DTC estimates the stator flux
vector and instantaneous torque from measured stator voltages and
currents using a voltage model integrator: ψ\textsubscript{s} =
∫(V\textsubscript{s} − R\textsubscript{s}I\textsubscript{s})dt, and
torque is computed as T\textsubscript{e} =
(3/2)(P/2)(ψ\textsubscript{sα}I\textsubscript{sβ} −
ψ\textsubscript{sβ}I\textsubscript{sα}). Two hysteresis comparators ---
one for flux error and one for torque error --- compare the estimated
values against their references, producing binary outputs that feed an
optimal switching table to select one of six active voltage vectors (or
two zero vectors) from the inverter. This bang-bang control structure
achieves extremely fast torque response (typically 1--2 ms, compared to
5--10 ms for FOC) because the inverter switching state is updated at
every control cycle (typically 25--40 kHz sampling) without the delay of
PWM modulation. The main drawback of classical DTC is variable switching
frequency and higher torque ripple compared to FOC, because the
hysteresis bands produce irregular switching patterns. Modern DTC
implementations (such as ABB's Direct Torque Control platform) address
this with model-predictive extensions that optimize switching sequences
over a prediction horizon, reducing torque ripple while maintaining the
fast dynamic response. DTC is used in high-performance industrial drives
for cranes, winders, rolling mills, and traction applications where
rapid torque changes are critical.

\begin{examplebox}

\textbf{Example 12.4.6:} A DTC-controlled 4-pole induction motor has the
following parameters: stator resistance R\textsubscript{s} = 0.4 Ω,
rated stator flux ψ\textsubscript{s,ref} = 0.85 Wb, DC bus voltage
V\textsubscript{DC} = 540 V, and the flux hysteresis band is ±0.02 Wb
and the torque hysteresis band is ±2 N·m. At a given instant, the
estimated flux is ψ\textsubscript{s} = 0.83 Wb and the estimated torque
is T\textsubscript{e} = 48 N·m, while the torque reference is 55 N·m.
Determine the hysteresis comparator outputs and the required inverter
action.

\textbf{Solution:}\\
Flux error: Δψ = ψ\textsubscript{s,ref} − ψ\textsubscript{s} = 0.85 −
0.83 = 0.02 Wb.\\
Since Δψ = +0.02 Wb equals the upper hysteresis limit, the flux
comparator output is +1 (increase flux).\\
Torque error: ΔT = T\textsubscript{ref} − T\textsubscript{e} = 55 − 48 =
7 N·m.\\
Since ΔT = +7 N·m exceeds the +2 N·m band, the torque comparator output
is +1 (increase torque).\\
With flux = +1, torque = +1, and the current flux sector (determined
from the flux angle), the optimal switching table selects a voltage
vector that both increases the flux magnitude and advances the flux
vector in the direction of rotation --- this simultaneously corrects the
flux deficit and increases torque.\\
The magnitude of each active voltage vector is V\textsubscript{DC} ×
√(2/3) = 540 × 0.816 = 441 V.\\
The torque will increase rapidly (within 1--2 switching cycles at 25
kHz, or \textasciitilde40--80 μs) until it enters the hysteresis band
around the 55 N·m reference, at which point the controller switches to
zero vectors or retarding vectors to maintain the torque within ±2 N·m.

\end{examplebox}

\subsection{12.4.7 Sensorless Motor
Control}\label{sensorless-motor-control}

Sensorless motor control eliminates the mechanical position and speed
sensors (encoders, resolvers, Hall effect sensors) from the motor drive
system by estimating rotor position and velocity from electrical
measurements alone. Removing these sensors reduces cost, eliminates a
common failure point (encoder cables and connectors are vulnerable to
vibration, contamination, and EMI), and enables motor operation in harsh
environments such as submersible pumps, sealed compressors, and
high-temperature applications where sensors cannot survive. The two
fundamental challenges are achieving accurate estimation across the full
speed range and maintaining stability during transient load changes.

\textbf{Back-EMF sensing} is the simplest sensorless technique, used
primarily with BLDC motors under trapezoidal commutation. During
six-step commutation, one of the three motor phases is always
unenergized (floating), and the back-EMF zero-crossing on that phase
indicates the rotor position midpoint between two commutation states.
The actual commutation is delayed by 30 electrical degrees from the
zero-crossing to align with the optimal switching instant. This method
works well above approximately 10--15\% of rated speed, where the
back-EMF signal is large enough to detect reliably, but fails at
standstill and very low speeds because the back-EMF magnitude is
proportional to speed: E\textsubscript{back} = K\textsubscript{e} × ω.

\textbf{Model-based observers} estimate the rotor flux angle and speed
from measured stator voltages and currents using mathematical models of
the motor. The \textbf{Luenberger observer} implements a state-space
model of the motor with correction terms proportional to the estimation
error: x̂̇ = Ax̂ + Bu + L(y − Cx̂), where L is the observer gain matrix
tuned for the desired convergence rate. The \textbf{sliding mode
observer (SMO)} uses a discontinuous switching function that drives the
estimation error to zero along a sliding surface, providing robustness
against parameter variations and model inaccuracies --- the
high-frequency chattering inherent in SMO is filtered to extract the
rotor position estimate. The \textbf{extended Kalman filter (EKF)}
treats the motor model as a nonlinear stochastic system, providing
optimal state estimation in the presence of measurement noise, but at
higher computational cost. These observers work well at medium to high
speeds but degrade below approximately 2--5\% of rated speed due to the
diminishing back-EMF signal and increased sensitivity to parameter
errors (particularly stator resistance R\textsubscript{s}, which varies
with temperature).

\textbf{High-frequency injection (HFI)} overcomes the low-speed
limitation by exploiting magnetic saliency --- the difference between
d-axis and q-axis inductances (L\textsubscript{d} ≠ L\textsubscript{q})
--- to determine rotor position independent of speed. A high-frequency
voltage signal (typically 500 Hz to 2 kHz, 5--20 V amplitude) is
superimposed on the fundamental excitation, and the resulting
high-frequency current response varies with rotor position due to the
saliency. Demodulating the high-frequency current component extracts the
rotor position angle. HFI provides position estimation down to zero
speed and is essential for applications requiring full torque at
standstill (e.g., elevator drives, crane hoists). The technique requires
measurable saliency (L\textsubscript{d}/L\textsubscript{q} ≠ 1), which
is inherent in interior permanent magnet (IPM) motors and synchronous
reluctance motors, but is minimal in surface-mount PM (SPM) motors where
L\textsubscript{d} ≈ L\textsubscript{q}. The injected signal produces
audible noise and additional losses, which are minimized by keeping the
injection amplitude as small as possible while maintaining a reliable
signal-to-noise ratio.

\textbf{Flux linkage estimation} provides an alternative approach where
the stator flux vector is computed by integrating the voltage equation:
ψ\textsubscript{s} = ∫(V\textsubscript{s} −
R\textsubscript{s}I\textsubscript{s})dt, and the rotor position is
derived from the angle between the estimated stator flux and rotor flux.
Pure integration suffers from DC offset drift, so practical
implementations use modified integrators (low-pass filters with
compensation, or programmable cascaded integrators) that prevent drift
while maintaining accuracy at operating frequencies.

Modern sensorless drives typically combine HFI at low speeds (0 to
\textasciitilde10\% rated speed) with a model-based observer at medium
and high speeds, using a smooth transition algorithm that blends the two
estimates across the crossover speed range. This hybrid approach
achieves full speed-range sensorless operation with position estimation
accuracy of ±5--10 electrical degrees, sufficient for most industrial
applications though not matching the sub-degree accuracy of
high-resolution encoders.

\begin{examplebox}

\textbf{Example 12.4.7:} A 6-pole BLDC motor with K\textsubscript{e} =
0.08 V/(rad/s) is operated with sensorless back-EMF zero-crossing
detection. The DC bus voltage is 48 V, the phase resistance is
R\textsubscript{ph} = 0.6 Ω, and the zero-crossing detection circuit
requires a minimum back-EMF of 3.0 V for reliable detection. The motor
is driving a fan load at steady state, and the measured back-EMF
zero-crossing period (time between consecutive zero-crossings on one
phase) is 1.25 ms. Calculate the minimum operating speed for sensorless
control and the rotor speed from the zero-crossing measurement.

\textbf{Solution:}\\
Minimum back-EMF for detection: E\textsubscript{min} = 3.0 V.\\
Minimum speed: ω\textsubscript{min} = E\textsubscript{min} /
K\textsubscript{e} = 3.0 / 0.08 = 37.5 rad/s.\\
Minimum speed in RPM: n\textsubscript{min} = 37.5 × 60 / (2π) = 358
RPM.\\
For the zero-crossing measurement: in a 6-pole (3 pole-pair) motor,
there are 3 electrical cycles per mechanical revolution.\\
Each electrical cycle has 6 zero-crossings (one per 60 electrical
degrees).\\
Zero-crossing period: T\textsubscript{ZC} = 1.25 ms = time for 60
electrical degrees.\\
Electrical period: T\textsubscript{e} = 6 × 1.25 = 7.50 ms.\\
Electrical frequency: f\textsubscript{e} = 1 / 0.00750 = 133.3 Hz.\\
Mechanical speed: n = f\textsubscript{e} / (P/2) = 133.3 / 3 = 44.4
rev/s = 2,667 RPM.\\
Mechanical speed in rad/s: ω = 2,667 × 2π / 60 = 279.3 rad/s.\\
Verify with back-EMF: E\textsubscript{back} = K\textsubscript{e} × ω =
0.08 × 279.3 = 22.3 V --- well above the 3.0 V minimum, confirming
reliable sensorless operation at this speed.

\end{examplebox}

\subsection{12.4.8 Flux Weakening and Constant-Power
Operation}\label{flux-weakening-and-constant-power-operation}

Flux weakening extends the operating speed range of a permanent magnet
motor beyond its base speed by injecting negative d-axis current to
oppose the rotor magnet flux, effectively reducing the net air-gap flux
and the back-EMF so the motor can spin faster within the inverter's
voltage limit. Below base speed, the motor operates in the
\textbf{constant-torque region} where full flux is maintained
(I\textsubscript{d} = 0 for SPM, or MTPA trajectory for IPM) and the
available torque is limited by the current rating of the inverter. At
base speed, the back-EMF equals the maximum voltage the inverter can
produce, and any further speed increase requires reducing the flux.
Above base speed, the motor enters the \textbf{constant-power region}
where torque decreases inversely with speed (P = τ × ω = constant) as
the flux is progressively weakened.

The motor's operating limits are described by two constraints in the
I\textsubscript{d}-I\textsubscript{q} plane. The \textbf{current limit
circle} has radius I\textsubscript{max}: I\textsubscript{d}² +
I\textsubscript{q}² ≤ I\textsubscript{max}², set by the inverter's
thermal rating. The \textbf{voltage limit ellipse} shrinks with
increasing speed: (L\textsubscript{d}I\textsubscript{d} +
λ\textsubscript{m})² + (L\textsubscript{q}I\textsubscript{q})² ≤
(V\textsubscript{max}/ω\textsubscript{e})², where V\textsubscript{max} =
V\textsubscript{DC}/√3 for space vector PWM. As speed increases, the
voltage ellipse contracts toward its center at
(−λ\textsubscript{m}/L\textsubscript{d}, 0), and the operating point
must lie within both the current circle and the voltage ellipse. The
\textbf{maximum torque per ampere (MTPA)} trajectory optimizes the
current angle for maximum torque at each current magnitude --- for SPM
motors this is simply I\textsubscript{d} = 0, but for IPM motors (where
L\textsubscript{d} ≠ L\textsubscript{q}) the MTPA angle shifts into the
negative I\textsubscript{d} region to exploit reluctance torque: T =
(3/2)(P/2){[}λ\textsubscript{m}I\textsubscript{q} + (L\textsubscript{d}
− L\textsubscript{q})I\textsubscript{d}I\textsubscript{q}{]}.

The \textbf{speed range extension ratio} (maximum speed divided by base
speed) depends on the motor's characteristic current I\textsubscript{ch}
= λ\textsubscript{m}/L\textsubscript{d}. When I\textsubscript{ch} =
I\textsubscript{max}, the voltage ellipse center lies exactly on the
current limit circle, enabling theoretically infinite constant-power
range --- this is the ``ideal'' flux weakening design point. Practical
IPM motors achieve speed range ratios of 2:1 to 4:1, with some traction
motors reaching 5:1 or higher through optimized rotor geometry (embedded
V-shaped magnets, flux barriers). SPM motors have limited flux weakening
capability (typically 1.2:1 to 1.5:1) because their low saliency
provides minimal reluctance torque contribution and their characteristic
current often exceeds I\textsubscript{max}. In electric vehicle
applications, flux weakening enables the motor to deliver high torque
for acceleration at low speeds while achieving high highway speeds
within the battery voltage constraint, replacing the function of a
multi-speed transmission.

\begin{examplebox}

\textbf{Example 12.4.8:} A 4-pole IPM motor for an electric vehicle has
the following parameters: λ\textsubscript{m} = 0.18 Wb,
L\textsubscript{d} = 4.0 mH, L\textsubscript{q} = 10.0 mH,
I\textsubscript{max} = 200 A, V\textsubscript{DC} = 350 V. Calculate the
base speed, the characteristic current, and the maximum speed achievable
with flux weakening.

\textbf{Solution:}\\
Maximum voltage (phase, for SVPWM): V\textsubscript{max} =
V\textsubscript{DC} / √3 = 350 / 1.732 = 202.1 V.\\
At base speed with I\textsubscript{d} = 0 (MTPA for simplicity at rated
current): the back-EMF determines the voltage limit.\\
The voltage equation magnitude at I\textsubscript{d} = 0:
V\textsubscript{s} = ω\textsubscript{e} × √(λ\textsubscript{m}² +
(L\textsubscript{q}I\textsubscript{q})²).\\
With I\textsubscript{q} = I\textsubscript{max} = 200 A:
V\textsubscript{s} = ω\textsubscript{e} × √(0.18² + (0.010 × 200)²) =
ω\textsubscript{e} × √(0.0324 + 4.0) = ω\textsubscript{e} × √4.0324 =
ω\textsubscript{e} × 2.008.\\
At base speed, V\textsubscript{s} = V\textsubscript{max}:
ω\textsubscript{e,base} = 202.1 / 2.008 = 100.6 rad/s (electrical).\\
Mechanical base speed: ω\textsubscript{m,base} = ω\textsubscript{e,base}
/ (P/2) = 100.6 / 2 = 50.3 rad/s = 480 RPM.\\
Characteristic current: I\textsubscript{ch} = λ\textsubscript{m} /
L\textsubscript{d} = 0.18 / 0.004 = 45.0 A.\\
Since I\textsubscript{ch} = 45 A \textless{} I\textsubscript{max} = 200
A, the voltage ellipse center is well inside the current circle,
indicating a wide constant-power speed range is achievable.\\
At maximum speed, the operating point approaches I\textsubscript{d} =
−I\textsubscript{ch} = −45 A, I\textsubscript{q} ≈ 0 (minimum torque,
maximum speed).\\
Maximum electrical speed: ω\textsubscript{e,max} = V\textsubscript{max}
/ (L\textsubscript{d} × \textbar I\textsubscript{d} +
I\textsubscript{ch}\textbar) --- but at I\textsubscript{d} =
−I\textsubscript{max} = −200 A:\\
V\textsubscript{s} = ω\textsubscript{e} ×
√((L\textsubscript{d}I\textsubscript{d} + λ\textsubscript{m})² +
(L\textsubscript{q}I\textsubscript{q})²) with I\textsubscript{q} = 0:\\
ω\textsubscript{e,max} = V\textsubscript{max} /
\textbar L\textsubscript{d} × (−200) + λ\textsubscript{m}\textbar{} =
202.1 / \textbar0.004 × (−200) + 0.18\textbar{} = 202.1 / \textbar−0.80
+ 0.18\textbar{} = 202.1 / 0.62 = 326.0 rad/s (electrical).\\
Mechanical max speed: ω\textsubscript{m,max} = 326.0 / 2 = 163.0 rad/s =
1,557 RPM.\\
Speed range ratio: 1,557 / 480 = 3.24:1.\\
This 3.2:1 speed extension is typical for IPM traction motors, allowing
the vehicle to reach highway speeds without a multi-speed gearbox.

\end{examplebox}

\section{12.5 Motor Specifications}\label{motor-specifications}

Motor specifications define the electrical, mechanical, and thermal
ratings that determine proper application, installation, and protection
of electric motors. Understanding nameplate data is essential for
selecting the correct conductor sizing, overcurrent protection, and
control equipment. Standardized efficiency classifications and motor
protection schemes ensure safe, reliable, and energy-efficient operation
throughout the motor's service life.

\subsection{12.5.1 Nameplate Data}\label{nameplate-data}

The motor nameplate provides the essential specifications needed for
proper installation, protection, and application. Key nameplate
parameters include rated power (HP or kW), rated voltage and frequency,
rated full-load current (FLA), rated speed (RPM), service factor (SF,
the permissible continuous overload factor, typically 1.0-1.15),
insulation class (B: 130°C, F: 155°C, H: 180°C maximum winding
temperature), enclosure type (ODP: Open Drip Proof, TEFC: Totally
Enclosed Fan Cooled, TENV: Totally Enclosed Non-Ventilated), and frame
size (NEMA or IEC standard dimensions). The NEMA design letter (A, B, C,
D) specifies the torque-speed characteristic, with Design B being the
most common general-purpose type. The efficiency rating (NEMA Premium,
IE3, IE4) indicates the motor's energy conversion efficiency at rated
load, with minimum efficiency standards mandated by regulations in most
countries.

\begin{examplebox}

\textbf{Example 12.5.1:} A motor nameplate reads: 25 HP, 460 V, 60 Hz,
3-phase, 1,770 RPM, FLA = 30.8 A, SF = 1.15, Insulation Class F, TEFC,
NEMA Design B, Efficiency = 93.0\%. Calculate the number of poles, the
full-load slip, the input power, the maximum continuous power with
service factor, and the maximum winding temperature.

\textbf{Solution:}\\
Number of poles: n\textsubscript{s} must be the nearest synchronous
speed above 1,770 RPM. n\textsubscript{s} = 1,800 RPM, so P =
120f/n\textsubscript{s} = 120 × 60 / 1800 = 4 poles.\\
Full-load slip: s = (1800 - 1770) / 1800 = 30/1800 = 1.67\%.\\
Input power: P\textsubscript{in} = P\textsubscript{out} / η = (25 × 746)
/ 0.930 = 18,650 / 0.930 = 20,054 W = 20.1 kW.\\
Verify with current: P\textsubscript{in} = √3 × V × I × PF. PF =
P\textsubscript{in} / (√3 × V × I) = 20,054 / (1.732 × 460 × 30.8) =
20,054 / 24,539 = 0.817 (typical for this motor size).\\
Maximum continuous power with SF: P\textsubscript{max} = 25 × 1.15 =
28.75 HP.\\
Maximum winding temperature (Class F): 155°C (with a 40°C ambient, this
allows a 115°C total hot-spot temperature rise, or 105°C average winding
rise by resistance measurement plus a 10°C hot-spot allowance).\\
Power losses: P\textsubscript{loss} = P\textsubscript{in} -
P\textsubscript{out} = 20,054 - 18,650 = 1,404 W.

\end{examplebox}

\subsection{12.5.2 Motor Protection}\label{motor-protection}

Motor protection devices and schemes prevent damage from electrical and
thermal faults that can destroy windings, bearings, and insulation.
Overcurrent protection (circuit breakers or fuses) interrupts the supply
during short circuits and severe overloads that exceed the motor's rated
current. Thermal overload relays (bimetallic or electronic) monitor the
motor current and trip after a time delay that approximates the motor's
thermal capacity, protecting against sustained moderate overloads that
cause gradual overheating. Phase loss (single-phasing) protection
detects the loss of one supply phase, which causes the motor to draw
excessive current on the remaining phases and overheat rapidly. Ground
fault protection detects current leaking to ground through damaged
insulation, preventing electrical shock and fire hazards. Additional
protection functions in electronic motor protection relays include phase
reversal, voltage unbalance, undercurrent (indicating loss of load such
as a broken belt or pump running dry), stall detection, and winding
temperature monitoring via embedded thermistors or RTDs (PTC or Pt100).

\begin{examplebox}

\textbf{Example 12.5.2:} A 50 HP, 460 V, 3-phase motor has a full-load
current of 62 A, a service factor of 1.15, and a locked-rotor current of
6× FLA. Select the thermal overload relay trip class and setting, and
determine the minimum circuit breaker size per NEC guidelines.

\textbf{Solution:}\\
Overload relay setting: the trip current is set at 115\% of FLA (to
allow operation at service factor): I\textsubscript{trip} = 1.15 × 62 =
71.3 A.\\
Select a Class 20 thermal overload relay (trips within 20 seconds at 6×
setting -- standard for most industrial motors).\\
Verify: at locked-rotor current I\textsubscript{LR} = 6 × 62 = 372 A,
the relay must trip before winding damage occurs.\\
Circuit breaker sizing (NEC 430.52 for inverse-time breaker, Design B
motor): maximum = 250\% of FLA = 2.50 × 62 = 155 A.\\
Since 155 A is not a standard ampere rating, NEC 430.52 Exception No.~1
permits the next higher standard size: select 175 A breaker
(alternatively, the next lower standard size of 150 A is also
code-compliant but may nuisance-trip during starting).\\
Short-circuit interrupting capacity must exceed the available fault
current at the motor terminals.\\
The branch circuit conductors must be rated at minimum 125\% of FLA =
1.25 × 62 = 77.5 A, requiring 4 AWG copper (rated 85 A at 75°C).

\end{examplebox}

\subsection{12.5.3 Motor Efficiency and
Standards}\label{motor-efficiency-and-standards}

Motor efficiency standards define minimum performance levels to reduce
energy waste, since electric motors consume roughly 45\% of global
electricity. The International Electrotechnical Commission (IEC)
standard IEC 60034-30-1 defines four efficiency classes for three-phase
induction motors: IE1 (standard), IE2 (high), IE3 (premium), and IE4
(super-premium), with IE5 (ultra-premium) under development. In North
America, NEMA MG 1 defines ``NEMA Premium'' efficiency levels that align
closely with IE3. Motor losses consist of stator copper losses (I²R in
the stator windings), rotor copper losses (I²R in the rotor conductors),
core losses (hysteresis and eddy currents in the laminations), friction
and windage losses, and stray load losses. Higher-efficiency motors use
more copper (larger conductors), thinner and higher-grade electrical
steel laminations, tighter air gaps, and optimized rotor slot geometry
to reduce these losses. The lifecycle electricity cost of a motor
typically exceeds its purchase price within the first few months of
operation, making efficiency a critical economic factor.

\begin{examplebox}

\textbf{Example 12.5.3:} A plant operates a 75 kW, 4-pole, 460 V
induction motor continuously (8,760 hours/year) at 75\% load. The
current IE1 motor has an efficiency of 91.0\% at 75\% load. A
replacement IE4 motor has an efficiency of 95.5\% at the same load
point. The electricity cost is \$0.09/kWh, and the IE4 motor costs
\$2,800 more than the IE1 replacement. Calculate the annual energy
consumption of each motor, the annual savings, and the simple payback
period.

\textbf{Solution:}\\
Mechanical output at 75\% load: P\textsubscript{mech} = 0.75 × 75 =
56.25 kW.\\
IE1 motor input power: P\textsubscript{in(IE1)} = P\textsubscript{mech}
/ η = 56.25 / 0.910 = 61.81 kW.\\
IE4 motor input power: P\textsubscript{in(IE4)} = 56.25 / 0.955 = 58.90
kW.\\
Power savings: ΔP = 61.81 - 58.90 = 2.91 kW.\\
Annual energy savings: ΔE = 2.91 × 8,760 = 25,492 kWh/year.\\
Annual cost savings: ΔC = 25,492 × \$0.09 = \$2,294/year.\\
Simple payback: \$2,800 / \$2,294 = 1.22 years.\\
Over a typical 20-year motor life, the total savings would be
approximately 20 × \$2,294 = \$45,880, a return of over 16× the premium
cost.

\end{examplebox}

\subsection{12.5.4 Motor Selection and
Sizing}\label{motor-selection-and-sizing}

Proper motor selection requires matching the motor's torque-speed
characteristics, power rating, duty cycle, and environmental ratings to
the driven load. The load torque profile determines the motor type:
constant-torque loads (conveyors, hoists, positive-displacement pumps)
require motors that deliver rated torque across the full speed range,
while variable-torque loads (centrifugal pumps, fans, blowers) follow a
torque ∝ speed² relationship and benefit from VFD-driven motors sized at
the maximum operating point. The motor must be sized for the worst-case
continuous load plus any required overload margin, accounting for the
duty cycle --- continuous duty (S1), short-time duty (S2), or
intermittent duty (S3--S10 per IEC 60034-1) --- since intermittent
operation allows a smaller motor due to cooling periods between load
cycles. The motor's thermal class and enclosure must be compatible with
the ambient temperature and environment (dust, moisture, corrosive
atmosphere, hazardous locations classified per NEC Article 500). The
moment of inertia of the load referred to the motor shaft
(J\textsubscript{load} = J\textsubscript{actual} ×
(N\textsubscript{motor}/N\textsubscript{load})² for geared systems)
determines the acceleration torque required: T\textsubscript{accel} =
(J\textsubscript{motor} + J\textsubscript{load}) × α, which must not
exceed the motor's breakdown torque or the drive's current limit.
Oversizing a motor wastes energy (motors are least efficient at light
loads) and reduces power factor, while undersizing leads to overheating,
shortened insulation life, and nuisance tripping.

\begin{examplebox}

\textbf{Example 12.5.4:} A conveyor system requires 8 kW of continuous
mechanical power at 1,200 RPM. The conveyor has a total reflected
inertia of J\textsubscript{load} = 0.8 kg·m² (referred to motor shaft),
and the system must accelerate from standstill to full speed in 3
seconds. The motor inertia is J\textsubscript{motor} = 0.05 kg·m².
Determine the required motor rating, the acceleration torque, the total
torque during acceleration, and verify the motor can deliver it.

\textbf{Solution:}\\
Continuous load torque: τ\textsubscript{load} = P / ω = 8,000 / (1200 ×
2π/60) = 8,000 / 125.7 = 63.7 N·m.\\
Angular acceleration: α = ω / t = 125.7 / 3 = 41.9 rad/s².\\
Total inertia: J\textsubscript{total} = J\textsubscript{motor} +
J\textsubscript{load} = 0.05 + 0.80 = 0.85 kg·m².\\
Acceleration torque: τ\textsubscript{accel} = J\textsubscript{total} × α
= 0.85 × 41.9 = 35.6 N·m.\\
Total torque during acceleration: τ\textsubscript{total} =
τ\textsubscript{load} + τ\textsubscript{accel} = 63.7 + 35.6 = 99.3
N·m.\\
Select a motor rated at least 8 kW continuous with adequate breakdown
torque.\\
A standard 11 kW (15 HP), 4-pole induction motor has a rated torque of
approximately 11,000 / 125.7 = 87.5 N·m and a typical breakdown torque
of 2.5 × 87.5 = 218.8 N·m.\\
The acceleration torque of 99.3 N·m is 113\% of rated torque, well
within the motor's capability.\\
The 11 kW motor provides a 37.5\% power margin for the continuous 8 kW
load.

\end{examplebox}

\subsection{12.5.5 Motor Bearings and Vibration
Analysis}\label{motor-bearings-and-vibration-analysis}

Bearings support the motor shaft, maintain the air gap between rotor and
stator, and are the most common point of failure in electric motors ---
bearing faults account for approximately 40--50\% of all motor failures.
\textbf{Ball bearings} (deep groove, angular contact) are the standard
for small to medium motors, using hardened steel balls rolling between
inner and outer races with grease or oil lubrication. \textbf{Roller
bearings} (cylindrical, spherical, tapered) carry higher radial and
axial loads in large motors. \textbf{Sleeve (journal) bearings} use an
oil film between the shaft and a bronze or babbitt-metal bushing,
providing quiet operation and very long life in large, high-speed
machines. Bearing life follows the L₁₀ rating: the number of revolutions
(or hours at a given speed) at which 10\% of a population of identical
bearings will have failed, calculated as L₁₀ = (C/P)\textsuperscript{3}
× 10⁶ revolutions for ball bearings, where C is the dynamic load rating
and P is the equivalent bearing load. \textbf{Vibration analysis} is the
primary predictive maintenance tool for motor bearings: an accelerometer
mounted on the bearing housing measures vibration spectra that reveal
specific fault signatures. A defect on the outer race produces vibration
at the ball pass frequency outer (BPFO), an inner race defect at BPFI, a
ball defect at BSF (ball spin frequency), and cage defects at FTF
(fundamental train frequency) --- each calculated from the bearing
geometry, number of balls, and shaft speed. Overall vibration severity
is classified by ISO 10816 (velocity in mm/s RMS): Zone A (\textless{}
1.8 mm/s, new condition), Zone B (1.8--4.5 mm/s, acceptable), Zone C
(4.5--11.2 mm/s, marginal), Zone D (\textgreater{} 11.2 mm/s, danger)
for Group 2 machines (15--75 kW). Trending vibration levels over time
detects degradation months before catastrophic failure, enabling planned
maintenance rather than unplanned downtime.

\begin{examplebox}

\textbf{Example 12.5.5:} A 30 kW, 4-pole induction motor operates at
1,770 RPM with 6205-2RS deep groove ball bearings (9 balls, ball
diameter d\textsubscript{b} = 7.94 mm, pitch diameter d\textsubscript{p}
= 38.5 mm, contact angle α = 0°). The bearing dynamic load rating is C =
14.0 kN, and the radial load on the drive-end bearing is P = 1.2 kN.
Calculate the L₁₀ bearing life in hours and the ball pass frequency
outer race (BPFO).

\textbf{Solution:}\\
L₁₀ life in revolutions: L₁₀ = (C/P)³ × 10⁶ = (14.0/1.2)³ × 10⁶ =
(11.67)³ × 10⁶ = 1,589 × 10⁶ revolutions.\\
Convert to hours: L₁₀(hours) = L₁₀ / (60 × n) = 1,589 × 10⁶ / (60 ×
1,770) = 1,589 × 10⁶ / 106,200 = 14,962 hours ≈ 15,000 hours (about 1.7
years of continuous operation).\\
BPFO = (N\textsubscript{b}/2) × (n/60) × (1 − d\textsubscript{b}cos α /
d\textsubscript{p}) = (9/2) × (1770/60) × (1 − 7.94/38.5) = 4.5 × 29.5 ×
(1 − 0.2062) = 4.5 × 29.5 × 0.7938 = 105.4 Hz.\\
A vibration peak at 105.4 Hz (or its harmonics at 210.8, 316.2 Hz) in
the bearing housing spectrum indicates an outer race defect
developing.\\
At the current load, the bearing should last \textasciitilde15,000
hours, but vibration monitoring can detect degradation well before the
L₁₀ life to prevent unexpected failures.

\end{examplebox}

\subsection{12.5.6 Motor Thermal Modeling and Insulation
Life}\label{motor-thermal-modeling-and-insulation-life}

Motor winding insulation degrades progressively with temperature, and
thermal management is the primary factor determining motor service life.
The \textbf{Arrhenius model} (also known as Montsinger's rule or the
``10-degree rule'') states that insulation life approximately halves for
every 10°C increase above the rated hot-spot temperature: L =
L\textsubscript{rated} × 2\textsuperscript{(Trated − Tactual)/10}, where
L\textsubscript{rated} is the design life at rated temperature
(typically 20,000 hours for Class F insulation at 155°C). Insulation
classes define maximum allowable winding temperatures: Class B (130°C),
Class F (155°C), and Class H (180°C), each including a 40°C ambient, a
temperature rise allowance, and a 10°C hot-spot margin.
\textbf{Lumped-parameter thermal models} represent the motor as a
network of thermal resistances (R\textsubscript{th} in °C/W) and thermal
capacitances (C\textsubscript{th} in J/°C) analogous to an electrical RC
circuit: the winding-to-stator-core resistance, stator-core-to-frame
resistance, and frame-to-ambient resistance (convection and radiation)
form a series thermal path, with each node having a thermal mass that
determines the transient heating and cooling time constants. The
dominant winding time constant is typically τ\textsubscript{w} =
R\textsubscript{th} × C\textsubscript{th} = 5--30 minutes for small to
medium motors, meaning the winding temperature follows T(t) =
T\textsubscript{ambient} + ΔT\textsubscript{ss}(1 −
e\textsuperscript{−t/τ}) during constant-load operation. For
intermittent duty (S3--S10 per IEC 60034-1), the motor can be loaded
above its continuous rating during the ON period provided the RMS
equivalent heating over the complete cycle does not exceed the
continuous thermal limit: the equivalent continuous current is
I\textsubscript{eq} = √(I₁²t₁ + I₂²t₂ + \ldots{} ) / (t₁ + t₂ + \ldots).
Motor protection relays implement thermal models (I²t algorithms or
first-order thermal replicas) that estimate winding temperature from
measured current and time, tripping before the insulation temperature
limit is exceeded.

\begin{examplebox}

\textbf{Example 12.5.6:} A Class F insulation motor (rated hot-spot
temperature 155°C) has a design life of 20,000 hours at rated load. The
motor operates in a 45°C ambient (5°C above the standard 40°C rating)
and carries 110\% of rated current continuously. The temperature rise is
proportional to I², so the actual temperature rise is 1.10² = 1.21 times
the rated rise. The rated temperature rise is 155 − 10 (hot-spot margin)
− 40 = 105°C. Calculate the actual hot-spot temperature and the expected
insulation life.

\textbf{Solution:}\\
Actual temperature rise: ΔT = 1.21 × 105 = 127.1°C.\\
Actual hot-spot temperature: T\textsubscript{actual} =
T\textsubscript{ambient} + ΔT = 45 + 127.1 = 172.1°C.\\
Temperature above rated hot-spot: ΔT\textsubscript{excess} = 172.1 − 155
= 17.1°C.\\
Expected insulation life: L = L\textsubscript{rated} ×
2\textsuperscript{(Trated − Tactual)/10} = 20,000 ×
2\textsuperscript{(155 − 172.1)/10} = 20,000 × 2\textsuperscript{−1.71}
= 20,000 × 0.3057 = 6,114 hours.\\
The combination of elevated ambient (+5°C) and overload (110\%) reduces
insulation life from 20,000 hours to approximately 6,100 hours --- a
69\% reduction.\\
This demonstrates why motors must be derated for high ambient
temperatures and why sustained overloads, even modest ones, dramatically
shorten motor life.\\
Operating at the rated conditions would yield: L = 20,000 ×
2\textsuperscript{(155 − (40 + 105 + 10))/10} = 20,000 × 2⁰ = 20,000
hours as expected.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-12-5-6}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch12_insulation_life.png}

\caption{Figure 12.5.6: Motor Insulation Life vs Temperature}

\end{figure}

\subsection{12.5.7 VFD Effects on Motor
Windings}\label{vfd-effects-on-motor-windings}

Variable frequency drives produce fast-switching PWM output waveforms
that subject motor windings, insulation, and bearings to stresses not
present with sinusoidal mains power. Understanding these effects is
essential for reliable VFD-motor systems, particularly with long cable
runs, high switching frequencies, and motors not rated for inverter
duty.

\textbf{Voltage reflection and doubling} occurs because the VFD output
cable acts as a transmission line at the steep-edged PWM switching
frequencies. When a voltage pulse travels down the cable and encounters
the motor terminals (a high-impedance mismatch), the pulse reflects and
adds to the incoming wave, producing a voltage overshoot at the motor
terminals that can reach nearly 2× the DC bus voltage. The reflection
magnitude depends on the cable's characteristic impedance Z₀ =
√(L\textsubscript{cable}/C\textsubscript{cable}) (typically 50--100 Ω)
relative to the motor's surge impedance (typically 1,000--5,000 Ω). Full
voltage doubling occurs when the cable propagation time
t\textsubscript{prop} = l/v\textsubscript{p} (where l is the cable
length and v\textsubscript{p} is the propagation velocity, typically
150--200 m/μs) exceeds half the inverter rise time:
t\textsubscript{prop} \textgreater{} t\textsubscript{rise}/2. For a
modern IGBT inverter with a rise time of 100 ns, the critical cable
length is l\textsubscript{crit} = v\textsubscript{p} ×
t\textsubscript{rise}/2 = 170 m/μs × 50 ns = 8.5 m. Beyond this length,
the reflected voltage at the motor terminals approaches 2 ×
V\textsubscript{DC}, stressing the turn-to-turn insulation in the first
few coils of the motor winding.

\textbf{dV/dt stress on insulation} is caused by the steep voltage edges
of PWM switching. The voltage across the first few turns of a motor
winding can be disproportionately large because the high-frequency
components of the voltage pulse distribute non-uniformly --- up to 80\%
of the pulse voltage can appear across the first 10--20\% of the winding
turns due to the inter-turn capacitance forming a capacitive voltage
divider at high frequencies. Standard motors with random-wound windings
(NEMA MG1 Part 30) are rated for a peak voltage of 1,000 V and a maximum
dV/dt of 1,760 V/μs for 460 V class motors. Exceeding these limits
causes partial discharge (corona) in the insulation that progressively
erodes the enamel coating, leading to turn-to-turn short circuits and
eventual winding failure --- sometimes within months of installation.

\textbf{Bearing currents} are induced by the common-mode voltage
generated by the PWM inverter. The three-phase PWM output produces a
non-zero common-mode voltage V\textsubscript{CM} = (V\textsubscript{a} +
V\textsubscript{b} + V\textsubscript{c})/3 that oscillates at the
switching frequency (typically 4--16 kHz) with amplitude up to
V\textsubscript{DC}/2. This common-mode voltage couples through the
parasitic capacitance between the stator winding and the rotor
(C\textsubscript{wr}, typically 10--100 pF) and between the rotor and
the grounded frame through the bearing (C\textsubscript{rb}). The
resulting shaft voltage builds up until it exceeds the dielectric
breakdown voltage of the bearing lubricant film (typically 5--30 V),
causing an electric discharge machining (EDM) event --- a tiny spark
that pits the bearing race surface. Repeated EDM events produce
characteristic ``fluting'' patterns (washboard-like grooves) on the
bearing races, leading to increased vibration, noise, and premature
bearing failure within 6--24 months instead of the normal 5--10 year
life. Shaft grounding rings (conductive microfiber rings that maintain a
low-impedance path from shaft to frame) and insulated bearings
(ceramic-coated outer race or hybrid ceramic balls) are the primary
mitigation measures.

\textbf{Output reactors and dV/dt filters} are installed between the VFD
and the motor to protect against voltage reflection and dV/dt stress. A
\textbf{3\% output reactor} (impedance = 3\% of motor base impedance)
reduces the dV/dt by slowing the voltage rise time and limits the peak
voltage overshoot, but does not eliminate reflections on long cables. A
\textbf{dV/dt filter} (LC low-pass circuit with a cutoff frequency
between the PWM switching frequency and the fundamental output
frequency) limits the dV/dt to 200--500 V/μs and clamps the peak
voltage, providing better protection for cable lengths up to 300 m. A
\textbf{sinusoidal filter} (also called a sine wave filter) uses a
higher-order LC network with a cutoff below the switching frequency to
reconstruct a near-sinusoidal waveform, eliminating virtually all
high-frequency stress but at higher cost, size, and power loss (1--3\%
of rated power).

\textbf{Inverter-duty motor ratings} per NEMA MG1 Part 31 specify
insulation systems designed for VFD operation. Part 31 motors withstand
peak voltages of 1,600 V (for 460 V class) with rise times down to 100
ns, compared to 1,000 V for standard Part 30 motors. They use reinforced
insulation systems including phase-separation insulation (between coils
of different phases), corona-resistant magnet wire with enhanced enamel
coatings, and vacuum pressure impregnation (VPI) with high-quality
resins that eliminate voids where partial discharge initiates. For
motors above 600 V, IEC 60034-18-42 defines Type I insulation (no
partial discharge expected during operation) and Type II insulation
(designed to withstand partial discharge throughout the motor's life).
\textbf{Cable length limits} depend on the VFD voltage class, switching
frequency, and output filtering: without filters, maximum recommended
cable lengths are typically 15--30 m for 460 V drives with fast IGBTs;
with a dV/dt filter, this extends to 150--300 m; and with a sinusoidal
filter, cable length is essentially unlimited.

\begin{examplebox}

\textbf{Example 12.5.7:} A 460 V VFD with a DC bus voltage of 650 V and
an IGBT rise time of 100 ns drives a standard (Part 30) motor through a
75 m cable. The cable propagation velocity is 170 m/μs. Calculate the
cable propagation time, determine whether voltage doubling occurs,
estimate the peak voltage at the motor terminals, and specify the
required output filter.

\textbf{Solution:}\\
Cable propagation time: t\textsubscript{prop} = l / v\textsubscript{p} =
75 / (170 × 10⁶) = 441 ns = 0.441 μs.\\
Critical cable length for voltage doubling: l\textsubscript{crit} =
v\textsubscript{p} × t\textsubscript{rise} / 2 = 170 × 10⁶ × 100 × 10⁻⁹
/ 2 = 8.5 m.\\
Since l = 75 m \textgreater\textgreater{} l\textsubscript{crit} = 8.5 m,
full voltage reflection occurs.\\
Peak voltage at motor terminals: V\textsubscript{peak} ≈ 2 ×
V\textsubscript{DC} × (1 − e\textsuperscript{−2tprop/trise}) for the
reflected wave. With t\textsubscript{prop} \textgreater\textgreater{}
t\textsubscript{rise}/2, the reflection coefficient approaches 1.0.\\
V\textsubscript{peak} ≈ 2 × 650 = 1,300 V.\\
The standard Part 30 motor is rated for a maximum peak of 1,000 V ---
the 1,300 V reflected voltage exceeds this by 30\%, creating a high risk
of insulation failure.\\
dV/dt at motor terminals (without filter): dV/dt ≈ V\textsubscript{DC} /
t\textsubscript{rise} = 650 / (100 × 10⁻⁹) = 6,500 V/μs --- far
exceeding the 1,760 V/μs Part 30 rating.\\
A \textbf{dV/dt filter} must be installed at the VFD output to limit the
peak voltage below 1,000 V and reduce the dV/dt below 1,760 V/μs, or the
motor must be replaced with an inverter-duty (Part 31) motor rated for
1,600 V peak. For a 75 m cable run, a dV/dt filter is the standard
solution and would typically reduce the peak terminal voltage to
approximately 750--850 V and the dV/dt to 200--400 V/μs.\\
Additionally, shaft grounding rings should be installed on the motor to
prevent bearing damage from EDM currents.

\end{examplebox}

\chapter{Chapter 13}\label{chapter-13}

\chapter{Operational Amplifiers}\label{operational-amplifiers}

The operational amplifier (op-amp) is a high-gain, differential-input,
single-ended-output voltage amplifier that serves as the most versatile
building block in analog circuit design. Ideally, an op-amp has infinite
open-loop gain, infinite input impedance, zero output impedance, and
infinite bandwidth, and while real devices deviate from these ideals,
modern op-amps come close enough that the ideal model is sufficient for
most circuit analysis. By connecting external resistors and capacitors
in feedback networks, a single op-amp can be configured to perform
amplification, buffering, summation, subtraction, integration,
differentiation, filtering, and comparison, making it indispensable in
signal conditioning, instrumentation, control systems, and audio
electronics.

\section{13.1 Ideal Op-Amp Model}\label{ideal-op-amp-model}

\subsection{13.1.1 Characteristics}\label{characteristics}

The ideal op-amp model is based on five assumptions that simplify
circuit analysis: infinite open-loop voltage gain (A → ∞), infinite
input impedance (Z\textsubscript{in} → ∞, so no current flows into the
input terminals), zero output impedance (Z\textsubscript{out} = 0, so
the output can drive any load without voltage drop), infinite bandwidth
(the gain is constant at all frequencies), and zero input offset voltage
(the output is zero when both inputs are equal). These assumptions lead
to two golden rules for analyzing op-amp circuits with negative
feedback: (1) the voltage difference between the inverting and
non-inverting inputs is zero (V+ = V−), and (2) no current flows into
either input terminal. These rules, combined with Kirchhoff's laws,
allow rapid analysis of virtually any op-amp feedback circuit.

\begin{examplebox}

\textbf{Example 13.1.1:} An op-amp circuit has the non-inverting input
connected to a 2.5 V reference. Using the ideal op-amp golden rules,
determine the voltage at the inverting input and the current into the
inverting input terminal.

\textbf{Solution:}\\
By the first golden rule (virtual short): V− = V+ = 2.5 V.\\
By the second golden rule (zero input current): I− = 0 A.\\
These two conditions, combined with the external feedback network, are
sufficient to solve for all voltages and currents in the circuit.\\
The virtual short does not mean the inputs are physically connected ---
it means the feedback forces the differential input voltage to zero.

\end{examplebox}

\subsection{13.1.2 Open-Loop
vs.~Closed-Loop}\label{open-loop-vs.-closed-loop}

In open-loop configuration (no feedback), the op-amp operates at its
maximum gain (typically 10⁵ to 10⁶ or 100--120 dB), and even a microvolt
difference between the inputs drives the output to one of the supply
rails, making it useful only as a comparator. Closed-loop configuration
connects a portion of the output back to the inverting input (negative
feedback), which reduces the gain to a stable, predictable value
determined by the feedback network. The closed-loop gain is
A\textsubscript{CL} = A\textsubscript{OL} / (1 + A\textsubscript{OL} ×
β), where β is the feedback fraction; when A\textsubscript{OL} × β
\textgreater\textgreater{} 1, this simplifies to A\textsubscript{CL} ≈
1/β, making the gain independent of the op-amp's open-loop
characteristics. Negative feedback also increases bandwidth (by the same
factor it reduces gain), reduces distortion, stabilizes gain against
temperature and supply voltage variations, and modifies the input and
output impedances. The gain-bandwidth product (GBW) is approximately
constant for a given op-amp: GBW = A\textsubscript{CL} ×
f\textsubscript{3dB}, where f\textsubscript{3dB} is the closed-loop
bandwidth.

\begin{examplebox}

\textbf{Example 13.1.2:} An op-amp has an open-loop gain of
A\textsubscript{OL} = 200,000 (106 dB) and a gain-bandwidth product of
GBW = 5 MHz. It is configured with a feedback network that sets β =
0.01. Calculate the closed-loop gain, the closed-loop bandwidth, and the
error between the ideal and actual closed-loop gain.

\textbf{Solution:}\\
Ideal closed-loop gain: A\textsubscript{CL(ideal)} = 1/β = 1/0.01 = 100
(40 dB).\\
Actual closed-loop gain: A\textsubscript{CL} = A\textsubscript{OL} / (1
+ A\textsubscript{OL} × β) = 200,000 / (1 + 200,000 × 0.01) = 200,000 /
2001 = 99.95.\\
Gain error: (100 - 99.95) / 100 × 100\% = 0.05\%.\\
Closed-loop bandwidth: f\textsubscript{3dB} = GBW / A\textsubscript{CL}
= 5,000,000 / 100 = 50 kHz.\\
If the gain were reduced to A\textsubscript{CL} = 10, the bandwidth
would increase to 500 kHz, illustrating the gain-bandwidth trade-off.

\end{examplebox}

\section{13.2 Inverting Configurations}\label{inverting-configurations}

Inverting configurations connect the input signal to the inverting (−)
terminal through an input element, with a feedback element from the
output back to the inverting input, while the non-inverting (+) terminal
is grounded or connected to a reference. The inverting input acts as a
virtual ground (or virtual reference), and all inverting circuits share
the property that the output signal is phase-inverted (180°) relative to
the input. By choosing different input and feedback elements ---
resistors, capacitors, or combinations --- the same basic topology
produces amplifiers, summers, integrators, and differentiators.

\subsection{13.2.1 Inverting Amplifier}\label{inverting-amplifier}

The inverting amplifier connects the input signal through a resistor
R\textsubscript{in} to the inverting input, with a feedback resistor
R\textsubscript{f} from the output to the inverting input, and the
non-inverting input grounded. The closed-loop voltage gain is
A\textsubscript{v} = -R\textsubscript{f} / R\textsubscript{in}, where
the negative sign indicates a 180° phase inversion between input and
output. The input impedance equals R\textsubscript{in} (since the
inverting input is at virtual ground), and the output impedance is
approximately zero. The inverting amplifier is one of the most commonly
used op-amp configurations, providing precise, stable gain set entirely
by the external resistor ratio.

\begin{examplebox}

\textbf{Example 13.2.1:} Design an inverting amplifier with a gain of
-20 using an input resistance of R\textsubscript{in} = 5 kΩ. Determine
R\textsubscript{f} and calculate the output voltage for an input of
V\textsubscript{in} = 0.3 V. Also find the current through
R\textsubscript{f}.

\textbf{Solution:}\\
A\textsubscript{v} = -R\textsubscript{f} / R\textsubscript{in}, so
R\textsubscript{f} = \textbar A\textsubscript{v}\textbar{} ×
R\textsubscript{in} = 20 × 5 kΩ = 100 kΩ.\\
Output voltage: V\textsubscript{out} = A\textsubscript{v} ×
V\textsubscript{in} = -20 × 0.3 = -6.0 V.\\
The inverting input is at virtual ground (0 V), so the current through
R\textsubscript{in} equals: I = V\textsubscript{in} /
R\textsubscript{in} = 0.3 / 5000 = 60 μA.\\
By the golden rule (no current into the op-amp), the same 60 μA flows
through R\textsubscript{f}.\\
Verification: V\textsubscript{out} = 0 - I × R\textsubscript{f} = 0 - 60
× 10⁻⁶ × 100,000 = -6.0 V.

\end{examplebox}

\subsection{13.2.2 Summing Amplifier}\label{summing-amplifier}

The summing amplifier extends the inverting configuration by connecting
multiple input signals through individual input resistors to the
inverting input (the summing junction), with a single feedback resistor
R\textsubscript{f}. The output voltage is V\textsubscript{out} =
-R\textsubscript{f} × (V₁/R₁ + V₂/R₂ + V₃/R₃ + \ldots), where each input
contributes independently to the output, weighted by its respective
resistor ratio. When all input resistors are equal (R₁ = R₂ = \ldots{} =
R), the output is V\textsubscript{out} = -(R\textsubscript{f}/R) × (V₁ +
V₂ + V₃ + \ldots), producing a scaled sum. Summing amplifiers are used
in audio mixers, digital-to-analog converters (R-2R ladder DACs), and
analog computing circuits where multiple signals must be combined with
independent weighting.

\begin{examplebox}

\textbf{Example 13.2.2:} A summing amplifier has R\textsubscript{f} = 47
kΩ, R₁ = 10 kΩ, R₂ = 22 kΩ, and R₃ = 47 kΩ. The inputs are V₁ = 1.0 V,
V₂ = -0.5 V, and V₃ = 2.0 V. Calculate the output voltage.

\textbf{Solution:}\\
V\textsubscript{out} = -R\textsubscript{f} × (V₁/R₁ + V₂/R₂ + V₃/R₃) =
-47,000 × (1.0/10,000 + (-0.5)/22,000 + 2.0/47,000) = -47,000 × (0.0001
+ (-0.00002273) + 0.00004255) = -47,000 × 0.00011982 = -5.63 V.\\
The contribution from each input: V₁ contributes -47,000 × 0.0001 =
-4.70 V, V₂ contributes -47,000 × (-0.00002273) = +1.07 V, and V₃
contributes -47,000 × 0.00004255 = -2.00 V.\\
Total: -4.70 + 1.07 + (-2.00) = -5.63 V.

\end{examplebox}

\subsection{13.2.3 Integrator}\label{integrator}

The integrator replaces the feedback resistor of the inverting amplifier
with a capacitor C, producing an output that is the time integral of the
input signal: V\textsubscript{out}(t) = -(1/RC)
∫V\textsubscript{in}(t)dt + V\textsubscript{initial}, where R is the
input resistance and V\textsubscript{initial} is the initial capacitor
voltage. For a constant DC input, the output ramps linearly; for a
sinusoidal input at frequency f, the integrator provides a gain of
1/(2πfRC) with a 90° phase lag. A practical integrator includes a large
resistor (R\textsubscript{f}, typically 10--100× R) in parallel with the
feedback capacitor to provide DC stability and prevent output saturation
due to input offset voltage and bias current. Integrators are used in
analog computers, PID controllers (the I term), waveform generators
(triangle wave from square wave input), and active filters.

\begin{examplebox}

\textbf{Example 13.2.3:} An op-amp integrator has R = 10 kΩ and C = 100
nF. A constant input of V\textsubscript{in} = -2.0 V is applied starting
at t = 0 with the capacitor initially discharged. Calculate the output
voltage at t = 1 ms and t = 5 ms. At what time does the output reach the
+12 V supply rail?

\textbf{Solution:}\\
Time constant: RC = 10,000 × 100 × 10⁻⁹ = 1.0 ms.\\
For a constant input: V\textsubscript{out}(t) = -(1/RC) ×
V\textsubscript{in} × t = -(1/0.001) × (-2.0) × t = 2000t.\\
At t = 1 ms: V\textsubscript{out} = 2000 × 0.001 = 2.0 V.\\
At t = 5 ms: V\textsubscript{out} = 2000 × 0.005 = 10.0 V.\\
The output reaches +12 V when: 12 = 2000t, so t = 12/2000 = 6.0 ms.\\
After 6.0 ms, the output saturates at the positive supply rail.\\
Ramp rate (slew): dV\textsubscript{out}/dt = 2000 V/s = 2.0 V/ms.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-2-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_integrator.png}

\caption{Figure 13.2.3: Op-Amp Integrator Step Response}

\end{figure}

\subsection{13.2.4 Differentiator}\label{differentiator}

The differentiator swaps the input resistor and feedback capacitor of
the integrator, placing a capacitor C at the input and a resistor
R\textsubscript{f} in the feedback path: V\textsubscript{out}(t) =
-R\textsubscript{f} × C × dV\textsubscript{in}/dt. The output is
proportional to the rate of change of the input signal, making it useful
for edge detection, frequency-to-voltage conversion, and the D term in
PID controllers. For a sinusoidal input at frequency f, the gain
increases linearly with frequency (6 dB/octave), which amplifies
high-frequency noise. Practical differentiators include a small series
resistor with the input capacitor (R\textsubscript{s}, typically
R\textsubscript{f}/10 to R\textsubscript{f}/100) to limit the
high-frequency gain and prevent oscillation, creating a bandlimited
differentiator that behaves as a true differentiator only below the
corner frequency f\textsubscript{c} = 1/(2πR\textsubscript{s}C).

\begin{examplebox}

\textbf{Example 13.2.4:} A differentiator has C = 10 nF and
R\textsubscript{f} = 100 kΩ. A triangular wave input with a peak-to-peak
amplitude of 4.0 V and a period of 2 ms is applied. Calculate the output
voltage during the rising and falling portions of the triangle wave.

\textbf{Solution:}\\
The time constant: R\textsubscript{f} × C = 100,000 × 10 × 10⁻⁹ = 1.0
ms.\\
The triangle wave rises from -2 V to +2 V in T/2 = 1 ms, so
dV\textsubscript{in}/dt(rising) = 4.0 / 0.001 = 4000 V/s.\\
During the rising portion: V\textsubscript{out} = -R\textsubscript{f} ×
C × dV\textsubscript{in}/dt = -0.001 × 4000 = -4.0 V.\\
During the falling portion: dV\textsubscript{in}/dt = -4000 V/s, so
V\textsubscript{out} = -0.001 × (-4000) = +4.0 V.\\
The output is a square wave alternating between -4.0 V and +4.0 V, which
is the derivative of the triangular input.\\
At the triangle wave peaks, the abrupt slope change causes sharp
transitions in the output.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-2-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_differentiator.png}

\caption{Figure 13.2.4: Op-Amp Differentiator Response}

\end{figure}

\subsection{13.2.5 Logarithmic and Exponential
Amplifiers}\label{logarithmic-and-exponential-amplifiers}

The logarithmic amplifier replaces the linear feedback resistor of an
inverting amplifier with a diode or BJT collector-base junction,
exploiting the exponential I--V relationship of a semiconductor junction
to produce an output proportional to the logarithm of the input. With a
BJT in the feedback path (collector to inverting input, emitter to
output), the output is V\textsubscript{out} = -(kT/q) ×
ln(V\textsubscript{in} / (I\textsubscript{S} × R\textsubscript{in})),
where kT/q ≈ 26 mV at 25°C, I\textsubscript{S} is the transistor
saturation current, and R\textsubscript{in} is the input resistor. The
exponential (antilog) amplifier reverses the arrangement, placing the
transistor at the input and a resistor in the feedback path, producing
V\textsubscript{out} = -I\textsubscript{S} × R\textsubscript{f} ×
e\textsuperscript{-Vinq/(kT)}. Because I\textsubscript{S} is strongly
temperature-dependent (approximately doubling every 10°C), practical log
amplifiers use a matched transistor pair in a temperature-compensated
configuration --- one transistor in the log circuit and a second in a
reference circuit --- to cancel the I\textsubscript{S} dependence and
produce V\textsubscript{out} = -(kT/q) ×
ln(V\textsubscript{in}/V\textsubscript{ref}). Integrated log amplifier
ICs (such as the LOG101 and LOG112) include matched transistors,
temperature compensation, and scaling amplifiers on a single die. Log
and antilog amplifiers enable analog multiplication and division (by
adding/subtracting logarithms), decibel-scale measurements, signal
compression for wide dynamic range (e.g., audio companders), and
RMS-to-DC conversion. The useful input dynamic range spans 3--7 decades
(e.g., 1 nA to 10 mA, or 10 μV to 10 V), limited by the transistor's
conformance to the ideal exponential law at low currents and by
high-injection effects at high currents.

\begin{examplebox}

\textbf{Example 13.2.5:} A logarithmic amplifier uses a BJT with
I\textsubscript{S} = 10⁻¹⁴ A in the feedback path and
R\textsubscript{in} = 10 kΩ. Calculate the output voltage for input
voltages of V\textsubscript{in} = 10 mV, 100 mV, 1 V, and 10 V at 25°C.
What is the change in output per decade of input?

\textbf{Solution:}\\
At 25°C, kT/q = 25.69 mV.\\
Input current: I\textsubscript{in} =
V\textsubscript{in}/R\textsubscript{in}.\\
V\textsubscript{out} = -(kT/q) ×
ln(I\textsubscript{in}/I\textsubscript{S}) = -0.025693 ×
ln(V\textsubscript{in}/(R\textsubscript{in} × I\textsubscript{S})).\\
For V\textsubscript{in} = 10 mV: I\textsubscript{in} = 1 μA,
V\textsubscript{out} = -0.025693 × ln(10⁻⁶/10⁻¹⁴) = -0.025693 × ln(10⁸)
= -0.025693 × 18.42 = -0.473 V.\\
For V\textsubscript{in} = 100 mV: I\textsubscript{in} = 10 μA,
V\textsubscript{out} = -0.025693 × ln(10⁹) = -0.025693 × 20.72 = -0.532
V.\\
For V\textsubscript{in} = 1 V: I\textsubscript{in} = 100 μA,
V\textsubscript{out} = -0.025693 × ln(10¹⁰) = -0.025693 × 23.03 = -0.592
V.\\
For V\textsubscript{in} = 10 V: I\textsubscript{in} = 1 mA,
V\textsubscript{out} = -0.025693 × ln(10¹¹) = -0.025693 × 25.33 = -0.651
V.\\
Change per decade: ΔV\textsubscript{out} = -(kT/q) × ln(10) = -0.025693
× 2.303 = -59.2 mV/decade.\\
A scaling amplifier typically multiplies this by a factor of 10--17 to
produce a convenient -1 V/decade output.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-2-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_log_amp.png}

\caption{Figure 13.2.5: Log Amplifier Transfer Curve}

\end{figure}

\subsection{13.2.6 Precision Rectifier}\label{precision-rectifier}

The precision rectifier (also called a superdiode) uses an op-amp to
overcome the forward voltage drop of a conventional diode, enabling
rectification of millivolt-level signals that would be completely lost
in a standard diode's 0.5--0.7 V threshold. In the basic half-wave
precision rectifier, a diode is placed in the feedback loop of an
inverting amplifier: during the positive input half-cycle, the op-amp
drives the diode into conduction and the circuit behaves as an inverting
amplifier with gain −R\textsubscript{f}/R\textsubscript{in}; during the
negative half-cycle, the diode is reverse-biased, the feedback loop
opens, and the output is zero (clamped by a pull-down resistor). The
effective forward voltage drop seen by the signal is reduced by the
op-amp's open-loop gain --- a 0.6 V silicon diode divided by
A\textsubscript{OL} = 100,000 yields an effective threshold of only 6
μV. A \textbf{full-wave precision rectifier} (absolute value circuit)
combines two op-amps: the first produces the inverted half-wave
rectified signal, and the second sums the original signal with twice the
inverted half-wave to produce \textbar V\textsubscript{in}\textbar{} ×
(R\textsubscript{f}/R\textsubscript{in}). Precision rectifiers are used
in AC-to-DC conversion for metering, AM demodulation of low-level
signals, and RMS-to-DC converters. The primary limitation is speed ---
when the diode turns off, the op-amp output must slew from the positive
rail to the negative rail (or vice versa) before the diode can conduct
again on the next half-cycle, limiting operation to frequencies well
below f\textsubscript{max} ≈ SR / (2πV\textsubscript{sat}), where
V\textsubscript{sat} is the op-amp saturation voltage.

\begin{examplebox}

\textbf{Example 13.2.6:} A precision full-wave rectifier (absolute value
circuit) uses op-amps with A\textsubscript{OL} = 100,000 and SR = 10
V/μs. The input is a 200 mV\textsubscript{peak}, 5 kHz sine wave.
Calculate the effective diode threshold, the DC output voltage (average
of \textbar V\textsubscript{in}\textbar), and the maximum operating
frequency if the op-amp saturates at ±12 V.

\textbf{Solution:}\\
Effective diode threshold: V\textsubscript{D(eff)} = V\textsubscript{F}
/ A\textsubscript{OL} = 0.6 / 100,000 = 6 μV --- negligible compared to
the 200 mV signal.\\
For a full-wave rectified sine wave, the average (DC) value is
V\textsubscript{dc} = 2V\textsubscript{peak}/π = 2 × 200 mV / π = 127.3
mV.\\
At 5 kHz this is well within the op-amp's capability.\\
Maximum operating frequency: when the diode turns off, the op-amp must
slew from +V\textsubscript{sat} to −V\textsubscript{sat} (24 V swing).\\
Recovery time: t\textsubscript{rec} = 2V\textsubscript{sat} / SR = 24 /
(10 × 10⁶) = 2.4 μs.\\
For less than 5\% distortion, the recovery time should be less than 5\%
of the half-period: t\textsubscript{rec} \textless{} 0.05 × T/2.\\
T/2 \textgreater{} t\textsubscript{rec} / 0.05 = 2.4 μs / 0.05 = 48 μs,
so f\textsubscript{max} \textless{} 1/(2 × 48 μs) = 10.4 kHz.\\
A faster op-amp (SR = 50 V/μs) would extend this to \textasciitilde52
kHz.

\end{examplebox}

\section{13.3 Non-Inverting
Configurations}\label{non-inverting-configurations}

Non-inverting configurations apply the input signal to the non-inverting
(+) terminal, providing high input impedance and a non-inverted output.
The feedback network connects from the output to the inverting terminal,
and the gain is always ≥ 1. This topology is preferred when the signal
source has high impedance (sensors, voltage dividers, reference
circuits) because the op-amp's input draws negligible current.

\subsection{13.3.1 Non-Inverting
Amplifier}\label{non-inverting-amplifier}

The non-inverting amplifier applies the input signal to the
non-inverting (+) input, with a voltage divider (R₁ to ground,
R\textsubscript{f} from output to inverting input) setting the feedback.
The closed-loop gain is A\textsubscript{v} = 1 + R\textsubscript{f}/R₁,
which is always greater than or equal to 1 and does not invert the
signal. The input impedance is extremely high (approaching the op-amp's
open-loop input impedance, typically \textgreater10⁹ Ω for FET-input
devices) because the input connects directly to the non-inverting
terminal with no input resistor. This high input impedance makes the
non-inverting amplifier ideal for buffering high-impedance sources such
as sensors and reference circuits.

\begin{examplebox}

\textbf{Example 13.3.1:} Design a non-inverting amplifier with a gain of
15 using R₁ = 3.3 kΩ. Calculate R\textsubscript{f}, the output voltage
for V\textsubscript{in} = 0.8 V, and the input impedance advantage over
an equivalent inverting amplifier.

\textbf{Solution:}\\
A\textsubscript{v} = 1 + R\textsubscript{f}/R₁, so R\textsubscript{f} =
(A\textsubscript{v} - 1) × R₁ = 14 × 3,300 = 46.2 kΩ (use 47 kΩ standard
value, giving A\textsubscript{v} = 1 + 47,000/3,300 = 15.24).\\
Output voltage: V\textsubscript{out} = 15.24 × 0.8 = 12.19 V.\\
Input impedance: for the non-inverting configuration,
Z\textsubscript{in} ≈ Z\textsubscript{in(op-amp)} × (1 +
A\textsubscript{OL} × β), which is typically \textgreater10⁹ Ω.\\
An equivalent inverting amplifier with gain of -15 using
R\textsubscript{in} = 3.3 kΩ would have Z\textsubscript{in} =
R\textsubscript{in} = 3.3 kΩ -- over 300,000× lower than the
non-inverting version.

\end{examplebox}

\subsection{13.3.2 Voltage Follower
(Buffer)}\label{voltage-follower-buffer}

The voltage follower (also called a unity-gain buffer) is the simplest
non-inverting configuration, with 100\% feedback (R\textsubscript{f} =
0, R₁ = ∞, or equivalently the output connected directly to the
inverting input). The gain is A\textsubscript{v} = 1, so
V\textsubscript{out} = V\textsubscript{in} with no inversion. The
voltage follower provides the highest possible input impedance and
lowest possible output impedance of any op-amp configuration, making it
ideal for impedance matching --- isolating a high-impedance source from
a low-impedance load without signal attenuation. It is commonly used to
buffer voltage references, sensor outputs, and voltage dividers that
would otherwise be loaded by downstream circuitry.

\begin{examplebox}

\textbf{Example 13.3.2:} A voltage divider produces 2.5 V from a 5.0 V
supply using two 100 kΩ resistors. A 1 kΩ load is connected. Calculate
the output voltage (a) without a buffer and (b) with a voltage follower
buffer. What is the loading error without the buffer?

\textbf{Solution:}

(a) Without buffer: the 1 kΩ load is in parallel with the lower 100 kΩ
resistor.\\
R\textsubscript{parallel} = (100,000 × 1,000) / (100,000 + 1,000) =
990.1 Ω.\\
V\textsubscript{out} = 5.0 × 990.1 / (100,000 + 990.1) = 5.0 × 990.1 /
100,990 = 0.0490 V.\\
Loading error: (2.5 - 0.049) / 2.5 × 100\% = 98.0\% -- the voltage
divider is completely collapsed.

(b) With buffer: the buffer input impedance is \textgreater10⁹ Ω, so the
divider sees essentially no load.\\
V\textsubscript{out(buffer input)} = 2.5 V.\\
The buffer drives the 1 kΩ load directly: V\textsubscript{out} = 2.5
V.\\
Loading error: ≈ 0\%.\\
The buffer transforms the 50 kΩ source impedance of the divider to ≈ 0
Ω.

\end{examplebox}

\subsection{13.3.3 Transimpedance
Amplifier}\label{transimpedance-amplifier}

The transimpedance amplifier (TIA) converts an input current to an
output voltage, with a transimpedance gain (transfer impedance) of
V\textsubscript{out} = -I\textsubscript{in} × R\textsubscript{f}, where
R\textsubscript{f} is the feedback resistor. The input current source
(typically a photodiode, phototransistor, or current-output DAC)
connects to the inverting input, which is held at virtual ground,
providing a low-impedance termination for the current source. A small
feedback capacitor C\textsubscript{f} is placed in parallel with
R\textsubscript{f} to stabilize the circuit against oscillation caused
by the input capacitance of the current source (C\textsubscript{in})
interacting with R\textsubscript{f}. The bandwidth of the TIA is limited
by the pole formed by R\textsubscript{f} and C\textsubscript{f}:
f\textsubscript{3dB} = 1/(2πR\textsubscript{f}C\textsubscript{f}), and
the optimal C\textsubscript{f} for a Butterworth-like response is
C\textsubscript{f} = √(C\textsubscript{in} / (2π × R\textsubscript{f} ×
GBW)), where GBW is the op-amp's gain-bandwidth product. Transimpedance
amplifiers are essential in fiber optic receivers, optical disc readers,
spectroscopy instruments, and any application requiring precise
measurement of small currents.

\begin{examplebox}

\textbf{Example 13.3.3:} A photodiode with a capacitance of
C\textsubscript{in} = 25 pF produces a photocurrent of 10 μA at the
operating light level. A TIA with R\textsubscript{f} = 100 kΩ is used to
convert this current to a voltage. The op-amp has a GBW of 10 MHz.
Calculate the output voltage, the optimal feedback capacitance
C\textsubscript{f} for stability, and the resulting signal bandwidth.

\textbf{Solution:}\\
Output voltage: V\textsubscript{out} = -I\textsubscript{in} ×
R\textsubscript{f} = -10 × 10⁻⁶ × 100,000 = -1.0 V.\\
Optimal feedback capacitance: C\textsubscript{f} = √(C\textsubscript{in}
/ (2π × R\textsubscript{f} × GBW)) = √(25 × 10⁻¹² / (2π × 100,000 × 10 ×
10⁶)) = √(25 × 10⁻¹² / 6.283 × 10¹²) = √(3.979 × 10⁻²⁴) = 1.99 × 10⁻¹² F
≈ 2.0 pF.\\
Signal bandwidth: f\textsubscript{3dB} =
1/(2πR\textsubscript{f}C\textsubscript{f}) = 1/(2π × 100,000 × 2.0 ×
10⁻¹²) = 1/(1.257 × 10⁻⁶) = 796 kHz.\\
Noise gain peaking frequency (where instability would occur without
C\textsubscript{f}): f\textsubscript{p} = √(GBW /
(2πR\textsubscript{f}C\textsubscript{in})) = √(10 × 10⁶ / (2π × 100,000
× 25 × 10⁻¹²)) = √(6.37 × 10¹¹) = 798 kHz.

\end{examplebox}

\subsection{13.3.4 Programmable Gain Amplifier
(PGA)}\label{programmable-gain-amplifier-pga}

A programmable gain amplifier allows its gain to be changed dynamically
--- either digitally via control pins or through software commands ---
enabling a single signal path to accommodate inputs spanning a wide
dynamic range. The simplest PGA uses an analog multiplexer to switch
between different feedback resistors in an inverting or non-inverting
configuration, providing gain steps set by the resistor ratios (e.g.,
gains of 1, 2, 4, 8). Integrated PGA ICs (such as the PGA280 and
MCP6S26) include laser-trimmed resistor networks with gain accuracy of
0.01--0.1\%, an input multiplexer, SPI or I²C control, and settling
times of 1--10 μs after a gain change. In data acquisition systems, the
PGA sits between the input multiplexer and the ADC, and the system
controller selects the gain for each channel based on the expected
signal level --- using high gain for small signals (thermocouples,
strain gauges) and low gain for large signals (voltage monitors),
maximizing the effective dynamic range of the ADC. A critical
specification is \textbf{gain switching transient} (glitch energy),
which is the brief output disturbance that occurs when the gain changes;
this transient must settle before the ADC samples, requiring a delay of
several time constants after each gain change. The \textbf{noise gain}
of a PGA increases with the programmed gain, so the input-referred noise
contribution of the ADC is divided by the PGA gain --- improving the
system's noise performance for small signals. Some Σ-Δ ADCs (e.g.,
ADS1256, AD7190) integrate a PGA on-chip with gains from 1 to 128,
eliminating the external PGA and its associated settling and noise
issues.

\begin{examplebox}

\textbf{Example 13.3.4:} A 16-bit SAR ADC with a ±5 V input range and an
input-referred noise of 120 μV\textsubscript{rms} is preceded by a PGA
with selectable gains of 1, 10, and 100. A thermocouple produces a 5 mV
signal. Calculate the effective ADC resolution (ENOB) at each PGA gain
setting and determine which gain maximizes measurement quality.

\textbf{Solution:}\\
ADC LSB = 10 V / 2¹⁶ = 152.6 μV.\\
At PGA gain = 1: signal at ADC = 5 mV (33 LSBs). Input-referred noise =
120 μV, SNR = 20log₁₀(5 mV / 120 μV) = 32.4 dB, ENOB = (32.4 − 1.76) /
6.02 = 5.1 bits --- very poor, only 33 of 65,536 codes used.\\
At PGA gain = 10: signal at ADC = 50 mV (328 LSBs). Noise referred to
input = 120 μV / 10 = 12 μV. SNR = 20log₁₀(5 mV / 12 μV) = 52.4 dB, ENOB
= 8.4 bits --- significant improvement.\\
At PGA gain = 100: signal at ADC = 500 mV (3,277 LSBs). Noise referred
to input = 120 μV / 100 = 1.2 μV. SNR = 20log₁₀(5 mV / 1.2 μV) = 72.4
dB, ENOB = 11.7 bits.\\
However, the PGA's own noise (e.g., 10 nV/√Hz over 100 kHz BW = 3.16
μV\textsubscript{rms}) now becomes the dominant noise source.\\
Combined input noise = √(1.2² + 3.16²) = 3.38 μV\textsubscript{rms}, SNR
= 63.4 dB, ENOB = 10.2 bits.\\
\textbf{Gain = 100} provides the best measurement, improving from 5.1 to
10.2 effective bits --- but the PGA's own noise limits further
improvement, and a lower-noise PGA or integrated Σ-Δ ADC with on-chip
PGA would be needed for higher resolution.

\end{examplebox}

\section{13.4 Differential and Instrumentation
Amplifiers}\label{differential-and-instrumentation-amplifiers}

Differential amplifiers amplify the difference between two input signals
while rejecting common-mode signals present on both inputs. This
capability is critical for measuring small signals from sensors (strain
gauges, thermocouples, current shunts) that sit on large common-mode
voltages or in noisy environments. The basic single-op-amp difference
amplifier is limited by resistor matching, while the three-op-amp
instrumentation amplifier overcomes this limitation with laser-trimmed
internal resistors and a single gain-setting resistor.

\subsection{13.4.1 Difference Amplifier}\label{difference-amplifier}

The difference amplifier uses four resistors arranged so that the op-amp
amplifies only the difference between two input signals while rejecting
any signal common to both inputs. The basic configuration applies V₁
through R₁ to the inverting input (with R₂ as feedback) and V₂ through
R₃ to the non-inverting input (with R₄ to ground). When R₂/R₁ = R₄/R₃,
the output is V\textsubscript{out} = (R₂/R₁)(V₂ - V₁). The Common-Mode
Rejection Ratio (CMRR) depends critically on resistor matching --- a
0.1\% mismatch in a gain-of-1 difference amplifier limits CMRR to
approximately 66 dB. For this reason, precision difference amplifiers
use laser-trimmed thin-film resistor networks integrated with the
op-amp.

\begin{examplebox}

\textbf{Example 13.4.1:} A difference amplifier with R₁ = R₃ = 10 kΩ and
R₂ = R₄ = 100 kΩ measures the voltage across a 0.1 Ω current sense
resistor carrying 5 A, with a common-mode voltage of 48 V. If R₄ has a
0.1\% tolerance error (R₄ = 100,100 Ω), calculate the ideal output, the
common-mode error, and the effective CMRR.

\textbf{Solution:}\\
Differential signal: V\textsubscript{diff} = I × R\textsubscript{sense}
= 5 × 0.1 = 0.5 V.\\
Gain: A\textsubscript{diff} = R₂/R₁ = 100,000/10,000 = 10.\\
Ideal output: V\textsubscript{out} = 10 × 0.5 = 5.0 V.\\
Common-mode gain with mismatched R₄: A\textsubscript{cm} ≈ (ΔR/R) ×
(R₂/R₁) / (1 + R₂/R₁) = (0.001) × 10 / 11 = 0.000909.\\
Common-mode error voltage: V\textsubscript{error} = A\textsubscript{cm}
× V\textsubscript{cm} = 0.000909 × 48 = 43.6 mV.\\
Total output: 5.0 + 0.0436 = 5.044 V (0.87\% error).\\
CMRR = A\textsubscript{diff} / A\textsubscript{cm} = 10 / 0.000909 =
11,000, or 20log₁₀(11,000) = 80.8 dB.

\end{examplebox}

\subsection{13.4.2 Instrumentation
Amplifier}\label{instrumentation-amplifier}

The instrumentation amplifier (INA) is a precision differential
amplifier consisting of three op-amps: two non-inverting input buffers
and one difference amplifier output stage. The input buffers provide
extremely high input impedance (\textgreater10⁹ Ω) on both inputs and
allow the differential gain to be set by a single external resistor
R\textsubscript{G}: A\textsubscript{v} = 1 + 2R/R\textsubscript{G},
where R is an internal matched resistor (typically 25 kΩ or 50 kΩ). The
output difference stage uses laser-trimmed internal resistors to achieve
CMRR of 80-120 dB without requiring external resistor matching. INAs are
the standard choice for amplifying small differential signals from
Wheatstone bridges, thermocouples, biomedical electrodes, and other
sensors in the presence of large common-mode voltages.

\begin{examplebox}

\textbf{Example 13.4.2:} An INA333 instrumentation amplifier has
internal resistors R = 25 kΩ and is configured with R\textsubscript{G} =
1 kΩ. It amplifies a strain gauge bridge that produces a 2.5 mV
differential signal with 2.5 V common mode. The INA has CMRR = 100 dB.
Calculate the gain, the desired output, and the common-mode error.

\textbf{Solution:}\\
Gain: A\textsubscript{v} = 1 + 2R/R\textsubscript{G} = 1 +
2(25,000)/1,000 = 1 + 50 = 51.\\
Desired output: V\textsubscript{out} = 51 × 2.5 mV = 127.5 mV.\\
CMRR = 100 dB = 10\^{}(100/20) = 100,000.\\
Common-mode gain: A\textsubscript{cm} = A\textsubscript{diff} / CMRR =
51 / 100,000 = 0.00051.\\
Common-mode error at output: V\textsubscript{error} =
A\textsubscript{cm} × V\textsubscript{cm} = 0.00051 × 2.5 = 1.275 mV.\\
Percentage error: 1.275 / 127.5 × 100\% = 1.0\%.\\
To reduce this error to \textless{} 0.1\%, a CMRR of at least 120 dB is
needed, or the common-mode voltage must be reduced.

\end{examplebox}

\subsection{13.4.3 Current Sense
Amplifiers}\label{current-sense-amplifiers}

Current sense amplifiers are specialized differential amplifiers
optimized for measuring voltage drops across low-value shunt resistors
(typically 1--100 mΩ) in power supply lines, providing an output voltage
proportional to the load current. Unlike general-purpose difference
amplifiers, current sense amplifiers are designed to operate with high
common-mode voltages --- \textbf{high-side} current sensing measures
current between the supply rail and the load, requiring the amplifier to
reject common-mode voltages up to the full bus voltage (12 V, 48 V, or
even 400 V+), while \textbf{low-side} sensing places the shunt between
the load and ground, where the common-mode voltage is near zero but the
ground path is interrupted. High-side sensing is preferred in most
applications because it preserves the load's ground connection and can
detect both load current and fault conditions (short to ground).
Dedicated current sense amplifier ICs (such as the INA181, INA240, and
INA293) integrate gain-setting resistors (gains of 20, 50, 100, or 200
V/V), laser-trimmed for accuracy, and achieve CMRR of 80--140 dB with
common-mode input ranges from -4 V to over 100 V. Bidirectional current
sense amplifiers can measure current flowing in both directions through
the shunt, using a reference voltage at the output midpoint, and are
essential in battery management systems (charge and discharge), motor
drives (H-bridge current), and regenerative braking systems. Key
specifications include gain error (\textless0.5\%), offset voltage
referred to input (\textless25 μV), common-mode rejection ratio, maximum
common-mode voltage, bandwidth (50 kHz to 1 MHz), and output voltage
range.

\begin{examplebox}

\textbf{Example 13.4.3:} A high-side current sense amplifier (INA181A3,
gain = 100 V/V) monitors load current through a 10 mΩ shunt resistor on
a 48 V bus. The amplifier has V\textsubscript{OS} = 35 μV (referred to
input), gain error = 0.3\%, and CMRR = 132 dB at DC. The load draws 20
A. Calculate the ideal output voltage, the total output error, and the
minimum detectable current.

\textbf{Solution:}\\
Shunt voltage: V\textsubscript{shunt} = I × R\textsubscript{shunt} = 20
× 0.010 = 200 mV.\\
Ideal output: V\textsubscript{out} = V\textsubscript{shunt} × Gain =
0.200 × 100 = 20.0 V --- this exceeds a typical 5 V supply, so in
practice the amplifier would saturate.\\
Using a 5 mΩ shunt instead: V\textsubscript{shunt} = 20 × 0.005 = 100
mV, V\textsubscript{out} = 100 mV × 100 = 10.0 V (within a 12 V supply
range).\\
Offset error at output: V\textsubscript{OS} × Gain = 35 × 10⁻⁶ × 100 =
3.5 mV.\\
Gain error: 0.3\% × 10.0 V = 30 mV.\\
CMRR error: CMRR = 132 dB = 3.981 × 10⁶. Common-mode referred-to-input
error = 48/3.981 × 10⁶ = 12.1 μV, at output = 12.1 μV × 100 = 1.21 mV.\\
Total output error ≈ 3.5 + 30 + 1.2 = 34.7 mV (0.35\% of 10.0 V).\\
Minimum detectable current (limited by offset): I\textsubscript{min} =
V\textsubscript{OS}/R\textsubscript{shunt} = 35 μV / 5 mΩ = 7 mA.

\end{examplebox}

\section{13.5 Active Filters}\label{active-filters}

Active filters use op-amps with resistors and capacitors to implement
frequency-selective circuits that can provide gain, low output
impedance, and sharp roll-off characteristics impossible with passive RC
networks alone. Unlike passive LC filters, active filters do not require
inductors (which are bulky, lossy, and impractical at low frequencies),
making them the standard approach for audio, instrumentation, and
control system filtering. Common topologies include Sallen-Key
(voltage-controlled voltage source), multiple feedback, and
state-variable, each offering different trade-offs in component
sensitivity, tuning flexibility, and available filter outputs.

\subsection{13.5.1 First-Order Filters}\label{first-order-filters}

First-order active filters use a single op-amp with one reactive element
(capacitor) to provide a frequency response with a -20 dB/decade (6
dB/octave) roll-off. A first-order lowpass filter places a capacitor in
parallel with the feedback resistor of an inverting amplifier: the gain
is flat at -R\textsubscript{f}/R\textsubscript{in} up to the cutoff
frequency f\textsubscript{c} = 1/(2πR\textsubscript{f}C), above which it
rolls off at -20 dB/decade. A first-order highpass filter places the
capacitor in series with the input resistor: the gain is zero at DC,
rises at +20 dB/decade, and levels off at
-R\textsubscript{f}/R\textsubscript{in} above f\textsubscript{c} =
1/(2πR\textsubscript{in}C). First-order active filters provide gain
(unlike passive RC filters which can only attenuate), have a
low-impedance output, and avoid loading effects on the source.

\begin{examplebox}

\textbf{Example 13.5.1:} Design a first-order active lowpass filter with
a passband gain of -5 (inverting) and a cutoff frequency of 3.4 kHz
(telephone bandwidth). Choose R\textsubscript{in} and calculate C for a
100 kΩ feedback resistor.

\textbf{Solution:}\\
Passband gain: A\textsubscript{v} =
-R\textsubscript{f}/R\textsubscript{in}, so R\textsubscript{in} =
R\textsubscript{f} / \textbar A\textsubscript{v}\textbar{} = 100,000 / 5
= 20 kΩ.\\
Cutoff frequency: f\textsubscript{c} = 1/(2πR\textsubscript{f}C), so C =
1/(2π × R\textsubscript{f} × f\textsubscript{c}) = 1/(2π × 100,000 ×
3,400) = 1 / (2.136 × 10⁹) = 468 pF (use 470 pF standard value).\\
Verification: f\textsubscript{c} = 1/(2π × 100,000 × 470 × 10⁻¹²) =
3,386 Hz ≈ 3.4 kHz.\\
At f = 10 kHz (2.95× f\textsubscript{c}): gain = -5 / √(1 +
(10,000/3,386)²) = -5 / √(1 + 8.72) = -5 / 3.12 = -1.60, or
20log₁₀(1.60/5) = -9.9 dB relative to the passband gain.

\end{examplebox}

\subsection{13.5.2 Sallen-Key Filters}\label{sallen-key-filters}

The Sallen-Key topology is the most popular second-order active filter
structure, using a single op-amp configured as a non-inverting amplifier
(typically unity gain) with two resistors and two capacitors forming the
frequency-selective network. The standard unity-gain Sallen-Key lowpass
filter has the transfer function with cutoff frequency
f\textsubscript{c} = 1/(2π√(R₁R₂C₁C₂)) and quality factor Q =
√(R₁R₂C₁C₂) / (C₂(R₁ + R₂)). By choosing equal-value components (R₁ = R₂
= R, C₁ = C₂ = C), the design simplifies to f\textsubscript{c} =
1/(2πRC) with Q = 0.5, which gives a critically damped response (no
overshoot, fastest settling time). For a Butterworth response (Q =
0.707), the capacitor ratio C₁/C₂ = 2 is used with equal resistors. The
Sallen-Key topology uses minimal components, has low sensitivity to
component tolerances at unity gain, and can be cascaded to create
higher-order filters.

\begin{examplebox}

\textbf{Example 13.5.2:} Design a unity-gain Sallen-Key Butterworth
lowpass filter with a cutoff frequency of 1 kHz. Use equal resistors and
a 10 nF capacitor for C₂. Calculate R and C₁.

\textbf{Solution:}\\
For a Butterworth response with equal resistors: C₁ = 2 × C₂ = 2 × 10 nF
= 20 nF.\\
Cutoff frequency: f\textsubscript{c} = 1/(2πR√(C₁C₂)) = 1/(2πR√(20 ×
10⁻⁹ × 10 × 10⁻⁹)).\\
√(C₁C₂) = √(200 × 10⁻¹⁸) = 14.14 × 10⁻⁹.\\
So R = 1/(2π × 1000 × 14.14 × 10⁻⁹) = 1/(88.86 × 10⁻⁶) = 11.25 kΩ (use
11 kΩ standard value).\\
Verification: f\textsubscript{c} = 1/(2π × 11,000 × 14.14 × 10⁻⁹) =
1/(977 × 10⁻⁶) = 1,024 Hz ≈ 1 kHz.\\
Q = √(R²C₁C₂) / (C₂ × 2R) = R√(C₁C₂) / (2RC₂) = √(C₁/C₂) / 2 = √2 / 2 =
0.707, confirming the Butterworth response.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-5-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_sallen_key.png}

\caption{Figure 13.5.2: Sallen-Key Butterworth Bode Plot}

\end{figure}

\subsection{13.5.3 State-Variable Filters}\label{state-variable-filters}

The state-variable filter uses three op-amps (a summing amplifier and
two integrators) connected in a feedback loop to simultaneously provide
lowpass, highpass, and bandpass outputs from a single circuit. The
center frequency is f₀ = 1/(2πRC) (where R and C are the integrator
components), the quality factor Q is set by the resistor ratios in the
summing amplifier, and the gain of each output is independently
controllable. A fourth op-amp can be added to sum the lowpass and
highpass outputs with appropriate weighting to produce a bandstop
(notch) response. The state-variable topology offers independent control
of f₀, Q, and gain --- changing the frequency does not affect Q, and
vice versa --- making it ideal for tunable filters, audio equalizers,
and measurement instruments where filter parameters must be adjusted
without interaction.

\begin{examplebox}

\textbf{Example 13.5.3:} A state-variable bandpass filter is designed
for a center frequency of f₀ = 5 kHz with Q = 10. The integrator
components are C = 10 nF. Calculate the integrator resistance R, the
bandwidth, and the lower and upper -3 dB frequencies.

\textbf{Solution:}\\
Integrator resistance: R = 1/(2πf₀C) = 1/(2π × 5,000 × 10 × 10⁻⁹) =
1/(314.16 × 10⁻⁶) = 3,183 Ω (use 3.16 kΩ standard value).\\
Bandwidth: BW = f₀/Q = 5,000/10 = 500 Hz.\\
Lower -3 dB frequency: f\textsubscript{L} = f₀ - BW/2 = 5,000 - 250 =
4,750 Hz.\\
Upper -3 dB frequency: f\textsubscript{H} = f₀ + BW/2 = 5,000 + 250 =
5,250 Hz.\\
(More precisely for high Q: f\textsubscript{L} = f₀ × (√(1 + 1/(4Q²)) -
1/(2Q)) = 4,756 Hz and f\textsubscript{H} = f₀ × (√(1 + 1/(4Q²)) +
1/(2Q)) = 5,256 Hz.)\\
The bandpass gain at f₀ equals Q × A₀, where A₀ is the integrator gain.

\end{examplebox}

\subsection{13.5.4 Multiple Feedback
Filters}\label{multiple-feedback-filters}

The multiple feedback (MFB) topology uses a single op-amp in an
inverting configuration with two feedback paths to implement
second-order lowpass, highpass, or bandpass filters. The MFB bandpass
filter is particularly popular because it provides a narrow bandpass
response with a single op-amp, using two resistors and two capacitors,
with the center frequency f₀ = 1/(2πC) × √(1/(R₁R₃)), the quality factor
Q = π × f₀ × C × R₂, and a midband gain of A₀ = -R₂/(2R₁). The MFB
lowpass filter offers an advantage over Sallen-Key at high Q values
because it is less sensitive to op-amp gain-bandwidth limitations and
provides an inherently inverting output. Component sensitivity is
moderate --- the Q and center frequency interact somewhat when
components are changed, making independent tuning more difficult than
with the state-variable topology. The MFB topology is widely used in
audio equalizers, anti-aliasing filters, and communication channel
filters.

\begin{examplebox}

\textbf{Example 13.5.4:} Design a multiple feedback bandpass filter with
a center frequency of f₀ = 2 kHz, Q = 5, and a midband gain of
\textbar A₀\textbar{} = 10 using equal capacitors C = 10 nF. Calculate
R₁, R₂, R₃, and the bandwidth.

\textbf{Solution:}\\
Bandwidth: BW = f₀ / Q = 2,000 / 5 = 400 Hz.\\
From the gain equation: A₀ = -R₂ / (2R₁), so R₂ = 2 ×
\textbar A₀\textbar{} × R₁.\\
From the Q equation: Q = π × f₀ × C × R₂, so R₂ = Q / (π × f₀ × C) = 5 /
(π × 2,000 × 10 × 10⁻⁹) = 5 / (62.83 × 10⁻⁶) = 79,577 Ω ≈ 79.6 kΩ (use
82 kΩ).\\
From the gain: R₁ = R₂ / (2 × \textbar A₀\textbar) = 82,000 / 20 = 4,100
Ω (use 3.9 kΩ).\\
From the center frequency: f₀ = (1/(2πC)) × √(1/(R₁R₃)), so R₃ = 1 /
((2πf₀C)² × R₁) = 1 / ((2π × 2,000 × 10 × 10⁻⁹)² × 3,900) = 1 / ((125.7
× 10⁻⁶)² × 3,900) = 1 / (1.580 × 10⁻⁸ × 3,900) = 1 / (6.162 × 10⁻⁵) =
16,228 Ω (use 16 kΩ).\\
Lower and upper -3 dB frequencies: f\textsubscript{L} ≈ 2,000 - 200 =
1,800 Hz, f\textsubscript{H} ≈ 2,000 + 200 = 2,200 Hz.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-5-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_mfb_bandpass.png}

\caption{Figure 13.5.4: MFB Bandpass Filter Frequency Response}

\end{figure}

\subsection{13.5.5 Notch (Band-Reject)
Filters}\label{notch-band-reject-filters}

A notch filter (band-reject filter) strongly attenuates a narrow band of
frequencies while passing all others, and is widely used to reject
power-line interference (50/60 Hz hum), eliminate specific tones in
audio processing, and remove carrier frequencies in communication
systems. The \textbf{Twin-T notch filter} is the most common passive
notch network, using two T-shaped RC paths in parallel --- one with
series resistors and a shunt capacitor (lowpass path), the other with
series capacitors and a shunt resistor (highpass path). The two paths
produce equal amplitude but opposite phase at the notch frequency f₀ =
1/(2πRC), creating a deep null. The passive Twin-T alone has a broad
notch (low Q ≈ 0.25) and limited rejection depth (\textasciitilde20 dB),
but placing it in the negative feedback loop of an op-amp with positive
feedback dramatically increases the Q and notch depth. With positive
feedback factor k applied from the output to the Twin-T center node, the
quality factor becomes Q = 1/(4(1 − k)), achieving Q = 5 at k = 0.95 and
Q = 25 at k = 0.99 --- narrow enough to reject 60 Hz while preserving
adjacent frequencies. An \textbf{active Twin-T notch filter} uses a
voltage follower buffer to feed a fraction of the output back to the
Twin-T junction, with the feedback ratio set by a resistive voltage
divider. Alternatively, the state-variable filter (§13.5.3) produces a
notch output by summing its lowpass and highpass outputs with equal
gain, and offers independently adjustable f₀ and Q --- a significant
advantage when the interfering frequency varies or must be tuned
precisely. Notch depth in practical circuits is limited by component
matching: the Twin-T requires R and C values matched to better than 1\%
for depths exceeding 40 dB, and the shunt resistor must be exactly R/2
while the shunt capacitor must be exactly 2C.

\begin{examplebox}

\textbf{Example 13.5.5:} Design an active Twin-T notch filter to reject
60 Hz power-line hum. Use C = 100 nF and calculate R. The positive
feedback fraction is k = 0.96. Determine the notch Q, the −3 dB
bandwidth, and the attenuation at 50 Hz and 120 Hz.

\textbf{Solution:}\\
Notch frequency: f₀ = 1/(2πRC), so R = 1/(2πf₀C) = 1/(2π × 60 × 100 ×
10⁻⁹) = 1/(37.70 × 10⁻⁶) = 26,526 Ω.\\
Use 26.7 kΩ (or 27 kΩ standard, giving f₀ = 58.9 Hz --- close enough, or
use 26.1 kΩ + 470 Ω in series for 26.57 kΩ).\\
The shunt resistor = R/2 = 13,263 Ω (use 13.3 kΩ), shunt capacitor = 2C
= 200 nF.\\
Quality factor: Q = 1/(4(1 − k)) = 1/(4 × 0.04) = 6.25.\\
Bandwidth: BW = f₀/Q = 60/6.25 = 9.6 Hz.\\
The −3 dB frequencies are approximately 60 ± 4.8 Hz = 55.2 Hz and 64.8
Hz.\\
Attenuation at 50 Hz: the offset from center is Δf = 10 Hz, normalized u
= 2Δf/BW = 20/9.6 = 2.08. For a second-order notch, the attenuation at
offset u is approximately 1/√(1 + 1/u²) of the passband gain = 1/√(1 +
0.231) = 0.902 = −0.89 dB (minimal attenuation).\\
At 120 Hz (2nd harmonic of 60 Hz): u = 2 × 60/9.6 = 12.5, attenuation ≈
0.997 = −0.026 dB (essentially no effect on the 2nd harmonic).\\
The narrow notch removes the 60 Hz fundamental while preserving the rest
of the spectrum.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-5-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_notch_filter.png}

\caption{Figure 13.5.5: Active Twin-T Notch Filter}

\end{figure}

\section{13.6 Comparators}\label{comparators}

Comparators operate the op-amp without negative feedback, exploiting the
extremely high open-loop gain to produce a binary output that indicates
which of two input voltages is larger. They serve as the interface
between the analog and digital domains, converting continuous signals
into logic levels for threshold detection, waveform shaping, and
analog-to-digital conversion. Adding positive feedback creates a Schmitt
trigger with hysteresis, which provides noise immunity essential for
reliable switching in real-world noisy environments.

\subsection{13.6.1 Basic Comparator}\label{basic-comparator}

A comparator operates the op-amp in open-loop (no negative feedback), so
the high gain drives the output to one of two saturation levels
depending on which input is larger. When V+ \textgreater{} V−, the
output goes to positive saturation (V\textsubscript{OH}, typically
V\textsubscript{CC} - 1 V for op-amps or V\textsubscript{CC} for
rail-to-rail comparators); when V+ \textless{} V−, the output goes to
negative saturation (V\textsubscript{OL}, typically V\textsubscript{EE}
+ 1 V or ground). Dedicated comparator ICs (such as the LM311, LM339,
and TLV3502) are optimized for this function with faster response times
(propagation delays of nanoseconds to microseconds), open-collector or
open-drain outputs for flexible interfacing, and no compensation
capacitor (which would slow the response). Comparators are used in level
detection, zero-crossing detection, analog-to-digital conversion, and
window comparator circuits.

\begin{examplebox}

\textbf{Example 13.6.1:} A comparator with V\textsubscript{OH} = 5.0 V
and V\textsubscript{OL} = 0 V has its inverting input connected to a 2.5
V reference. The non-inverting input receives a 1 kHz sine wave of 3 V
peak centered at 2.5 V (V\textsubscript{in} = 2.5 + 3sin(2π × 1000t)).
Determine the output waveform and the fraction of each period the output
is high.

\textbf{Solution:}\\
The comparator output is high when V\textsubscript{in} \textgreater{}
V\textsubscript{ref} = 2.5 V, i.e., when 2.5 + 3sin(2π × 1000t)
\textgreater{} 2.5, which simplifies to sin(2π × 1000t) \textgreater{}
0.\\
This is true for 0 \textless{} t \textless{} T/2 (the positive
half-cycle).\\
The output is a square wave at 1 kHz with 50\% duty cycle,
V\textsubscript{OH} = 5.0 V for the first half-period and
V\textsubscript{OL} = 0 V for the second half-period.\\
If the reference were shifted to 4.0 V: the condition becomes 3sin(2π ×
1000t) \textgreater{} 1.5, or sin(ωt) \textgreater{} 0.5, which is true
for π/6 \textless{} ωt \textless{} 5π/6.\\
Duty cycle = (5π/6 - π/6) / (2π) = (4π/6) / (2π) = 33.3\%.

\end{examplebox}

\subsection{13.6.2 Schmitt Trigger}\label{schmitt-trigger}

The Schmitt trigger adds positive feedback (from the output to the
non-inverting input) to a comparator, creating hysteresis --- two
different threshold voltages for rising and falling input transitions.
The upper threshold V\textsubscript{TH} (at which the output switches
low-to-high) is higher than the lower threshold V\textsubscript{TL} (at
which it switches high-to-low), with the hysteresis voltage
V\textsubscript{H} = V\textsubscript{TH} - V\textsubscript{TL}.
Hysteresis prevents rapid output oscillation (chatter) when a noisy
input signal hovers near the threshold, which is the primary problem
with a basic comparator used on noisy signals. An \textbf{inverting}
Schmitt trigger places the input signal at the inverting terminal; with
R₁ from the output to the non-inverting input and R₂ from the
non-inverting input to ground, the thresholds are V\textsubscript{TH} =
V\textsubscript{OH} × R₂/(R₁ + R₂) and V\textsubscript{TL} =
V\textsubscript{OL} × R₂/(R₁ + R₂). A \textbf{non-inverting} Schmitt
trigger places the input signal at the non-inverting terminal with a
fixed reference at the inverting terminal; positive feedback through R₁
and R₂ shifts the effective threshold up when the output is high and
down when the output is low, producing the same hysteresis behavior with
an in-phase output.

\begin{examplebox}

\textbf{Example 13.6.2:} Design a \textbf{non-inverting} Schmitt trigger
using a comparator with V\textsubscript{OH} = 5.0 V and
V\textsubscript{OL} = 0 V that has thresholds of V\textsubscript{TH} =
3.0 V and V\textsubscript{TL} = 2.0 V for cleaning up a noisy digital
signal. Calculate the required R₁ and R₂ ratio and the hysteresis
voltage. If R₂ = 10 kΩ, find R₁.

\textbf{Solution:}\\
For this non-inverting Schmitt trigger with a reference at the inverting
input: V\textsubscript{TH} = V\textsubscript{ref} + (V\textsubscript{OH}
- V\textsubscript{ref}) × R₂/(R₁ + R₂) and V\textsubscript{TL} =
V\textsubscript{ref} + (V\textsubscript{OL} - V\textsubscript{ref}) ×
R₂/(R₁ + R₂).\\
With V\textsubscript{ref} at the midpoint: V\textsubscript{ref} =
(V\textsubscript{TH} × V\textsubscript{OL} - V\textsubscript{TL} ×
V\textsubscript{OH}) / (V\textsubscript{OL} - V\textsubscript{OH} +
V\textsubscript{TH} - V\textsubscript{TL}) = (3.0 × 0 - 2.0 × 5.0) / (0
- 5.0 + 3.0 - 2.0) = -10 / -4.0 = 2.5 V.\\
Feedback ratio: R₂/(R₁ + R₂) = (V\textsubscript{TH} -
V\textsubscript{ref}) / (V\textsubscript{OH} - V\textsubscript{ref}) =
(3.0 - 2.5) / (5.0 - 2.5) = 0.5/2.5 = 0.2.\\
With R₂ = 10 kΩ: 10,000/(R₁ + 10,000) = 0.2, so R₁ + 10,000 = 50,000, R₁
= 40 kΩ.\\
Hysteresis: V\textsubscript{H} = V\textsubscript{TH} -
V\textsubscript{TL} = 3.0 - 2.0 = 1.0 V.\\
Any noise with amplitude less than 1.0 V peak-to-peak will not cause
false triggering.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-6-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_schmitt_trigger.png}

\caption{Figure 13.6.2: Schmitt Trigger Hysteresis}

\end{figure}

\subsection{13.6.3 Wien Bridge and Phase-Shift
Oscillators}\label{wien-bridge-and-phase-shift-oscillators}

Op-amp oscillators generate continuous periodic waveforms (sinusoidal,
square, or triangular) without an external input signal, using positive
feedback to sustain oscillation at a frequency determined by the RC
network in the feedback loop. The \textbf{Barkhausen criterion} requires
that the loop gain equals exactly 1 (\textbar Aβ\textbar{} = 1) and the
total phase shift around the loop equals 0° (or 360°) at the oscillation
frequency. The \textbf{Wien bridge oscillator} is the most popular
op-amp sine wave generator, using a series RC and parallel RC network
(Wien network) in the positive feedback path that produces zero phase
shift at f₀ = 1/(2πRC), where the network's attenuation is 1/3. The
non-inverting amplifier must therefore provide a gain of exactly 3
(R\textsubscript{f} = 2R₁) to satisfy the Barkhausen gain condition. In
practice, the gain is set slightly above 3 to ensure oscillation
startup, and an amplitude stabilization mechanism --- either a nonlinear
element (small incandescent lamp whose resistance increases with
amplitude) or an AGC circuit using a FET or analog multiplier --- limits
the output to a clean sinusoid. Without stabilization, the gain excess
causes clipping distortion. The \textbf{phase-shift oscillator} uses
three cascaded RC highpass or lowpass sections to provide the required
180° phase shift at the oscillation frequency, combined with an
inverting amplifier that contributes the remaining 180°. For three
identical RC highpass sections, the oscillation frequency is f₀ =
1/(2πRC√6), and the required gain is
\textbar A\textsubscript{v}\textbar{} = 29 (R\textsubscript{f} =
29R\textsubscript{in}). Phase-shift oscillators produce lower distortion
than Wien bridge oscillators without amplitude stabilization but have a
higher minimum gain requirement and less convenient frequency tuning.

\begin{examplebox}

\textbf{Example 13.6.3:} Design a Wien bridge oscillator for f₀ = 10 kHz
using C = 1.5 nF. Calculate R, and determine R\textsubscript{f} if R₁ =
10 kΩ. If the gain is set 5\% above the critical value for reliable
startup, what is the actual R\textsubscript{f}?

\textbf{Solution:}\\
Wien bridge frequency: f₀ = 1/(2πRC), so R = 1/(2πf₀C) = 1/(2π × 10,000
× 1.5 × 10⁻⁹) = 1/(94.25 × 10⁻⁶) = 10,610 Ω (use 10.7 kΩ or 10 kΩ + 620
Ω in series).\\
Required gain for oscillation: A\textsubscript{v} = 3 exactly, so
R\textsubscript{f} = 2 × R₁ = 2 × 10,000 = 20 kΩ.\\
With 5\% gain excess for startup: A\textsubscript{v} = 3 × 1.05 = 3.15,
R\textsubscript{f} = (3.15 - 1) × R₁ = 2.15 × 10,000 = 21.5 kΩ (use 22
kΩ).\\
Verification: f₀ = 1/(2π × 10,610 × 1.5 × 10⁻⁹) = 1/(100.00 × 10⁻⁶) =
10,000 Hz = 10 kHz.\\
The 5\% gain excess will cause slight clipping at the supply rails;
adding a 1N4148 diode amplitude limiter or a small incandescent lamp
(e.g., \#327 lamp, R\textsubscript{cold} ≈ 50 Ω) in the feedback network
stabilizes the amplitude for a clean sinusoidal output with THD
\textless{} 1\%.

\end{examplebox}

\subsection{13.6.4 Relaxation Oscillator and Astable
Multivibrator}\label{relaxation-oscillator-and-astable-multivibrator}

A relaxation oscillator generates square and triangular waves by
alternately charging and discharging a capacitor between two threshold
voltages set by a Schmitt trigger (positive feedback comparator). The
basic op-amp astable multivibrator connects a capacitor from the output
to the inverting input through a resistor R (forming an RC integrator),
while a resistive voltage divider (R₁ and R₂) from the output to the
non-inverting input establishes the switching thresholds. The capacitor
charges toward the current output level through R; when the capacitor
voltage reaches the Schmitt trigger threshold, the output snaps to the
opposite rail, and the capacitor begins charging in the reverse
direction. The resulting output is a square wave, and the voltage across
the capacitor is a triangular (or exponential) wave. The oscillation
frequency is f = 1 / (2RC × ln((1 + β)/(1 − β))), where β = R₂/(R₁ + R₂)
is the feedback fraction. For β = 0.5 (R₁ = R₂), f = 1/(2RC × ln(3)) =
1/(2.197RC). A separate \textbf{triangle wave generator} uses a Schmitt
trigger driving an integrator: the Schmitt trigger produces a square
wave that feeds an op-amp integrator, whose output ramps linearly up and
down between the Schmitt trigger thresholds, producing a high-quality
triangle wave with linear slopes (unlike the exponential waveform of the
basic astable). The frequency is f = 1/(4RC) × (R₂/R₁), where R and C
are the integrator components and R₂/R₁ sets the Schmitt trigger
hysteresis. Relaxation oscillators are simpler than Wien bridge
oscillators but produce square and triangular waves rather than
sinusoids, and are widely used in function generators, pulse-width
modulators, and clock sources where sinusoidal purity is not required.

\begin{examplebox}

\textbf{Example 13.6.4:} An op-amp astable multivibrator uses R = 22 kΩ,
C = 10 nF, and the feedback divider has R₁ = R₂ = 10 kΩ (β = 0.5). The
op-amp saturates at ±12 V. Calculate the oscillation frequency, the
capacitor voltage swing (threshold voltages), and the duty cycle. If R₁
is changed to 20 kΩ (β = 1/3), what is the new frequency?

\textbf{Solution:}\\
Feedback fraction: β = R₂/(R₁ + R₂) = 10,000/20,000 = 0.5.\\
Threshold voltages: V\textsubscript{TH} = +β × V\textsubscript{sat} =
0.5 × 12 = +6 V, V\textsubscript{TL} = -β × V\textsubscript{sat} = 0.5 ×
(-12) = -6 V.\\
The capacitor swings between -6 V and +6 V.\\
Frequency: f = 1/(2RC × ln((1 + β)/(1 − β))) = 1/(2 × 22,000 × 10 × 10⁻⁹
× ln(1.5/0.5)) = 1/(440 × 10⁻⁶ × ln(3)) = 1/(440 × 10⁻⁶ × 1.0986) =
1/(483.4 × 10⁻⁶) = 2,069 Hz ≈ 2.07 kHz.\\
Duty cycle: 50\% (symmetric thresholds and equal charging paths).\\
With R₁ = 20 kΩ: β = 10,000/30,000 = 1/3. f = 1/(440 μs ×
ln((4/3)/(2/3))) = 1/(440 μs × ln(2)) = 1/(440 μs × 0.6931) = 1/(304.9
μs) = 3,279 Hz ≈ 3.28 kHz.\\
The lower β reduces the threshold voltages to ±4 V (smaller capacitor
swing) and the ln term decreases from ln(3) to ln(2), both of which
reduce the period. The frequency increases to 3,280 Hz --- 59\% higher
than the β = 0.5 case.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-6-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_relaxation_osc.png}

\caption{Figure 13.6.4: Relaxation Oscillator Waveforms}

\end{figure}

\section{13.7 Real Op-Amp Limitations}\label{real-op-amp-limitations}

Real op-amps deviate from the ideal model in ways that introduce DC
errors, limit bandwidth and output speed, and allow unwanted signals to
leak through. Understanding these non-ideal parameters --- input offset
voltage, bias current, slew rate, CMRR, and PSRR --- is essential for
predicting circuit accuracy, selecting the right op-amp for an
application, and designing compensation techniques that minimize errors.
High-precision applications such as instrumentation, data acquisition,
and medical electronics require careful attention to these limitations.

\subsection{13.7.1 Input Offset and Bias}\label{input-offset-and-bias}

Real op-amps have a small but nonzero input offset voltage
(V\textsubscript{OS}, typically 0.1--5 mV) that appears as if a small
voltage source is connected between the inputs, causing a DC error at
the output equal to V\textsubscript{OS} × (1 +
R\textsubscript{f}/R\textsubscript{in}). Input bias current
(I\textsubscript{B}, typically pA for FET-input to μA for bipolar-input
op-amps) flows into each input terminal and creates voltage errors when
it flows through source resistances. The input offset current
(I\textsubscript{OS} = \textbar I\textsubscript{B+} -
I\textsubscript{B-}\textbar) represents the mismatch between the two
input bias currents. The bias current error can be minimized by placing
a compensation resistor equal to R\textsubscript{in} \textbar\textbar{}
R\textsubscript{f} at the non-inverting input, so that equal bias
currents flowing through equal resistances produce a common-mode voltage
that is rejected. Auto-zero and chopper-stabilized op-amps achieve
offset voltages below 10 μV by continuously measuring and correcting the
offset.

\begin{examplebox}

\textbf{Example 13.7.1:} An inverting amplifier with R\textsubscript{in}
= 10 kΩ and R\textsubscript{f} = 1 MΩ (gain = -100) uses a bipolar
op-amp with V\textsubscript{OS} = 2 mV and I\textsubscript{B} = 200 nA.
Calculate the total output offset voltage with and without a bias
compensation resistor at the non-inverting input.

\textbf{Solution:}\\
Without compensation resistor (non-inverting input grounded through 0
Ω):\\
Output offset due to V\textsubscript{OS}: V\textsubscript{out(OS)} =
V\textsubscript{OS} × (1 + R\textsubscript{f}/R\textsubscript{in}) =
0.002 × 101 = 202 mV.\\
Output offset due to I\textsubscript{B} at inverting input:
V\textsubscript{out(IB)} = I\textsubscript{B} × R\textsubscript{f} = 200
× 10⁻⁹ × 1,000,000 = 200 mV.\\
Total output offset: ≈ 202 + 200 = 402 mV (worst case).\\
With compensation resistor R\textsubscript{comp} = R\textsubscript{in}
\textbar\textbar{} R\textsubscript{f} = 10,000 \textbar\textbar{}
1,000,000 = 9,901 Ω at the non-inverting input:\\
The I\textsubscript{B} component is now rejected (only
I\textsubscript{OS} matters).\\
Assuming I\textsubscript{OS} = 10\% of I\textsubscript{B} = 20 nA:
V\textsubscript{out(IOS)} = I\textsubscript{OS} × R\textsubscript{f} =
20 × 10⁻⁹ × 1,000,000 = 20 mV.\\
Total: ≈ 202 + 20 = 222 mV -- a 45\% reduction.

\end{examplebox}

\subsection{13.7.2 Slew Rate}\label{slew-rate}

Slew rate (SR) is the maximum rate of change of the output voltage,
typically specified in V/μs. It is caused by the limited current
available to charge the internal compensation capacitor and is
independent of the closed-loop gain. When the required output rate of
change exceeds the slew rate, the output cannot follow the input
faithfully, causing slew-rate limiting (distortion of fast edges and
large-amplitude high-frequency signals). For a sinusoidal output of
amplitude V\textsubscript{p} at frequency f, the maximum rate of change
is 2πfV\textsubscript{p}, and the full-power bandwidth is
f\textsubscript{FP} = SR / (2πV\textsubscript{p}). A general-purpose
op-amp like the LM741 has SR = 0.5 V/μs, while high-speed op-amps
achieve 1,000-10,000 V/μs.

\begin{examplebox}

\textbf{Example 13.7.2:} An op-amp with a slew rate of SR = 13 V/μs
produces a 10 V peak sine wave. Calculate the full-power bandwidth. If
the amplifier is used to amplify a 100 kHz square wave to ±10 V,
determine the 10-90\% rise time limited by slew rate and whether the
output is distorted.

\textbf{Solution:}\\
Full-power bandwidth: f\textsubscript{FP} = SR / (2πV\textsubscript{p})
= 13 × 10⁶ / (2π × 10) = 13 × 10⁶ / 62.83 = 206.9 kHz.\\
The op-amp can produce a 10 V peak sine wave without slew-rate
distortion up to 207 kHz.\\
For the square wave: the output must transition from -10 V to +10 V (ΔV
= 20 V).\\
Slew-limited rise time: t\textsubscript{rise} = ΔV / SR = 20 / (13 ×
10⁶) = 1.538 μs.\\
The 10--90\% rise time: t\textsubscript{r(10-90)} = 0.8 × ΔV / SR = 16 /
(13 × 10⁶) s = 1.231 μs.\\
At 100 kHz, the period is 10 μs and the half-period is 5 μs.\\
Since the rise time (1.54 μs) is 30.8\% of the half-period, the square
wave output will have noticeably sloped edges but will reach the full
±10 V before the next transition.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-13-7-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch13_slew_rate.png}

\caption{Figure 13.7.2: Slew Rate Limiting}

\end{figure}

\subsection{13.7.3 Common-Mode Rejection Ratio
(CMRR)}\label{common-mode-rejection-ratio-cmrr}

The Common-Mode Rejection Ratio quantifies how well an op-amp rejects
signals that appear equally on both inputs, defined as CMRR =
A\textsubscript{diff} / A\textsubscript{cm}, typically expressed in
decibels: CMRR(dB) = 20log₁₀(A\textsubscript{diff} /
A\textsubscript{cm}). An ideal op-amp has infinite CMRR
(A\textsubscript{cm} = 0), meaning common-mode signals produce no
output. Real op-amps achieve CMRR of 70--120 dB, which degrades with
frequency (typically -20 dB/decade above a few hundred hertz). In
practice, the effective CMRR of a circuit depends on both the op-amp's
intrinsic CMRR and the matching of external resistors. A common-mode
voltage V\textsubscript{cm} produces an equivalent differential input
error of V\textsubscript{cm} / CMRR, which is then amplified by the
closed-loop gain.

\begin{examplebox}

\textbf{Example 13.7.3:} An op-amp with CMRR = 90 dB is used in a
non-inverting amplifier with a gain of 50. The input signal is 10 mV
differential riding on a 5 V common-mode voltage (e.g., from a remote
sensor). Calculate the desired output, the common-mode error at the
output, and the signal-to-error ratio.

\textbf{Solution:}\\
CMRR = 90 dB = 10\^{}(90/20) = 31,623.\\
Desired output: V\textsubscript{out(signal)} = 50 × 10 mV = 500 mV.\\
Equivalent input error from common-mode: V\textsubscript{error(input)} =
V\textsubscript{cm} / CMRR = 5.0 / 31,623 = 158 μV.\\
Error at output: V\textsubscript{error(output)} = 50 × 158 μV = 7.91
mV.\\
Signal-to-error ratio: 500 / 7.91 = 63.2, or 20log₁₀(63.2) = 36.0 dB.\\
Output accuracy: 7.91/500 × 100\% = 1.58\%.\\
For a 1 mV input signal (50 mV output), the error becomes 15.8\% ---
demonstrating why instrumentation amplifiers with \textgreater100 dB
CMRR are needed for small signals in the presence of large common-mode
voltages.

\end{examplebox}

\subsection{13.7.4 Power Supply Rejection Ratio
(PSRR)}\label{power-supply-rejection-ratio-psrr}

The Power Supply Rejection Ratio measures how well an op-amp rejects
noise and ripple on its power supply rails, defined as PSRR =
ΔV\textsubscript{supply} / ΔV\textsubscript{OS}, where
ΔV\textsubscript{OS} is the resulting change in input offset voltage
caused by a change ΔV\textsubscript{supply} in the supply voltage.
Expressed in decibels: PSRR(dB) = 20log₁₀(ΔV\textsubscript{supply} /
ΔV\textsubscript{OS}). Typical DC PSRR values range from 80 to 120 dB,
but PSRR degrades significantly with frequency (typically -20
dB/decade), falling to 40--60 dB at 10 kHz and even lower at higher
frequencies. This frequency dependence means that high-frequency
switching noise from DC-DC converters can couple through the op-amp's
supply pins into the signal path. Proper power supply bypassing (100 nF
ceramic capacitor placed as close as possible to each supply pin,
supplemented by a 10 μF bulk capacitor) is essential to minimize
supply-borne noise. In mixed-signal systems, separate analog and digital
supply planes with LC or ferrite-bead filtering are used to prevent
digital switching noise from degrading analog performance.

\begin{examplebox}

\textbf{Example 13.7.4:} An op-amp with DC PSRR = 100 dB and PSRR at 100
kHz = 50 dB is powered by a 5 V supply with 20 mV\textsubscript{pp}
ripple at 100 kHz from a nearby switching regulator. The op-amp is
configured as a non-inverting amplifier with a gain of 20. Calculate the
equivalent input noise from the supply ripple and the output ripple
voltage. Compare with a bypassed supply that reduces the ripple to 0.5
mV\textsubscript{pp} at 100 kHz.

\textbf{Solution:}\\
PSRR at 100 kHz = 50 dB = 10\^{}(50/20) = 316.2.\\
Equivalent input offset change: ΔV\textsubscript{OS} =
ΔV\textsubscript{supply} / PSRR = 20 mV / 316.2 = 63.2
μV\textsubscript{pp}.\\
Output ripple: V\textsubscript{ripple(out)} = ΔV\textsubscript{OS} ×
A\textsubscript{CL} = 63.2 μV × 20 = 1.264 mV\textsubscript{pp}.\\
With proper bypassing (0.5 mV\textsubscript{pp} ripple):
ΔV\textsubscript{OS} = 0.5 mV / 316.2 = 1.58 μV\textsubscript{pp}.\\
Output ripple: 1.58 × 20 = 31.6 μV\textsubscript{pp}.\\
The bypass capacitor provides a 40× (32 dB) improvement.\\
For a 12-bit, 5 V ADC (1 LSB = 1.22 mV), the unbypassed ripple of 1.264
mV exceeds 1 LSB and would corrupt the measurement, while the bypassed
ripple of 31.6 μV is well below 1 LSB.

\end{examplebox}

\subsection{13.7.5 Op-Amp Noise Analysis}\label{op-amp-noise-analysis}

Every op-amp generates internal noise that sets a fundamental limit on
the smallest signal the circuit can resolve. Op-amp noise is modeled as
two uncorrelated sources referred to the input: a \textbf{voltage noise
source} e\textsubscript{n} (in nV/√Hz) in series with the non-inverting
input, and a \textbf{current noise source} i\textsubscript{n} (in pA/√Hz
or fA/√Hz) flowing into each input terminal. Both have two spectral
regions: a flat \textbf{white noise} region at higher frequencies and a
rising \textbf{1/f (flicker) noise} region below a corner frequency
f\textsubscript{c} (typically 1--100 Hz for bipolar op-amps and
10--1,000 Hz for JFET/CMOS types). In the 1/f region the noise density
increases as 1/√f, so the power spectral density rises as 1/f --- hence
the name. Bipolar-input op-amps (e.g., OP27, AD797) have low voltage
noise (1--3 nV/√Hz) but higher current noise (0.4--2 pA/√Hz) due to base
current shot noise, making them optimal with low source impedances
(\textless10 kΩ). JFET and CMOS op-amps (e.g., OPA140, ADA4625) have
very low current noise (1--10 fA/√Hz) but moderately higher voltage
noise (4--15 nV/√Hz), making them ideal for high-impedance sources
(\textgreater100 kΩ). The \textbf{total input-referred noise} of an
op-amp circuit is: e\textsubscript{n,total} = √(e\textsubscript{n}² +
(i\textsubscript{n} × R\textsubscript{S})² + 4kTR\textsubscript{S}),
where R\textsubscript{S} is the effective source resistance seen by each
input and 4kTR\textsubscript{S} is the Johnson (thermal) noise of the
source resistance (at 25°C, 4kT = 1.66 × 10⁻²⁰ V²/Hz per ohm). To obtain
the total RMS noise, the noise spectral density is integrated over the
circuit bandwidth: V\textsubscript{n,rms} = e\textsubscript{n,total} ×
√(BW), where BW is the equivalent noise bandwidth (1.57 ×
f\textsubscript{3dB} for a single-pole system). For circuits with
significant 1/f noise contribution, the integral includes a
ln(f\textsubscript{H}/f\textsubscript{L}) term for the 1/f region.

\begin{examplebox}

\textbf{Example 13.7.5:} A non-inverting amplifier with a gain of 100
uses an op-amp with e\textsubscript{n} = 4 nV/√Hz (white noise) and
i\textsubscript{n} = 1.2 pA/√Hz. The source resistance is
R\textsubscript{S} = 1 kΩ and the circuit bandwidth is 10 kHz. The 1/f
corner is at 5 Hz (negligible for this bandwidth). Calculate the total
input-referred noise, the output noise, and the minimum detectable
signal (SNR = 1).

\textbf{Solution:}\\
Source resistance thermal noise density: e\textsubscript{R} =
√(4kTR\textsubscript{S}) = √(1.66 × 10⁻²⁰ × 1,000) = √(1.66 × 10⁻¹⁷) =
4.07 nV/√Hz.\\
Current noise contribution: e\textsubscript{in} = i\textsubscript{n} ×
R\textsubscript{S} = 1.2 × 10⁻¹² × 1,000 = 1.2 nV/√Hz.\\
Total input-referred noise density: e\textsubscript{n,total} = √(4² +
1.2² + 4.07²) = √(16 + 1.44 + 16.56) = √34.0 = 5.83 nV/√Hz.\\
The voltage noise and thermal noise dominate; current noise is
negligible at this low source impedance.\\
Equivalent noise bandwidth (single-pole): BW\textsubscript{n} = 1.57 ×
10,000 = 15,700 Hz.\\
Total input-referred RMS noise: V\textsubscript{n,rms} = 5.83 × 10⁻⁹ ×
√15,700 = 5.83 × 10⁻⁹ × 125.3 = 730 nV = 0.73 μV\textsubscript{rms}.\\
Output noise: V\textsubscript{n,out} = 0.73 μV × 100 = 73
μV\textsubscript{rms}.\\
Minimum detectable signal (SNR = 0 dB): 0.73 μV\textsubscript{rms} at
the input, or about 2.1 μV\textsubscript{pp} (using a 2.9× crest
factor).\\
For a 10 mV signal, the SNR = 20log₁₀(10 mV / 0.73 μV) = 82.7 dB.

\end{examplebox}

\subsection{13.7.6 Input and Output Voltage Range
Limitations}\label{input-and-output-voltage-range-limitations}

Real op-amps have finite input and output voltage ranges that constrain
circuit operation. The \textbf{input common-mode range} (ICMR) specifies
the range of voltages that can be applied to both inputs simultaneously
without degrading performance --- exceeding the ICMR causes a dramatic
drop in CMRR, increased offset, or in some op-amps (notably those with
PNP input stages), \textbf{input phase reversal}, where the output
suddenly inverts polarity when an input exceeds the ICMR, potentially
latching up positive-feedback circuits. Standard op-amps (e.g., LM741)
have an ICMR that extends from about V\textsubscript{EE} + 2 V to
V\textsubscript{CC} − 2 V, losing 2 V of headroom at each rail.
\textbf{Rail-to-rail input} (RRI) op-amps use complementary NMOS/PMOS
(or NPN/PNP) input differential pairs that hand off as the input voltage
traverses the supply range, extending the ICMR to include both supply
rails --- but the handoff region (crossover) introduces a step change in
V\textsubscript{OS} and I\textsubscript{B}, degrading linearity and CMRR
in the crossover zone. The \textbf{output voltage swing} specifies how
close the output can approach the supply rails under load. Standard
op-amps with bipolar output stages typically swing to within 1--2 V of
each rail (e.g., ±13 V output from ±15 V supplies), while
\textbf{rail-to-rail output} (RRO) op-amps use CMOS output stages that
can swing to within 10--50 mV of each rail with light loads (but the
saturation voltage increases with load current: V\textsubscript{sat} =
I\textsubscript{load} × R\textsubscript{DS(on)}). Single-supply designs
(V\textsubscript{CC} = 3.3 V or 5 V, V\textsubscript{EE} = 0 V) require
rail-to-rail input and output (RRIO) op-amps to maximize the usable
signal range, because even a 0.5 V headroom loss at each rail reduces
the available swing to 2.3 V from a 3.3 V supply --- a 30\% dynamic
range penalty. Key specifications to evaluate include: maximum output
current (short-circuit current, typically 20--40 mA), output impedance
in the linear region (\textless1 Ω) vs.~near the rails (rising sharply),
and capacitive load stability (many RRO op-amps oscillate with loads
\textgreater100 pF without a series isolation resistor of 10--100 Ω).

\begin{examplebox}

\textbf{Example 13.7.6:} A single-supply (V\textsubscript{CC} = 3.3 V,
V\textsubscript{EE} = 0 V) non-inverting amplifier with a gain of 2 uses
an op-amp with output swing specifications of V\textsubscript{OL} = 50
mV and V\textsubscript{OH} = V\textsubscript{CC} − 80 mV at
I\textsubscript{load} = 5 mA, and R\textsubscript{DS(on)} = 40 Ω for the
output FETs. The input is a 0--1.5 V sensor signal biased at 0.825 V.
Calculate the maximum undistorted output swing, and determine the output
swing and saturation voltage if the load draws 10 mA.

\textbf{Solution:}\\
At I\textsubscript{load} = 5 mA: V\textsubscript{OL} = 50 mV,
V\textsubscript{OH} = 3.3 − 0.08 = 3.22 V. Output swing = 3.22 − 0.05 =
3.17 V\textsubscript{pp}.\\
With gain = 2: output range = 2 × 0 to 2 × 1.5 = 0 to 3.0 V. The output
can swing from 0.05 V to 3.0 V without clipping (3.0 V \textless{} 3.22
V).\\
At I\textsubscript{load} = 10 mA: V\textsubscript{sat} =
I\textsubscript{load} × R\textsubscript{DS(on)} = 0.010 × 40 = 0.4 V.
V\textsubscript{OL} ≈ 0.4 V, V\textsubscript{OH} ≈ 3.3 − 0.4 = 2.9 V.
Output swing = 2.9 − 0.4 = 2.5 V\textsubscript{pp}.\\
The amplifier output at 2 × 1.5 = 3.0 V exceeds V\textsubscript{OH} =
2.9 V, causing clipping on the positive peaks.\\
Maximum undistorted input at 10 mA: V\textsubscript{in,max} =
V\textsubscript{OH} / gain = 2.9 / 2 = 1.45 V.\\
The 50 mV loss at the low end also clips: V\textsubscript{in,min} =
V\textsubscript{OL} / gain = 0.4 / 2 = 0.2 V.\\
The usable input range shrinks from 0--1.5 V to 0.2--1.45 V --- a 17\%
reduction in dynamic range due to the heavier load.\\
Using a lighter load (\textgreater10 kΩ) or a buffer stage would restore
the full swing.

\end{examplebox}

\chapter{Chapter 14}\label{chapter-14}

\chapter{National Electrical Code
(NEC)}\label{national-electrical-code-nec}

The National Electrical Code (NEC), published as NFPA 70, establishes
the minimum requirements for safe electrical installations in the United
States and is adopted by reference in most state and local
jurisdictions. While the NEC is fundamentally a safety document rather
than a design manual, its rules govern the practical implementation of
nearly every electrical engineering calculation --- from conductor
sizing and overcurrent protection to motor circuit design and
transformer installations. The code is organized into nine chapters plus
annexes, with articles numbered to group related topics (e.g., Article
310 for conductors, Article 430 for motors), and article numbers remain
stable across editions even as specific requirements evolve. This
chapter covers the engineering calculations and principles behind the
most frequently used NEC articles, giving the electrical engineer the
quantitative tools to translate a design into a code-compliant
installation.

\section{14.1 NEC Organization and
Structure}\label{nec-organization-and-structure}

\subsection{14.1.1 Code Organization}\label{code-organization}

The NEC's nine-chapter structure follows a logical progression from
general definitions and requirements (Chapter 1) through wiring design
(Chapter 2), wiring methods (Chapter 3), equipment (Chapter 4), special
occupancies (Chapter 5), special equipment (Chapter 6), special
conditions (Chapter 7), communications (Chapter 8), and reference tables
(Chapter 9). A critical rule is that Chapters 5, 6, and 7 can supplement
or modify the requirements of Chapters 1 through 4, meaning that a
special-condition article may override a general requirement. Engineers
must also understand that the NEC sets minimum standards for safety ---
it does not guarantee an adequate, efficient, or expandable
installation.

\begin{examplebox}

\textbf{Example 14.1.1:} An engineer is designing a motor circuit in a
Class I hazardous (classified) location. Article 430 (Chapter 4)
requires motor branch circuit conductors to be rated at 125\% of the
motor full-load current. Article 501 (Chapter 5) for Class I hazardous
locations requires the wiring method to be rigid metal conduit with
threaded fittings. If the motor FLC is 28 A, determine the minimum
conductor ampacity required by Article 430 and identify which chapter's
wiring method rules take precedence.

\textbf{Solution:}\\
Minimum conductor ampacity per Article 430: I\textsubscript{min} = 1.25
× 28 = 35 A.\\
Per the NEC hierarchy, Article 501 (Chapter 5) supplements and can
modify Article 430 (Chapter 4) requirements.\\
Therefore, the wiring method must comply with Article 501 (rigid metal
conduit with threaded fittings), while the conductor sizing still
follows Article 430.\\
A 10 AWG THWN-2 copper conductor rated at 40 A at 90°C (35 A at 75°C
termination limit) satisfies the 35 A minimum ampacity requirement.

\end{examplebox}

\subsection{14.1.2 Key Tables and
References}\label{key-tables-and-references}

Several NEC tables are used so frequently that engineers should know
them by article number. Table 310.16 provides allowable ampacities for
insulated conductors rated 0--2000 V in raceway, cable, or direct burial
based on conductor size, insulation temperature rating, and conductor
material. Table 310.15(C)(1) provides ambient temperature correction
factors, and the conduit fill adjustment factors account for mutual
heating when multiple conductors share a raceway. Table 250.122 sizes
equipment grounding conductors based on the overcurrent protective
device rating. Table 430.250 lists full-load currents for three-phase AC
motors, and Table 430.52 provides maximum overcurrent device ratings for
motor branch circuits. Chapter 9, Table 1 gives conduit fill
percentages, and Chapter 9, Tables 4 and 5 provide conduit and conductor
dimensions for performing conduit fill calculations.

\begin{examplebox}

\textbf{Example 14.1.2:} An engineer must size conductors for a 200 A
feeder installed in EMT conduit in an ambient temperature of 38°C. The
conductors are THWN-2 copper (rated 90°C). Using Table 310.16 and the
temperature correction factors, determine the minimum conductor size.

\textbf{Solution:}\\
From Table 310.16, the 75°C column governs for termination purposes per
110.14(C). At 75°C, 3/0 AWG copper is rated at 200 A.\\
However, the 90°C ampacity can be used for derating purposes. From Table
310.16, 1/0 AWG copper at 90°C is rated at 170 A.\\
Temperature correction factor for 90°C conductors at 38°C ambient:
0.91.\\
Corrected ampacity: 170 × 0.91 = 154.7 A --- insufficient.\\
For 2/0 AWG at 90°C: 195 × 0.91 = 177.5 A --- still insufficient.\\
For 3/0 AWG at 90°C: 225 × 0.91 = 204.8 A --- exceeds 200 A and does not
exceed the 75°C termination rating of 200 A.\\
Minimum conductor size: 3/0 AWG copper THWN-2.

\end{examplebox}

\section{14.2 Conductor Sizing and
Ampacity}\label{conductor-sizing-and-ampacity}

Proper conductor sizing ensures that wiring can safely carry the
required current without excessive heating, while also meeting voltage
drop performance goals. The NEC uses a multi-factor approach: base
ampacity from Table 310.16 is modified by temperature correction factors
for elevated ambient temperatures and conduit fill adjustment factors
when multiple conductors share a raceway. The physical conduit size must
also accommodate the total cross-sectional area of all conductors per
the conduit fill requirements of Chapter 9. Conductor sizing is often
the first calculation an electrical engineer performs and the foundation
for all downstream protection and equipment selections.

\subsection{14.2.1 Ampacity Tables and Conductor
Selection}\label{ampacity-tables-and-conductor-selection}

Table 310.16 is the primary ampacity table for conductors rated 0--2000
V installed in raceway, cable, or direct burial (not more than three
current-carrying conductors). The table provides ampacities at three
insulation temperature ratings (60, 75, and 90°C) for both copper and
aluminum/copper-clad aluminum conductors. Conductor sizing must account
for the continuous load rule: conductors supplying continuous loads
(loads expected to operate for three hours or more) must have an
ampacity of at least 125\% of the continuous load plus 100\% of the
non-continuous load. When selecting a conductor, the engineer must
verify that the selected size satisfies all three constraints: ampacity
after derating, termination temperature limits, and voltage drop
recommendations.

\begin{examplebox}

\textbf{Example 14.2.1:} A 480 V, three-phase feeder supplies 150 A of
continuous load and 40 A of non-continuous load. The conductors are
copper THWN-2 (90°C insulation) terminated on equipment rated for 75°C.
Determine the minimum required conductor ampacity and select the
conductor size from Table 310.16.

\textbf{Solution:}\\
Required ampacity = 1.25 × 150 + 1.00 × 40 = 187.5 + 40 = 227.5 A.\\
From Table 310.16 at 75°C (termination limit): 4/0 AWG copper = 230 A.
Check: 230 A ≥ 227.5 A.\\
The actual load current is 150 + 40 = 190 A, and the overcurrent device
must be rated at least 227.5 A (next standard size: 250 A per
240.6(A)).\\
Minimum conductor size: 4/0 AWG copper THWN-2, protected by a 250 A
overcurrent device.

\end{examplebox}

\subsection{14.2.2 Temperature Correction
Factors}\label{temperature-correction-factors}

When the ambient temperature exceeds the standard 30°C assumed in Table
310.16, the conductor ampacity must be reduced using correction factors
from Table 310.15(C)(1). The correction factor decreases as ambient
temperature increases, reflecting the reduced thermal margin available
for I²R heating of the conductor. For conductors with higher insulation
temperature ratings, the correction factors are more favorable (less
derating) at elevated ambient temperatures, which is one advantage of
specifying 90°C insulation even when terminations limit the usable
ampacity.

\begin{examplebox}

\textbf{Example 14.2.2:} A set of 2 AWG THWN-2 copper conductors (90°C
rated) is installed in a rooftop conduit where the ambient temperature
is 52°C. Determine the corrected ampacity and compare it to the same
conductors with THW insulation (75°C rated).

\textbf{Solution:}\\
From Table 310.16 base ampacities: 2 AWG at 90°C = 130 A; 2 AWG at 75°C
= 115 A.\\
Temperature correction factor at 52°C (51--55°C band): for 90°C
insulation, factor = 0.76; for 75°C insulation, factor = 0.67.\\
Corrected ampacity for THWN-2: 130 × 0.76 = 98.8 A.\\
Corrected ampacity for THW: 115 × 0.67 = 77.1 A.\\
The 90°C insulation retains 76\% of its base ampacity while the 75°C
insulation retains only 67\%, demonstrating a 28\% advantage in
current-carrying capacity for the higher-rated insulation in
high-temperature environments.

\end{examplebox}

\subsection{14.2.3 Conduit Fill Adjustment
Factors}\label{conduit-fill-adjustment-factors}

When more than three current-carrying conductors are installed in a
single raceway or cable, the heat generated by each conductor raises the
temperature of all adjacent conductors, requiring an ampacity
adjustment. For 4--6 conductors the adjustment factor is 0.80, for 7--9
conductors it is 0.70, and the factor continues to decrease as the
number of conductors increases. Neutral conductors that carry only
unbalanced current in a balanced three-phase system are generally not
counted as current-carrying conductors, but a neutral conductor that
carries harmonic currents (common with nonlinear loads such as computers
and VFDs) must be counted per 310.15(E). The conduit fill adjustment can
be combined multiplicatively with the ambient temperature correction
factor when both conditions apply simultaneously.

\begin{examplebox}

\textbf{Example 14.2.3:} An electrical contractor installs 12
current-carrying THWN-2 copper conductors (6 circuits of 2 conductors
each) in a single conduit. Each conductor is 8 AWG. The ambient
temperature is 35°C. Determine the adjusted ampacity per conductor.

\textbf{Solution:}\\
Base ampacity of 8 AWG THWN-2 copper at 90°C from Table 310.16: 55 A.\\
Ambient temperature correction factor at 35°C for 90°C insulation:
0.96.\\
Conduit fill adjustment factor for 12 current-carrying conductors
(10--20 range): 0.50.\\
Adjusted ampacity: 55 × 0.96 × 0.50 = 26.4 A.\\
If the circuit load exceeds 26.4 A per conductor, the engineer must
either upsize the conductors, reduce the number of conductors per
conduit, or use separate conduits.\\
For comparison, with only 3 conductors per conduit (no adjustment): 55 ×
0.96 = 52.8 A --- twice the capacity.

\end{examplebox}

\subsection{14.2.4 Conductor Properties and
Resistance}\label{conductor-properties-and-resistance}

NEC Chapter 9, Table 8 provides DC resistance values for copper and
aluminum conductors at 75°C, which are essential for voltage drop
calculations. The resistance of a conductor is proportional to its
length and inversely proportional to its cross-sectional area, and
increases with temperature at approximately 0.393\% per degree C for
copper. For AC circuits, the effective resistance is slightly higher
than the DC resistance due to skin effect (current crowding at the
conductor surface at 60 Hz), which becomes significant for conductors
larger than 250 kcmil; NEC Chapter 9, Table 9 provides AC impedance
values including both resistance and reactance for conductors in various
raceway types.

\begin{examplebox}

\textbf{Example 14.2.4:} A 350 kcmil copper conductor carries 300 A in a
steel conduit. From NEC Chapter 9, Table 9, the effective AC impedance
is R = 0.0382 Ω/1000 ft and X = 0.0441 Ω/1000 ft. For a 250-foot one-way
run supplying a load at 0.85 power factor lagging, calculate the
per-phase voltage drop.

\textbf{Solution:}\\
One-way conductor length: 250 ft.\\
Effective R per conductor: 0.0382 × 250/1000 = 0.00955 Ω.\\
Effective X per conductor: 0.0441 × 250/1000 = 0.01103 Ω.\\
Per-phase voltage drop: V\textsubscript{drop} = I × (R cos(θ) + X
sin(θ)) = 300 × (0.00955 × 0.85 + 0.01103 × 0.527) = 300 × (0.00812 +
0.00581) = 300 × 0.01393 = 4.18 V per phase.\\
For a 277 V line-to-neutral system: percent drop = 4.18/277 × 100 =
1.51\%.\\
For a three-phase 480 V circuit, the line-to-line voltage drop = √3 ×
4.18 = 7.24 V, or 7.24/480 × 100 = 1.51\%.

\end{examplebox}

\subsection{14.2.5 Conduit Fill
Calculations}\label{conduit-fill-calculations}

NEC Chapter 9, Table 1 limits the percentage of a conduit's internal
cross-sectional area that may be occupied by conductors: 53\% for one
conductor, 31\% for two conductors, and 40\% for three or more
conductors. These fill limits prevent excessive conductor heating and
ensure that conductors can be pulled through the raceway without damage.
The calculation compares the total cross-sectional area of all
conductors (including insulation, from Chapter 9, Table 5) against the
allowable fill area of the conduit (from Chapter 9, Table 4). When
conductors of different sizes share a conduit, each conductor's area is
summed individually. Nipples (conduit sections ≤ 24 inches) are
permitted 60\% fill per Table 1, Note 4, recognizing the reduced thermal
concern for very short runs.

\begin{examplebox}

\textbf{Example 14.2.5:} An electrician must install the following
THWN-2 copper conductors in a single EMT conduit: three 4 AWG (power
circuit) and four 12 AWG (control circuit). Determine the minimum EMT
conduit size using NEC Chapter 9 tables. From Table 5: 4 AWG THWN-2 area
= 0.0824 in², 12 AWG THWN-2 area = 0.0133 in².

\textbf{Solution:}\\
Total conductor area: 3 × 0.0824 + 4 × 0.0133 = 0.2472 + 0.0532 = 0.3004
in².\\
Total conductors = 7 (three or more), so 40\% fill applies.\\
Required conduit area: 0.3004 / 0.40 = 0.7510 in².\\
From Chapter 9, Table 4 for EMT: 3/4'' EMT has an internal area of 0.533
in² (insufficient, 0.533 × 0.40 = 0.213 in²). 1'' EMT has an internal
area of 0.864 in² (40\% fill = 0.346 in² --- sufficient).\\
Minimum conduit size: 1'' EMT.\\
Verification: fill percentage = 0.3004 / 0.864 × 100 = 34.8\%
\textless{} 40\% limit.

\end{examplebox}

\subsection{14.2.6 Rooftop Conduit Temperature
Adders}\label{rooftop-conduit-temperature-adders}

Conduits and cables installed on or above rooftops exposed to direct
sunlight are subject to significantly higher ambient temperatures than
indicated by weather data alone. NEC Table 310.15(C)(1)(a) requires a
temperature adder to be applied to the outdoor ambient temperature when
conductors or cables are installed in conduit exposed to sunlight on or
above rooftops. The adder depends on the distance above the roof
surface: conduit on the roof surface (touching) adds 33°C (60°F), ½ inch
above the roof adds 22°C (40°F), 3½ inches above adds 17°C (30°F), and
12 inches above adds 14°C (25°F). These adders reflect the heat absorbed
and re-radiated by the roofing material, which can raise the air
temperature inside the conduit well above the outdoor ambient. Conduit
installed more than 36 inches above the roof surface is exempt from the
adder per the 2023 NEC. The adjusted ambient temperature (weather
ambient + roof adder) is then used with the temperature correction
factors from Table 310.15(C)(1) to determine the corrected conductor
ampacity. This double penalty --- the roof adder pushes the effective
ambient far above 30°C, and the correction factor reduces the base
ampacity accordingly --- frequently forces the engineer to upsize
conductors by one to three AWG sizes compared to an indoor installation.
Rooftop HVAC equipment, solar panel feeder conduit, and rooftop-mounted
antenna cabling are common applications where this derating must be
considered.

\begin{examplebox}

\textbf{Example 14.2.6:} A conduit installed directly on a flat roof
surface feeds a rooftop HVAC unit. The outdoor ambient temperature is
40°C. The conductors are 6 AWG THWN-2 copper (90°C rated). Calculate the
effective ambient temperature, the temperature correction factor, and
the derated ampacity. Compare to the same conductor installed indoors at
30°C.

\textbf{Solution:}\\
Roof surface adder from Table 310.15(C)(1)(a): +33°C for conduit on the
roof surface.\\
Effective ambient: 40 + 33 = 73°C.\\
Temperature correction factor for 90°C insulation at 73°C ambient
(interpolating from Table 310.15(C)(1)): factor ≈ 0.41.\\
Base ampacity of 6 AWG THWN-2 at 90°C: 75 A.\\
Derated ampacity: 75 × 0.41 = \textbf{30.8 A}.\\
Indoor comparison at 30°C ambient: no correction needed, ampacity = 75 A
(at 90°C rating), but limited to 65 A by 75°C termination rating.\\
The rooftop installation loses 59\% of its current-carrying capacity.\\
If the HVAC unit draws 40 A, 6 AWG is insufficient on the rooftop ---
upgrade to 4 AWG (90°C base = 95 A, derated = 95 × 0.41 = 39.0 A ---
still marginal) or 3 AWG (90°C base = 110 A, derated = 110 × 0.41 = 45.1
A --- sufficient).\\
Raising the conduit 3½ inches above the roof on standoffs reduces the
adder to 17°C: effective ambient = 57°C, which falls in the 56--60°C
band, correction factor ≈ 0.71, and 6 AWG derated ampacity = 75 × 0.71 =
53.3 A --- sufficient for the 40 A load and saving two wire sizes.

\end{examplebox}

\section{14.3 Overcurrent Protection}\label{overcurrent-protection}

Overcurrent protection is the NEC's primary mechanism for preventing
fires and equipment damage from excessive current flow. Article 240
establishes the rules for sizing and applying fuses and circuit
breakers, with standard device ratings listed in 240.6(A). The
protection scheme must address both sustained overloads (moderate
overcurrent for extended periods) and short-circuit faults (thousands of
amperes for fractions of a second). Tap rules, coordination between
upstream and downstream devices, and available short-circuit current
calculations are critical engineering considerations for any
distribution system.

\subsection{14.3.1 Standard Overcurrent Device
Ratings}\label{standard-overcurrent-device-ratings}

NEC Section 240.6(A) lists the standard ampere ratings for fuses and
circuit breakers: 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100,
110, 125, 150, 175, 200, 225, 250, 300, 350, 400, 450, 500, 600, 700,
800, 1000, 1200, 1600, 2000, 2500, 3000, 4000, 5000, and 6000 A. Per
240.4(B), for circuits rated 800 A or less, the next standard size
overcurrent device above the conductor ampacity is permitted, provided
the conductors are not supplying multi-outlet receptacle branch
circuits. For circuits over 800 A, the overcurrent device rating must
not exceed the conductor ampacity.

\begin{examplebox}

\textbf{Example 14.3.1:} A feeder has a calculated load of 185 A
(continuous). The conductors must be sized at 125\% of continuous load =
231.25 A. From Table 310.16 (75°C copper): 4/0 AWG = 230 A, 250 kcmil =
255 A. Determine the correct conductor size and overcurrent device
rating.

\textbf{Solution:}\\
Required conductor ampacity: 1.25 × 185 = 231.25 A.\\
From Table 310.16 at 75°C: 4/0 AWG = 230 A (insufficient, 230
\textless{} 231.25). 250 kcmil = 255 A (sufficient).\\
Per 240.4(B), the overcurrent device may be the next standard size above
the conductor ampacity: the next standard size above 255 A is 300 A.\\
However, the overcurrent device must also be rated at least 231.25 A for
the continuous load rule.\\
Select 250 kcmil conductors with a 250 A standard breaker, since 250 ≥
231.25 and 255 ≥ 250.

\end{examplebox}

\subsection{14.3.2 Conductor Protection and Tap
Rules}\label{conductor-protection-and-tap-rules}

The general rule is that conductors must be protected at their ampacity
by an overcurrent device at the point where they receive their supply
(240.4). However, Article 240.21 provides important exceptions known as
``tap rules'' that allow conductors to be supplied from a larger feeder
without overcurrent protection at the tap point, provided specific
length and termination conditions are met. The 10-foot tap rule
(240.21(B)(1)) allows unprotected tap conductors up to 10 feet if they
have an ampacity at least 10\% of the upstream overcurrent device and
terminate in a single overcurrent device that limits the load to the tap
conductor ampacity. The 25-foot tap rule (240.21(B)(2)) allows taps up
to 25 feet if the conductors have an ampacity of at least one-third of
the upstream overcurrent device rating and are protected from physical
damage.

\begin{examplebox}

\textbf{Example 14.3.2:} A 400 A feeder supplies a tap to a panelboard
20 feet away. The tap terminates in a 100 A main breaker in the
panelboard. Determine the minimum tap conductor size per the 25-foot tap
rule for copper THWN-2 conductors (75°C terminations).

\textbf{Solution:}\\
The 25-foot tap rule (240.21(B)(2)) requires:\\
(1) tap conductors not exceeding 25 ft --- satisfied (20 ft).\\
(2) Tap conductor ampacity ≥ 1/3 of upstream device: 400/3 = 133.3 A.
From Table 310.16 at 75°C: 1 AWG = 130 A (insufficient), 1/0 AWG = 150 A
(sufficient).\\
(3) Tap terminates in a single overcurrent device (100 A breaker) ---
satisfied.\\
Minimum tap conductor size: 1/0 AWG copper THWN-2 (rated 150 A ≥ 133.3
A).\\
The panelboard's 100 A main breaker protects the downstream circuits,
and the 1/0 AWG tap conductors are rated well above the 100 A load they
supply.

\end{examplebox}

\subsection{14.3.3 Overcurrent Device
Coordination}\label{overcurrent-device-coordination}

Coordination (also called selectivity) ensures that when a fault occurs,
only the overcurrent device nearest to the fault operates, while
upstream devices remain closed to minimize the extent of the outage.
This requires that the time-current characteristics of downstream
devices (faster) and upstream devices (slower) do not overlap at any
fault current level within the system's range. Engineers use
manufacturers' time-current characteristic (TCC) curves to verify
coordination by plotting the downstream device curve below (faster than)
the upstream device curve with adequate margin.

\begin{examplebox}

\textbf{Example 14.3.3:} A main breaker is rated at 800 A with an
adjustable long-time delay and a downstream feeder breaker is rated at
200 A. At a fault current of 2,000 A, the 200 A breaker clears in 0.05
seconds and the 800 A breaker has a minimum clearing time of 0.10
seconds. At 5,000 A, the 200 A breaker clears in 0.02 seconds and the
800 A breaker clears in 0.04 seconds. Determine whether the two devices
coordinate at both fault levels.

\textbf{Solution:}\\
At 2,000 A: coordination ratio = upstream time / downstream time = 0.10
/ 0.05 = 2.0:1. The upstream device is 2× slower, providing adequate
coordination.\\
At 5,000 A: coordination ratio = 0.04 / 0.02 = 2.0:1. Again, the
upstream device is 2× slower.\\
Both devices coordinate at these fault levels since the upstream device
always clears more slowly, allowing the downstream device to isolate the
fault first.\\
A minimum coordination ratio of 1.5:1 is generally considered
acceptable.\\
If both devices operate in the instantaneous trip region at very high
fault currents, coordination may be lost --- this must be checked at the
maximum available fault current.

\end{examplebox}

\subsection{14.3.4 Short-Circuit Current
Calculations}\label{short-circuit-current-calculations}

NEC Section 110.9 requires that overcurrent devices have an interrupting
rating sufficient for the available fault current at their line
terminals, and Section 110.10 requires that equipment withstand the
available fault current. Calculating the available short-circuit current
at each point in the distribution system is therefore a fundamental NEC
compliance task. The point-to-point method estimates fault current by
starting with the transformer secondary fault current
(I\textsubscript{fault} = I\textsubscript{FLA} / Z\textsubscript{pu})
and then reducing it through the impedance of each downstream conductor
segment using the formula f = (1.732 × L × I\textsubscript{fault}) / (C
× V\textsubscript{LL}) for three-phase circuits, where L is the
conductor length in feet and C is a constant based on conductor material
and size. The upstream utility contribution is typically obtained from
the utility company as the available fault current at the service
entrance, or can be calculated from the transformer kVA and impedance
assuming an infinite bus on the primary.

\begin{examplebox}

\textbf{Example 14.3.4:} A 500 kVA, 480Y/277 V, three-phase transformer
has an impedance of 5.75\%. The secondary conductors are 500 kcmil
copper, 30 feet long, to a main distribution panel (MDP). Calculate the
available fault current at the transformer secondary and at the MDP.
Assume an infinite primary bus. The ``C'' constant for 500 kcmil copper
is 26,706.

\textbf{Solution:}\\
Transformer secondary full-load current: I\textsubscript{FLA} = 500,000
/ (1.732 × 480) = 500,000 / 831.4 = 601.4 A.\\
Available fault current at transformer secondary (infinite bus):
I\textsubscript{sc(xfmr)} = I\textsubscript{FLA} / Z\textsubscript{pu} =
601.4 / 0.0575 = 10,459 A.\\
Multiplier factor for conductor impedance: f = (1.732 × 30 × 10,459) /
(26,706 × 480) = 543,450 / 12,818,880 = 0.04239.\\
Available fault current at MDP: I\textsubscript{sc(MDP)} =
I\textsubscript{sc(xfmr)} / (1 + f) = 10,459 / 1.04239 = 10,034 A.\\
All overcurrent devices at the MDP must have an interrupting rating ≥
10,034 A (select standard 10 kAIC or 14 kAIC rated devices).\\
Standard molded-case circuit breakers are typically rated 10 kAIC or 14
kAIC at 480 V.

\end{examplebox}

\subsection{14.3.5 Arc-Fault Circuit Interrupter (AFCI)
Protection}\label{arc-fault-circuit-interrupter-afci-protection}

Arc-fault circuit interrupters detect dangerous arcing conditions ---
series arcs (caused by damaged conductors, loose connections, or broken
wires) and parallel arcs (line-to-neutral or line-to-ground faults
through carbonized insulation) --- that may not draw enough current to
trip a standard overcurrent device but generate sufficient heat to
ignite surrounding combustible materials. NEC Section 210.12 requires
AFCI protection for all 120 V, single-phase, 15 A and 20 A branch
circuits supplying outlets and devices in dwelling unit bedrooms, living
rooms, hallways, closets, kitchens, laundry areas, and most other
habitable spaces. The requirement has expanded with each code cycle: the
1999 NEC required AFCI only in bedrooms, while the 2023 NEC requires it
in virtually all dwelling unit areas except bathrooms (which require
GFCI) and garages. Combination-type AFCIs (the only type currently
accepted by the code) detect both series and parallel arcs using
electronic algorithms that distinguish dangerous arcing signatures from
normal arcing events such as motor brush commutation, switch operation,
and plug insertion. AFCIs are available as circuit breakers (the most
common form), receptacle-type devices (outlet branch circuit AFCIs), and
portable devices. The AFCI must be listed to UL 1699 and installed at
the origin of the branch circuit, though 210.12(A) permits alternative
means (listed outlet branch circuit AFCI receptacles at the first
outlet) when it is impractical to install an AFCI breaker at the origin
of the branch circuit. AFCI devices trip at arc signatures with as few
as 8 half-cycles of arcing current, providing fire protection that
standard breakers cannot offer --- a 5 A series arc through a damaged
cord in a 15 A circuit would never trip a standard breaker but generates
enough heat to ignite wood or fabric.

\begin{examplebox}

\textbf{Example 14.3.5:} A dwelling unit has a 20 A, 120 V branch
circuit supplying six duplex receptacles in a living room. The circuit
is wired with 12 AWG NM-B cable (Romex) and is 85 feet from the
panelboard to the first outlet. An AFCI breaker is installed per 210.12.
If a series arc develops in a damaged section of cord plugged into the
farthest outlet, with an arc current of 5 A at 120 V, calculate the arc
power, explain why a standard breaker would not trip, and confirm AFCI
applicability.

\textbf{Solution:}\\
Arc power: P\textsubscript{arc} = V × I = 120 × 5 = 600 W.\\
A standard 20 A breaker trips thermally at approximately 135\% of rating
(27 A) after 1 hour, or magnetically at 5--10× rating (100--200 A) for
instantaneous trip.\\
The 5 A arc current is only 25\% of the breaker rating --- far below any
trip threshold --- and would dissipate 600 W indefinitely, easily
igniting nearby combustible materials (paper ignites at
\textasciitilde230°C, wood at \textasciitilde300°C).\\
The AFCI breaker detects the characteristic irregular current waveform
of the series arc (random variations in arc impedance as the gap ionizes
and deionizes each half-cycle) and trips within 8--60 half-cycles
(67--500 ms at 60 Hz).\\
Per 210.12(A), living room outlets in a dwelling unit require AFCI
protection.\\
The NM-B wiring method is permitted and does not affect the AFCI
requirement.

\end{examplebox}

\section{14.4 Grounding and Bonding}\label{grounding-and-bonding}

Grounding and bonding form the safety backbone of any electrical
installation, providing a low-impedance fault current return path that
enables overcurrent devices to clear ground faults quickly. System
grounding connects one conductor of the electrical system to earth,
while equipment grounding provides a metallic return path from
enclosures and equipment frames back to the source. Bonding ensures
electrical continuity between all metallic components so that no
dangerous voltage differences can exist between exposed surfaces.
Articles 250 and related sections establish one of the most detailed and
critical areas of the NEC.

\subsection{14.4.1 System Grounding}\label{system-grounding}

System grounding connects one conductor of the electrical system
(typically the neutral in a wye-connected system) to earth through a
grounding electrode at the service entrance or separately derived
system. For solidly grounded systems (the most common configuration for
services under 1000 V), the neutral-to-ground connection is made at the
service disconnecting means, creating a low-impedance ground fault
return path through the grounding electrode conductor and the equipment
grounding conductors. The grounding electrode system (Article 250, Part
III) requires bonding together all available electrodes --- metal water
pipe, building steel, concrete-encased electrode (Ufer ground), and
ground rods --- to create a robust earth connection with the lowest
practical impedance.

\begin{examplebox}

\textbf{Example 14.4.1:} A 208Y/120 V, three-phase, 400 A service has a
grounding electrode system consisting of a 10-foot driven ground rod and
a concrete-encased electrode. Using Table 250.66, determine the minimum
grounding electrode conductor (GEC) size for copper, and calculate the
ground fault current if the total ground fault impedance is 0.25 Ω.

\textbf{Solution:}\\
From Table 250.66 for service entrance conductors of 500 kcmil copper
(typical for a 400 A service): the minimum grounding electrode conductor
is 1/0 AWG copper.\\
Ground fault current on a 120 V circuit (line to neutral/ground):
I\textsubscript{fault} = V / Z\textsubscript{total} = 120 / 0.25 = 480
A.\\
This fault current is well above the 20 A branch circuit breaker rating,
ensuring the breaker trips quickly.\\
Note: the majority of the fault current returns through the equipment
grounding conductor (metallic path), not through the earth --- earth
impedance is typically far too high to clear faults reliably, which is
why equipment grounding conductors are required.

\end{examplebox}

\subsection{14.4.2 Equipment Grounding
Conductors}\label{equipment-grounding-conductors}

Equipment grounding conductors (EGCs) provide the low-impedance return
path for ground fault current from the point of the fault back to the
source (transformer or generator neutral), enabling the overcurrent
device to operate and clear the fault. Table 250.122 sizes the EGC based
on the rating of the upstream overcurrent device, not on the circuit
conductor size, ensuring the grounding conductor can carry the expected
fault current for the time required for the overcurrent device to
operate. EGCs can be a wire (insulated or bare), a metallic raceway
(rigid metal conduit, intermediate metal conduit, or electrical metallic
tubing), or the metal armor/sheath of a cable assembly. For larger
installations, Section 250.122(B) requires the EGC to be proportionally
upsized when ungrounded conductors are increased in size to compensate
for voltage drop.

\begin{examplebox}

\textbf{Example 14.4.2:} A 480 V feeder is protected by a 200 A circuit
breaker and uses 3/0 AWG copper conductors in rigid metal conduit. The
feeder is 300 feet long, and the ungrounded conductors were increased
from the minimum 3/0 AWG to 250 kcmil to limit voltage drop. Determine
the minimum EGC size from Table 250.122 and the adjusted EGC size per
250.122(B).

\textbf{Solution:}\\
From Table 250.122, for a 200 A overcurrent device: minimum EGC size = 6
AWG copper.\\
Per 250.122(B), when conductors are increased in size for voltage drop,
the EGC must be proportionally increased: size increase factor =
circular mil area of installed conductor / circular mil area of minimum
required conductor = 250,000 / 167,800 (3/0 AWG) = 1.49.\\
Adjusted EGC area = 26,240 (6 AWG) × 1.49 = 39,098 circular mils.\\
From the wire gauge table: 4 AWG = 41,740 circular mils.\\
Minimum adjusted EGC: 4 AWG copper.\\
The rigid metal conduit also serves as an equipment grounding conductor
per 250.118, providing a redundant ground fault current path.

\end{examplebox}

\subsection{14.4.3 Ground Fault
Protection}\label{ground-fault-protection}

Ground fault protection of equipment (GFPE) is required by NEC 230.95
for solidly grounded wye services of more than 150 V to ground but not
exceeding 1000 V, where the service disconnect is rated 1000 A or more
--- this covers the common 480Y/277 V service configuration. GFPE
operates on the principle of detecting current imbalance between the
phase conductors and the neutral, typically using a zero-sequence
current transformer that sums the currents in all conductors passing
through it; any net current indicates a ground fault. Unlike ground
fault circuit interrupter (GFCI) protection for personnel (which trips
at 5 mA), equipment GFPE typically trips at 1200 A or less with a time
delay of up to one second, providing protection against arcing ground
faults that might not produce enough current to trip standard
overcurrent devices.

\begin{examplebox}

\textbf{Example 14.4.3:} A 480Y/277 V, 2000 A service has ground fault
protection set at 800 A pickup with a 0.5-second time delay. An arcing
ground fault develops on a feeder with an impedance that limits the
fault current to 600 A. Determine whether the GFPE will detect this
fault, and calculate the energy (I²t) dissipated if the fault persists
for 10 seconds.

\textbf{Solution:}\\
The GFPE pickup is set at 800 A. The fault current is 600 A, which is
below the 800 A pickup threshold.\\
The GFPE will not detect or clear this fault.\\
Energy at the fault point (assuming the fault persists for 10 seconds):
I²t = 600² × 10 = 3,600,000 A²·s.\\
If the GFPE pickup were set at 400 A, the relay would detect the fault
and trip after 0.5 seconds: I²t = 600² × 0.5 = 180,000 A²·s --- a 20×
reduction in arc energy.\\
This illustrates the importance of setting GFPE at the lowest practical
level.

\end{examplebox}

\subsection{14.4.4 Bonding}\label{bonding}

Bonding ensures electrical continuity between all metallic components of
the electrical system (enclosures, raceways, grounding conductors, and
non-current-carrying metal parts) so that fault current can flow freely
through a low-impedance path back to the source. Article 250, Part V
establishes bonding requirements, and Section 250.104 requires bonding
of metal piping systems and structural steel that may become energized.
Bonding jumpers must be sized per Table 250.66 (for service equipment)
or Table 250.122 (for downstream equipment), and connections must use
listed methods such as pressure connectors, clamps, or exothermic welds
to ensure reliable, low-resistance joints.

\begin{examplebox}

\textbf{Example 14.4.4:} A metal water pipe enters a building and runs
parallel to the electrical service for 15 feet before connecting to a
plastic pipe section. The service is 208Y/120 V, 600 A, with 500 kcmil
copper service entrance conductors. Determine the minimum bonding jumper
size required to bond the water pipe to the service grounding electrode
system per Table 250.66.

\textbf{Solution:}\\
From Table 250.66, for service entrance conductors of 500 kcmil copper:
the minimum bonding jumper size is 1/0 AWG copper.\\
The bonding jumper must be connected to the water pipe on the street
side of any plastic pipe section or water meter, ensuring the entire
metallic pipe length is bonded to the grounding system.\\
If the water pipe were the sole grounding electrode, a supplemental
electrode (ground rod or concrete-encased electrode) would also be
required per 250.53(D)(2), since a metal water pipe electrode must be
supplemented.

\end{examplebox}

\subsection{14.4.5 Ground-Fault Circuit Interrupter (GFCI)
Protection}\label{ground-fault-circuit-interrupter-gfci-protection}

A ground-fault circuit interrupter (GFCI) is a personnel protection
device that detects leakage current flowing through an unintended path
--- typically through a person's body to ground --- and disconnects the
circuit within milliseconds. The GFCI operates on the differential
current principle: a toroidal current transformer encircles both the
line and neutral conductors, and under normal conditions the currents
are equal and opposite, producing zero net flux. When current leaks
through a ground fault (e.g., a person touching an energized conductor
while grounded), the imbalance is detected and the device trips at a
threshold of 4--6 mA (Class A GFCI, the only type permitted by the NEC
for personnel protection), interrupting the circuit in approximately 25
ms --- fast enough to prevent ventricular fibrillation, which can occur
at currents above 30 mA sustained for more than a few hundred
milliseconds. NEC Section 210.8 specifies the locations requiring GFCI
protection, which has expanded significantly with each code cycle. For
\textbf{dwelling units} (210.8(A)), the 2023 NEC requires GFCI
protection for all 125 V through 250 V, single-phase, 50 A or less
receptacles in bathrooms, garages, outdoors, crawl spaces, unfinished
basements, kitchens, laundry areas, boathouses, and within 6 feet of
sinks, bathtubs, and shower stalls. For \textbf{non-dwelling
occupancies} (210.8(B)), GFCI protection is required in bathrooms,
kitchens, rooftops, outdoors, within 6 feet of sinks, indoor wet
locations, locker rooms, and garages/service bays. The 2023 NEC notably
expanded GFCI requirements to 250 V circuits (protecting 208 V and 240 V
receptacles in addition to 120 V) and to circuits up to 50 A (covering
welding outlets, EV chargers, and large appliances). GFCI devices are
available as \textbf{circuit breakers} (installed in the panelboard,
protecting the entire branch circuit), \textbf{receptacles} (protecting
that outlet and downstream outlets), and \textbf{portable devices}
(cord-connected for temporary use on construction sites per 590.6).
\textbf{Nuisance tripping} --- false trips caused by accumulated leakage
current from long cable runs, VFDs, EMI filters, or multiple appliances
--- is a common field problem; NEC 210.8 now includes a provision
(effective 2023) allowing self-test GFCI devices that automatically
verify functionality. The total normal leakage current on a
GFCI-protected circuit should be kept below 1 mA to provide adequate
margin against the 4--6 mA trip threshold.

\begin{examplebox}

\textbf{Example 14.4.5:} A kitchen in a dwelling unit has four duplex
receptacles on a 20 A, 120 V GFCI-protected branch circuit. The circuit
wiring is 12 AWG NM-B, 90 feet from the panel to the first outlet. Each
outlet serves an appliance with a typical leakage current of 0.5 mA per
appliance. If all four appliances are operating simultaneously,
calculate the total leakage current, the remaining margin before
nuisance tripping, and the maximum additional leakage from the cable
that can be tolerated.

\textbf{Solution:}\\
Total appliance leakage: 4 × 0.5 mA = 2.0 mA.\\
GFCI Class A trip threshold: 5 mA (nominal midpoint of 4--6 mA range).\\
Remaining margin: 5.0 − 2.0 = 3.0 mA.\\
Cable leakage (NM-B in a dry location at 60 Hz): approximately 0.01 mA
per foot of cable for typical residential wiring = 90 × 0.01 = 0.9 mA.\\
Total system leakage: 2.0 + 0.9 = 2.9 mA.\\
Margin to trip: 5.0 − 2.9 = 2.1 mA (42\% of trip threshold).\\
This is adequate but not generous --- adding a fifth appliance with 0.5
mA leakage would reduce the margin to 1.6 mA, and a damp or degraded
cable could push the total above 4 mA, causing nuisance trips.\\
Best practice: limit total leakage to below 1 mA per circuit by
distributing appliances across multiple GFCI circuits.\\
Per 210.8(A)(7), all kitchen receptacles serving countertop surfaces in
a dwelling unit require GFCI protection, and per 210.52(B), at least two
20 A small-appliance branch circuits are required.

\end{examplebox}

\section{14.5 Motor Circuits}\label{motor-circuits}

Motor circuits have unique NEC requirements because motors draw high
inrush currents during starting (typically 6--8 times the running
current) and may be subject to sustained overloads during operation.
Article 430 addresses every aspect of motor circuit design with a
layered protection approach: branch circuit conductors sized at 125\% of
FLC, short-circuit protection sized to pass starting current without
tripping, overload protection set to the motor's actual nameplate
current, and a disconnecting means within sight of the motor. The use of
NEC table FLC values (rather than nameplate current) for conductor and
short-circuit protection sizing is a key distinction unique to motor
circuits.

\subsection{14.5.1 Motor Full-Load Current
Tables}\label{motor-full-load-current-tables}

The NEC requires that motor branch circuit conductors and overcurrent
devices be sized using the full-load current (FLC) values from NEC Table
430.248 (single-phase) or 430.250 (three-phase), not the actual motor
nameplate current. This ensures that the circuit can safely supply any
motor of that horsepower and voltage rating, even if the specific motor
has a lower nameplate current than the table value. Using the table FLC
rather than the nameplate current provides a margin for motor
replacement, variations between manufacturers, and the conservative
assumption that the motor may operate at its rated load continuously.

\begin{examplebox}

\textbf{Example 14.5.1:} A 30 HP, 460 V, three-phase motor has a
nameplate FLA of 38 A. From NEC Table 430.250, the full-load current for
a 30 HP, 460 V motor is 40 A. The motor is Design B with a code letter G
(locked-rotor kVA per HP of 5.6--6.29). Calculate the motor branch
circuit conductor minimum ampacity and the locked-rotor current.

\textbf{Solution:}\\
Motor branch circuit conductor ampacity per 430.22: I\textsubscript{min}
= 1.25 × FLC (from table) = 1.25 × 40 = 50 A.\\
From Table 310.16 at 75°C: 6 AWG copper = 65 A (sufficient).\\
Locked-rotor current estimate from code letter G: kVA\textsubscript{LR}
= 6.0 (mid-range) × 30 HP = 180 kVA.\\
I\textsubscript{LR} = kVA\textsubscript{LR} / (√3 × V) = 180,000 /
(1.732 × 460) = 180,000 / 796.9 = 226 A (approximately 5.65× FLC).\\
Note that the nameplate FLA (38 A) is lower than the table FLC (40 A),
but the NEC requires using the table value of 40 A for all conductor and
overcurrent device sizing calculations.

\end{examplebox}

\subsection{14.5.2 Motor Branch Circuit Conductor
Sizing}\label{motor-branch-circuit-conductor-sizing}

Per NEC 430.22, motor branch circuit conductors must have an ampacity of
at least 125\% of the motor FLC from the applicable NEC table. For
multiple motors on a single feeder, Section 430.24 requires the feeder
conductor ampacity to be at least 125\% of the largest motor FLC plus
100\% of all other motor FLCs plus 100\% of any non-motor loads.
Temperature correction and conduit fill adjustment factors from Article
310 must be applied on top of the 125\% motor sizing requirement, and
the final conductor size must also meet voltage drop recommendations for
long runs.

\begin{examplebox}

\textbf{Example 14.5.2:} A motor control center (MCC) feeder supplies
three motors: Motor 1 (50 HP, 460 V, three-phase, FLC = 65 A), Motor 2
(25 HP, 460 V, three-phase, FLC = 34 A), and Motor 3 (10 HP, 460 V,
three-phase, FLC = 14 A), plus a 30 A continuous lighting load.
Determine the minimum feeder conductor ampacity per NEC 430.24.

\textbf{Solution:}\\
Per 430.24: feeder ampacity = 1.25 × largest motor FLC + sum of
remaining motor FLCs + non-motor continuous loads × 1.25.\\
Largest motor: Motor 1 at 65 A.\\
I\textsubscript{feeder} = 1.25 × 65 + 34 + 14 + 1.25 × 30 = 81.25 + 34 +
14 + 37.5 = 166.75 A.\\
From Table 310.16 at 75°C: 2/0 AWG copper = 175 A (sufficient).\\
The overcurrent protection for the feeder is determined separately per
430.62: maximum rating = largest motor branch circuit OCPD rating + sum
of FLCs of other motors + non-motor loads.

\end{examplebox}

\subsection{14.5.3 Motor Overcurrent
Protection}\label{motor-overcurrent-protection}

Motor circuits require two levels of overcurrent protection: (1)
overload protection (Article 430, Part III), which protects the motor,
motor control apparatus, and conductors against excessive heating from
sustained overloads, and is typically set at 115--125\% of the motor
nameplate current; and (2) short-circuit and ground fault protection
(Article 430, Part IV), which protects the circuit against
high-magnitude fault currents and is sized per Table 430.52 based on the
type of overcurrent device and motor design letter. The short-circuit
protection is intentionally oversized (up to 250\% for inverse-time
breakers, 300\% for dual-element fuses with Design B motors) to allow
the motor starting current (typically 6--8× FLC) to pass without
tripping the protective device.

\begin{examplebox}

\textbf{Example 14.5.3:} A 15 HP, 460 V, three-phase, Design B motor has
a full-load current of 21 A (from Table 430.250) and a nameplate FLA of
19.5 A with a service factor of 1.15. Select the overload relay setting
and the maximum inverse-time circuit breaker size per Table 430.52.

\textbf{Solution:}\\
Overload protection per 430.32(A)(1): for a motor with service factor ≥
1.15, the overload relay trips at not more than 125\% of nameplate FLA:
I\textsubscript{OL} = 1.25 × 19.5 = 24.4 A (set relay trip to 24.4 A or
next available setting).\\
Short-circuit/ground fault protection per Table 430.52 for Design B
motor with inverse-time breaker: maximum = 250\% of FLC = 2.50 × 21 =
52.5 A.\\
The next standard breaker size per 240.6(A): 60 A (430.52(C)(1),
Exception 1 permits rounding up).\\
Final motor branch circuit: 10 AWG copper conductors (rated 35 A at
75°C, ≥ 1.25 × 21 = 26.25 A), 60 A inverse-time circuit breaker, and
overload relay set at 24.4 A.

\end{examplebox}

\subsection{14.5.4 Motor Disconnecting
Means}\label{motor-disconnecting-means}

NEC Article 430, Part IX requires a disconnecting means within sight of
the motor location and the driven machinery, capable of disconnecting
the motor and its controller from the supply circuit. The disconnect
must have an ampere rating of at least 115\% of the motor FLC
(430.110(A)) and be capable of interrupting the locked-rotor current of
the motor if it is a switch type. For motors over 2 HP at 300 V or less,
the disconnect must be a motor-circuit switch rated in horsepower, a
molded-case circuit breaker, or a molded-case switch.

\begin{examplebox}

\textbf{Example 14.5.4:} A 75 HP, 460 V, three-phase motor has a
full-load current of 96 A from Table 430.250. Determine the minimum
disconnect ampere rating and the locked-rotor current the disconnect
must be capable of interrupting (motor code letter F, kVA/HP range
5.0--5.59).

\textbf{Solution:}\\
Minimum disconnect rating per 430.110(A): I\textsubscript{disc} = 1.15 ×
FLC = 1.15 × 96 = 110.4 A.\\
Select the next standard disconnect rating: 200 A (common available size
above 110.4 A).\\
Locked-rotor current: kVA\textsubscript{LR} = 5.3 (mid-range code letter
F) × 75 HP = 397.5 kVA.\\
I\textsubscript{LR} = 397,500 / (√3 × 460) = 397,500 / 796.9 = 499 A.\\
The selected 200 A motor-circuit switch must have an interrupting rating
of at least 499 A, which is standard for horsepower-rated motor-circuit
switches of this size.\\
The disconnect must be located within sight (visible and not more than
50 feet) from the motor.

\end{examplebox}

\subsection{14.5.5 Variable Frequency Drive (VFD) Circuit
Requirements}\label{variable-frequency-drive-vfd-circuit-requirements}

Variable frequency drives present unique NEC compliance challenges
because of their high-frequency PWM switching output, reflected voltage
waves on long motor cables, common-mode currents, and harmonic currents
drawn from the supply. NEC Article 430, Part X (Adjustable-Speed Drive
Systems) and Section 430.130 address VFD-specific requirements.
\textbf{Branch circuit conductors} supplying a VFD must be sized at
125\% of the VFD's rated input current (not the motor FLC), since the
VFD's input current may differ from the motor current due to power
factor and efficiency. \textbf{Motor leads} between the VFD and motor
require careful cable selection: the NEC permits standard THWN/THHN
conductors, but in practice VFD-rated cable (with symmetrical ground
conductors, heavy insulation rated for the peak voltage stress, and low
capacitance) is recommended for runs exceeding 50--100 feet to withstand
the reflected voltage waves that can reach 2× the DC bus voltage
(\textasciitilde1200 V peak for a 480 V VFD) at the motor terminals.
\textbf{Overcurrent protection} on the VFD input follows standard motor
branch circuit rules (Table 430.52), while the VFD itself provides
electronic overload protection for the motor, eliminating the need for a
separate thermal overload relay if the VFD is listed for that function
per 430.130(A). \textbf{Grounding} is critical: 430.130(B) requires the
equipment grounding conductor to be a wire-type EGC (conduit alone is
insufficient for VFD circuits due to high-frequency common-mode currents
that flow through stray capacitance) sized per Table 250.122 or larger.
Many VFD manufacturers recommend a symmetrical EGC arrangement (three
ground conductors in the motor cable) to provide a low-impedance path
for common-mode current and reduce bearing damage from shaft voltage
discharge. The VFD input circuit must include appropriate harmonic
filtering or must be sized for the harmonic current content per
310.15(E) when the neutral carries triplen harmonics.

\begin{examplebox}

\textbf{Example 14.5.5:} A 50 HP, 460 V, three-phase induction motor is
driven by a VFD with a rated input current of 62 A. The VFD is located
200 feet from the motor. The supply circuit is 250 feet from the MCC to
the VFD. Size the supply-side conductors and overcurrent protection per
NEC requirements. The motor FLC from Table 430.250 is 65 A.

\textbf{Solution:}\\
\textbf{Supply-side conductors} (MCC to VFD): Minimum ampacity = 1.25 ×
62 A (VFD input current) = 77.5 A. From Table 310.16 at 75°C: 4 AWG
copper = 85 A (sufficient).\\
\textbf{Short-circuit protection} per Table 430.52 for Design B motor
with inverse-time breaker: 250\% × 65 A (motor FLC from table) = 162.5
A. Next standard size: 175 A.\\
\textbf{Motor-side conductors} (VFD to motor): Sized at 125\% of motor
FLC = 1.25 × 65 = 81.25 A. From Table 310.16 at 75°C: 4 AWG copper = 85
A.\\
At 200 feet, reflected voltage waves are a concern --- the critical
cable length for a 480 V VFD with 100 ns rise time is approximately
L\textsubscript{crit} = v × t\textsubscript{rise} / 2 = (200 m/μs × 100
ns) / 2 = 10 m ≈ 33 feet. Since 200 feet \textgreater\textgreater{} 33
feet, VFD-rated cable or an output reactor/dv/dt filter is recommended
to limit motor terminal voltage to \textless{} 1000 V peak.\\
\textbf{Equipment grounding conductor}: Per Table 250.122 for a 175 A
OCPD: 6 AWG copper, wire-type per 430.130(B).

\end{examplebox}

\subsection{14.5.6 Hazardous Location
Classifications}\label{hazardous-location-classifications}

NEC Articles 500--516 govern electrical installations in locations where
flammable gases, vapors, liquids, combustible dusts, or ignitable fibers
may be present in sufficient concentrations to create a risk of fire or
explosion. The NEC uses two classification systems: the traditional
\textbf{Class/Division} system (Article 500) and the international
\textbf{Zone} system (Articles 505/506). In the Class/Division system,
\textbf{Class I} locations contain flammable gases or vapors (petroleum
refineries, paint spray booths, fuel dispensing), \textbf{Class II}
locations contain combustible dusts (grain elevators, coal handling,
metal powder processing), and \textbf{Class III} locations contain
ignitable fibers or flyings (textile mills, woodworking shops). Each
class is subdivided into two Divisions: \textbf{Division 1} indicates
that hazardous concentrations exist under normal operating conditions or
frequently during maintenance, while \textbf{Division 2} indicates that
hazardous concentrations exist only under abnormal conditions
(accidental rupture, equipment failure). The Zone system (more common
internationally and increasingly used in the U.S.) divides Class I
locations into \textbf{Zone 0} (hazardous continuously or for long
periods), \textbf{Zone 1} (hazardous under normal operations), and
\textbf{Zone 2} (hazardous only under abnormal conditions), and Class
II/III locations into Zones 20, 21, and 22 respectively. Wiring methods
in Division 1 are the most restrictive: Class I, Division 1 requires
threaded rigid metal conduit or mineral-insulated (MI) cable, with all
fittings, boxes, and equipment rated \textbf{explosionproof} (designed
to contain an internal explosion and cool escaping gases below the
ignition temperature) or \textbf{intrinsically safe} (energy-limited
circuits incapable of igniting the atmosphere). Division 2 permits
standard wiring methods (MC cable, EMT in some cases) with sealed
fittings at boundaries, and equipment may be \textbf{nonincendive}
rather than explosionproof. Equipment is further classified by
\textbf{Group} (A through G based on the specific gas or dust) and by
\textbf{Temperature Code} (T1 through T6, indicating the maximum surface
temperature --- e.g., T3A = 180°C, T6 = 85°C --- which must be below the
auto-ignition temperature of the specific hazardous material).

\begin{examplebox}

\textbf{Example 14.5.6:} A petroleum refinery has a pump room where
flammable vapors (Group D --- propane, auto-ignition temperature 450°C)
are present under normal operations. The room requires a 20 HP, 460 V
motor with a VFD and associated lighting. Classify the location, specify
the equipment temperature code, and determine the minimum wiring method
requirements for both the motor circuit and lighting.

\textbf{Solution:}\\
Classification: \textbf{Class I, Division 1, Group D} --- flammable gas
(propane) present under normal operating conditions.\\
Temperature code: propane auto-ignition temperature = 450°C. Equipment
surface temperature must be below 450°C. A T3 rating (200°C max surface)
provides ample margin and is standard for most Class I motors.\\
Motor: must be rated for Class I, Division 1, Group D, T3 --- an
explosionproof motor with an enclosure designed to contain any internal
ignition.\\
VFD: the VFD itself should be located outside the hazardous area (in a
general-purpose room) whenever possible; if it must be in the Division 1
area, it requires a purged and pressurized (Type X or Z) enclosure per
Article 500.7(D) or an explosionproof enclosure.\\
Wiring method: \textbf{threaded rigid metal conduit (RMC)} with
explosionproof fittings at all connection points. All conduit entries to
the motor and junction boxes require sealing fittings per 501.15(A)
within 18 inches of the enclosure to prevent gas migration through the
conduit system.\\
Lighting: must use explosionproof fixtures rated for Class I, Division
1, Group D. If LED fixtures are used, the fixture must be listed for the
classification and the temperature code must account for the LED driver
heat.\\
Conduit seals are required at boundary points where conduit transitions
from the Division 1 area to an unclassified area.

\end{examplebox}

\section{14.6 Transformer Connections}\label{transformer-connections}

Transformer overcurrent protection rules in Article 450 differ from
standard conductor protection because transformers must tolerate
magnetizing inrush current (typically 8--12 times rated current for the
first few cycles) without nuisance tripping. The NEC permits either
primary-only protection (simpler, less precise) or dual
primary-and-secondary protection (more components but tighter
coordination). Separately derived systems created by transformers
require their own grounding and bonding per Article 250.30, establishing
an independent ground fault return path for the secondary system.

\subsection{14.6.1 Transformer Overcurrent Protection (Primary
Only)}\label{transformer-overcurrent-protection-primary-only}

For transformers rated 1000 V or less, NEC Table 450.3(B) permits
primary-only protection at not more than 125\% of the primary rated
current. If 125\% does not correspond to a standard overcurrent device
rating, the next standard size up is permitted. Primary-only protection
is simpler and less expensive since no secondary overcurrent device is
required, but it provides less precise protection of the secondary
conductors, which must be sized to handle the full transformer capacity.
The primary overcurrent device must have an interrupting rating
sufficient for the available fault current at the transformer location.

\begin{examplebox}

\textbf{Example 14.6.1:} A 75 kVA, 480 V delta primary / 240/120 V
secondary, single-phase (center-tapped) transformer is installed with
primary-only overcurrent protection. Determine the primary rated current
and the maximum overcurrent device size per Table 450.3(B).

\textbf{Solution:}\\
Primary rated current: I\textsubscript{primary} = S / V = 75,000 / 480 =
156.3 A.\\
Maximum primary OCPD per Table 450.3(B): 125\% of rated current = 1.25 ×
156.3 = 195.3 A. The next standard fuse or breaker size per 240.6(A):
200 A.\\
Secondary rated current: I\textsubscript{secondary} = 75,000 / 240 =
312.5 A (line-to-line).\\
The secondary conductors must be rated for at least 312.5 A since there
is no secondary overcurrent protection. From Table 310.16 at 75°C: 400
kcmil copper = 335 A (sufficient for 312.5 A).

\end{examplebox}

\subsection{14.6.2 Transformer Overcurrent Protection (Primary and
Secondary)}\label{transformer-overcurrent-protection-primary-and-secondary}

When overcurrent protection is provided on both the primary and
secondary sides, NEC Table 450.3(B) permits the primary device to be
rated up to 250\% of the primary current, provided the secondary device
is rated at no more than 125\% of the secondary current. This
dual-protection scheme allows the primary device to be sized large
enough to withstand magnetizing inrush current without nuisance
tripping, while the secondary device provides tighter protection for the
transformer and secondary conductors. For transformers with impedance of
6\% or less (most distribution transformers), the secondary overcurrent
device limits the maximum fault current that can flow through the
transformer.

\begin{examplebox}

\textbf{Example 14.6.2:} A 150 kVA, three-phase, 480 V delta primary /
208Y/120 V secondary transformer has an impedance of 5.5\%. Overcurrent
protection is provided on both the primary and secondary. Determine the
primary and secondary overcurrent device sizes, and calculate the
maximum secondary fault current.

\textbf{Solution:}\\
Primary rated current: I\textsubscript{primary} = S / (√3 × V) = 150,000
/ (1.732 × 480) = 150,000 / 831.4 = 180.4 A.\\
Maximum primary OCPD (250\% with secondary protection): 2.50 × 180.4 =
451.1 A. Next standard size above 451.1 A: 500 A.\\
Secondary rated current: I\textsubscript{secondary} = 150,000 / (1.732 ×
208) = 150,000 / 360.3 = 416.3 A.\\
Maximum secondary OCPD (125\%): 1.25 × 416.3 = 520.4 A. Next standard
size: 600 A.\\
Maximum secondary fault current (infinite bus primary):
I\textsubscript{fault} = I\textsubscript{secondary} /
Z\textsubscript{pu} = 416.3 / 0.055 = 7,569 A.\\
The secondary overcurrent device must have an interrupting rating of at
least 7,569 A.

\end{examplebox}

\subsection{14.6.3 Secondary Conductor
Protection}\label{secondary-conductor-protection}

Transformer secondary conductors must be protected from overcurrent,
either by the transformer primary overcurrent device, the secondary
overcurrent device, or the limitations of the transformer itself.
Section 240.21(C) provides specific tap rules for transformer secondary
conductors, similar to the feeder tap rules in 240.21(B). The most
commonly used provision is the 25-foot secondary conductor rule
(240.21(C)(6)), which allows secondary conductors up to 25 feet without
overcurrent protection at the transformer if the conductor ampacity
meets specified minimums and the conductors terminate in a single
overcurrent device.

\begin{examplebox}

\textbf{Example 14.6.3:} A three-phase, 112.5 kVA, 480/208Y/120 V
transformer has its primary protected by a 200 A breaker. The secondary
conductors run 18 feet to a panelboard with a 400 A main breaker.
Determine the minimum secondary conductor size per the 240.21(C)(6) tap
rule.

\textbf{Solution:}\\
Secondary rated current: I\textsubscript{sec} = 112,500 / (1.732 × 208)
= 112,500 / 360.3 = 312.3 A.\\
Per 240.21(C)(6) (25-foot rule), the NEC minimum secondary conductor
ampacity is one-third of the primary OCPD expressed on the secondary
voltage basis.\\
Primary OCPD equivalent on secondary: 200 × (480/208) = 200 × 2.308 =
461.5 A equivalent. One-third of this: 461.5 / 3 = 153.8 A --- this is
the NEC code minimum.\\
For this installation, the secondary conductors are sized to carry the
full transformer secondary current (312.3 A) so the transformer can
serve its rated load without restriction.\\
From Table 310.16 at 75°C: 350 kcmil copper = 310 A (insufficient for
312.3 A). 500 kcmil = 380 A (sufficient).\\
Minimum secondary conductor: 500 kcmil copper per phase, with 18-foot
run to 400 A main breaker.

\end{examplebox}

\subsection{14.6.4 Separately Derived Systems and
Grounding}\label{separately-derived-systems-and-grounding}

A separately derived system is one that has no direct electrical
connection (including a solidly connected grounded conductor) to the
supply conductors of another system --- the most common example is a
transformer with no neutral-to-neutral connection between primary and
secondary. Per Article 250.30, separately derived systems must be
grounded at the source (transformer secondary) by bonding the neutral to
the equipment grounding system and to a grounding electrode. The bonding
jumper, system bonding jumper, and grounding electrode conductor are
sized per Tables 250.66 and 250.102(C) based on the transformer
secondary conductor size. The neutral-to-ground bond must be made at
only one point to prevent parallel paths for normal neutral current
through the equipment grounding system.

\begin{examplebox}

\textbf{Example 14.6.4:} A 225 kVA, 480 V delta / 208Y/120 V wye
transformer is a separately derived system. The secondary conductors are
350 kcmil copper per phase. Determine the system bonding jumper size and
the grounding electrode conductor size per Article 250.30.

\textbf{Solution:}\\
System bonding jumper per 250.30(A)(1) and Table 250.102(C)(1): for 350
kcmil ungrounded conductors, the minimum bonding jumper is 2 AWG
copper.\\
Grounding electrode conductor per 250.30(A)(5) and Table 250.66: for 350
kcmil service-entrance conductors, the minimum GEC is 2 AWG copper.\\
If a structural metal electrode or concrete-encased electrode is
available, 250.30(A)(5) limits the GEC to a maximum of 3/0 AWG copper
(no need to be larger regardless of transformer size).\\
The neutral-to-ground bond is made at the transformer secondary terminal
compartment, and the grounded conductor (neutral) is insulated (not
bonded to the enclosure) at all downstream points.

\end{examplebox}

\subsection{14.6.5 Delta-Wye Transformer Neutral
Sizing}\label{delta-wye-transformer-neutral-sizing}

In a delta primary / wye secondary transformer (the most common
three-phase distribution configuration), the secondary neutral conductor
carries the unbalanced current between the three phases plus any
zero-sequence harmonic currents generated by nonlinear loads. For a
perfectly balanced linear load, the neutral current is zero and the
neutral conductor carries no current. However, in modern buildings with
high concentrations of switch-mode power supplies (computers, LED
drivers, VFDs), the third harmonic (180 Hz) and its odd multiples
(triplen harmonics: 3rd, 9th, 15th, \ldots) are additive in the neutral
rather than cancelling as balanced fundamental currents do. The neutral
current from triplen harmonics can be calculated as I\textsubscript{N} =
3 × I₃\textsubscript{(phase)}, where I₃ is the third harmonic current
per phase. In severe cases, the neutral current can exceed the phase
current --- a building with a 40\% third harmonic on each phase will
have a neutral current of 3 × 40\% = 120\% of the phase fundamental
current. NEC Section 220.61 normally permits reducing the neutral
conductor for feeders based on the unbalanced load, but Section
310.15(E) requires counting the neutral as a current-carrying conductor
when it carries predominantly harmonic currents, applying the conduit
fill derating factors. For this reason, many engineers specify a
full-sized or double-sized neutral for transformer secondaries serving
nonlinear loads, and some separately derived systems use an oversized
neutral bus or a separate neutral for each phase to prevent neutral
overheating.

\begin{examplebox}

\textbf{Example 14.6.5:} A 225 kVA, 480 V delta / 208Y/120 V wye
transformer serves a data center with predominantly nonlinear loads. The
balanced three-phase load draws 540 A per phase at the secondary, with a
measured third harmonic content of 33\% per phase. Calculate the neutral
current, determine whether the standard neutral conductor is adequately
sized, and size the neutral conductor.

\textbf{Solution:}\\
Phase fundamental current: I₁ = 540 A.\\
Third harmonic current per phase: I₃ = 0.33 × 540 = 178.2 A.\\
Triplen harmonics add in the neutral: I\textsubscript{N(3rd)} = 3 ×
178.2 = 534.6 A.\\
Total neutral current (dominated by third harmonic): I\textsubscript{N}
≈ 534.6 A.\\
This is 534.6/540 = 99\% of the phase current --- the neutral carries
nearly as much current as the phase conductors.\\
A standard neutral sized at 60\% of phase ampacity (as permitted by
220.61 for balanced loads) would be rated for only 0.60 × 540 = 324 A,
resulting in dangerous overheating.\\
The neutral must be sized for at least 534.6 A.\\
From Table 310.16 at 75°C: two 350 kcmil copper in parallel (2 × 310 A =
620 A) or one 700 kcmil copper (460 A --- insufficient) or one 1000
kcmil copper (545 A --- marginal).\\
Use two 350 kcmil copper per neutral for adequate capacity and margin.\\
Per 310.15(E), the neutral counts as a current-carrying conductor for
conduit fill derating purposes.

\end{examplebox}

\subsection{14.6.6 K-Factor Transformers and Harmonic
Derating}\label{k-factor-transformers-and-harmonic-derating}

Standard dry-type transformers are designed for sinusoidal (linear)
loads, and when they serve nonlinear loads rich in harmonics ---
computers, VFDs, LED drivers, UPS systems --- the harmonic currents
cause additional heating in the windings (due to skin effect and
proximity effect, which increase winding resistance at higher
frequencies) and in the core (due to increased eddy current losses
proportional to the square of frequency and flux density). If the extra
heating is not accounted for, the transformer's insulation life is
shortened and the transformer may overheat. The \textbf{K-factor}
quantifies the harmonic heating effect as K = Σ(I\textsubscript{h}²×h²)
/ Σ(I\textsubscript{h}²), where I\textsubscript{h} is the per-unit
current of the h-th harmonic and h is the harmonic order. For a purely
sinusoidal load, K = 1. Typical K-factors for common load types are: K-1
(linear loads --- motors, resistive heating), K-4 (moderate harmonics
--- mixed commercial loads with some computers), K-13 (high harmonics
--- data centers, heavy computer loads), and K-20 (severe harmonics ---
VFDs with SCR front ends, high-density computing). \textbf{K-rated
transformers} are manufactured with design modifications to withstand
the additional harmonic heating: oversized neutrals (200\% rated),
reduced flux density in the core (lower core losses at harmonic
frequencies), transposed and insulated winding conductors (reduced eddy
current losses), and additional thermal capacity. A K-13 transformer is
typically 15--30\% more expensive than a standard K-1 unit of the same
kVA rating but avoids the need to derate the standard transformer. For
existing standard transformers serving nonlinear loads, the alternative
to replacement is \textbf{harmonic derating}: the transformer is loaded
to a fraction of its nameplate rating to keep the total losses within
the thermal design limits. The derated capacity is approximately:
S\textsubscript{derated} = S\textsubscript{rated} / √K, though the exact
derating depends on the transformer's eddy current loss factor
(typically 5--15\% of total load loss for dry-type transformers).
ANSI/IEEE C57.110 provides the detailed calculation method for
determining the maximum allowable load current in the presence of
harmonics. A harmonic survey (using a power quality analyzer to measure
the current spectrum at the transformer secondary) is the first step in
determining whether a K-rated transformer or harmonic filtering is
needed.

\begin{examplebox}

\textbf{Example 14.6.6:} A standard 150 kVA, 480/208Y/120 V dry-type
transformer (K-1 rated, eddy current loss factor P\textsubscript{EC-R} =
8\% of rated load loss) serves a data center load with the following
measured harmonic current spectrum (in per-unit of fundamental): I₁ =
1.00, I₃ = 0.82, I₅ = 0.58, I₇ = 0.38, I₉ = 0.18, I₁₁ = 0.09. Calculate
the K-factor, the required K-rated transformer, and the derated capacity
if a standard transformer must be used.

\textbf{Solution:}\\
K-factor = Σ(I\textsubscript{h}² × h²) / Σ(I\textsubscript{h}²).\\
Numerator: I₁²×1² + I₃²×3² + I₅²×5² + I₇²×7² + I₉²×9² + I₁₁²×11² =
1.00²×1 + 0.82²×9 + 0.58²×25 + 0.38²×49 + 0.18²×81 + 0.09²×121 = 1.000 +
6.052 + 8.410 + 7.076 + 2.624 + 0.980 = 26.14.\\
Denominator: Σ(I\textsubscript{h}²) = 1.000 + 0.672 + 0.336 + 0.144 +
0.032 + 0.0081 = 2.192.\\
K = 26.14 / 2.192 = \textbf{11.9}.\\
A \textbf{K-13} rated transformer is required (next standard K-rating
above 11.9).\\
For derating the existing K-1 transformer per IEEE C57.110: the maximum
per-unit load current is I\textsubscript{max} = √(1 / (1 +
P\textsubscript{EC-R} × (K − 1))) = √(1 / (1 + 0.08 × (11.9 − 1))) = √(1
/ (1 + 0.872)) = √(1 / 1.872) = √0.534 = \textbf{0.731 pu}.\\
Derated capacity: 0.731 × 150 = \textbf{109.7 kVA}.\\
The standard transformer can only safely serve 110 kVA of this
harmonic-rich load --- a 27\% capacity reduction.\\
If the data center requires the full 150 kVA, either a K-13 replacement
transformer or a harmonic filter (active or passive, targeting the 3rd
and 5th harmonics) must be installed.

\end{examplebox}

\section{14.7 Voltage Drop
Calculations}\label{voltage-drop-calculations}

While the NEC does not mandate specific voltage drop limits,
Informational Notes in Articles 210 and 215 recommend no more than 3\%
voltage drop on branch circuits and 5\% total (feeder plus branch
circuit) for reasonable efficiency of operation. Excessive voltage drop
wastes energy as I²R losses in conductors, reduces motor torque (torque
is proportional to voltage squared), dims lighting, and can cause
sensitive electronic equipment to malfunction. Voltage drop calculations
use conductor resistance and reactance values from NEC Chapter 9, Table
9, with separate formulas for single-phase and three-phase circuits, and
account for power factor since reactive current flowing through
conductor reactance contributes to the voltage drop.

\subsection{14.7.1 Single-Phase Voltage
Drop}\label{single-phase-voltage-drop}

For single-phase circuits, the voltage drop is calculated as
V\textsubscript{drop} = 2 × I × L × (R cos(θ) + X sin(θ)) / 1000, where
I is the load current in amperes, L is the one-way conductor length in
feet, R and X are the conductor resistance and reactance per 1000 feet
from NEC Chapter 9, Table 9, and θ is the power factor angle. The factor
of 2 accounts for the current flowing through both the line and return
conductors. While the NEC does not mandate a maximum voltage drop,
Informational Notes in Sections 210.19(A) and 215.2(A)(4) recommend that
branch circuit voltage drop not exceed 3\% and that the total voltage
drop (feeder plus branch circuit) not exceed 5\%.

\begin{examplebox}

\textbf{Example 14.7.1:} A 120 V, single-phase branch circuit supplies a
16 A continuous load at the end of a 150-foot run. The conductors are 12
AWG copper in PVC conduit (R = 1.93 Ω/1000 ft, X = 0.054 Ω/1000 ft from
Chapter 9, Table 9). The load power factor is unity. Determine the
voltage drop and whether it meets the NEC 3\% recommendation.

\textbf{Solution:}\\
V\textsubscript{drop} = 2 × I × L × R / 1000 (X is negligible at unity
PF for small conductors).\\
V\textsubscript{drop} = 2 × 16 × 150 × 1.93 / 1000 = 4800 × 1.93 / 1000
= 9.26 V.\\
Percent voltage drop: 9.26 / 120 × 100 = 7.72\%. This exceeds the
recommended 3\% maximum.\\
To achieve 3\%: V\textsubscript{drop(max)} = 0.03 × 120 = 3.6 V.\\
Required resistance: R\textsubscript{max} = V\textsubscript{drop} × 1000
/ (2 × I × L) = 3.6 × 1000 / (2 × 16 × 150) = 0.75 Ω/1000 ft.\\
From Chapter 9, Table 9: 6 AWG copper = 0.491 Ω/1000 ft (sufficient).\\
Upgrade to 6 AWG copper for a voltage drop of 2 × 16 × 150 × 0.491 /
1000 = 2.36 V = 1.96\%.

\end{examplebox}

\subsection{14.7.2 Three-Phase Voltage
Drop}\label{three-phase-voltage-drop}

For balanced three-phase circuits, the line-to-line voltage drop is
V\textsubscript{drop} = √3 × I × L × (R cos(θ) + X sin(θ)) / 1000, where
the √3 factor replaces the factor of 2 used in single-phase calculations
because the return path is through the other two phases rather than a
dedicated neutral conductor. The percent voltage drop is calculated
relative to the line-to-line voltage. For three-phase motor circuits,
the voltage drop at the motor terminals during starting (when the
current is 6--8× the running current) can be significantly larger than
the running voltage drop, potentially causing the motor to stall or fail
to start if the terminal voltage drops below approximately 80\% of rated
voltage.

\begin{examplebox}

\textbf{Example 14.7.2:} A 460 V, three-phase feeder supplies a 100 A
load at 0.85 power factor lagging over a 400-foot run. The conductors
are 1/0 AWG copper in steel conduit (R = 0.122 Ω/1000 ft, X = 0.0442
Ω/1000 ft from Chapter 9, Table 9). Calculate the voltage drop and the
voltage at the load terminals.

\textbf{Solution:}\\
V\textsubscript{drop} = √3 × I × L × (R cos(θ) + X sin(θ)) / 1000.
cos(θ) = 0.85, sin(θ) = 0.527.\\
V\textsubscript{drop} = 1.732 × 100 × 400 × (0.122 × 0.85 + 0.0442 ×
0.527) / 1000 = 1.732 × 100 × 400 × (0.1037 + 0.0233) / 1000 = 69,280 ×
0.1270 / 1000 = 8.80 V.\\
Percent voltage drop: 8.80 / 460 × 100 = 1.91\%.\\
Voltage at load terminals: V\textsubscript{load} = 460 − 8.80 = 451.2 V.
This is within the 3\% recommendation for feeders.\\
During motor starting at 600 A inrush: V\textsubscript{drop(start)} = 6
× 8.80 = 52.8 V, giving a starting voltage of 460 − 52.8 = 407.2 V =
88.5\% of rated voltage --- adequate for most motor types.

\end{examplebox}

\subsection{14.7.3 Voltage Drop in Parallel
Conductors}\label{voltage-drop-in-parallel-conductors}

For large feeders where a single conductor per phase would be
impractical (above 500 kcmil, skin effect losses increase
significantly), the NEC permits paralleling conductors per Section
310.10(G), requiring that parallel conductors be the same length,
material, size, insulation type, and termination method to ensure equal
current distribution. The effective resistance and reactance per phase
is divided by the number of parallel conductors, proportionally reducing
the voltage drop. Voltage drop calculations for parallel conductors use
the per-conductor impedance divided by the number of conductors per
phase, then apply the standard voltage drop formula.

\begin{examplebox}

\textbf{Example 14.7.3:} A 480 V, three-phase, 800 A feeder uses two 500
kcmil copper conductors per phase in parallel, installed in two separate
steel conduits. The one-way run is 250 feet, and the load power factor
is 0.90 lagging. From Chapter 9, Table 9: R = 0.0293 Ω/1000 ft and X =
0.0439 Ω/1000 ft for 500 kcmil in steel conduit. Calculate the voltage
drop.

\textbf{Solution:}\\
Effective impedance per phase (two conductors in parallel):
R\textsubscript{eff} = 0.0293 / 2 = 0.01465 Ω/1000 ft.
X\textsubscript{eff} = 0.0439 / 2 = 0.02195 Ω/1000 ft.\\
cos(θ) = 0.90, sin(θ) = 0.436.\\
V\textsubscript{drop} = √3 × 800 × 250 × (0.01465 × 0.90 + 0.02195 ×
0.436) / 1000 = 1.732 × 800 × 250 × (0.01319 + 0.00957) / 1000 = 346,400
× 0.02276 / 1000 = 7.88 V.\\
Percent voltage drop: 7.88 / 480 × 100 = 1.64\%.\\
Without parallel conductors, a single 1000 kcmil conductor (R = 0.0186,
X = 0.0423) would give: V\textsubscript{drop} = 1.732 × 800 × 250 ×
(0.0186 × 0.90 + 0.0423 × 0.436) / 1000 = 346,400 × 0.03518 / 1000 =
12.19 V = 2.54\%, demonstrating the advantage of parallel conductors for
both ampacity and voltage drop.

\end{examplebox}

\subsection{14.7.4 Conductor Sizing for Voltage
Drop}\label{conductor-sizing-for-voltage-drop}

In many installations, voltage drop --- not ampacity --- is the
controlling factor that determines the required conductor size,
particularly for long branch circuit runs to motors, lighting panels, or
remote equipment. The design process inverts the voltage drop formula to
solve for the maximum allowable conductor resistance, then selects the
conductor from NEC Chapter 9, Table 9 that meets this resistance
requirement. When the voltage-drop-sized conductor exceeds the
ampacity-sized conductor, the larger size governs. A common engineering
practice is to size feeders for ≤ 2\% drop, leaving 3\% margin for
branch circuits to stay within the 5\% total recommendation.

\begin{examplebox}

\textbf{Example 14.7.4:} A 208 V, three-phase branch circuit supplies a
42 A continuous load (lighting panel) at the end of a 275-foot run in
PVC conduit at unity power factor. The maximum allowable voltage drop is
2\%. Determine the minimum conductor size to meet both the ampacity and
voltage drop requirements.

\textbf{Solution:}\\
Ampacity requirement: 1.25 × 42 = 52.5 A continuous load. From Table
310.16 at 75°C: 6 AWG copper = 65 A (sufficient for ampacity).\\
Voltage drop requirement: V\textsubscript{drop(max)} = 0.02 × 208 = 4.16
V.\\
Rearranging the three-phase voltage drop formula for R (at unity PF, X
contribution is negligible): R\textsubscript{max} =
V\textsubscript{drop} × 1000 / (√3 × I × L) = 4.16 × 1000 / (1.732 × 42
× 275) = 4,160 / 20,005 = 0.2080 Ω/1000 ft.\\
From Chapter 9, Table 9 (PVC conduit): 6 AWG = 0.510 Ω/1000 ft
(V\textsubscript{drop} = 1.732 × 42 × 275 × 0.510/1000 = 10.20 V =
4.90\% --- too high).\\
4 AWG = 0.321 Ω/1000 ft (V\textsubscript{drop} = 6.42 V = 3.09\% ---
still exceeds 2\%).\\
2 AWG = 0.206 Ω/1000 ft (V\textsubscript{drop} = 4.12 V = 1.98\% ---
meets the 2\% target).\\
1 AWG = 0.164 Ω/1000 ft (V\textsubscript{drop} = 3.28 V = 1.58\%).\\
Minimum conductor size: 2 AWG copper --- governed by voltage drop, not
ampacity (2 AWG is rated 115 A, far more than the 52.5 A requirement).

\end{examplebox}

\subsection{14.7.5 Service Load
Calculations}\label{service-load-calculations}

NEC Article 220 provides two methods for calculating the total demand
load on a building's electrical service: the \textbf{standard method}
(Article 220, Parts III--IV) and the \textbf{optional method} (Article
220, Part V, Section 220.82 for dwelling units). Both methods apply
\textbf{demand factors} --- percentage reductions that account for the
statistical improbability that all loads will operate simultaneously at
full capacity --- to convert the total connected load into the design
demand load used for sizing the service entrance conductors and main
overcurrent device. The standard method calculates general lighting and
receptacle loads from Table 220.12 at 3 VA/ft² for dwellings (or the
applicable VA/ft² for the occupancy type), applies the demand factors
from Table 220.42 (first 3,000 VA at 100\%, remainder at 35\% for
dwellings), adds fixed appliance loads at 75\% demand if four or more
appliances (220.53), adds the dryer at 5,000 VA minimum per Table
220.54, and adds cooking equipment at reduced demand per Table 220.55
(e.g., one 12 kW range reduces to 8 kW). The largest motor load is added
at 125\% per 220.50. The \textbf{optional method} (220.82) is simpler
for existing dwellings or where the total connected load can be
determined: the first 10 kVA of general load is taken at 100\%, the
remainder at 40\%, and HVAC is added at 100\% of the largest system
(heating or cooling, since they do not operate simultaneously per
220.60). For commercial buildings, Article 220 Part IV provides demand
factors for specific load types including lighting (Table 220.42),
receptacles (Table 220.44: first 10 kVA at 100\%, remainder at 50\%),
and specific equipment loads. The calculated demand load determines the
minimum service entrance conductor size (per Table 310.16) and the main
overcurrent device rating (per 230.79 --- minimum 100 A for a single
dwelling).

\begin{examplebox}

\textbf{Example 14.7.5:} A 2,400 ft² single-family dwelling has the
following loads: general lighting and receptacles (3 VA/ft²), two 20 A
small-appliance circuits, one laundry circuit, one 12 kW electric range,
one 5.5 kW clothes dryer, one 4.5 kW water heater, one 5 ton (6 kW) air
conditioner, and one 10 kW electric furnace. Calculate the service
demand load using the standard method and determine the minimum service
size.

\textbf{Solution:}\\
\textbf{General lighting:} 2,400 ft² × 3 VA/ft² = 7,200 VA.\\
\textbf{Small-appliance circuits:} 2 × 1,500 VA = 3,000 VA.\\
\textbf{Laundry circuit:} 1,500 VA.\\
Total general load: 7,200 + 3,000 + 1,500 = 11,700 VA.\\
Apply Table 220.42 demand factors: first 3,000 VA at 100\% = 3,000 VA;
remaining 8,700 VA at 35\% = 3,045 VA.\\
Net general load: 3,000 + 3,045 = \textbf{6,045 VA}.\\
\textbf{Range:} Table 220.55, Column C for one range ≤ 12 kW: demand =
\textbf{8,000 VA}.\\
\textbf{Dryer:} Table 220.54 for one dryer: 5,500 VA (or 5,000 VA
minimum, use nameplate) = \textbf{5,500 VA}.\\
\textbf{Water heater:} 4,500 VA (fixed appliance; with fewer than 4
fixed appliances, taken at 100\%) = \textbf{4,500 VA}.\\
\textbf{Heating/cooling (220.60):} use the larger --- furnace 10,000 VA
\textgreater{} A/C 6,000 VA, so heating governs: \textbf{10,000 VA}.\\
Total demand: 6,045 + 8,000 + 5,500 + 4,500 + 10,000 = \textbf{34,045
VA}.\\
Service current (240 V single-phase): I = 34,045 / 240 = \textbf{141.9
A}.\\
Minimum service size per 230.79: 150 A or 200 A (the two common
residential service sizes above 100 A). Select \textbf{200 A} service
for capacity margin.\\
Service entrance conductors: 2/0 AWG copper THWN-2 (rated 175 A at 75°C
--- insufficient for 200 A OCPD) or 4/0 AWG copper (rated 230 A at 75°C
--- sufficient). Use \textbf{4/0 AWG copper} for the 200 A service.

\end{examplebox}

\section{14.8 Emergency and Standby Power
Systems}\label{emergency-and-standby-power-systems}

NEC Articles 700, 701, and 702 establish requirements for power systems
that provide electricity when the normal supply fails, with the
stringency of requirements proportional to the criticality of the loads
served. \textbf{Article 700 --- Emergency Systems} covers loads whose
failure would create a hazard to life safety: egress lighting, exit
signs, fire alarm systems, fire pumps, smoke control, and elevator
recall. Emergency systems must have an alternate power source that
restores power within \textbf{10 seconds} of normal supply failure, must
have their wiring kept entirely independent from all other wiring
(separate raceways, cables, and panelboards, or 2-hour fire-rated
enclosures), and must have fully selective (coordinated) overcurrent
protection so that a fault on one emergency branch does not trip the
entire emergency system. \textbf{Article 701 --- Legally Required
Standby Systems} covers loads whose loss would create hazards or hamper
rescue/fire operations but that can tolerate a longer restoration time
--- typically \textbf{60 seconds}. Examples include heating/ventilation
for occupied areas, communications systems, and industrial processes
whose interruption could create hazards. Wiring for legally required
standby may share raceways with other legally required standby circuits
but must be independent of normal and emergency circuits.
\textbf{Article 702 --- Optional Standby Systems} covers loads whose
loss would cause inconvenience or economic loss but not life-safety
hazards --- data centers, commercial refrigeration, and building HVAC.
Optional standby has no mandated restoration time and no requirement for
wiring independence. All three articles require the alternate power
source to have sufficient capacity for the connected load, and Article
700.4 requires a written record of periodic testing and maintenance.
\textbf{Transfer switches} (Article 700.5) are required for emergency
and legally required standby systems and must be automatic, listed for
emergency use, electrically operated and mechanically held, and approved
by the authority having jurisdiction. Generator sizing must account for
motor starting inrush (largest motor at locked-rotor current plus
running load of all others), the sequence of load transfer (stepped
loading to avoid generator overload), and the power factor of the
connected load. The generator must be located on the premises and must
have sufficient on-site fuel for the required operating duration ---
typically \textbf{2 hours} for emergency systems per 700.12, though the
authority having jurisdiction may require more for hospitals (96 hours
per NFPA 110 for healthcare facilities).

\subsection{14.8.1 Generator Sizing and Transfer Switch
Requirements}\label{generator-sizing-and-transfer-switch-requirements}

Sizing an emergency or standby generator requires calculating the total
connected load for each power system category (emergency, legally
required standby, optional standby), accounting for motor starting
inrush currents, applying appropriate demand and diversity factors, and
selecting a generator with adequate kW and kVA capacity at the required
power factor. The generator's transient voltage and frequency response
during load step changes must also be considered --- NFPA 110 requires
that the generator maintain voltage within ±10\% and frequency within ±3
Hz of rated values during load application and rejection transients. The
automatic transfer switch (ATS) monitors the normal source, detects a
failure (typically voltage drop below 85\% on any phase for more than
1--3 seconds), sends a start signal to the generator, and transfers the
load after the generator reaches acceptable voltage and frequency ---
all within the 10-second window mandated by Article 700. Modern transfer
switches include bypass isolation capability (allowing maintenance of
the transfer mechanism without interrupting power), programmable time
delays (engine start, time to transfer, time to retransfer, engine
cool-down), and in-phase transition monitoring (for paralleling
applications). For systems with multiple transfer switches, a load
priority scheme ensures that the most critical loads (emergency)
transfer first, legally required standby loads transfer next, and
optional standby loads transfer last --- preventing the generator from
being overloaded by simultaneous motor starting across all load
categories.

\begin{examplebox}

\textbf{Example 14.8.1:} A hospital requires an emergency generator to
serve the following loads: emergency egress lighting (25 kW), fire alarm
and communications (10 kW), fire pump --- 50 HP, 460 V motor (FLC = 65
A, locked-rotor = 390 A), two elevators --- 25 HP each (FLC = 34 A each,
locked-rotor = 204 A each), and critical HVAC (80 kW at 0.85 PF). The
generator serves a 480Y/277 V, three-phase system. Size the generator in
kW and kVA, accounting for motor starting.

\textbf{Solution:}\\
\textbf{Running loads:} Lighting: 25 kW. Fire alarm: 10 kW. Fire pump
running: P = √3 × 480 × 65 × 0.85 = 45.9 kW. Elevators running (2): P =
2 × √3 × 480 × 34 × 0.85 = 2 × 24.0 = 48.0 kW. HVAC: 80 kW.\\
Total running: 25 + 10 + 45.9 + 48.0 + 80 = \textbf{208.9 kW}.\\
\textbf{Motor starting analysis} (worst case --- fire pump starts with
all other loads running): Fire pump starting kVA = √3 × 480 × 390 / 1000
= 324.3 kVA (at \textasciitilde0.30 PF starting = 97.3 kW).\\
Running load without fire pump: 208.9 − 45.9 = 163.0 kW.\\
Total kW during fire pump start: 163.0 + 97.3 = 260.3 kW.\\
Total kVA during start: 163.0/0.85 + 324.3 = 191.8 + 324.3 = 516.1 kVA
(but at mixed PF).\\
Using a load management strategy that sequences motor starts (fire pump
starts first before elevators), the generator must handle: fire pump
starting kVA + lighting + fire alarm = 324.3 + 25/0.85 + 10/0.85 = 324.3
+ 29.4 + 11.8 = 365.5 kVA peak, then steady-state 208.9 kW / 0.85 =
245.8 kVA.\\
\textbf{Generator selection:} Minimum \textbf{continuous rating = 250
kW} (at 0.8 PF = 312.5 kVA) with a \textbf{motor starting capability of
375+ kVA} to maintain voltage within the ±10\% tolerance during fire
pump starting. Select a \textbf{300 kW / 375 kVA} standby-rated
generator to provide margin.\\
Per NFPA 110 for Type 10 (healthcare), fuel storage must provide
\textbf{96 hours} of operation at full load: fuel consumption ≈ 21
gallons/hour for a 300 kW diesel generator, requiring a minimum
2,016-gallon fuel tank.

\end{examplebox}

\chapter{Chapter 15}\label{chapter-15}

\chapter{Networking}\label{networking}

Networking is the engineering discipline concerned with interconnecting
computing devices and systems to exchange data reliably across physical
media and logical protocols. While computer science focuses on
software-layer abstractions, the electrical engineering perspective
emphasizes the physical transport of signals --- the fiber optic links,
coaxial cables, and copper pairs that carry bits as light pulses,
electromagnetic waves, and voltage transitions. The Open Systems
Interconnection (OSI) model provides a layered framework that maps
cleanly to EE concerns: from the physical layer's signal integrity,
attenuation, and bandwidth through the data link and network layers that
frame, address, and route information, to the transport layer protocols
that ensure end-to-end delivery. This chapter covers the physical media,
optical systems, wireless technologies, and protocol fundamentals that
every electrical engineer encounters when designing or supporting
networked infrastructure.

\section{15.1 The OSI Model}\label{the-osi-model}

The OSI (Open Systems Interconnection) model is a conceptual framework
developed by the International Organization for Standardization (ISO)
that divides network communication into seven distinct layers, each with
a well-defined role and interface to the layers above and below it. The
model provides a common language for describing how data moves from an
application on one device to an application on another, regardless of
the underlying hardware and software.

\subsection{15.1.1 Layer Overview and
Encapsulation}\label{layer-overview-and-encapsulation}

The seven OSI layers, from bottom to top, are: Physical (Layer 1), Data
Link (Layer 2), Network (Layer 3), Transport (Layer 4), Session (Layer
5), Presentation (Layer 6), and Application (Layer 7). When data is
transmitted, it passes down through the layers at the sender, with each
layer adding its own header (and sometimes a trailer) to the data
received from the layer above --- a process called encapsulation. At the
receiver, each layer strips its corresponding header and passes the
payload up to the next layer (decapsulation). Layers 5 through 7 are
primarily software concerns (session management, data formatting,
application interfaces) and are outside the scope of this EE reference.
The four lower layers --- Physical, Data Link, Network, and Transport
--- are where electrical engineering intersects with networking, dealing
with signals, frames, packets, and segments.

\begin{examplebox}

\textbf{Example 15.1.1:} An application sends a 1,000-byte payload over
an Ethernet network using IPv4 and TCP. The headers added are: TCP (20
bytes), IPv4 (20 bytes), and Ethernet (14-byte header + 4-byte FCS = 18
bytes). Calculate the total frame size and the protocol efficiency
(ratio of payload to total frame size).

\textbf{Solution:}\\
Total headers and trailer: 20 (TCP) + 20 (IPv4) + 18 (Ethernet) = 58
bytes\\
Total frame size: 1,000 + 58 = \textbf{1,058 bytes}\\
Protocol efficiency: η = 1,000 / 1,058 = \textbf{0.9452 = 94.5\%}

Note: Including the 8-byte preamble/SFD and 12-byte inter-frame gap
(which are not part of the frame but are required on the wire), the
total on-wire overhead is 58 + 20 = 78 bytes, reducing the wire
efficiency to 1,000 / 1,078 = 92.8\%.

\end{examplebox}

\subsection{15.1.2 Physical Layer (Layer
1)}\label{physical-layer-layer-1}

The physical layer defines the electrical, optical, and mechanical
specifications for transmitting raw bits over a communication channel.
It specifies signal encoding schemes (NRZ, Manchester, 8b/10b, 64b/66b,
PAM-4), voltage or light levels, bit timing, connector types, and cable
pinouts. The physical layer does not interpret the meaning of the bits
--- it only ensures they are placed on the medium and recovered at the
far end with acceptable error rates. Key EE parameters at this layer
include signal amplitude, characteristic impedance, rise and fall times,
jitter, and eye diagram specifications.

\begin{examplebox}

\textbf{Example 15.1.2:} A PAM-4 physical layer uses 4-level signaling
(2 bits per symbol) at a symbol rate of 833 Msymbols/s per wire pair,
transmitted across four twisted pairs simultaneously. Calculate (a) the
bit rate per pair, (b) the total aggregate bit rate, and (c) verify the
bits per symbol.

\textbf{Solution:}

(a) Bit rate per pair:\\
Bits per symbol = log₂(4) = 2\\
Bit rate per pair = 833 × 10⁶ × 2 = \textbf{1,666 Mbps = 1.666 Gbps}

(b) Total aggregate bit rate:\\
Total = 4 pairs × 1.666 Gbps = \textbf{6.664 Gbps}

(c) Bits per symbol verification:\\
PAM-4 has 4 levels: \{−3, −1, +1, +3\}\\
Each symbol encodes log₂(4) = \textbf{2 bits per symbol} ✓

\end{examplebox}

\subsection{15.1.3 Data Link Layer (Layer
2)}\label{data-link-layer-layer-2}

The data link layer provides node-to-node data transfer on a shared or
point-to-point link, handling framing, physical addressing (MAC
addresses), error detection, and media access control. Ethernet is the
dominant Layer 2 technology in LANs, using 48-bit MAC addresses and a
CRC-32 checksum for frame integrity verification. Switches operate at
Layer 2, forwarding frames based on MAC address tables and segmenting
collision domains. VLANs (IEEE 802.1Q) extend Layer 2 by inserting a
4-byte tag into the Ethernet frame that includes a 12-bit VLAN ID,
enabling logical network segmentation over shared physical
infrastructure.

\begin{examplebox}

\textbf{Example 15.1.3:} An Ethernet switch has a MAC address table
capacity of 16,384 entries, each storing a 48-bit MAC address plus an
8-bit port number. Calculate (a) the memory required for the MAC address
table and (b) the maximum number of VLANs possible with the 12-bit VLAN
ID field in an 802.1Q tag.

\textbf{Solution:}

(a) Memory per entry: 48 bits (MAC) + 8 bits (port) = 56 bits = 7
bytes\\
Total memory: 16,384 × 7 = \textbf{114,688 bytes ≈ 112 KB}

(b) Maximum VLANs:\\
12-bit VLAN ID: 2¹² = 4,096 possible values\\
VLAN 0 and VLAN 4095 are reserved, so usable VLANs = \textbf{4,094}

\end{examplebox}

\subsection{15.1.4 Network Layer (Layer 3)}\label{network-layer-layer-3}

The network layer is responsible for logical addressing, routing, and
forwarding packets across multiple interconnected networks
(internetworking). IP (Internet Protocol) is the dominant Layer 3
protocol, assigning hierarchical addresses that enable routers to make
forwarding decisions based on destination network prefixes. Unlike Layer
2 MAC addresses which are flat and locally significant, Layer 3 IP
addresses are structured with network and host portions, enabling
scalable routing through aggregation and summarization. The Time-to-Live
(TTL) field prevents packets from looping indefinitely by decrementing
at each router hop; when TTL reaches zero, the packet is discarded.

\begin{examplebox}

\textbf{Example 15.1.4:} A router processes packets at a rate of 10
million packets per second (10 Mpps). The average packet size is 512
bytes. Calculate (a) the throughput in Gbps and (b) the maximum number
of hops a packet can traverse if the initial TTL is set to 64.

\textbf{Solution:}

(a) Throughput:\\
Bits per packet = 512 × 8 = 4,096 bits\\
Throughput = 10 × 10⁶ × 4,096 = 40.96 × 10⁹ bps = \textbf{40.96 Gbps}

(b) Maximum hops:\\
Each router decrements TTL by 1. Starting at TTL = 64:\\
Maximum hops = \textbf{63} successful router hops (each router
decrements TTL by 1; the 64th router decrements TTL to 0 and discards
the packet without forwarding it)

\end{examplebox}

\subsection{15.1.5 Transport Layer (Layer
4)}\label{transport-layer-layer-4}

The transport layer provides end-to-end communication services between
application processes on different hosts, using port numbers (16-bit,
range 0--65535) to multiplex multiple connections over a single IP
address. TCP provides connection-oriented, reliable delivery with flow
control and congestion avoidance, while UDP provides connectionless,
best-effort delivery with minimal overhead. The choice between TCP and
UDP depends on whether the application requires guaranteed delivery
(file transfer, web browsing, email) or prioritizes low latency (voice,
video, gaming, DNS queries). Segment size is constrained by the Maximum
Transmission Unit (MTU) of the path, typically 1,500 bytes for Ethernet.

\begin{examplebox}

\textbf{Example 15.1.5:} A TCP connection has a receive window size of
65,535 bytes and the round-trip time (RTT) is 40 ms. Calculate (a) the
maximum achievable throughput (window-limited) and (b) the total number
of unique port numbers available for simultaneous connections.

\textbf{Solution:}

(a) Maximum throughput (bandwidth-delay product limit):\\
Throughput = Window size / RTT = 65,535 bytes / 0.040 s = 1,638,375
bytes/s\\
Convert to Mbps: 1,638,375 × 8 = 13,107,000 bps = \textbf{13.1 Mbps}

(b) Unique port numbers:\\
16-bit port field: 2¹⁶ = \textbf{65,536 port numbers} (0--65535)\\
Well-known ports (0--1023) are reserved for standard services, leaving
64,512 for dynamic/ephemeral use.

\end{examplebox}

\section{15.2 Physical Media: Copper}\label{physical-media-copper}

Copper cabling has been the foundation of electrical communication since
the telegraph era and remains the dominant medium for local-area
networking, cable television distribution, and last-mile access. The two
principal forms --- coaxial cable and twisted-pair cable --- each offer
distinct impedance characteristics, bandwidth capabilities, and noise
immunity suited to different applications.

\subsection{15.2.1 Coaxial Cable}\label{coaxial-cable}

Coaxial cable consists of a central conductor surrounded by a dielectric
insulator, a conductive shield (braid, foil, or both), and an outer
jacket, forming a transmission line with well-defined characteristic
impedance. The two standard impedances are 75 Ω (used in cable
television, CATV, and video distribution with RG-6/RG-59) and 50 Ω (used
in RF systems, test equipment, and data networks with RG-58/RG-213). The
coaxial geometry provides inherent shielding against external
electromagnetic interference, as the outer conductor acts as a Faraday
cage for the inner conductor. Characteristic impedance is determined by
Z₀ = (138 / √ε\textsubscript{r}) × log₁₀(D/d), where D is the inner
diameter of the shield and d is the outer diameter of the center
conductor. The velocity of propagation is v\textsubscript{p} = c /
√ε\textsubscript{r}, where c is the speed of light and
ε\textsubscript{r} is the relative permittivity of the dielectric.

\begin{examplebox}

\textbf{Example 15.2.1:} An RG-6 coaxial cable has a center conductor
diameter d = 1.024 mm, a shield inner diameter D = 4.700 mm, and a foam
polyethylene dielectric with ε\textsubscript{r} = 1.45. Calculate (a)
the characteristic impedance and (b) the velocity of propagation as a
percentage of the speed of light.

\textbf{Solution:}

(a) Characteristic impedance:\\
Z₀ = (138 / √ε\textsubscript{r}) × log₁₀(D/d) = (138 / √1.45) ×
log₁₀(4.700 / 1.024)\\
√1.45 = 1.2042\\
138 / 1.2042 = 114.6\\
log₁₀(4.700 / 1.024) = log₁₀(4.590) = 0.6618\\
Z₀ = 114.6 × 0.6618 = \textbf{75.8 Ω ≈ 75 Ω} ✓

(b) Velocity of propagation:\\
v\textsubscript{p} = c / √ε\textsubscript{r} = c / 1.2042 = 0.8304c\\
Velocity of propagation = \textbf{83.0\% of the speed of light}

\end{examplebox}

\subsection{15.2.2 Twisted-Pair Cable}\label{twisted-pair-cable}

Twisted-pair cable consists of insulated copper conductors twisted
together in pairs to reduce electromagnetic interference and crosstalk
between adjacent pairs. Unshielded twisted pair (UTP) relies solely on
the twist geometry for noise rejection, while shielded variants (STP,
FTP, S/FTP) add metallic foil or braided shields around individual pairs
or the entire cable bundle. Category ratings define the maximum
supported frequency bandwidth: Cat 5e supports up to 100 MHz, Cat 6 up
to 250 MHz, Cat 6A up to 500 MHz, and Cat 8 up to 2 GHz. The twist rate
(twists per meter) varies between pairs within the same cable to
minimize pair-to-pair crosstalk, and each category specifies tighter
performance requirements for attenuation, NEXT, and return loss.

\begin{examplebox}

\textbf{Example 15.2.2:} A 100 m Cat 6A UTP cable has a maximum
attenuation of 32.8 dB at 500 MHz. A signal is transmitted at 0 dBm at
500 MHz. Calculate (a) the received signal power in dBm and (b) the
received power in milliwatts.

\textbf{Solution:}

(a) Received power in dBm:\\
P\textsubscript{rx} = P\textsubscript{tx} − Attenuation = 0 − 32.8 =
\textbf{−32.8 dBm}

(b) Convert to milliwatts:\\
P\textsubscript{rx} = 10\textsuperscript{(−32.8/10)} =
10\textsuperscript{−3.28} = 5.25 × 10⁻⁴ mW = \textbf{0.000525 mW = 0.525
μW}

\end{examplebox}

\subsection{15.2.3 Signal Attenuation and
Bandwidth}\label{signal-attenuation-and-bandwidth}

Signal attenuation in copper cables increases with both frequency and
distance, following an approximately square-root-of-frequency
relationship for coaxial cable (due to skin effect losses dominating)
and a more complex function for twisted pair. The bandwidth-distance
product characterizes the information-carrying capacity of a medium:
doubling the distance approximately halves the usable bandwidth.
Insertion loss is specified in dB per unit length (dB/100 m) at specific
test frequencies, and the total link loss must remain within the
receiver's dynamic range for reliable operation. Skin effect causes
current to flow in an increasingly thin layer near the conductor surface
at higher frequencies, increasing the effective AC resistance and thus
the attenuation.

\begin{examplebox}

\textbf{Example 15.2.3:} An RG-6 coaxial cable has measured attenuation
of 5.6 dB/100 m at 400 MHz and 8.9 dB/100 m at 1 GHz. For a 60 m cable
run carrying a 750 MHz CATV signal, estimate the attenuation using the
square-root frequency scaling relationship from the 400 MHz
specification.

\textbf{Solution:}\\
Square-root frequency scaling: α(f₂) ≈ α(f₁) × √(f₂/f₁)\\
α(750 MHz) ≈ 5.6 × √(750/400) = 5.6 × √1.875 = 5.6 × 1.3693 = 7.67
dB/100 m

Total attenuation for 60 m:\\
Loss = 7.67 × (60/100) = \textbf{4.60 dB}

Verification: The estimated 7.67 dB/100 m at 750 MHz falls between the
5.6 (at 400 MHz) and 8.9 (at 1 GHz) specifications, confirming the
estimate is reasonable.

\end{examplebox}

\subsection{15.2.4 Crosstalk and Noise}\label{crosstalk-and-noise}

Crosstalk is the unwanted coupling of signals from one conductor pair to
another within the same cable or between adjacent cables, and is the
primary impairment limiting the performance of twisted-pair Ethernet.
Near-End Crosstalk (NEXT) is measured at the same end as the transmitter
and is the most critical parameter because it represents interference
where the desired signal has not yet been attenuated by cable loss.
Far-End Crosstalk (FEXT) is measured at the opposite end and is
partially attenuated by cable loss, making it less severe than NEXT. The
Attenuation-to-Crosstalk Ratio (ACR) --- defined as NEXT minus insertion
loss (both in dB) --- indicates the signal-to-interference margin
available to the receiver, and must be positive for reliable
communication.

\begin{examplebox}

\textbf{Example 15.2.4:} A Cat 6 cable has a NEXT value of 44.3 dB and
an insertion loss of 21.7 dB at 250 MHz. Calculate (a) the ACR and (b)
determine whether the link meets a minimum ACR requirement of 10 dB.

\textbf{Solution:}

(a) Attenuation-to-Crosstalk Ratio:\\
ACR = NEXT − Insertion Loss = 44.3 − 21.7 = \textbf{22.6 dB}

(b) The ACR of 22.6 dB \textbf{exceeds the 10 dB minimum} by a margin of
12.6 dB. This means the desired signal arrives at the receiver 22.6 dB
stronger than the crosstalk interference, providing comfortable margin
for reliable operation at 250 MHz.

\end{examplebox}

\subsection{15.2.5 Cable Testing and
Certification}\label{cable-testing-and-certification}

Structured cabling installations must be tested and certified to verify
compliance with TIA-568 or ISO 11801 performance standards before being
placed into service. Cable certification testers (such as Fluke DSX
CableAnalyzer) measure key parameters across the full frequency range of
the cable category and issue a pass/fail result against the selected
standard. The primary test parameters include wiremap (verifying correct
pin-to-pin connectivity and detecting opens, shorts, crossed pairs, and
split pairs), insertion loss (signal attenuation from end to end), NEXT
(Near-End Crosstalk between pairs), PS-NEXT (Power Sum NEXT from all
adjacent pairs), return loss (impedance mismatch reflections), and
propagation delay and delay skew between pairs. Two test configurations
are defined: the permanent link test (from patch panel IDC to outlet
IDC, excluding patch cords) and the channel test (full end-to-end path
including patch cords). A permanent link test is preferred for new
installations because it certifies only the permanently installed
cabling, independent of the patch cords used.

\begin{examplebox}

\textbf{Example 15.2.5:} A Cat 6A cable installation is tested using a
permanent link adapter. The tester reports: insertion loss = 18.2 dB at
500 MHz (limit: 28.1 dB), NEXT = 42.8 dB at 500 MHz (limit: 33.1 dB),
and return loss = 14.5 dB at 500 MHz (limit: 12.0 dB). Determine whether
each parameter passes and calculate the headroom (margin) for each.

\textbf{Solution:}\\
Insertion loss: 18.2 dB measured vs.~28.1 dB limit. Since lower
insertion loss is better, 18.2 \textless{} 28.1 --- \textbf{PASS} with
28.1 − 18.2 = \textbf{9.9 dB headroom}.\\
NEXT: 42.8 dB measured vs.~33.1 dB limit. Since higher NEXT is better
(more isolation), 42.8 \textgreater{} 33.1 --- \textbf{PASS} with 42.8 −
33.1 = \textbf{9.7 dB headroom}.\\
Return loss: 14.5 dB measured vs.~12.0 dB limit. Since higher return
loss is better (less reflection), 14.5 \textgreater{} 12.0 ---
\textbf{PASS} with 14.5 − 12.0 = \textbf{2.5 dB headroom}.\\
All three parameters pass with positive margin. The return loss has the
least headroom and would be the first parameter to fail if cable quality
degrades or connectors are improperly terminated.

\end{examplebox}

\section{15.3 Physical Media: Fiber
Optics}\label{physical-media-fiber-optics}

Fiber optic communication transmits information as pulses of light
through thin glass or plastic fibers, offering enormous bandwidth,
immunity to electromagnetic interference, low attenuation over long
distances, and inherent electrical isolation. Fiber is the dominant
medium for telecommunications backbone, metropolitan networks, submarine
cables, and increasingly for data center and enterprise interconnects.

\subsection{15.3.1 Optical Fiber Structure and
Types}\label{optical-fiber-structure-and-types}

An optical fiber consists of a cylindrical glass or plastic core
surrounded by a cladding of slightly lower refractive index, which
confines light within the core by total internal reflection. The
critical angle for total internal reflection is determined by Snell's
law: sin θ\textsubscript{c} = n\textsubscript{clad} /
n\textsubscript{core}, and the numerical aperture NA =
√(n\textsubscript{core}² − n\textsubscript{clad}²) defines the cone of
light that can enter and propagate through the fiber. Standard
telecommunications fiber uses a silica glass core (n ≈ 1.468) and
cladding (n ≈ 1.463), with a protective acrylate buffer coating and
outer jacket. The two fundamental types --- single-mode fiber (SMF) and
multimode fiber (MMF) --- differ in core diameter and the number of
propagation modes they support.

\begin{examplebox}

\textbf{Example 15.3.1:} A step-index optical fiber has a core
refractive index n\textsubscript{core} = 1.468 and a cladding refractive
index n\textsubscript{clad} = 1.463. Calculate (a) the numerical
aperture, (b) the critical angle for total internal reflection, and (c)
the maximum acceptance half-angle of the fiber.

\textbf{Solution:}

(a) Numerical aperture:\\
NA = √(n\textsubscript{core}² − n\textsubscript{clad}²) = √(1.468² −
1.463²) = √(2.1550 − 2.1404) = √0.01465 = \textbf{0.121}

(b) Critical angle:\\
sin θ\textsubscript{c} = n\textsubscript{clad} / n\textsubscript{core} =
1.463 / 1.468 = 0.99659\\
θ\textsubscript{c} = sin⁻¹(0.99659) = \textbf{85.27°}

(c) Maximum acceptance half-angle (in air, n₀ = 1.0):\\
sin θ\textsubscript{a} = NA / n₀ = 0.121 / 1.0 = 0.121\\
θ\textsubscript{a} = sin⁻¹(0.121) = \textbf{6.95°}

\end{examplebox}

\subsection{15.3.2 Single-Mode Fiber}\label{single-mode-fiber}

Single-mode fiber (SMF) has a small core diameter (typically 8--10 μm
for an overall 9/125 μm specification) that supports only the
fundamental LP₀₁ propagation mode, eliminating modal dispersion and
enabling transmission over distances exceeding 100 km without
regeneration. ITU-T G.652 defines standard SMF with zero-dispersion
wavelength near 1310 nm and typical attenuation of 0.35 dB/km at 1310 nm
and 0.20 dB/km at 1550 nm. Chromatic dispersion (approximately 17
ps/(nm·km) at 1550 nm) causes different wavelengths within the source's
spectral width to travel at slightly different velocities, broadening
pulses over distance and limiting the bit-rate-distance product. SMF is
the dominant medium for metro, long-haul, and submarine
telecommunications, as well as enterprise backbone and data center
interconnects exceeding 300 m.

\begin{examplebox}

\textbf{Example 15.3.2:} A single-mode fiber link operates at 1550 nm
over a distance of 80 km. The fiber has an attenuation of 0.22 dB/km and
chromatic dispersion of 17 ps/(nm·km). The laser source has a spectral
width of 0.1 nm. Calculate (a) the total fiber attenuation and (b) the
total chromatic dispersion (pulse broadening) over the link.

\textbf{Solution:}

(a) Total fiber attenuation:\\
Loss = 0.22 dB/km × 80 km = \textbf{17.6 dB}

(b) Total chromatic dispersion:\\
Δτ = D × L × Δλ = 17 ps/(nm·km) × 80 km × 0.1 nm = \textbf{136 ps}

At 10 Gbps (bit period = 100 ps), this 136 ps of pulse broadening
exceeds the bit period and would cause intersymbol interference,
requiring dispersion compensation or a narrower-linewidth laser. At 2.5
Gbps (bit period = 400 ps), the 136 ps broadening is within tolerance.

\end{examplebox}

\subsection{15.3.3 Multimode Fiber}\label{multimode-fiber}

Multimode fiber (MMF) has a larger core diameter (50 μm or 62.5 μm) that
supports hundreds of propagation modes, each traveling at a slightly
different velocity and creating modal dispersion that limits bandwidth
and reach. Graded-index MMF uses a parabolic refractive index profile to
equalize mode group velocities, significantly reducing modal dispersion
compared to step-index designs. The standard OM categories specify the
modal bandwidth as a bandwidth-distance product: OM1 (62.5 μm, 200
MHz·km at 850 nm), OM3 (50 μm, 2,000 MHz·km), OM4 (50 μm, 4,700 MHz·km),
and OM5 (50 μm, 4,700 MHz·km with SWDM support at 850--953 nm). MMF is
used primarily in enterprise LANs and data centers for distances up to
300--550 m at 10--100 Gbps, where the lower cost of VCSEL transmitters
and relaxed alignment tolerances provide economic advantages over SMF.

\begin{examplebox}

\textbf{Example 15.3.3:} An OM4 multimode fiber has a bandwidth-distance
product of 4,700 MHz·km at 850 nm. Determine (a) the maximum modal
bandwidth available for a 300 m data center link and (b) the maximum
supportable bit rate assuming bandwidth ≈ 0.7 × bit rate for NRZ
signaling.

\textbf{Solution:}

(a) Modal bandwidth at 300 m:\\
BW = 4,700 MHz·km / 0.300 km = \textbf{15,667 MHz ≈ 15.7 GHz}

(b) Maximum bit rate (NRZ):\\
Bit rate ≈ BW / 0.7 = 15,667 / 0.7 = \textbf{22,381 Mbps ≈ 22.4 Gbps}

This explains why OM4 can support 10GBASE-SR (10 Gbps) up to 400 m and
25GBASE-SR (25 Gbps) up to approximately 100 m, but requires parallel
lanes (e.g., 4 × 25G) for 100 Gbps.

\end{examplebox}

\subsection{15.3.4 Optical Transmitters and
Receivers}\label{optical-transmitters-and-receivers}

Optical transmitters convert electrical signals to modulated light using
laser diodes (LD) or light-emitting diodes (LED), with the choice
depending on data rate, distance, and cost requirements. Vertical-Cavity
Surface-Emitting Lasers (VCSELs) operating at 850 nm are the standard
source for multimode fiber links, while Distributed Feedback (DFB)
lasers at 1310 nm or 1550 nm serve single-mode applications. Optical
receivers use PIN photodiodes or Avalanche Photodiodes (APD) to convert
light back to electrical current, with receiver sensitivity specified in
dBm as the minimum optical power required to achieve a target bit error
rate (typically 10⁻¹²). Transceiver modules (SFP, SFP+, SFP28, QSFP28,
QSFP-DD) integrate the transmitter, receiver, and control electronics
into a hot-pluggable, standardized form factor with digital diagnostics
monitoring (DOM) for real-time power and temperature readings.

\begin{examplebox}

\textbf{Example 15.3.4:} An SFP+ transceiver for 10GBASE-LR has a
minimum transmit power of −1 dBm and a receiver sensitivity of −14.4 dBm
at BER = 10⁻¹². Calculate the total optical power budget available for
fiber attenuation, connector losses, and splice losses.

\textbf{Solution:}\\
Power budget = P\textsubscript{tx,min} −
P\textsubscript{rx,sensitivity}\\
Power budget = (−1) − (−14.4) = \textbf{13.4 dB}

This 13.4 dB budget must cover all losses in the link:\\
- Fiber attenuation (0.35 dB/km at 1310 nm × distance)\\
- Connector losses (0.3--0.5 dB each)\\
- Splice losses (0.1 dB each for fusion splices)\\
- System margin (typically 1--3 dB)

At 0.35 dB/km with two connectors (1 dB) and 2 dB margin: max distance =
(13.4 − 1 − 2) / 0.35 = 29.7 km. The 10GBASE-LR standard specifies a
maximum reach of 10 km, providing substantial margin.

\end{examplebox}

\subsection{15.3.5 Fiber Link Budgets}\label{fiber-link-budgets}

A fiber optic link budget accounts for all optical power gains and
losses between the transmitter and receiver to verify that the signal
arrives with sufficient power for reliable detection. The power budget
equals the transmitter output power minus the receiver sensitivity, and
must exceed the sum of all losses: fiber attenuation (dB/km × distance),
connector losses (typically 0.3--0.5 dB each), splice losses (typically
0.1 dB each for fusion splices), and a system margin (typically 3 dB)
for aging, temperature variations, and future repairs. If the link
budget is insufficient, options include using a higher-power
transmitter, a more sensitive receiver (APD instead of PIN), optical
amplifiers, or regenerators. For DWDM systems, the link budget must be
calculated per channel, accounting for wavelength-dependent fiber loss
and multiplexer/demultiplexer insertion losses.

\begin{examplebox}

\textbf{Example 15.3.5:} A 40 km single-mode fiber link at 1550 nm uses
connectors at each end (0.5 dB each), 4 fusion splices (0.1 dB each),
and a fiber attenuation of 0.25 dB/km. The transmitter output is +3 dBm
and the receiver sensitivity is −28 dBm. Calculate (a) the total link
loss, (b) the power budget, (c) the available margin, and (d) whether
the link closes with a 3 dB system margin.

\textbf{Solution:}

(a) Total link loss:\\
Fiber: 0.25 × 40 = 10.0 dB\\
Connectors: 2 × 0.5 = 1.0 dB\\
Splices: 4 × 0.1 = 0.4 dB\\
Total loss = 10.0 + 1.0 + 0.4 = \textbf{11.4 dB}

(b) Power budget:\\
Budget = P\textsubscript{tx} − P\textsubscript{rx,sens} = (+3) − (−28) =
\textbf{31 dB}

(c) Available margin:\\
Margin = Budget − Total loss = 31 − 11.4 = \textbf{19.6 dB}

(d) With 3 dB system margin required: 19.6 \textgreater{} 3, so the link
\textbf{closes with 16.6 dB of excess margin}. This link is
significantly over-engineered; a lower-cost transceiver with less power
budget would suffice.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-15-3-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch15_fiber_link_budget.png}

\caption{Figure 15.3.5: SMF link power margin vs fiber length for three common attenuation values (0.20, 0.25, 0.35 dB/km). Budget = 31 dB; fixed losses = 1.4 dB (2 connectors + 4 splices); system margin = 3 dB. The §15.3.5 example (40 km, 0.25 dB/km) is marked with a 16.6 dB margin.}

\end{figure}

\subsection{15.3.6 Fiber Troubleshooting and
OTDR}\label{fiber-troubleshooting-and-otdr}

An Optical Time-Domain Reflectometer (OTDR) is the primary instrument
for characterizing and troubleshooting fiber optic links, providing a
graphical trace of attenuation versus distance along the entire fiber
from a single end. The OTDR launches short pulses of light into the
fiber and measures the Rayleigh backscatter (continuous low-level
reflections from microscopic density variations in the glass) and
Fresnel reflections (discrete reflections at interfaces where the
refractive index changes abruptly, such as connectors, mechanical
splices, and fiber breaks). On the OTDR trace, fiber spans appear as a
steadily declining line (the slope equals the fiber attenuation in
dB/km), fusion splices appear as small step losses (typically 0.02--0.10
dB with no reflection spike), connectors appear as reflection spikes
with an associated insertion loss, and a fiber break or open end appears
as a large reflection spike followed by noise floor. The OTDR calculates
distance using d = (c × t) / (2 × n), where t is the round-trip time of
the reflected pulse, n is the group refractive index of the fiber
(typically 1.4677 for SMF at 1550 nm), and the factor of 2 accounts for
the round trip. Key OTDR specifications include dynamic range (maximum
measurable fiber loss, typically 25--45 dB), dead zone (minimum distance
after a reflection before the next event can be detected --- event dead
zone of 0.8--3 m and attenuation dead zone of 5--20 m), and pulse width
(shorter pulses give better spatial resolution but less dynamic range).

Common fiber faults and their OTDR signatures:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1892}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4054}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4054}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Fault
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
OTDR Signature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Cause
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fusion splice & Small step loss (0.02--0.10 dB), no reflection & Normal
splice point \\
Mechanical splice & Step loss (0.1--0.5 dB) with small reflection &
Field-installed splice \\
Connector & Reflection spike + insertion loss (0.3--0.75 dB) & Patch
panel, equipment port \\
Dirty connector & Increased reflection and loss vs.~baseline &
Contamination on endface \\
Macrobend & Localized loss with no reflection & Tight bend, cable pinch,
improper routing \\
Fiber break & Large reflection spike, signal drops to noise floor & Cut,
crushed, or severed cable \\
Ghosting & False reflection at 2× the distance of a strong reflector &
Double reflection artifact \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.3.6:} An OTDR with a pulse width of 100 ns is used to
test a 25 km single-mode fiber span at 1550 nm (group refractive index n
= 1.4677). The trace shows the fiber launch at 0 m, a fusion splice at
8.2 km with 0.05 dB loss, a connector at 15.6 km with 0.40 dB loss, and
the fiber end at 25.0 km. The fiber attenuation slope is 0.21 dB/km.
Calculate (a) the spatial resolution (pulse length in the fiber), (b)
the total end-to-end link loss from the OTDR trace, and (c) the expected
optical power at the far end if the launch power is 0 dBm.

\textbf{Solution:}

(a) Spatial resolution (one-way pulse length in fiber):\\
v\textsubscript{fiber} = c / n = 3.0 × 10⁸ / 1.4677 = 2.044 × 10⁸ m/s\\
Pulse length = v\textsubscript{fiber} × pulse width = 2.044 × 10⁸ × 100
× 10⁻⁹ = 20.44 m\\
Spatial resolution ≈ \textbf{20.4 m} (events closer than this cannot be
individually resolved)

(b) Total link loss from OTDR trace:\\
Fiber attenuation: 0.21 × 25.0 = 5.25 dB\\
Fusion splice: 0.05 dB\\
Connector: 0.40 dB\\
Total = 5.25 + 0.05 + 0.40 = \textbf{5.70 dB}

(c) Expected power at far end:\\
P\textsubscript{rx} = P\textsubscript{tx} − Total loss = 0 − 5.70 =
\textbf{−5.70 dBm}

Note: The OTDR measures from one end only. Best practice is to test from
both ends and average the splice losses, because OTDR measurements can
show apparent ``gainers'' (negative splice loss) when transitioning from
a fiber with a larger mode field diameter to one with a smaller
diameter, due to differences in backscatter levels between the two fiber
sections.

\end{examplebox}

\section{15.4 Dense Wavelength Division Multiplexing
(DWDM)}\label{dense-wavelength-division-multiplexing-dwdm}

Dense Wavelength Division Multiplexing is an optical transport
technology that multiplies the capacity of a single fiber by
transmitting multiple independent optical signals simultaneously, each
on a different wavelength (color) of light. DWDM is the backbone
technology for long-haul telecommunications, submarine cables, and
high-capacity metro networks, enabling terabits per second of aggregate
capacity over a single fiber pair.

\subsection{15.4.1 WDM Fundamentals and Channel
Spacing}\label{wdm-fundamentals-and-channel-spacing}

Wavelength Division Multiplexing (WDM) transmits multiple independent
optical signals simultaneously over a single fiber by assigning each
signal a different wavelength, analogous to frequency-division
multiplexing in radio systems. Coarse WDM (CWDM) uses wide channel
spacing of 20 nm across the 1270--1610 nm range, supporting up to 18
channels without optical amplification. Dense WDM (DWDM) uses tight
channel spacing defined by the ITU-T G.694.1 frequency grid, with
standard spacings of 100 GHz (≈ 0.8 nm) and 50 GHz (≈ 0.4 nm) in the
C-band (1530--1565 nm), supporting 40 to 96 channels per fiber. The
C-band is preferred because it coincides with the minimum loss window of
silica fiber (≈ 0.20 dB/km) and the gain bandwidth of Erbium-Doped Fiber
Amplifiers (EDFAs).

\begin{examplebox}

\textbf{Example 15.4.1:} A DWDM system uses the ITU-T 100 GHz grid in
the C-band from 191.7 THz to 196.1 THz. Calculate (a) the number of
channels, (b) the wavelength range in nm (using c = f × λ), and (c) the
channel spacing in nm at the center of the band.

\textbf{Solution:}

(a) Number of channels:\\
Bandwidth = 196.1 − 191.7 = 4.4 THz = 4,400 GHz\\
Channels = 4,400 / 100 + 1 = \textbf{45 channels}

(b) Wavelength range:\\
λ\textsubscript{min} = c / f\textsubscript{max} = 3 × 10⁸ / (196.1 ×
10¹²) = 1,529.8 nm\\
λ\textsubscript{max} = c / f\textsubscript{min} = 3 × 10⁸ / (191.7 ×
10¹²) = 1,564.9 nm\\
Wavelength range: \textbf{1,529.8 nm to 1,564.9 nm} (35.1 nm span)

(c) Channel spacing in nm at band center:\\
f\textsubscript{center} = (191.7 + 196.1) / 2 = 193.9 THz\\
Δλ = c × Δf / f² = (3 × 10⁸ × 100 × 10⁹) / (193.9 × 10¹²)² = 3 × 10¹⁹ /
3.760 × 10²⁸ = \textbf{0.798 nm ≈ 0.8 nm}

\end{examplebox}

\subsection{15.4.2 Optical Amplifiers
(EDFA)}\label{optical-amplifiers-edfa}

The Erbium-Doped Fiber Amplifier (EDFA) amplifies optical signals
directly in the fiber without optical-to-electrical-to-optical (O-E-O)
conversion, making it the enabling technology for long-haul DWDM
networks. An EDFA consists of a length of erbium-doped fiber pumped by a
980 nm or 1480 nm laser diode; incoming signal photons in the C-band
stimulate emission of additional photons at the same wavelength, phase,
and direction, providing 15--30 dB of gain per amplifier. EDFAs amplify
all DWDM channels simultaneously but add amplified spontaneous emission
(ASE) noise, characterized by the noise figure (typically 4--6 dB). The
optical signal-to-noise ratio (OSNR) degrades with each amplifier in a
chain, ultimately limiting the maximum reach of an amplified system.

\begin{examplebox}

\textbf{Example 15.4.2:} A DWDM link uses 5 inline EDFAs, each with a
gain of 20 dB and a noise figure of 5.5 dB. The input signal power per
channel is −2 dBm and the span loss between amplifiers equals the EDFA
gain (20 dB). Calculate the OSNR at the receiver in a 0.1 nm reference
bandwidth. Use the approximation: OSNR ≈ P\textsubscript{in} − NF − 10
log₁₀(N) + 58 dBm (where N is the number of amplifiers and 58 dBm
accounts for the noise bandwidth constant hν × Δν for 0.1 nm at 1550
nm).

\textbf{Solution:}\\
OSNR = P\textsubscript{in} − NF − 10 log₁₀(N) + 58\\
P\textsubscript{in} = −2 dBm\\
NF = 5.5 dB\\
10 log₁₀(5) = 6.99 dB

OSNR = −2 − 5.5 − 6.99 + 58 = \textbf{43.5 dB}

For 100 Gbps DP-QPSK coherent detection, the required OSNR is
approximately 12--15 dB, so this system has more than 28 dB of OSNR
margin --- indicating either the span count could be increased
significantly or the channel power could be reduced to mitigate fiber
nonlinearities.

\end{examplebox}

\subsection{15.4.3 DWDM System Design}\label{dwdm-system-design}

DWDM system design integrates fiber characteristics, amplifier
placement, channel plan, and transceiver specifications to achieve the
required capacity over the target distance. Span engineering determines
amplifier spacing based on fiber loss (typically 80--120 km spans for
terrestrial systems), with total system reach limited by accumulated ASE
noise and fiber nonlinear effects such as four-wave mixing and
self-phase modulation. Modern coherent transceivers use advanced
modulation formats (DP-QPSK, DP-16QAM) and digital signal processing to
achieve 100--400 Gbps per channel over thousands of kilometers. The
total system capacity equals the per-channel bit rate multiplied by the
number of channels.

\begin{examplebox}

\textbf{Example 15.4.3:} A DWDM system carries 80 channels at 100 Gbps
each over 1,200 km of fiber with EDFA amplifier spacing of 80 km. The
fiber attenuation is 0.22 dB/km at 1550 nm. Calculate (a) the total
system capacity, (b) the number of inline amplifiers required, and (c)
the span loss that each EDFA must compensate.

\textbf{Solution:}

(a) Total system capacity:\\
Capacity = 80 channels × 100 Gbps = \textbf{8,000 Gbps = 8 Tbps}

(b) Number of inline amplifiers:\\
Number of spans = 1,200 / 80 = 15 spans\\
Inline amplifiers = 15 − 1 = \textbf{14} (first span has a booster
amplifier at the transmitter, last span has a pre-amplifier at the
receiver; 14 inline amplifiers in between)

Note: Including booster and pre-amplifier, total amplifiers = 14 + 2 =
16.

(c) Span loss per amplifier:\\
Loss per span = 0.22 × 80 = \textbf{17.6 dB}\\
Each EDFA must provide at least 17.6 dB of gain to compensate the span
loss.

\end{examplebox}

\section{15.5 Ethernet}\label{ethernet}

Ethernet is the dominant networking technology for local-area networks
(LANs) and data centers, originally developed at Xerox PARC in the 1970s
and standardized as IEEE 802.3. It has evolved from 10 Mbps shared
coaxial bus to 400 Gbps point-to-point fiber and copper links while
maintaining backward-compatible frame formats.

\subsection{15.5.1 Frame Structure and MAC
Addressing}\label{frame-structure-and-mac-addressing}

An Ethernet frame consists of a preamble (7 bytes of alternating 1/0
pattern), start-of-frame delimiter (SFD, 1 byte), destination MAC
address (6 bytes), source MAC address (6 bytes), EtherType/length field
(2 bytes), payload (46--1,500 bytes), and frame check sequence (FCS, 4
bytes of CRC-32). The 48-bit MAC address uniquely identifies each
network interface, with the first 24 bits assigned as an
Organizationally Unique Identifier (OUI) by IEEE and the remaining 24
bits assigned by the manufacturer. The minimum frame size of 64 bytes
(excluding preamble and SFD) was originally required to ensure collision
detection in half-duplex CSMA/CD operation, though modern full-duplex
Ethernet has eliminated this concern. The 12-byte inter-frame gap (IFG)
is required between consecutive frames to allow receiver clock recovery.

\begin{examplebox}

\textbf{Example 15.5.1:} A network link carries 50,000 Ethernet frames
per second, each with the maximum 1,500-byte payload. Calculate (a) the
payload throughput in Mbps and (b) the total line rate in Mbps including
all overhead (8 bytes preamble/SFD + 14 bytes header + 4 bytes FCS + 12
bytes IFG).

\textbf{Solution:}

(a) Payload throughput:\\
Payload bits per frame = 1,500 × 8 = 12,000 bits\\
Throughput = 50,000 × 12,000 = 600,000,000 bps = \textbf{600 Mbps}

(b) Total line rate:\\
Overhead per frame = 8 + 14 + 4 + 12 = 38 bytes\\
Total frame on wire = 1,500 + 38 = 1,538 bytes = 12,304 bits\\
Line rate = 50,000 × 12,304 = 615,200,000 bps = \textbf{615.2 Mbps}

Protocol efficiency = 600 / 615.2 = 97.5\%. Ethernet overhead is minimal
for maximum-size frames but increases significantly for small frames
(e.g., 64-byte frames have only 46 bytes of payload, reducing efficiency
to 54.8\% (46 payload / 84 bytes on-wire)).

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-15-5-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch15_ethernet_efficiency.png}

\caption{Figure 15.5.1: Ethernet protocol efficiency vs payload size (46–9000 bytes). Fixed on-wire overhead is 38 bytes (8 preamble/SFD + 14 header + 4 FCS + 12 IFG). Efficiency rises from 54.8\% at the minimum 46-byte payload to 97.5\% at 1500 bytes and exceeds 99\% for jumbo frames.}

\end{figure}

\subsection{15.5.2 Ethernet Physical
Standards}\label{ethernet-physical-standards}

Ethernet physical layer standards define the signaling, encoding, and
media specifications for each combination of speed and medium, following
the naming convention speed-BASE-media (e.g., 1000BASE-T for 1 Gbps over
twisted pair, 10GBASE-SR for 10 Gbps short-reach multimode fiber). Key
copper standards include 100BASE-TX (100 Mbps, Cat 5, 100 m), 1000BASE-T
(1 Gbps, Cat 5e, 100 m), 10GBASE-T (10 Gbps, Cat 6A, 100 m), and
25GBASE-T/40GBASE-T (Cat 8, 30 m). Fiber standards span from 10GBASE-SR
(10 Gbps, 300 m on OM3 MMF) and 10GBASE-LR (10 Gbps, 10 km on SMF) to
100GBASE-SR4 (100 Gbps, 4 × 25G lanes, 100 m on OM4) and 400GBASE-DR4
(400 Gbps, 4 × 100G, 500 m on SMF). Each standard specifies transmit
power, receiver sensitivity, and the resulting maximum link distance for
a given media type.

\begin{examplebox}

\textbf{Example 15.5.2:} A data center uses 10GBASE-SR optics (850 nm
VCSEL) over OM3 multimode fiber. The minimum transmit power is −7.3 dBm,
the receiver sensitivity is −11.1 dBm, and the fiber attenuation at 850
nm is 3.5 dB/km. Calculate (a) the power budget, (b) the maximum
fiber-only distance (ignoring connectors), and (c) the maximum distance
accounting for 2 connector pairs at 0.5 dB each.

\textbf{Solution:}

(a) Power budget:\\
Budget = P\textsubscript{tx,min} − P\textsubscript{rx,sens} = (−7.3) −
(−11.1) = \textbf{3.8 dB}

(b) Maximum fiber-only distance:\\
d\textsubscript{max} = Budget / α = 3.8 / 3.5 = \textbf{1.09 km = 1,086
m}

(c) With connector losses:\\
Available for fiber = 3.8 − (2 × 0.5) = 2.8 dB\\
d\textsubscript{max} = 2.8 / 3.5 = \textbf{0.80 km = 800 m}

Note: The IEEE 802.3 standard specifies 10GBASE-SR maximum reach as 300
m on OM3, which accounts for modal bandwidth limitations (not just
attenuation) and provides margin for worst-case conditions.

\end{examplebox}

\subsection{15.5.3 Power over Ethernet
(PoE)}\label{power-over-ethernet-poe}

Power over Ethernet (PoE) delivers DC power alongside data over standard
twisted-pair Ethernet cabling, eliminating the need for separate power
outlets at each device location. IEEE 802.3af (PoE, Type 1) provides up
to 15.4 W at the Power Sourcing Equipment (PSE) port with a guaranteed
12.95 W at the Powered Device (PD), sufficient for VoIP phones and basic
access points. IEEE 802.3at (PoE+, Type 2) doubles the power to 30 W at
the PSE (25.5 W at the PD) for PTZ cameras and advanced APs. IEEE
802.3bt (PoE++, Type 3/4) delivers up to 60 W (Type 3) or 90 W (Type 4)
at the PSE using all four pairs, supporting high-power devices such as
LED lighting fixtures, thin clients, and outdoor access points. Power is
delivered as 48 VDC (nominal, range 44--57 V) over two or four pairs
using either Mode A (data pairs, phantom power on pins 1-2 and 3-6) or
Mode B (spare pairs, pins 4-5 and 7-8), with the PSE and PD negotiating
the power class through a classification handshake. Power loss in the
cable follows P\textsubscript{loss} = I² × R\textsubscript{cable}, and
the maximum cable resistance per NEC for PoE installations must account
for temperature rise in bundled cables per TIA TSB-184.

\begin{examplebox}

\textbf{Example 15.5.3:} A PoE+ switch port delivers 30 W (802.3at, Type
2) to a wireless access point over a 75-meter Cat 6A cable run. The DC
resistance of Cat 6A is 7.0 Ω/100 m per conductor (two conductors per
pair, two pairs used for Mode B power). Calculate the total cable
resistance, the current drawn, the power lost in the cable, and the
power delivered to the AP.

\textbf{Solution:}\\
Cable resistance per pair (round trip --- current flows out on one
conductor and returns on the other): R\textsubscript{pair} = 2 × 7.0 ×
(75/100) = 2 × 5.25 = 10.5 Ω.\\
With two pairs in parallel for power delivery: R\textsubscript{cable} =
10.5 / 2 = 5.25 Ω.\\
PSE output voltage: 50 V (nominal).\\
Current: I = P / V = 30 / 50 = 0.60 A.\\
Cable power loss: P\textsubscript{loss} = I² × R\textsubscript{cable} =
0.60² × 5.25 = 0.36 × 5.25 = 1.89 W.\\
Power at the PD: P\textsubscript{PD} = 30 − 1.89 = 28.11 W.\\
Voltage at PD: V\textsubscript{PD} = 50 − (0.60 × 5.25) = 50 − 3.15 =
46.85 V.\\
Efficiency: η = 28.11 / 30 = 93.7\%.\\
The PD voltage of 46.85 V is above the minimum 42.5 V required by the
standard.

\end{examplebox}

\subsection{15.5.4 Ethernet Switching and Spanning
Tree}\label{ethernet-switching-and-spanning-tree}

Ethernet switches operate at Layer 2 by learning which MAC addresses are
reachable through each port, building a \textbf{MAC address table} (also
called a CAM table) that maps destination MAC addresses to switch ports.
When a frame arrives, the switch records the source MAC and ingress
port; if the destination MAC is in the table, the frame is forwarded
only to the associated port (unicast forwarding), otherwise it is
flooded to all ports except the ingress port (unknown unicast flooding).
This learning-and-forwarding process provides microsecond-level latency
and full wire-speed performance for known destinations. In networks with
redundant links between switches --- essential for high availability ---
Layer 2 loops can form, causing \textbf{broadcast storms} where frames
circulate endlessly, rapidly saturating bandwidth and crashing the
network. The \textbf{Spanning Tree Protocol (STP, IEEE 802.1D)} prevents
loops by electing a root bridge (the switch with the lowest bridge ID),
calculating the shortest path cost from every switch to the root, and
placing redundant ports into a blocking state so that the active
topology forms a loop-free tree. STP convergence takes 30--50 seconds
(listening → learning → forwarding), which is unacceptable for modern
networks. \textbf{Rapid Spanning Tree Protocol (RSTP, IEEE 802.1w)}
reduces convergence to 1--3 seconds by introducing edge ports (directly
connected to end devices, transition immediately to forwarding),
alternate ports (pre-computed backup root ports), and a
proposal/agreement handshake between switches that eliminates the
listening and learning timers. \textbf{Multiple Spanning Tree Protocol
(MSTP, IEEE 802.1s)} maps groups of VLANs to separate spanning tree
instances, allowing different VLANs to use different active paths and
enabling per-VLAN load balancing across redundant links. Modern data
center networks increasingly replace STP with Layer 3 routing protocols
(OSPF, BGP) at the access layer or with proprietary multi-chassis link
aggregation (MLAG/vPC) that presents two physical switches as a single
logical switch, eliminating STP entirely.

\begin{examplebox}

\textbf{Example 15.5.4:} A network has four switches (S1--S4) connected
in a ring: S1↔S2, S2↔S3, S3↔S4, S4↔S1. All links are 1 Gbps with a path
cost of 4. Switch bridge priorities are: S1 = 4096, S2 = 8192, S3 =
32768, S4 = 32768. Determine the RSTP root bridge, the root ports on
each non-root switch, and which port is placed in the alternate
(blocking) state to break the loop.

\textbf{Solution:}\\
Root bridge election: S1 has the lowest bridge priority (4096), so
\textbf{S1 is the root bridge}.\\
Root port selection (lowest cost path to root): S2 root port = port
facing S1 (cost 4, direct link). S4 root port = port facing S1 (cost 4,
direct link).\\
S3 has two paths to the root: via S2 (cost 4 + 4 = 8) or via S4 (cost 4
+ 4 = 8). Both paths have equal cost, so S3 selects the path through the
neighbor with the lower bridge ID: S2 (8192) \textless{} S4 (32768), so
\textbf{S3's root port faces S2} (cost 8).\\
Designated ports: on each link segment, the switch closer to the root
places its port in the designated (forwarding) role. S1's ports facing
S2 and S4 are both designated. S2's port facing S3 is designated (S2 is
closer to root than S3).\\
The remaining port --- \textbf{S3's port facing S4} (or equivalently
S4's port facing S3) --- has no role and is placed in the
\textbf{alternate (blocking) state}. Specifically, S4's port facing S3
becomes designated (S4 has cost 4 vs S3's cost 8 from that segment), so
\textbf{S3's port facing S4 is alternate/blocking}.\\
The active tree is: S1↔S2↔S3 and S1↔S4, with the S3↔S4 link blocked. If
the S1↔S2 link fails, RSTP promotes S3's alternate port to root port
within 1--3 seconds, restoring connectivity through S3↔S4↔S1.

\end{examplebox}

\section{15.6 Internet Protocol (IP)}\label{internet-protocol-ip}

The Internet Protocol provides the logical addressing and routing
framework that enables packets to be forwarded across interconnected
networks from source to destination. IP operates at Layer 3 and is the
universal network-layer protocol of the Internet, with two versions in
active use: IPv4 and IPv6.

\subsection{15.6.1 IPv4 Addressing and
Subnetting}\label{ipv4-addressing-and-subnetting}

IPv4 uses 32-bit addresses written in dotted-decimal notation (e.g.,
192.168.1.100), divided into a network portion and a host portion by a
subnet mask. The subnet mask, expressed as a prefix length (e.g., /24
means 24 network bits and 8 host bits), determines how many subnets and
hosts are available: a /24 network provides 2⁸ − 2 = 254 usable host
addresses (excluding the network address and broadcast address).
Classless Inter-Domain Routing (CIDR) replaced the original classful
system (Class A/B/C), allowing arbitrary prefix lengths and enabling
efficient allocation through Variable Length Subnet Masks (VLSM).
Subnetting is a fundamental skill for configuring routers, switches,
firewalls, and any IP-enabled embedded system or IoT device.

\begin{examplebox}

\textbf{Example 15.6.1:} A company is assigned the network 172.16.0.0/16
and needs to create 60 subnets, each supporting at least 200 hosts.
Determine (a) the required subnet mask (prefix length), (b) the number
of available subnets, (c) the number of usable hosts per subnet, and (d)
the network and broadcast addresses of the first two subnets.

\textbf{Solution:}

(a) Determine the minimum host bits: 2ᵐ − 2 ≥ 200 → m = 8 (2⁸ − 2 = 254
≥ 200)\\
From the /16 base, the remaining bits after host allocation: 32 − 16 − 8
= 8 subnet bits\\
Subnets available: 2⁸ = 256 ≥ 60 ✓ (meets the requirement with room to
spare)\\
\textbf{Prefix length = /24} (256 subnets, 254 usable hosts each)

(b) Available subnets: 2⁸ = \textbf{256 subnets}

(c) Usable hosts per subnet: 2⁸ − 2 = \textbf{254 hosts}

(d) First two subnets:\\
Subnet 1: Network \textbf{172.16.0.0/24}, Broadcast 172.16.0.255, Hosts
172.16.0.1--172.16.0.254\\
Subnet 2: Network \textbf{172.16.1.0/24}, Broadcast 172.16.1.255, Hosts
172.16.1.1--172.16.1.254

\end{examplebox}

\subsection{15.6.2 IPv6 Addressing}\label{ipv6-addressing}

IPv6 uses 128-bit addresses written as eight groups of four hexadecimal
digits separated by colons (e.g.,
2001:0db8:0000:0001:0000:0000:0000:0001), with abbreviation rules:
leading zeros within each group may be omitted, and a single sequence of
consecutive all-zero groups may be replaced by ::. The vastly larger
address space (2¹²⁸ ≈ 3.4 × 10³⁸ addresses) eliminates the address
exhaustion problem that drove NAT deployment in IPv4. Standard practice
assigns a /64 prefix to each subnet, leaving 64 bits for the interface
identifier, which can be derived from the device's MAC address using the
Modified EUI-64 method or generated randomly for privacy. IPv6 is
increasingly relevant as IoT devices, industrial sensors, and embedded
systems adopt it for direct end-to-end addressability without NAT.

\begin{examplebox}

\textbf{Example 15.6.2:} An IoT sensor has the MAC address
00:1A:2B:3C:4D:5E and is on the IPv6 subnet 2001:0db8:abcd:0012::/64.
Using the Modified EUI-64 method, derive the full 128-bit IPv6 address
and write it in abbreviated notation.

\textbf{Solution:}\\
Step 1 --- Split MAC and insert FFFE:\\
00:1A:2B → 00:1A:2B:\textbf{FF:FE}:3C:4D:5E

Step 2 --- Flip the 7th bit (Universal/Local bit) of the first byte:\\
First byte: 00 = 0000 0000 → flip bit 7 (from left, 0-indexed bit 6) →
0000 0010 = 02\\
Modified: \textbf{02}:1A:2B:FF:FE:3C:4D:5E

Step 3 --- Form the interface ID (regroup as 16-bit words):\\
021A:2BFF:FE3C:4D5E

Step 4 --- Combine with subnet prefix:\\
Full address: 2001:0db8:abcd:0012:021A:2BFF:FE3C:4D5E\\
Abbreviated: \textbf{2001:db8:abcd:12:21a:2bff:fe3c:4d5e}

\end{examplebox}

\subsection{15.6.3 IP Routing Protocols}\label{ip-routing-protocols}

Routing protocols enable routers to automatically discover network
topology, exchange reachability information, and compute optimal
forwarding paths without manual static route configuration. They are
divided into Interior Gateway Protocols (IGPs), which operate within a
single autonomous system (AS), and Exterior Gateway Protocols (EGPs),
which exchange routes between autonomous systems across the Internet.
\textbf{OSPF (Open Shortest Path First)}, defined in RFC 2328 (OSPFv2
for IPv4) and RFC 5340 (OSPFv3 for IPv6), is a link-state IGP that
builds a complete topological map of the network by flooding Link-State
Advertisements (LSAs) to all routers within an area. Each router
independently runs Dijkstra's Shortest Path First (SPF) algorithm on
this link-state database (LSDB) to compute the shortest-cost path to
every destination. OSPF uses a hierarchical area design: Area 0 (the
backbone) interconnects all other areas through Area Border Routers
(ABRs), reducing the size of the LSDB and limiting the scope of SPF
recalculations. Interface costs are typically set inversely proportional
to bandwidth --- the default cost formula is cost = reference bandwidth
/ interface bandwidth (e.g., 100 Mbps reference / 1 Gbps = cost 1, / 10
Gbps = cost 0.1, often rounded or using 10⁸ or 10⁹ reference). OSPF
converges in seconds after a topology change, making it suitable for
enterprise and service provider networks. \textbf{BGP (Border Gateway
Protocol)}, defined in RFC 4271, is the path-vector EGP that glues the
Internet together by exchanging routing information between autonomous
systems. BGP selects routes based on a multi-step decision process:
highest local preference, shortest AS path length, lowest origin type,
lowest MED, eBGP over iBGP, lowest IGP cost to next hop, and lowest
router ID as tiebreakers. Unlike OSPF's metric-based shortest path, BGP
enables policy-based routing --- network operators apply route maps,
prefix lists, and community attributes to control which routes are
accepted, preferred, and advertised to neighbors. The current Internet
BGP routing table contains over 950,000 IPv4 prefixes and 200,000+ IPv6
prefixes, requiring routers with substantial memory and processing
capability.

\begin{examplebox}

\textbf{Example 15.6.3:} An enterprise network has three OSPF areas. A
router in Area 1 needs to reach a destination in Area 2. The path
options are: (A) Area 1 → ABR1 → Area 0 → ABR2 → Area 2, with link costs
10 + 5 + 5 + 10 = 30; (B) Area 1 → ABR3 → Area 0 → ABR2 → Area 2, with
link costs 5 + 20 + 5 + 10 = 40. Additionally, BGP receives an external
route to the same destination prefix from an eBGP peer with AS path
length 3 and local preference 100 (default). The OSPF route has a
default administrative distance of 110 and BGP external has 20. Which
route is installed in the routing table?

\textbf{Solution:}\\
When multiple routing protocols offer routes to the same destination,
the route with the lowest administrative distance (AD) is preferred.\\
OSPF AD = 110, eBGP AD = 20. Since 20 \textless{} 110, the \textbf{eBGP
route is installed} in the routing table, regardless of the OSPF cost
being lower.\\
Within OSPF alone, path A (cost 30) would be preferred over path B (cost
40) by the SPF algorithm.\\
The administrative distance hierarchy ensures that directly connected
routes (AD 0) are preferred over static routes (AD 1), which are
preferred over eBGP (AD 20), which is preferred over OSPF (AD 110).\\
If the BGP route is withdrawn, the router falls back to the OSPF path A
with cost 30.

\end{examplebox}

\subsection{15.6.4 Network Address Translation
(NAT)}\label{network-address-translation-nat}

Network Address Translation allows hosts with private (RFC 1918) IP
addresses --- 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16 --- to
communicate with the public Internet by translating their source
addresses at the network boundary. NAT was originally a stopgap measure
to conserve the limited IPv4 address space (approximately 4.3 billion
addresses, exhausted by IANA in 2011), but it has become a permanent
fixture of network architecture due to its additional benefits of hiding
internal topology and providing a basic security boundary.
\textbf{Static NAT} maps a single private address to a single public
address in a permanent one-to-one translation, used for servers that
must be reachable from the Internet at a fixed address. \textbf{Dynamic
NAT} allocates public addresses from a pool on a first-come-first-served
basis, with each session receiving a different public address; when the
pool is exhausted, new connections are rejected. \textbf{Port Address
Translation (PAT)}, also called NAT overload, is by far the most common
form --- it maps thousands of internal hosts to a single public IP
address by using unique source port numbers (from the 1024--65535
ephemeral range) to distinguish sessions. A PAT translation table entry
contains (private IP, private port, public IP, public port, protocol)
and is created when an internal host initiates an outbound connection;
reply packets are translated back using the table entry. PAT allows a
typical home or small office to share one public IPv4 address among
hundreds of devices. \textbf{Carrier-Grade NAT (CGNAT, RFC 6598)}
applies a second layer of PAT at the ISP level, sharing a smaller pool
of public addresses among many subscribers using the reserved
100.64.0.0/10 shared address space. CGNAT conserves public addresses but
introduces complications for peer-to-peer applications, inbound
connections, and geolocation. NAT limitations include breaking
end-to-end connectivity (inbound connections require explicit port
forwarding or NAT traversal techniques like STUN/TURN), adding state to
the network (the NAT device must maintain per-session translation
tables), complicating protocols that embed IP addresses in the payload
(FTP, SIP, H.323 --- requiring Application Layer Gateways), and
increasing latency from translation processing.

\begin{examplebox}

\textbf{Example 15.6.4:} A small office has 50 workstations using
private addresses in the 192.168.1.0/24 range. The ISP provides a single
public IPv4 address (203.0.113.5). During peak usage, 35 workstations
each have an average of 40 simultaneous TCP/UDP sessions (web browsing,
email, SaaS applications). Calculate (a) the total number of NAT
translation entries, (b) the percentage of the ephemeral port range
consumed, and (c) whether PAT can support this load. If the office grows
to 200 workstations with the same session profile, determine the NAT
table size and whether a single public IP is still sufficient.

\textbf{Solution:}

(a) Total sessions: 35 × 40 = \textbf{1,400 simultaneous NAT entries}.

(b) Ephemeral port range: 65535 − 1024 + 1 = 64,512 available ports per
protocol. For TCP and UDP combined: 2 × 64,512 = 129,024 port mappings.
Utilization: 1,400 / 129,024 = \textbf{1.09\%} --- well within capacity.

(c) PAT can easily handle this load; typical consumer NAT devices
support 8,000--32,000 simultaneous entries, and enterprise firewalls
support 500,000--2,000,000+.\\
With 200 workstations: assuming the same 70\% active ratio and 40
sessions each: 140 × 40 = \textbf{5,600 entries}, consuming 5,600 /
129,024 = 4.3\% of the port space. A single public IP is still
sufficient.\\
PAT becomes strained only at tens of thousands of simultaneous sessions
(common in large enterprises or CGNAT deployments), at which point
multiple public IPs are pooled.

\end{examplebox}

\subsection{15.6.5 CIDR Notation and Route
Aggregation}\label{cidr-notation-and-route-aggregation}

Classless Inter-Domain Routing (CIDR, RFC 4632) is the modern IP
addressing scheme that replaced the wasteful classful system (Class
A/B/C) by allowing subnet masks at any bit boundary, not just /8, /16,
or /24. CIDR notation appends a prefix length to an IP address ---
\textbf{192.168.1.0/24} means the first 24 bits are the network portion
and the remaining 8 bits identify hosts. The prefix length directly
determines the number of addresses in the block: a /n prefix contains
2\textsuperscript{(32−n)} addresses for IPv4. Common CIDR blocks and
their sizes:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Prefix & Addresses & Usable Hosts & Common Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
/32 & 1 & 1 (host route) & Loopback, host-specific route \\
/31 & 2 & 2 (no network/broadcast) & Point-to-point link --- RFC 3021 \\
/30 & 4 & 2 & Point-to-point link (legacy) \\
/27 & 32 & 30 & Small department \\
/24 & 256 & 254 & Standard LAN subnet \\
/22 & 1,024 & 1,022 & Large LAN \\
/16 & 65,536 & 65,534 & Campus aggregate \\
/8 & 16,777,216 & 16,777,214 & Major allocation \\
\end{longtable}
}

To determine the network address from any IP and prefix, a bitwise AND
is performed between the IP address and the subnet mask. The subnet mask
for /n has n leading 1-bits followed by (32 − n) zero-bits: a /24 mask
is 255.255.255.0, a /20 mask is 255.255.240.0, and a /27 mask is
255.255.255.224. The broadcast address is the network address with all
host bits set to 1, and usable host addresses range from (network + 1)
to (broadcast − 1).

\textbf{Route aggregation} (supernetting or summarization) is the
critical CIDR application that keeps the global Internet routing table
manageable. An ISP that owns the contiguous block 198.51.100.0 through
198.51.103.255 (four /24 networks) can advertise a single /22 route
(198.51.100.0/22) to its upstream providers, reducing four routing table
entries to one. Aggregation requires contiguous, power-of-two-aligned
address blocks: the four /24s must start on a /22 boundary (the first
two bits of the third octet must be the same across all four networks).
More generally, 2\textsuperscript{k} contiguous /n networks aggregate
into one /(n − k) route. Without CIDR aggregation, the global BGP
routing table --- currently exceeding 950,000 IPv4 prefixes --- would be
many times larger and would exceed the memory capacity of most routers.

\begin{examplebox}

\textbf{Example 15.6.5:} An organization is assigned four contiguous /24
networks: 10.4.16.0/24, 10.4.17.0/24, 10.4.18.0/24, and 10.4.19.0/24.
(a) Determine the single CIDR summary route that covers all four
networks. (b) A host has the address 10.4.18.137/22 --- calculate the
network address, broadcast address, and usable host range. (c) Can
10.4.16.0/24 and 10.4.18.0/24 (non-contiguous) be summarized into a
single route without including 10.4.17.0/24?

\textbf{Solution:}

(a) The four networks span 10.4.16.0 through 10.4.19.255 = 4 × 256 =
1,024 addresses. The aggregate prefix: 2² networks of /24 would need
/(24 − 2) = /22, since 2² = 4.\\
Verify alignment: 10.4.16.0 in binary (third octet): 00010000. A /22
boundary requires the last 2 bits of the second-to-last octet to be host
bits. 16 = 00010000, so the /22 block starts at 10.4.16.0 (bits 0--1 of
the third octet are variable). \textbf{Summary route: 10.4.16.0/22}.

(b) Network address: AND the IP with the /22 mask (255.255.252.0):
10.4.18.137 AND 255.255.252.0 = \textbf{10.4.16.0} (third octet: 18 AND
252 = 16).\\
Broadcast: set all host bits to 1: \textbf{10.4.19.255} (third octet: 16
OR 3 = 19, fourth octet: 255).\\
Usable range: \textbf{10.4.16.1 -- 10.4.19.254} (1,022 hosts).

(c) No --- 10.4.16.0 and 10.4.18.0 are not contiguous (10.4.17.0 lies
between them). Any CIDR summary that covers both would be 10.4.16.0/22,
which includes 10.4.17.0/24 and 10.4.19.0/24 as well. Route aggregation
requires contiguous address blocks; skipping 10.4.17.0 would require
advertising two separate routes.

\end{examplebox}

\subsection{15.6.6 /31 and /127 Point-to-Point
Subnets}\label{and-127-point-to-point-subnets}

Point-to-point links --- the inter-router WAN connections and eBGP
peering sessions that form the backbone of the Internet --- need only
two addresses: one for each endpoint. Historically, operators used
\textbf{/30} subnets (4 addresses: network address, router A, router B,
broadcast), wasting 50\% of the allocation on reserved addresses that
serve no functional purpose on a two-host link. RFC 3021 (2000)
eliminated this waste by defining /31 subnets: both of the two addresses
in the block are usable as host addresses; there is no designated
network address or broadcast address. On a /31, the even address (host
bit = 0) and the odd address (host bit = 1) are both assigned to router
interfaces, and hosts process packets addressed to either one. For an
ISP with 2,000 point-to-point inter-router links, switching from /30 to
/31 reduces address consumption from 8,000 addresses to 4,000 --- a
savings of an entire /19 block.

\textbf{eBGP peering links} --- sessions between two autonomous systems
(ASes) at Internet Exchange Points (IXPs) or over private interconnects
--- are the most common use case for /31 addressing. Each eBGP peer
requires one IP address on the shared link; the two routers form a BGP
session using those directly connected addresses as the local and remote
neighbor addresses. The absence of network and broadcast addresses in
/31 is irrelevant because point-to-point links have no need for
broadcast traffic. Many large ISPs and content providers mandate /31 on
all inter-AS peering interfaces as a matter of address-conservation
policy.

\textbf{IPv6 /127 subnets} (RFC 6164, 2011) serve the same role for IPv6
that /31 serves for IPv4. Early IPv6 practice used /64 subnets even for
point-to-point links, which wastes 2⁶⁴ − 2 addresses per link. RFC 6164
defines /127 subnets for inter-router links: both the ::0 and ::1
addresses are usable host addresses, exactly mirroring the /31 model.
/127 also closes the ``subnet-router anycast'' vulnerability present on
/126 links (the IPv6 near-equivalent of /30), where the all-zeros
address in a /64 is reserved as a subnet-router anycast address. Major
network equipment vendors (Cisco, Nokia, Juniper) fully support /31 and
/127 on physical and logical interfaces.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Subnet & Protocol & Addresses & Usable & Wastes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
/30 & IPv4 & 4 & 2 & 2 (network + broadcast) \\
/31 & IPv4 & 2 & 2 & 0 --- RFC 3021 \\
/126 & IPv6 & 4 & 2 & 2 (network + anycast) \\
/127 & IPv6 & 2 & 2 & 0 --- RFC 6164 \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.6.6:} A regional ISP operates 480 inter-router
point-to-point WAN links (backbone links between its own routers) and
120 eBGP peering sessions with external ASes, for a total of 600
two-endpoint links. The ISP has a /20 IPv4 allocation (4,096 addresses)
reserved for infrastructure addressing. (a) How many /30 subnets would
be needed and what percentage of the /20 would they consume? (b) How
many /31 subnets are needed and what percentage is consumed? (c) With
/31 addressing, how many additional point-to-point links could the ISP
support from the same /20 block? (d) Show the /31 subnet assignment and
eBGP neighbor configuration for a peering link between the ISP (AS
65001) and a peer (AS 65002) using the subnet 203.0.113.64/31.

\textbf{Solution:}

(a) /30 approach: Each /30 provides 2 usable addresses and consumes 4
total addresses.\\
600 links × 4 addresses = \textbf{2,400 addresses} required.\\
A /20 contains 2⁽³²⁻²⁰⁾ = 4,096 addresses.\\
Utilization: 2,400 / 4,096 = \textbf{58.6\%} consumed, 1,696 addresses
remaining.

(b) /31 approach: Each /31 consumes 2 addresses (both usable).\\
600 links × 2 addresses = \textbf{1,200 addresses} required.\\
Utilization: 1,200 / 4,096 = \textbf{29.3\%} consumed, 2,896 addresses
remaining.

(c) Remaining addresses with /31: 4,096 − 1,200 = 2,896 addresses.\\
Each additional link needs 2 addresses: 2,896 / 2 = \textbf{1,448
additional links} supportable.\\
(With /30, only 1,696 / 4 = 424 additional links would be possible from
the same pool.)

(d) The /31 block 203.0.113.64/31 contains exactly two addresses:

\begin{itemize}
\tightlist
\item
  203.0.113.64 --- assigned to ISP router interface (AS 65001 side)
\item
  203.0.113.65 --- assigned to peer router interface (AS 65002 side)
\end{itemize}

ISP router configuration (Cisco IOS-XR style):

\begin{verbatim}
interface GigabitEthernet0/0/0
 ipv4 address 203.0.113.64 255.255.255.254   ! /31 mask
!
router bgp 65001
 neighbor 203.0.113.65
  remote-as 65002
  address-family ipv4 unicast
\end{verbatim}

Peer router configuration:

\begin{verbatim}
interface GigabitEthernet0/0/0
 ipv4 address 203.0.113.65 255.255.255.254   ! /31 mask
!
router bgp 65002
 neighbor 203.0.113.64
  remote-as 65001
  address-family ipv4 unicast
\end{verbatim}

The /31 mask in dotted-decimal is 255.255.255.254 (31 leading 1-bits).
There is no ``network address'' or ``broadcast address'' --- both
203.0.113.64 and 203.0.113.65 are live interface addresses. The BGP
session comes up between the two /31 addresses exactly as it would on a
/30, with no behavioral difference visible to the routing protocol.

\end{examplebox}

\section{15.7 Transport Protocols}\label{transport-protocols}

Transport protocols operate at Layer 4 of the OSI model, providing
end-to-end data delivery services between application processes. The two
dominant transport protocols --- TCP and UDP --- represent fundamentally
different design trade-offs between reliability and simplicity.

\subsection{15.7.1 TCP (Transmission Control
Protocol)}\label{tcp-transmission-control-protocol}

TCP provides reliable, ordered, and error-checked delivery of a byte
stream between applications, using a three-way handshake (SYN, SYN-ACK,
ACK) to establish connections and sequence numbers to detect and
retransmit lost segments. The sliding window mechanism allows multiple
segments to be in flight simultaneously, with the receiver's advertised
window size (up to 65,535 bytes, or up to 1 GB with the window scaling
option from RFC 7323) controlling the amount of unacknowledged data. TCP
congestion control algorithms (slow start, congestion avoidance, fast
retransmit, fast recovery) dynamically adjust the sending rate to avoid
overwhelming the network. The effective throughput of a TCP connection
is fundamentally limited by the window size and the round-trip time:
Throughput ≤ Window / RTT, known as the bandwidth-delay product (BDP)
constraint.

\begin{examplebox}

\textbf{Example 15.7.1:} A TCP file transfer operates over a link with
100 Mbps capacity and 20 ms round-trip time (RTT). The TCP receive
window is 64 KB (65,535 bytes). Calculate (a) the bandwidth-delay
product of the link, (b) the maximum achievable throughput, (c) the link
utilization, and (d) the window size needed to fully utilize the 100
Mbps link.

\textbf{Solution:}

(a) Bandwidth-delay product:\\
BDP = Bandwidth × RTT = 100 × 10⁶ × 0.020 = 2,000,000 bits =
\textbf{250,000 bytes ≈ 244 KB}

(b) Maximum throughput (window-limited):\\
Throughput = Window / RTT = 65,535 / 0.020 = 3,276,750 bytes/s\\
= 3,276,750 × 8 = 26,214,000 bps = \textbf{26.2 Mbps}

(c) Link utilization:\\
Utilization = 26.2 / 100 = \textbf{26.2\%}

(d) Window needed for full utilization:\\
Window = BDP = \textbf{250,000 bytes ≈ 244 KB}\\
This requires the TCP window scaling option (RFC 7323), since the base
window field is limited to 65,535 bytes.

\end{examplebox}

\subsection{15.7.2 UDP (User Datagram
Protocol)}\label{udp-user-datagram-protocol}

UDP provides a minimal, connectionless transport service with only 8
bytes of header overhead (source port, destination port, length, and
checksum), compared to TCP's 20-byte minimum header. UDP does not
provide reliability, ordering, or flow control --- datagrams may be
lost, duplicated, or arrive out of order, and the application must
handle these conditions if required. This simplicity makes UDP ideal for
real-time applications where retransmission would add unacceptable
latency: VoIP, video streaming, online gaming, DNS queries, SNMP network
management, DHCP, and NTP time synchronization. The lack of congestion
control means UDP can transmit at whatever rate the application
produces, which is both an advantage (predictable timing) and a risk
(potential network congestion).

\begin{examplebox}

\textbf{Example 15.7.2:} A VoIP system uses the G.711 codec (64 kbps,
8,000 samples/s, 8 bits per sample) with 20 ms voice frames (160 bytes
of audio per packet). Each packet is encapsulated with 8 bytes UDP, 20
bytes IPv4, and 18 bytes Ethernet (14-byte header + 4-byte FCS).
Calculate (a) the total bandwidth per voice call including all headers
and (b) the header overhead as a percentage.

\textbf{Solution:}

(a) Total bytes per packet:\\
Payload: 160 bytes (voice)\\
Headers: 8 (UDP) + 20 (IP) + 18 (Ethernet) = 46 bytes\\
Total: 160 + 46 = 206 bytes per packet

Packets per second: 1 / 0.020 = 50 packets/s\\
Total bandwidth = 206 × 8 × 50 = \textbf{82,400 bps = 82.4 kbps}

Including preamble/SFD (8 bytes) and IFG (12 bytes): total on-wire = 226
bytes\\
On-wire bandwidth = 226 × 8 × 50 = \textbf{90,400 bps = 90.4 kbps}

(b) Header overhead:\\
Overhead = (82,400 − 64,000) / 82,400 = 18,400 / 82,400 =
\textbf{22.3\%}

The 64 kbps voice codec requires 82.4 kbps of actual network bandwidth
--- a 28.8\% increase over the payload rate. This is why VoIP system
designers sometimes use larger frame sizes (e.g., 30 ms or 40 ms) to
improve efficiency, at the cost of increased latency.

\end{examplebox}

\subsection{15.7.3 Sockets}\label{sockets}

A socket is a software endpoint that provides an application programming
interface (API) for sending and receiving data over a network, combining
an IP address and a port number into a single addressable entity. The
Berkeley sockets API, originally introduced in BSD Unix in 1983, remains
the foundation of network programming across virtually all operating
systems (Linux, Windows, macOS) and is exposed in languages from C to
Python, Java, and Go. A TCP socket connection is uniquely identified by
a 4-tuple: (source IP, source port, destination IP, destination port),
which allows a single server port (e.g., port 443 for HTTPS) to handle
thousands of simultaneous connections from different clients because
each connection has a unique combination of source IP and source port.
UDP sockets are connectionless --- the application sends and receives
individual datagrams to and from specific address/port pairs without
establishing a persistent connection.

The typical socket lifecycle for TCP follows a client-server pattern:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3636}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3636}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Server
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Client
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \texttt{socket()} --- create socket & \texttt{socket()} --- create
socket \\
2 & \texttt{bind()} --- assign local IP:port & (optional bind) \\
3 & \texttt{listen()} --- mark as passive, set backlog & \\
4 & \texttt{accept()} --- block until client connects &
\texttt{connect()} --- initiate three-way handshake \\
5 & \texttt{send()} / \texttt{recv()} --- exchange data &
\texttt{send()} / \texttt{recv()} --- exchange data \\
6 & \texttt{close()} --- terminate connection & \texttt{close()} ---
terminate connection \\
\end{longtable}
}

Socket options configure behavior such as \texttt{SO\_REUSEADDR} (allow
immediate rebinding after a server restart), \texttt{TCP\_NODELAY}
(disable Nagle's algorithm for low-latency applications),
\texttt{SO\_RCVBUF} / \texttt{SO\_SNDBUF} (set receive and send buffer
sizes to match the bandwidth-delay product), and \texttt{SO\_KEEPALIVE}
(detect dead connections with periodic probes). For embedded systems and
IoT devices, lightweight socket implementations (lwIP, uIP) provide the
same API in resource-constrained environments with as little as 10--20
KB of RAM.

\begin{examplebox}

\textbf{Example 15.7.3:} A server application listens on port 8080 and
accepts connections from clients. The server has IP address 10.0.1.50.
Three clients connect simultaneously: Client A (192.168.1.10, ephemeral
port 49152), Client B (192.168.1.20, ephemeral port 52301), and Client C
(192.168.1.10, ephemeral port 49153 --- same IP as Client A). Determine
(a) the 4-tuple identifying each connection, (b) the total number of
sockets the server process holds, and (c) the maximum theoretical number
of simultaneous TCP connections to this single server port from a single
client IP address.

\textbf{Solution:}

(a) Connection 4-tuples:\\
Connection A: \textbf{(192.168.1.10, 49152, 10.0.1.50, 8080)}\\
Connection B: \textbf{(192.168.1.20, 52301, 10.0.1.50, 8080)}\\
Connection C: \textbf{(192.168.1.10, 49153, 10.0.1.50, 8080)}

Each is unique even though all three share the same destination IP and
port, because the source IP:port differs.

(b) Server sockets:\\
1 listening socket (bound to 10.0.1.50:8080, waiting for new
connections)

\begin{itemize}
\tightlist
\item
  3 connected sockets (one per accepted client connection) = \textbf{4
  sockets total}
\end{itemize}

(c) Maximum simultaneous connections from one client IP:\\
The ephemeral port range is 16-bit (0--65535), but typically the OS uses
ports 49152--65535 (IANA dynamic range) = 16,384 ports. Each unique
source port creates a distinct 4-tuple, so the maximum from a single
client IP to a single server port is \textbf{16,384 connections} (or up
to 65,535 if the full port range is used).

\end{examplebox}

\subsection{15.7.4 WSGI (Web Server Gateway
Interface)}\label{wsgi-web-server-gateway-interface}

The Web Server Gateway Interface (WSGI), defined in PEP 3333, is a
standard interface between web servers and Python web applications that
decouples the application framework from the HTTP server, allowing any
WSGI-compliant application to run on any WSGI-compliant server. Before
WSGI, each Python web framework (Zope, Twisted, CherryPy) required its
own server integration, making deployment inflexible and
framework-locked. A WSGI application is a callable (function or class
with a \texttt{\_\_call\_\_} method) that accepts two arguments ---
\texttt{environ} (a dictionary containing the HTTP request data,
headers, server variables, and CGI-like metadata) and
\texttt{start\_response} (a callback function the application calls to
set the HTTP status code and response headers) --- and returns an
iterable of byte strings as the response body. WSGI servers (Gunicorn,
uWSGI, Waitress, mod\_wsgi) handle the low-level socket operations, HTTP
parsing, process/thread management, and connection pooling, then invoke
the WSGI application callable for each request. WSGI middleware is a
component that wraps a WSGI application to add cross-cutting
functionality such as URL routing, authentication, session management,
gzip compression, or logging --- the middleware itself is a WSGI
application that calls the inner application, forming a composable
pipeline.

The WSGI architecture in a typical deployment:

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2917}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4583}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Layer
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Role
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Client & Browser / API client & Sends HTTP request \\
Reverse proxy & Nginx / Apache & TLS termination, static files, load
balancing \\
WSGI server & Gunicorn / uWSGI & Process management, socket handling,
HTTP parsing \\
WSGI middleware & (optional) & Authentication, compression, routing \\
WSGI application & Flask / Django & Business logic, generates HTTP
response \\
\end{longtable}
}

ASGI (Asynchronous Server Gateway Interface) extends the WSGI model for
asynchronous Python applications, supporting WebSockets, HTTP/2, and
long-lived connections that WSGI's synchronous request-response model
cannot handle. ASGI servers (Uvicorn, Daphne, Hypercorn) serve
frameworks like FastAPI, Starlette, and Django Channels.

\begin{examplebox}

\textbf{Example 15.7.4:} A Gunicorn WSGI server is configured with 4
worker processes, each handling requests synchronously (one request at a
time per worker). The average request processing time is 50 ms.
Determine (a) the maximum requests per second (RPS) the server can
sustain, (b) the number of workers needed to handle 500 RPS, and (c) the
recommended worker count using Gunicorn's formula of (2 × CPU cores) + 1
for a server with 8 CPU cores.

\textbf{Solution:}

(a) Maximum RPS with 4 workers:\\
Each worker handles 1 / 0.050 = 20 requests/s\\
Total RPS = 4 × 20 = \textbf{80 requests/s}

(b) Workers for 500 RPS:\\
Workers = 500 / 20 = \textbf{25 workers}

(c) Gunicorn recommended formula:\\
Workers = (2 × 8) + 1 = \textbf{17 workers}\\
At 50 ms per request: 17 × 20 = 340 RPS. To reach 500 RPS with 17
workers, the average response time would need to decrease to 1 /
(500/17) = \textbf{34 ms}, or async workers (gevent/eventlet) could be
used to handle I/O-bound waiting concurrently within each worker.

\end{examplebox}

\subsection{15.7.5 QUIC Protocol}\label{quic-protocol}

QUIC (originally ``Quick UDP Internet Connections'') is a
transport-layer protocol built on top of UDP that provides reliable,
multiplexed, encrypted connections with significantly reduced handshake
latency compared to TCP+TLS. Standardized as RFC 9000 (2021) and serving
as the transport for HTTP/3 (RFC 9114), QUIC now carries over 30\% of
all web traffic globally. Traditional HTTPS requires a TCP three-way
handshake (1 RTT) followed by a TLS 1.3 handshake (1 RTT), totaling 2
RTTs before the first byte of application data can be sent. QUIC
integrates the cryptographic handshake into the transport handshake,
achieving a 1-RTT connection setup for new connections and 0-RTT for
resumed connections (where the client sends application data in the very
first packet using a pre-shared key from a previous session). QUIC
eliminates TCP's head-of-line blocking problem by implementing
independent, multiplexed streams within a single connection --- if a
packet carrying data for stream A is lost, only stream A stalls while
streams B and C continue receiving data, unlike TCP where a single lost
segment blocks all data behind it in the byte stream. Each QUIC
connection is identified by a Connection ID (not by the 4-tuple of IP
addresses and ports), enabling seamless connection migration when a
client changes networks (e.g., switching from Wi-Fi to cellular) without
requiring a new handshake. QUIC mandates TLS 1.3 encryption for all
connections --- there is no unencrypted mode --- and encrypts both the
payload and most of the transport header fields, making the protocol
more resistant to middlebox interference and network ossification than
TCP. Flow control operates at both the stream level (limiting bytes per
stream) and the connection level (limiting total bytes across all
streams), and congestion control uses algorithms similar to TCP (Cubic,
BBR) but implemented entirely in user space, allowing rapid iteration
without kernel changes.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
TCP + TLS 1.3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
QUIC
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Handshake latency (new) & 2 RTT (1 TCP + 1 TLS) & 1 RTT \\
Handshake latency (resumed) & 1 RTT (TCP Fast Open + 0-RTT TLS) & 0
RTT \\
Head-of-line blocking & Yes (single byte stream) & No (independent
streams) \\
Connection migration & No (tied to 4-tuple) & Yes (Connection ID) \\
Encryption & Optional (TLS layer) & Mandatory (TLS 1.3 built-in) \\
Implementation & Kernel (TCP) + user space (TLS) & User space (entire
stack) \\
Middlebox traversal & Subject to NAT/firewall TCP manipulation &
UDP-based, fewer middlebox issues \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.7.5:} A web browser loads a page that requires 50
resources (HTML, CSS, JS, images) from the same server over a network
path with 40 ms RTT and 0.5\% packet loss rate. Compare the connection
setup time and the impact of packet loss for (a) HTTP/2 over TCP+TLS 1.3
and (b) HTTP/3 over QUIC.

\textbf{Solution:}

(a) HTTP/2 over TCP + TLS 1.3:\\
Connection setup = 1 RTT (TCP SYN/SYN-ACK) + 1 RTT (TLS 1.3) = 2 × 40 =
\textbf{80 ms}\\
All 50 resources are multiplexed over a single TCP connection. With
0.5\% loss probability per packet, the probability that at least one
packet is lost over 50 resources (assuming \textasciitilde10 packets per
resource = 500 packets): P(≥1 loss) = 1 − (1 − 0.005)⁵⁰⁰ = 1 − 0.995⁵⁰⁰
= 1 − 0.0816 = \textbf{91.8\%}. When any packet is lost, TCP's
head-of-line blocking stalls \textbf{all 50 streams} until the
retransmission completes (1 additional RTT = 40 ms).

(b) HTTP/3 over QUIC:\\
Connection setup = 1 RTT = \textbf{40 ms} (50\% faster)\\
For resumed connections: 0 RTT = \textbf{0 ms} (data sent immediately)\\
With the same 91.8\% probability of at least one lost packet, QUIC's
independent stream multiplexing means only the \textbf{affected
stream(s) stall} --- the other 49 resources continue loading unimpeded.
Expected streams affected per loss event ≈ 1 out of 50, so \textbf{98\%
of resources are unaffected} by any single packet loss, compared to 0\%
for HTTP/2 over TCP.

\end{examplebox}

\section{15.8 Wireless Networking
(Wi-Fi)}\label{wireless-networking-wi-fi}

Wireless local-area networks (WLANs) based on the IEEE 802.11 family of
standards provide untethered network connectivity using radio-frequency
signals in unlicensed spectrum bands. Wi-Fi technology has evolved
through multiple generations, each increasing data rates, spectral
efficiency, and multi-user capabilities while operating in the 2.4 GHz,
5 GHz, and 6 GHz bands.

\subsection{15.8.1 Wi-Fi Standards and
Comparison}\label{wi-fi-standards-and-comparison}

The IEEE 802.11 standards have progressed through several major
generations, each identified by both an amendment letter and a Wi-Fi
Alliance generation number. Wi-Fi 4 (802.11n, 2009) introduced MIMO (up
to 4 spatial streams) and 40 MHz channels in the 2.4 GHz and 5 GHz
bands, reaching maximum PHY rates of 600 Mbps. Wi-Fi 5 (802.11ac, 2013)
expanded to 80 MHz and 160 MHz channels in 5 GHz only, added MU-MIMO for
downlink, and supports up to 8 spatial streams with 256-QAM modulation
for a maximum PHY rate of 6,933 Mbps. Wi-Fi 6 (802.11ax, 2020)
introduced OFDMA (Orthogonal Frequency Division Multiple Access) for
efficient multi-user scheduling, 1024-QAM, and operates in both 2.4 GHz
and 5 GHz bands with maximum PHY rates up to 9,608 Mbps. Wi-Fi 7
(802.11be, 2024) added 320 MHz channels in the 6 GHz band, 4096-QAM, and
multi-link operation (MLO) for aggregate rates exceeding 46 Gbps.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1064}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1170}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0745}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2021}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1277}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2234}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1489}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Standard
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Generation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Bands
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Max Channel Width
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Modulation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Max Spatial Streams
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Max PHY Rate
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
802.11n & Wi-Fi 4 & 2.4 / 5 GHz & 40 MHz & 64-QAM & 4 & 600 Mbps \\
802.11ac & Wi-Fi 5 & 5 GHz & 160 MHz & 256-QAM & 8 & 6,933 Mbps \\
802.11ax & Wi-Fi 6/6E & 2.4 / 5 / 6 GHz & 160 MHz & 1024-QAM & 8 & 9,608
Mbps \\
802.11be & Wi-Fi 7 & 2.4 / 5 / 6 GHz & 320 MHz & 4096-QAM & 16 & 46,120
Mbps \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.8.1:} Compare the spectral efficiency of Wi-Fi 5
(802.11ac) and Wi-Fi 6 (802.11ax) for a single spatial stream on an 80
MHz channel. Wi-Fi 5 uses 256-QAM with 5/6 coding rate and 234 data
subcarriers with a 3.2 μs symbol duration (plus 0.8 μs guard interval).
Wi-Fi 6 uses 1024-QAM with 5/6 coding rate and 980 data subcarriers with
a 12.8 μs symbol duration (plus 0.8 μs guard interval). Calculate the
maximum PHY data rate for each.

\textbf{Solution:}\\
\textbf{Wi-Fi 5 (802.11ac):}\\
Bits per subcarrier = log₂(256) × (5/6) = 8 × 0.8333 = 6.667 coded
bits\\
Symbol rate = 1 / (3.2 + 0.8) μs = 1 / 4.0 μs = 250,000 symbols/s\\
Data rate = 234 × 6.667 × 250,000 = \textbf{390.0 Mbps}\\
Spectral efficiency = 390 / 80 = 4.88 bps/Hz

\textbf{Wi-Fi 6 (802.11ax):}\\
Bits per subcarrier = log₂(1024) × (5/6) = 10 × 0.8333 = 8.333 coded
bits\\
Symbol rate = 1 / (12.8 + 0.8) μs = 1 / 13.6 μs = 73,529 symbols/s\\
Data rate = 980 × 8.333 × 73,529 = \textbf{600.5 Mbps}\\
Spectral efficiency = 600.5 / 80 = 7.51 bps/Hz

Wi-Fi 6 achieves \textbf{54.0\% higher throughput} and \textbf{54.0\%
better spectral efficiency} than Wi-Fi 5 on the same 80 MHz channel,
primarily through denser subcarrier spacing (78.125 kHz vs.~312.5 kHz)
and higher-order modulation.

\end{examplebox}

\subsection{15.8.2 RF Propagation and Link
Budget}\label{rf-propagation-and-link-budget}

Wireless signal strength decreases with distance due to free-space path
loss (FSPL), which increases with both distance and frequency according
to FSPL (dB) = 20 log₁₀(d) + 20 log₁₀(f) + 32.44, where d is distance in
km and f is frequency in MHz. In indoor environments, additional losses
from walls, floors, furniture, and multipath fading further reduce the
signal, typically adding 3--15 dB per wall depending on material
(drywall ≈ 3 dB, concrete ≈ 10--15 dB). The received signal power must
exceed the receiver sensitivity (typically −65 dBm for high-rate
operation or −85 dBm for basic connectivity) to maintain a reliable
link. A wireless link budget sums the transmitter power, antenna gains,
and all path losses to predict the received signal strength and
determine the maximum range or required access point density.

\begin{examplebox}

\textbf{Example 15.8.2:} A Wi-Fi 6 access point transmits at 20 dBm (100
mW) on a 5 GHz channel (5,500 MHz) with an antenna gain of 4 dBi. The
client device has an antenna gain of 2 dBi and a receiver sensitivity of
−65 dBm for 802.11ax MCS11 (1024-QAM, 5/6). Calculate (a) the free-space
path loss at 30 m, (b) the received signal strength (free-space, no
obstructions), and (c) the maximum free-space range at which the link
can operate at MCS11.

\textbf{Solution:}

(a) Free-space path loss at 30 m:\\
FSPL = 20 log₁₀(0.030) + 20 log₁₀(5500) + 32.44\\
= 20 × (−1.523) + 20 × 3.740 + 32.44\\
= −30.46 + 74.81 + 32.44 = \textbf{76.8 dB}

(b) Received signal strength at 30 m:\\
P\textsubscript{rx} = P\textsubscript{tx} + G\textsubscript{tx} +
G\textsubscript{rx} − FSPL\\
= 20 + 4 + 2 − 76.8 = \textbf{−50.8 dBm}

This is well above the −65 dBm sensitivity --- the link has 14.2 dB of
margin at 30 m in free space.

(c) Maximum range for MCS11:\\
Maximum allowable path loss = P\textsubscript{tx} + G\textsubscript{tx}
+ G\textsubscript{rx} − P\textsubscript{rx,min}\\
= 20 + 4 + 2 − (−65) = 91 dB\\
91 = 20 log₁₀(d) + 20 log₁₀(5500) + 32.44\\
20 log₁₀(d) = 91 − 74.81 − 32.44 = −16.25\\
log₁₀(d) = −0.8125\\
d = 10⁻⁰·⁸¹²⁵ = 0.1539 km = \textbf{153.9 m} (free space)

In practice, indoor walls and multipath reduce this to approximately
15--30 m for reliable MCS11 operation.

\end{examplebox}

\subsection{15.8.3 Wireless Security}\label{wireless-security}

Wireless networks are inherently more vulnerable than wired networks
because the radio signal propagates beyond the physical boundaries of
the facility, allowing any device within range to intercept frames or
attempt to associate with the access point. Wireless security has
evolved through several generations, each addressing vulnerabilities of
its predecessor. \textbf{WEP (Wired Equivalent Privacy)} used a 40-bit
or 104-bit static key with RC4 encryption but was fatally flawed --- the
24-bit initialization vector (IV) repeated after only 2²⁴ ≈ 16.7 million
frames, enabling key recovery attacks in minutes. \textbf{WPA (Wi-Fi
Protected Access)} introduced TKIP (Temporal Key Integrity Protocol) as
an interim fix, using per-packet keys and a message integrity check, but
TKIP itself was later found vulnerable to certain attacks. \textbf{WPA2}
(IEEE 802.11i, 2004) replaced TKIP with AES-CCMP (Counter Mode with
CBC-MAC Protocol), providing robust 128-bit encryption that remains
unbroken when used with strong passphrases. WPA2-Personal uses a
Pre-Shared Key (PSK) derived from a passphrase via PBKDF2 with 4,096
iterations, while WPA2-Enterprise uses IEEE 802.1X authentication with a
RADIUS server and EAP (Extensible Authentication Protocol) methods such
as EAP-TLS (certificate-based, strongest), PEAP (server certificate +
inner MSCHAPv2), and EAP-TTLS. \textbf{WPA3} (2018) addresses remaining
WPA2 weaknesses: WPA3-Personal replaces the PSK four-way handshake with
SAE (Simultaneous Authentication of Equals), a zero-knowledge proof
protocol based on the Dragonfly key exchange that provides resistance to
offline dictionary attacks even with weak passphrases, and forward
secrecy (compromising the passphrase does not decrypt previously
captured traffic). WPA3-Enterprise mandates 192-bit equivalent
cryptographic strength using CNSA (Commercial National Security
Algorithm) suite with AES-256-GCM and SHA-384, and requires Protected
Management Frames (PMF/802.11w) to prevent deauthentication and
disassociation attacks. \textbf{802.1X} port-based network access
control authenticates devices before granting network access, using a
three-party model: the supplicant (client device), the authenticator
(access point or switch), and the authentication server (RADIUS). The
authenticator blocks all traffic from the supplicant except 802.1X
(EAPoL) frames until the RADIUS server validates the supplicant's
credentials and returns an Access-Accept with optional VLAN assignment
and session parameters.

\begin{examplebox}

\textbf{Example 15.8.3:} A corporate Wi-Fi network uses WPA3-Enterprise
with EAP-TLS (mutual certificate authentication) and a RADIUS server.
The AES-256-GCM cipher provides 256-bit key strength. Calculate (a) the
number of possible key combinations for a brute-force attack, (b) the
time required to exhaust all keys at a rate of 10¹² guesses per second,
and (c) compare the security of a WPA2-Personal network with an
8-character lowercase passphrase to WPA3-SAE with the same passphrase.

\textbf{Solution:}

(a) AES-256 key combinations: 2²⁵⁶ = 1.158 × 10⁷⁷ possible keys.

(b) Time to exhaust: 1.158 × 10⁷⁷ / 10¹² = 1.158 × 10⁶⁵ seconds = 3.67 ×
10⁵⁷ years --- far beyond the age of the universe (1.38 × 10¹⁰ years),
confirming that AES-256 is computationally infeasible to brute-force.

(c) WPA2-PSK with 8 lowercase letters: 26⁸ = 2.089 × 10¹¹ possible
passphrases. An offline dictionary attack after capturing the four-way
handshake can test 10⁶ passphrases/second (GPU-accelerated), exhausting
the keyspace in 2.089 × 10¹¹ / 10⁶ = 208,900 seconds ≈ \textbf{2.4
days}.\\
WPA3-SAE with the same passphrase: SAE requires an online interaction
with the AP for each guess attempt, limiting the rate to approximately
10 attempts/second before the AP implements rate limiting. Exhaustion
time: 2.089 × 10¹¹ / 10 = 2.089 × 10¹⁰ seconds ≈ \textbf{662 years}.\\
WPA3-SAE transforms a weak 2.4-day attack into a 662-year attack by
eliminating offline attacks, though a strong passphrase (12+ characters,
mixed case/numbers/symbols) is still recommended.

\end{examplebox}

\section{15.9 Network Infrastructure}\label{network-infrastructure}

Network infrastructure encompasses the physical equipment that
interconnects end devices, provides traffic forwarding, and organizes
cabling within facilities. Switches, routers, and structured cabling
systems (including patch panels) form the backbone of any wired network,
from a single wiring closet to a multi-building campus or data center.

\subsection{15.9.1 Switches}\label{switches}

A network switch is a Layer 2 device that forwards Ethernet frames
between ports based on destination MAC addresses, maintaining a MAC
address table (also called a CAM table) that maps each learned MAC
address to the port where it was observed. When a frame arrives, the
switch looks up the destination MAC in its table and forwards the frame
only to the corresponding port (unicast), or floods the frame to all
ports (except the source port) if the destination is unknown or is a
broadcast/multicast address. Switches operate in store-and-forward mode
(buffering the entire frame and checking the CRC before forwarding) or
cut-through mode (forwarding as soon as the destination address is read,
reducing latency to as low as 1--2 μs). Managed switches add features
such as VLANs (IEEE 802.1Q), Spanning Tree Protocol (STP/RSTP for loop
prevention), Link Aggregation (LAG/802.3ad for bonding multiple physical
links), Quality of Service (QoS for traffic prioritization), and port
security. Layer 3 switches combine switching and routing in a single
device, performing inter-VLAN routing at wire speed using hardware-based
forwarding (ASICs or FPGAs) rather than software-based routing.

\begin{examplebox}

\textbf{Example 15.9.1:} A 48-port Gigabit Ethernet switch has a
switching fabric rated at 176 Gbps and a forwarding rate of 130.95 Mpps.
Determine (a) whether the fabric is non-blocking (can handle full-duplex
wire-speed traffic on all ports simultaneously) and (b) the minimum
packet size at which the switch can sustain wire-speed forwarding.

\textbf{Solution:}

(a) Non-blocking check:\\
Full-duplex bandwidth per port = 2 × 1 Gbps = 2 Gbps (1 Gbps in each
direction)\\
Total required fabric bandwidth = 48 × 2 = 96 Gbps\\
Switching fabric = 176 Gbps \textgreater{} 96 Gbps →
\textbf{Non-blocking} ✓

(b) Minimum wire-speed packet size:\\
Wire-speed packet rate (all 48 ports, full duplex) at minimum 64-byte
frames:\\
Ethernet overhead per frame on wire = 64 bytes + 8 (preamble/SFD) + 12
(IFG) = 84 bytes\\
Max frames/s per port = 1 × 10⁹ / (84 × 8) = 1,488,095 fps\\
Total for 48 ports (full duplex, but forwarding counts each frame once):
48 × 1,488,095 = 71,428,571 fps

Switch forwarding rate = 130.95 × 10⁶ fps\\
Wire-speed rate for 48 ports at 64-byte frames = 71.4 Mpps\\
Since 130.95 Mpps \textgreater{} 71.4 Mpps, the switch can forward at
wire speed even at the \textbf{minimum 64-byte frame size} ✓

\end{examplebox}

\subsection{15.9.2 Routers}\label{routers}

A router is a Layer 3 device that forwards packets between different IP
networks (subnets) based on destination IP addresses, using a routing
table populated by static configuration or dynamic routing protocols.
Unlike switches that operate on MAC addresses within a single broadcast
domain, routers make forwarding decisions using the longest-prefix match
against the destination IP address, decrement the TTL, recompute the IP
header checksum, and rewrite the Layer 2 (MAC) headers for the next hop.
Dynamic routing protocols exchange reachability information between
routers: Interior Gateway Protocols (IGPs) such as OSPF (Open Shortest
Path First) and IS-IS operate within an autonomous system using
link-state algorithms, while BGP (Border Gateway Protocol) exchanges
routes between autonomous systems across the Internet. Modern routers
forward packets at line rate using hardware-based forwarding engines
(ASICs with Ternary Content-Addressable Memory, or TCAM), achieving
forwarding rates of hundreds of millions to billions of packets per
second in core and data center routers.

\begin{examplebox}

\textbf{Example 15.9.2:} A router has four 100 Gbps interfaces and a
forwarding capacity of 600 Mpps. Determine (a) the total bidirectional
bandwidth, (b) whether the router can handle wire-speed forwarding of
64-byte packets on all interfaces simultaneously, and (c) the maximum
number of full routing table entries (IPv4 prefix + next-hop, each
consuming 8 bytes) that can fit in 4 MB of TCAM.

\textbf{Solution:}

(a) Total bidirectional bandwidth:\\
4 interfaces × 100 Gbps × 2 (full duplex) = \textbf{800 Gbps}

(b) Wire-speed check at 64-byte packets:\\
Frames per second per 100G interface = 100 × 10⁹ / (84 × 8) =
148,809,524 fps\\
Total for 4 interfaces = 4 × 148,809,524 = 595,238,095 fps ≈ 595.2
Mpps\\
Router capacity = 600 Mpps \textgreater{} 595.2 Mpps →
\textbf{Wire-speed at 64 bytes} ✓

(c) TCAM routing table capacity:\\
Entries = 4 × 10⁶ bytes / 8 bytes per entry = \textbf{500,000 entries}\\
The current Internet IPv4 routing table contains approximately 950,000
prefixes, so 4 MB of TCAM at 8 bytes/entry would be insufficient for a
full Internet routing table. In practice, TCAM entries are wider (40--80
bytes for prefix + mask + action fields), further reducing capacity.

\end{examplebox}

\subsection{15.9.3 Patch Panels and Structured
Cabling}\label{patch-panels-and-structured-cabling}

A patch panel is a passive (unpowered) device mounted in a rack or
cabinet that provides a termination point for horizontal cabling runs
from wall outlets, consolidation points, or other equipment. Each port
on the patch panel has an insulation displacement contact (IDC)
connection on the back (where permanent horizontal cables are punched
down) and an RJ-45 jack on the front (where patch cords connect to
switch ports). Structured cabling standards (TIA-568, ISO/IEC 11801)
define a hierarchical topology: the Equipment Room (ER) or Main
Distribution Frame (MDF) houses core switches and serves as the building
entry point, Telecommunications Rooms (TR) or Intermediate Distribution
Frames (IDF) house access-layer switches on each floor, and horizontal
cabling connects the TR to individual work-area outlets within the 90 m
permanent link limit (100 m total channel length including patch cords).
Patch panels are labeled using a consistent nomenclature: rack
identifier, panel position (U-height), and port number (e.g.,
``MDF-R1-U24-P12'' identifies rack 1 in the MDF, patch panel at
U-position 24, port 12). Fiber patch panels (fiber distribution frames,
or FDFs) serve the same purpose for fiber optic cabling, using LC, SC,
or MPO adapters and typically organizing fibers by strand count and
cable routing.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MDF & Main Distribution Frame --- primary equipment room, building entry
point \\
IDF & Intermediate Distribution Frame --- floor-level telecom room \\
TR & Telecommunications Room (TIA term for IDF) \\
Horizontal cable & Permanent cable from TR patch panel to work-area
outlet (max 90 m) \\
Backbone cable & Cable connecting MDF to IDFs (between floors or
buildings) \\
Patch cord & Short cable from patch panel to switch or from outlet to
device \\
Permanent link & Tested cable path from patch panel IDC to outlet IDC
(max 90 m) \\
Channel & Full end-to-end path including patch cords (max 100 m for
copper) \\
U-height & Rack unit (1U = 1.75 inches / 44.45 mm); a 24-port panel is
typically 1U \\
110 block & Punch-down termination block for voice/data (alternative to
RJ-45 panel) \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.9.3:} A three-story office building has an MDF in the
basement and one IDF per floor. Each floor has 80 data drops. The
horizontal cable runs average 45 m from the IDF to wall outlets. Patch
cords are 3 m at the IDF (panel to switch) and 2 m at the work area
(outlet to device). Determine (a) the total channel length per drop, (b)
whether it meets the TIA-568 100 m channel limit, (c) the number of
24-port patch panels needed per IDF, and (d) the minimum number of
48-port switches per IDF (assuming one switch port per data drop).

\textbf{Solution:}

(a) Total channel length:\\
Channel = IDF patch cord + horizontal cable + work area patch cord\\
= 3 + 45 + 2 = \textbf{50 m}

(b) TIA-568 compliance:\\
50 m \textless{} 100 m → \textbf{Compliant} ✓ (with 50 m of margin)\\
Permanent link = 45 m \textless{} 90 m → \textbf{Compliant} ✓

(c) Patch panels per IDF:\\
Panels = 80 ports / 24 ports per panel = 3.33 → \textbf{4 patch panels}
(96 ports, 16 spare)

(d) Switches per IDF:\\
Switches = 80 ports / 48 ports per switch = 1.67 → \textbf{2 switches}
(96 ports, 16 spare)

\end{examplebox}

\subsection{15.9.4 VLANs and Network
Segmentation}\label{vlans-and-network-segmentation}

Virtual LANs (VLANs) partition a single physical switch (or a group of
interconnected switches) into multiple isolated broadcast domains, each
behaving as an independent Layer 2 network. IEEE 802.1Q defines the
standard by inserting a 4-byte tag into the Ethernet frame between the
source MAC address and the EtherType field; the tag contains a 3-bit
Priority Code Point (PCP) for QoS, a 1-bit Drop Eligible Indicator
(DEI), and a 12-bit VLAN ID (VID) supporting 4,094 usable VLANs (VIDs
1--4094; VID 0 is priority-tagged only, VID 4095 is reserved). Switch
ports are configured as \textbf{access ports} (carrying a single
untagged VLAN, connected to end devices) or \textbf{trunk ports}
(carrying multiple tagged VLANs, connected to other switches, routers,
or servers). The native VLAN on a trunk is carried untagged for backward
compatibility with non-VLAN-aware devices. VLANs provide security
through broadcast domain isolation (a host in VLAN 10 cannot directly
communicate with VLAN 20 without a Layer 3 router or inter-VLAN
routing), reduce unnecessary broadcast traffic, and enable flexible
network design independent of physical topology --- a user can be in the
same VLAN regardless of which floor or building they connect from.
\textbf{Inter-VLAN routing} requires a Layer 3 device (router or Layer 3
switch) with an interface or Switched Virtual Interface (SVI) in each
VLAN. A common design pattern is the ``router-on-a-stick'' topology,
where a single router interface carries all VLANs as 802.1Q
sub-interfaces on a trunk link to the switch, though dedicated Layer 3
switch SVIs are preferred for performance. \textbf{Private VLANs} (RFC
5765) further subdivide a VLAN into promiscuous, isolated, and community
ports for micro-segmentation within a single IP subnet --- commonly used
in data centers and multi-tenant environments where hosts in the same
subnet should not communicate directly.

\begin{examplebox}

\textbf{Example 15.9.4:} A campus network has three buildings connected
by fiber trunk links to a core switch. The network requires four VLANs:
VLAN 10 (Engineering, 200 hosts), VLAN 20 (Finance, 50 hosts), VLAN 30
(Guest Wi-Fi, 100 hosts), and VLAN 99 (Management, 20 hosts). Each
building has a 48-port access switch trunked to the core. Calculate (a)
the number of 802.1Q tag bits used for VLANs vs.~total tag bits, (b) the
subnet sizes needed for each VLAN using the smallest appropriate CIDR
prefix from the 10.0.0.0/8 space, and (c) the total bandwidth overhead
of 802.1Q tagging on a trunk carrying 100,000 frames per second.

\textbf{Solution:}

(a) VLAN ID field: 12 bits out of the 32-bit (4-byte) 802.1Q tag. VLAN
bits / total tag bits = 12/32 = \textbf{37.5\%}. The remaining bits are:
TPID (16 bits, fixed at 0x8100 identifying the frame as tagged), PCP (3
bits), DEI (1 bit).

(b) Subnet sizing:\\
VLAN 10 (200 hosts): needs 2ⁿ − 2 ≥ 200 → n = 8 (254 hosts) →
\textbf{10.0.10.0/24}.\\
VLAN 20 (50 hosts): needs 2ⁿ − 2 ≥ 50 → n = 6 (62 hosts) →
\textbf{10.0.20.0/26}.\\
VLAN 30 (100 hosts): needs 2ⁿ − 2 ≥ 100 → n = 7 (126 hosts) →
\textbf{10.0.30.0/25}.\\
VLAN 99 (20 hosts): needs 2ⁿ − 2 ≥ 20 → n = 5 (30 hosts) →
\textbf{10.0.99.0/27}.

(c) 802.1Q overhead: each tagged frame adds 4 bytes. At 100,000 fps:
overhead = 100,000 × 4 × 8 = 3,200,000 bps = \textbf{3.2 Mbps}. On a 10
Gbps trunk, this is 3.2/10,000 = 0.032\% --- negligible.

\end{examplebox}

\subsection{15.9.5 Network Security
Fundamentals}\label{network-security-fundamentals}

Network security protects data in transit, prevents unauthorized access,
and detects malicious activity through a layered defense-in-depth
strategy combining hardware, software, and policy controls.
\textbf{Firewalls} are the primary perimeter defense, inspecting traffic
and enforcing rules that permit or deny packets based on
source/destination IP address, port number, protocol, and connection
state. \textbf{Stateless packet filters} (ACL-based) evaluate each
packet independently against ordered rules --- fast but unable to
distinguish between legitimate reply traffic and unsolicited inbound
connections. \textbf{Stateful firewalls} track the state of each TCP/UDP
session in a connection table (SYN, ESTABLISHED, RELATED), automatically
allowing return traffic for established sessions while blocking
unsolicited inbound packets --- the standard for modern network
firewalls. \textbf{Next-generation firewalls (NGFW)} add
application-layer inspection (identifying applications regardless of
port number), intrusion prevention, URL filtering, and TLS decryption.
\textbf{Access Control Lists (ACLs)} are ordered rule sets applied to
router or switch interfaces that filter traffic by matching packet
header fields; rules are processed top-down and the first match
determines the action (permit or deny), with an implicit ``deny all'' at
the end. Standard ACLs filter by source IP only, while extended ACLs
filter by source IP, destination IP, protocol, and port numbers.
\textbf{Virtual Private Networks (VPNs)} create encrypted tunnels over
untrusted networks (the Internet) to provide confidentiality, integrity,
and authentication for remote access and site-to-site connectivity.
IPsec VPNs operate at Layer 3 using Authentication Header (AH) for
integrity or Encapsulating Security Payload (ESP) for encryption +
integrity, with Internet Key Exchange (IKEv2) negotiating the security
associations. SSL/TLS VPNs operate at Layers 4--7 and are accessible
through standard web browsers, simplifying remote-access deployments.
\textbf{Intrusion Detection Systems (IDS)} passively monitor network
traffic for signatures of known attacks and anomalous behavior,
generating alerts for security analysts. \textbf{Intrusion Prevention
Systems (IPS)} operate inline and can automatically block or drop
malicious traffic in real time. Both use signature-based detection
(matching known attack patterns) and anomaly-based detection (flagging
deviations from a baseline traffic profile). The \textbf{802.1X}
standard provides port-based network access control, requiring devices
to authenticate (via RADIUS) before the switch port grants network
access --- preventing unauthorized devices from connecting to the LAN.

\begin{examplebox}

\textbf{Example 15.9.5:} An enterprise firewall has the following
stateful ACL rules applied to the outside (Internet-facing) interface,
processed in order:\\
1. Permit TCP from any to 203.0.113.10 port 443 (HTTPS web server)\\
2. Permit TCP from any to 203.0.113.11 port 25 (SMTP mail server)\\
3. Permit UDP from any to 203.0.113.12 port 53 (DNS server)\\
4. Deny IP from any to 203.0.113.0/24 (block all other inbound)\\
5. Permit IP from 203.0.113.0/24 to any (allow outbound and return
traffic)

\end{examplebox}

Determine the firewall's action for each of these packets: (a) TCP SYN
to 203.0.113.10:443 from 198.51.100.5:49152, (b) TCP SYN to
203.0.113.10:22 (SSH) from 198.51.100.5:49200, (c) UDP packet to
203.0.113.12:53 from 198.51.100.8:5353, (d) TCP ACK to 203.0.113.50:1025
from 93.184.216.34:80 (reply to outbound web request with an existing
session in the state table).

\textbf{Solution:}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Matches rule 1 (TCP, destination 203.0.113.10, port 443) →
  \textbf{Permitted}. A new session entry is created in the state table.
\item
  Destination is 203.0.113.10 but port 22 (SSH) does not match rule 1
  (port 443) or rule 2 (port 25) or rule 3 (UDP port 53). Matches rule 4
  (deny all to 203.0.113.0/24) → \textbf{Denied (dropped)}. SSH access
  from the Internet is blocked.
\item
  Matches rule 3 (UDP, destination 203.0.113.12, port 53) →
  \textbf{Permitted}.
\item
  This is a reply packet to an outbound connection. The stateful
  firewall checks the session table first --- because an established
  session exists for the outbound HTTP request from 203.0.113.50 to
  93.184.216.34:80, the return ACK packet is \textbf{permitted as
  ESTABLISHED return traffic} without needing to match any explicit ACL
  rule. Without stateful inspection, this packet would match rule 4 and
  be denied, breaking all outbound web browsing.
\end{enumerate}

\subsection{15.9.6 Software-Defined Networking
(SDN)}\label{software-defined-networking-sdn}

Software-Defined Networking separates the network's control plane (the
intelligence that decides where traffic should go) from the data plane
(the hardware that actually forwards packets), centralizing routing
decisions in a software-based SDN controller while switches and routers
become simple forwarding devices that execute instructions received from
the controller. In traditional networking, each device runs its own
control-plane protocols (OSPF, BGP, STP) and makes independent
forwarding decisions based on distributed state, making network-wide
policy changes slow and error-prone --- an administrator must configure
each device individually. SDN replaces this distributed model with a
logically centralized controller that has a global view of the network
topology, traffic flows, and device capabilities, enabling programmatic,
automated network management through northbound APIs (REST, gRPC)
exposed to applications and orchestration systems.

The \textbf{OpenFlow} protocol (ONF standard) was the first widely
adopted southbound API connecting the SDN controller to forwarding
devices. An OpenFlow switch maintains one or more flow tables, each
containing flow entries that match packet headers against rules and
specify actions (forward to port, drop, modify header, send to
controller). When a packet arrives that matches no flow entry, the
switch sends it to the controller (a ``packet-in'' message), which
installs a new flow entry to handle subsequent matching packets. Modern
SDN has evolved beyond pure OpenFlow to include overlay-based
architectures (VXLAN, GENEVE) where the underlay network runs
traditional routing and the SDN controller manages virtual network
overlays, as well as intent-based networking where administrators
specify desired outcomes (``isolate IoT devices from corporate
servers'') rather than device-level configurations. Data center SDN
platforms (VMware NSX, Cisco ACI, OpenStack Neutron) manage thousands of
virtual switches across hypervisors, providing microsegmentation,
distributed firewalling, and load balancing entirely in software.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3548}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3226}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3226}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
SDN Layer
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Function
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Examples
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Application layer & Business logic, network apps & Load balancer,
firewall policy, traffic engineering \\
Northbound API & Controller ↔ application interface & REST API, gRPC,
NETCONF/YANG \\
Control plane & Centralized network intelligence & ONOS, OpenDaylight,
VMware NSX, Cisco ACI \\
Southbound API & Controller ↔ switch interface & OpenFlow, OVSDB, P4,
gNMI \\
Data plane & Packet forwarding & Open vSwitch (OVS), bare-metal
switches, SmartNICs \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.9.6:} An SDN controller manages a data center fabric
with 96 top-of-rack (ToR) switches, each with 48 × 25 Gbps server-facing
ports and 6 × 100 Gbps uplinks to spine switches. The controller
installs flow entries that each consume 512 bytes of TCAM. Each ToR
switch has 16 MB of TCAM. Calculate (a) the total server-facing
bandwidth in the fabric, (b) the maximum number of flow entries per ToR
switch, and (c) the total flow state the controller must manage if each
switch averages 60\% TCAM utilization.

\textbf{Solution:}

(a) Total server-facing bandwidth:\\
Per ToR: 48 × 25 = 1,200 Gbps = 1.2 Tbps\\
Total fabric: 96 × 1,200 = 115,200 Gbps = \textbf{115.2 Tbps}

(b) Maximum flow entries per ToR:\\
Entries = 16 × 10⁶ / 512 = \textbf{31,250 flow entries}

(c) Total flow state at 60\% utilization:\\
Entries per switch = 31,250 × 0.60 = 18,750\\
Total across fabric = 96 × 18,750 = \textbf{1,800,000 flow entries}\\
Total TCAM state = 1,800,000 × 512 = 921.6 × 10⁶ bytes ≈ \textbf{922 MB}
of flow state managed by the controller.

\end{examplebox}

\section{15.10 Network Performance}\label{network-performance}

Network performance metrics quantify how effectively a network
transports data between endpoints, bridging the physical and protocol
layers into measurable parameters that engineers use for system design,
capacity planning, and troubleshooting.

\subsection{15.10.1 Latency and Propagation
Delay}\label{latency-and-propagation-delay}

Network latency is the total time for a packet to travel from source to
destination, composed of propagation delay (signal travel time through
the medium), serialization delay (time to place all bits on the wire),
processing delay (router/switch forwarding time), and queuing delay
(time spent waiting in buffers). Propagation delay depends on the
medium: approximately 4.9 μs/km in fiber (speed of light / refractive
index ≈ c/1.468), 4.5--5.0 μs/km in copper (depending on cable type and
velocity factor), and 3.33 μs/km in free space. Serialization delay
equals packet size divided by link rate: a 1,500-byte packet takes 12 μs
on a 1 Gbps link and 1.2 μs on a 10 Gbps link. For long-distance links,
propagation delay dominates; for short, high-speed links, processing and
queuing delays are more significant.

\begin{examplebox}

\textbf{Example 15.10.1:} A 1,500-byte packet traverses a path
consisting of 500 km of single-mode fiber (refractive index n = 1.468)
and passes through 3 routers, each adding 50 μs of processing delay. The
link rate is 10 Gbps. Calculate (a) the propagation delay, (b) the
serialization delay, (c) the total one-way latency, and (d) the
round-trip time (RTT).

\textbf{Solution:}

(a) Propagation delay:\\
v\textsubscript{fiber} = c / n = 3.0 × 10⁸ / 1.468 = 2.044 × 10⁸ m/s\\
t\textsubscript{prop} = distance / velocity = 500,000 / (2.044 × 10⁸) =
\textbf{2,446 μs = 2.446 ms}

(b) Serialization delay:\\
t\textsubscript{serial} = packet size / link rate = (1,500 × 8) / (10 ×
10⁹) = 12,000 / 10¹⁰ = \textbf{1.2 μs}

(c) Total one-way latency:\\
Processing delay = 3 × 50 = 150 μs\\
t\textsubscript{total} = 2,446 + 1.2 + 150 = \textbf{2,597.2 μs ≈ 2.60
ms}

(d) Round-trip time:\\
RTT = 2 × t\textsubscript{total} = 2 × 2.60 = \textbf{5.20 ms}

The propagation delay (2.446 ms) dominates at 94.2\% of the total, with
processing (5.8\%) and serialization (0.05\%) being negligible. This
demonstrates why the speed of light, not link bandwidth, limits latency
on long-distance networks.

\end{examplebox}

\subsection{15.10.2 Throughput and Bandwidth
Utilization}\label{throughput-and-bandwidth-utilization}

Throughput is the actual rate of successful data delivery, which is
always less than the raw line rate due to protocol overhead,
retransmissions, and congestion. The Shannon-Hartley theorem establishes
the theoretical maximum channel capacity: C = B × log₂(1 + SNR), where B
is the bandwidth in Hz and SNR is the linear signal-to-noise ratio. For
practical systems, the spectral efficiency (bps/Hz) depends on the
modulation scheme and coding rate: 10GBASE-T achieves approximately 2.5
bps/Hz across its effective bandwidth, while 100G coherent optics using
DP-16QAM achieve approximately 4 bps/Hz. Network utilization should
typically be kept below 70--80\% of capacity to avoid excessive queuing
delays and packet loss.

\begin{examplebox}

\textbf{Example 15.10.2:} A copper Ethernet link has a usable bandwidth
of 250 MHz and achieves an SNR of 30 dB. Calculate (a) the Shannon
channel capacity and (b) the spectral efficiency of the actual
1000BASE-T (1 Gbps) system operating over this bandwidth.

\textbf{Solution:}

(a) Shannon capacity:\\
SNR (linear) = 10\textsuperscript{(30/10)} = 1,000\\
C = B × log₂(1 + SNR) = 250 × 10⁶ × log₂(1,001) = 250 × 10⁶ × 9.967\\
C = \textbf{2,491.8 Mbps ≈ 2.49 Gbps}

(b) Spectral efficiency of 1000BASE-T:\\
η = Data rate / Bandwidth = 1,000 / 250 = \textbf{4.0 bps/Hz}

Note: 1000BASE-T uses four pairs simultaneously at 250 Mbps each (125
Msymbols/s × PAM-5 encoding), so the per-pair spectral efficiency is 250
/ 62.5 ≈ 4.0 bps/Hz (using 62.5 MHz bandwidth per pair). The Shannon
limit of 2.49 Gbps confirms that the 1 Gbps rate operates well below the
theoretical maximum, providing margin for practical impairments.

\end{examplebox}

\subsection{15.10.3 Bit Error Rate (BER)}\label{bit-error-rate-ber}

Bit Error Rate (BER) is the ratio of erroneously received bits to the
total number of bits transmitted, expressed as a probability (e.g.,
10⁻¹² means on average one bit error per trillion bits). For fiber optic
links, BER depends on received optical power, receiver noise, and
modulation format, with receiver sensitivity defined as the minimum
power to achieve a target BER (typically 10⁻¹² for telecom or 10⁻⁹
pre-FEC for data communications). Forward Error Correction (FEC) adds
redundant bits that allow the receiver to detect and correct errors,
effectively improving the BER by several orders of magnitude at the cost
of small bandwidth overhead (typically 7--25\%). The Q-factor relates
BER to an equivalent signal-to-noise metric: BER = 0.5 × erfc(Q / √2),
with Q = 7.03 corresponding to BER ≈ 10⁻¹².

\begin{examplebox}

\textbf{Example 15.10.3:} A 10 Gbps fiber optic link operates
continuously for 24 hours. (a) At a BER of 10⁻¹², calculate the expected
number of bit errors and the mean time between errors. (b) If FEC with
7\% overhead improves the pre-FEC BER threshold from 10⁻¹² to 10⁻³, how
many pre-FEC errors per second would the FEC decoder need to correct at
the threshold?

\textbf{Solution:}

(a) At BER = 10⁻¹²:\\
Total bits in 24 hours = 10 × 10⁹ × 24 × 3600 = 8.64 × 10¹⁴ bits\\
Expected errors = 8.64 × 10¹⁴ × 10⁻¹² = \textbf{864 errors per day}\\
Mean time between errors = 1 / (10 × 10⁹ × 10⁻¹²) = 1 / 0.01 =
\textbf{100 seconds}

(b) At pre-FEC BER = 10⁻³:\\
Effective line rate with 7\% FEC overhead = 10 × 1.07 = 10.7 Gbps\\
Pre-FEC errors per second = 10.7 × 10⁹ × 10⁻³ = \textbf{10.7 × 10⁶ =
10.7 million errors/s}

The FEC decoder must correct 10.7 million errors per second at the
threshold BER while reducing the post-FEC BER to below 10⁻¹²,
demonstrating the remarkable power of modern error correction codes.

\end{examplebox}

\subsection{15.10.4 Network Timing and
Synchronization}\label{network-timing-and-synchronization}

Precise time synchronization across networked devices is critical for
distributed measurement systems, power grid protection, financial
trading, telecommunications, and industrial control. The Network Time
Protocol (NTP) synchronizes clocks over packet networks to within 1--10
ms of UTC using a hierarchical stratum system, where stratum 0 devices
are reference clocks (GPS receivers, atomic clocks), stratum 1 servers
connect directly to reference clocks, and each subsequent stratum adds
another hop. The Precision Time Protocol (PTP, IEEE 1588) achieves
sub-microsecond synchronization (typically 10--100 ns) by using hardware
timestamping in network interface cards and PTP-aware switches
(transparent clocks or boundary clocks) to measure and compensate for
network path delay asymmetry. Synchronous Ethernet (SyncE, ITU-T
G.8261/G.8262) distributes a frequency reference through the Ethernet
physical layer by locking the transmit clock to a recovered clock from
the upstream link, providing the frequency accuracy required by
telecommunications equipment (±4.6 ppm for free-running, ±0.01 ppm when
locked). PTP and SyncE are often combined --- SyncE provides frequency
synchronization while PTP provides phase/time synchronization ---
enabling applications such as 5G radio access networks that require ±1.5
μs time alignment between base stations.

\begin{examplebox}

\textbf{Example 15.10.4:} A PTP grandmaster clock synchronizes a
boundary clock over a network path with a measured mean path delay of
2.35 μs and a delay asymmetry of 120 ns. The boundary clock's oscillator
has a free-running accuracy of ±10 ppm. Calculate (a) the time error
introduced by the delay asymmetry if not compensated, (b) the clock
drift in microseconds over a 1-hour PTP holdover period (if the
grandmaster becomes unreachable), and (c) the maximum time between PTP
sync messages to maintain ±1 μs accuracy.

\textbf{Solution:}

(a) Delay asymmetry error: PTP assumes symmetric path delays. An
asymmetry of 120 ns causes a time offset of asymmetry / 2 = 120 / 2 =
\textbf{60 ns}. This error is constant and can be corrected if the
asymmetry is known and configured.

(b) Clock drift during holdover: drift rate = ±10 ppm = ±10 μs per
second. Over 1 hour: drift = 10 × 10⁻⁶ × 3,600 = \textbf{0.036 s = 36
ms}. To maintain ±1 μs during holdover: maximum holdover time = 1 μs /
(10 μs/s) = \textbf{0.1 s = 100 ms}.

(c) Maximum sync interval for ±1 μs: the sync message corrects the
accumulated drift. To keep error \textless{} 1 μs with ±10 ppm drift:
T\textsubscript{sync} \textless{} 1 μs / (10 μs/s) = \textbf{0.1 s}.\\
PTP sync messages should be sent at intervals ≤ 100 ms (typically
configured at 1 per second or 8 per second for high-accuracy
applications). With a better oscillator (±0.1 ppm OCXO), the interval
extends to T\textsubscript{sync} \textless{} 1 / 0.1 = 10 s.

\end{examplebox}

\subsection{15.10.5 Quality of Service
(QoS)}\label{quality-of-service-qos}

Quality of Service is a set of mechanisms that allow network devices to
differentiate traffic classes and provide preferential treatment to
delay-sensitive, loss-sensitive, or business-critical applications over
best-effort traffic. Without QoS, all packets compete equally for
bandwidth and buffer space, and during congestion, latency-sensitive
traffic (VoIP, video conferencing, industrial control) suffers the same
packet loss and delay as bulk file transfers or software updates. QoS
operates through three fundamental mechanisms: \textbf{classification
and marking} (identifying traffic and tagging it with a priority),
\textbf{queuing and scheduling} (placing packets into different queues
and determining the order of transmission), and \textbf{policing and
shaping} (enforcing rate limits and smoothing traffic bursts).

\textbf{Classification and Marking:} Traffic is classified at the
network edge by inspecting packet headers (source/destination IP, port
number, DSCP field, 802.1p/PCP bits) or using deep packet inspection
(DPI) for application-layer identification. The Differentiated Services
Code Point (DSCP) is a 6-bit field in the IP header (part of the 8-bit
Type of Service / Traffic Class byte) that encodes 64 possible per-hop
behaviors (PHBs). The most common PHBs are: Expedited Forwarding (EF,
DSCP 46) for low-latency traffic like VoIP, Assured Forwarding (AF
classes AF11--AF43, 12 codepoints) for guaranteed-delivery business
traffic with drop probability tiers, and Default/Best Effort (DSCP 0)
for standard traffic. At Layer 2, the IEEE 802.1p Priority Code Point
(PCP) provides 3 bits (8 priority levels, 0--7) within the 802.1Q VLAN
tag for Ethernet frame prioritization.

\textbf{Queuing and Scheduling:} Switches and routers place classified
packets into multiple output queues (typically 4--8 per port) and use
scheduling algorithms to determine which queue is serviced next.
\textbf{Strict Priority (SP)} always services the highest-priority queue
first --- guarantees minimum latency for voice/video but can starve
lower-priority queues if the high-priority queue is never empty.
\textbf{Weighted Round Robin (WRR)} services queues in rotation but
gives more slots to higher-weight queues, preventing starvation while
still providing differentiation. \textbf{Weighted Fair Queuing (WFQ)}
allocates bandwidth proportionally to each flow based on assigned
weights. \textbf{Low Latency Queuing (LLQ)} combines a strict priority
queue for real-time traffic with a weighted fair queuing system for
remaining traffic classes --- the standard for modern enterprise QoS.
\textbf{Weighted Random Early Detection (WRED)} proactively drops
packets from lower-priority flows before the queue is full, using the
DSCP or IP precedence value to set different drop probability curves per
traffic class, avoiding TCP global synchronization (where all flows
reduce their window simultaneously after tail-drop).

\textbf{Policing and Shaping:} A \textbf{policer} enforces a rate limit
by measuring traffic against a token bucket and immediately dropping or
re-marking packets that exceed the committed information rate (CIR). A
\textbf{shaper} also enforces a rate limit but buffers excess traffic
and transmits it later, smoothing bursts at the cost of added latency.
Policing is typically applied at ingress (network edge), while shaping
is applied at egress.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1447}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1447}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0658}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2763}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1974}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1711}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
QoS Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
DSCP Value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
PHB
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Latency Target
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Loss Target
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Voice & 46 (EF) & Expedited Forwarding & VoIP & \textless{} 150 ms &
\textless{} 1\% \\
Video & 34 (AF41) & Assured Forwarding 41 & Video conferencing &
\textless{} 200 ms & \textless{} 2\% \\
Signaling & 24 (CS3) & Class Selector 3 & Call setup, routing protocols
& \textless{} 500 ms & \textless{} 1\% \\
Business & 18 (AF21) & Assured Forwarding 21 & ERP, database,
transactional & \textless{} 500 ms & \textless{} 3\% \\
Best Effort & 0 (BE) & Default & Web, email, file transfer & No
guarantee & No guarantee \\
Scavenger & 8 (CS1) & Class Selector 1 & Backup, software updates & No
guarantee & Higher drop \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 15.10.5:} An enterprise WAN link has a capacity of 100
Mbps and carries three traffic classes: VoIP (EF, requiring \textless{}
150 ms latency and \textless{} 1\% loss), business applications (AF21),
and best-effort traffic (BE). The network carries 50 concurrent G.711
VoIP calls, each requiring 87.2 kbps (64 kbps codec + IP/UDP/RTP
overhead with 20 ms packetization). The QoS policy allocates the LLQ
strict priority queue at 10\% of link capacity for EF, 50\% WFQ for
AF21, and 40\% WFQ for BE. Calculate (a) the bandwidth consumed by VoIP,
(b) whether the LLQ allocation is sufficient, (c) the serialization
delay for a 1,500-byte best-effort packet, and (d) the maximum queuing
delay for a voice packet if 3 best-effort packets are ahead of it in the
interface output queue (without QoS) vs.~with LLQ.

\textbf{Solution:}

(a) VoIP bandwidth:\\
50 calls × 87.2 kbps = 4,360 kbps = \textbf{4.36 Mbps}

(b) LLQ allocation check:\\
LLQ bandwidth = 100 × 0.10 = 10 Mbps\\
VoIP requirement = 4.36 Mbps\\
Utilization = 4.36 / 10 = 43.6\% → \textbf{Sufficient} ✓ (with 56.4\%
headroom for burst absorption)

(c) Serialization delay for 1,500-byte packet:\\
t\textsubscript{serial} = (1,500 × 8) / (100 × 10⁶) = 12,000 / 10⁸ =
\textbf{0.12 ms}

(d) Queuing delay comparison:\\
\textbf{Without QoS:} Voice packet waits behind 3 × 1,500-byte
packets:\\
Delay = 3 × 0.12 = \textbf{0.36 ms} (plus risk of loss if queue is full)

\textbf{With LLQ:} Voice packet is in the strict priority queue and is
serviced immediately after the current packet finishes transmitting.
Maximum wait = serialization of one MTU-sized packet already on the wire
= \textbf{0.12 ms}. LLQ reduces the worst-case queuing delay by 3× in
this scenario. For a heavily loaded link with 50+ packets queued, the
improvement is far greater --- without QoS, voice delay could reach 6+
ms per hop, while LLQ keeps it under 0.12 ms per hop.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-15-10-5}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch15_qos_llq.png}

\caption{Figure 15.10.5: LLQ bandwidth allocation (left) and voice packet queuing delay comparison (right) for a 100 Mbps WAN link. EF receives 10 Mbps (43.6\% utilized by 50 VoIP calls), AF21 receives 50 Mbps, and BE receives 40 Mbps. LLQ reduces worst-case voice queuing delay from 360 μs to 120 μs — a 3× improvement.}

\end{figure}

\chapter{Chapter 16}\label{chapter-16}

\chapter{Antenna Design and
Principles}\label{antenna-design-and-principles}

Antenna engineering bridges the gap between guided electromagnetic waves
in transmission lines and radiated waves in free space. An antenna is
fundamentally a transducer that converts electrical energy into
electromagnetic radiation (transmitting) or captures radiation and
converts it back to electrical signals (receiving). The design of an
antenna involves balancing competing requirements including gain,
bandwidth, impedance matching, polarization, physical size, and cost.
This chapter covers the key antenna types --- from simple wire antennas
to sophisticated phased arrays --- along with the fundamental
parameters, design equations, and practical considerations that every
engineer needs for antenna selection and design.

\section{16.1 Antenna Fundamentals}\label{antenna-fundamentals-1}

The performance of any antenna is characterized by a set of fundamental
parameters that describe how it radiates or receives electromagnetic
energy. Understanding these parameters is essential for selecting the
right antenna for a given application and for designing communication,
radar, and sensing systems.

\subsection{16.1.1 Radiation Mechanism and Radiation
Patterns}\label{radiation-mechanism-and-radiation-patterns}

An antenna radiates electromagnetic waves when time-varying current
flows through a conductor, causing accelerating charges that produce
changing electric and magnetic fields that propagate outward. The region
immediately surrounding the antenna (within a distance of approximately
2D²/λ, where D is the largest antenna dimension) is the near-field
region, where the fields are complex and do not exhibit plane-wave
behavior. Beyond this distance is the far-field (Fraunhofer) region,
where the radiated fields decay as 1/r and the radiation pattern is
fully formed and independent of distance.

The radiation pattern is a graphical representation of the antenna's
radiated power as a function of direction, typically plotted in polar or
rectangular coordinates. Key pattern features include the main lobe (the
direction of maximum radiation), sidelobes (minor lobes adjacent to the
main lobe), back lobe (radiation in the direction opposite the main
lobe), and nulls (directions of zero or minimum radiation). The
half-power beamwidth (HPBW) is the angular width of the main lobe
between the −3 dB points, and the first null beamwidth (FNBW) extends
between the first nulls on either side of the main lobe. The sidelobe
level (SLL) is typically expressed in dB below the main lobe peak, with
values of −13 dB for uniform illumination and −20 to −40 dB for tapered
or optimized distributions.

\begin{examplebox}

\textbf{Example 16.1.1:} A directional antenna has a measured HPBW of
30° in the E-plane and 35° in the H-plane. The first sidelobe is 15 dB
below the main lobe peak. Estimate (a) the directivity using the
approximate formula D ≈ 32,400 / (θ\textsubscript{E} ×
θ\textsubscript{H}), and (b) the sidelobe power relative to the main
lobe.

\textbf{Solution:}

(a) Directivity: D ≈ 32,400 / (30 × 35) = 32,400 / 1,050 = 30.86
(linear)\\
D (dB) = 10 log₁₀(30.86) = \textbf{14.9 dBi}

(b) Sidelobe level = −15 dB means the sidelobe power is 10⁻¹·⁵ = 0.0316
times the main lobe power, or \textbf{3.16\%} of the peak power density.
This is a moderate sidelobe level, typical of practical horn or
reflector antennas without special sidelobe suppression techniques.

\end{examplebox}

\subsection{16.1.2 Antenna Parameters}\label{antenna-parameters}

Directivity (D) measures how strongly an antenna focuses radiation in
its peak direction compared to an isotropic radiator: D =
4πU\textsubscript{max} / P\textsubscript{rad}, where
U\textsubscript{max} is the maximum radiation intensity and
P\textsubscript{rad} is the total radiated power. Antenna gain (G)
accounts for efficiency losses: G = ηD, where the radiation efficiency η
(typically 0.5--0.99) includes ohmic losses in the conductors and
dielectric, but not mismatch losses. The effective isotropic radiated
power (EIRP) is EIRP = P\textsubscript{t}G\textsubscript{t},
representing the equivalent power an isotropic antenna would need to
produce the same peak radiation intensity.

The effective aperture A\textsubscript{e} = Gλ²/(4π) relates gain to the
equivalent area the antenna presents to an incoming wave. Radiation
resistance R\textsubscript{rad} is the equivalent resistance that would
dissipate the same power as the antenna radiates, and the input
impedance Z\textsubscript{in} = R\textsubscript{rad} +
R\textsubscript{loss} + jX\textsubscript{ant} includes both radiation
resistance, loss resistance, and reactance. Antenna bandwidth is
typically defined as the frequency range over which VSWR remains below
2:1 (return loss \textgreater{} 9.5 dB), and it ranges from \textless{}
1\% for resonant patches to \textgreater{} 100\% for wideband designs
like log-periodic arrays. Polarization describes the orientation of the
electric field vector: linear (vertical or horizontal), circular (RHCP
or LHCP), or elliptical, with a polarization loss factor cos²(Δφ) for
linear misalignment or 3 dB loss for circular-to-linear reception.

\begin{examplebox}

\textbf{Example 16.1.2:} A parabolic dish antenna with a diameter of 2 m
and aperture efficiency of 0.60 operates at 6 GHz. Determine (a) the
gain, (b) the effective aperture, (c) the EIRP if fed with 10 W, and (d)
the HPBW.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 6 × 10⁹ = 0.05 m.\\
G = η(πD/λ)² = 0.60 × (π × 2 / 0.05)² = 0.60 × (125.66)² = 0.60 × 15,791
= 9,475 (linear)\\
G (dBi) = 10 log₁₀(9,475) = \textbf{39.8 dBi}

(b) Effective aperture: A\textsubscript{e} = Gλ²/(4π) = 9,475 × 0.05² /
(4π) = 9,475 × 0.0025 / 12.566 = \textbf{1.88 m²}\\
This equals η × A\textsubscript{physical} = 0.60 × π(1)² = 1.88 m²,
confirming the result.

(c) EIRP = P\textsubscript{t} × G = 10 × 9,475 = 94,750 W = 10 + 39.8 =
\textbf{49.8 dBW} (or 79.8 dBm) EIRP

(d) HPBW ≈ 70λ/D = 70 × 0.05 / 2 = \textbf{1.75°}

\end{examplebox}

\subsection{16.1.3 Friis Transmission Equation and Link
Budgets}\label{friis-transmission-equation-and-link-budgets}

The Friis transmission equation relates the received power to the
transmitted power for a free-space radio link:
P\textsubscript{r}/P\textsubscript{t} =
G\textsubscript{t}G\textsubscript{r}(λ/(4πd))², where G\textsubscript{t}
and G\textsubscript{r} are the transmit and receive antenna gains, λ is
the wavelength, and d is the distance. The term (λ/(4πd))² is the
free-space path loss (FSPL) expressed as a power ratio, and in decibels
the equation becomes: P\textsubscript{r}(dBm) = P\textsubscript{t}(dBm)
+ G\textsubscript{t}(dBi) + G\textsubscript{r}(dBi) − FSPL(dB), where
FSPL = 20 log₁₀(4πd/λ). This equation assumes line-of-sight propagation
with no reflections, diffraction, or atmospheric absorption, and it
forms the foundation of all link budget analyses (see also Ch. 2, §2.8).

For radar systems, the radar range equation extends Friis to account for
the round-trip path and target scattering: P\textsubscript{r} =
P\textsubscript{t}G\textsubscript{t}²λ²σ / ((4π)³R⁴), where σ is the
radar cross section (RCS) of the target in m² and R is the range. The R⁴
dependence (compared to R² for one-way links) means radar performance
degrades rapidly with distance, making high-gain antennas and powerful
transmitters essential for long-range detection.

\begin{examplebox}

\textbf{Example 16.1.3:} A Ku-band satellite downlink operates at 12 GHz
with a satellite EIRP of 52 dBW. The ground station uses a 0.6 m dish
with 60\% aperture efficiency. The orbital altitude is 35,786 km
(geostationary). Determine (a) the receive antenna gain, (b) the
free-space path loss, and (c) the received power.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 12 × 10⁹ = 0.025 m.\\
G\textsubscript{r} = 0.60 × (π × 0.6 / 0.025)² = 0.60 × (75.40)² = 0.60
× 5,685 = 3,411\\
G\textsubscript{r}(dBi) = 10 log₁₀(3,411) = \textbf{35.3 dBi}

(b) FSPL = 20 log₁₀(4π × 35,786,000 / 0.025) = 20 log₁₀(1.80 × 10¹⁰) =
20 × 10.255 = \textbf{205.1 dB}

(c) P\textsubscript{r} = EIRP + G\textsubscript{r} − FSPL = 52 + 35.3 −
205.1 = \textbf{−117.8 dBW} (or −87.8 dBm)

This received power level is typical for satellite TV reception, where
the receiver noise floor is around −130 dBW (kTB with B ≈ 30 MHz),
providing adequate carrier-to-noise ratio for demodulation.

\end{examplebox}

\section{16.2 Wire Antennas}\label{wire-antennas}

Wire antennas are the simplest and most widely used antenna type,
consisting of straight or curved conductors carrying RF current. Their
low cost, ease of fabrication, and well-understood behavior make them
the default choice for frequencies from HF through UHF.

\subsection{16.2.1 Dipole Antennas}\label{dipole-antennas-1}

The dipole is the most fundamental antenna type, consisting of two
collinear conductors fed at the center. A short dipole (total length L
\textless\textless{} λ) has a radiation resistance of
R\textsubscript{rad} = 20π²(L/λ)², which is very small (e.g., 2 Ω for L
= λ/10), making it inefficient due to the dominance of ohmic losses. The
half-wave dipole (L = λ/2) is the practical standard: its input
impedance is 73 + j42.5 Ω at exact resonance, and shortening the element
to approximately 0.95 × λ/2 eliminates the reactive component, yielding
a purely resistive 73 Ω input. The half-wave dipole has a gain of 2.15
dBi (1.64 linear) and a donut-shaped omnidirectional radiation pattern
in the plane perpendicular to the antenna axis.

The folded dipole consists of two parallel half-wave elements connected
at the ends, with the feed applied to only one element. The folded
geometry transforms the input impedance to approximately 4 × 73 = 292 Ω
(a convenient match to 300 Ω twin-lead transmission line) while
providing significantly wider bandwidth than a simple dipole ---
typically 10--20\% compared to 5--8\% for a standard dipole. This
impedance transformation occurs because the folded dipole supports both
antenna-mode and transmission-line-mode currents, and the four-fold
impedance increase applies to any two-conductor folded element with
equal conductor diameters.

\begin{examplebox}

\textbf{Example 16.2.1:} Design a half-wave dipole for the 2 m amateur
radio band at 146 MHz. Determine (a) the theoretical half-wavelength,
(b) the practical element length (using the 0.95 shortening factor), (c)
the radiation resistance, and (d) the gain in dBd (relative to a
dipole).

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 146 × 10⁶ = 2.055 m. Half-wavelength =
\textbf{1.027 m} (total tip-to-tip).

(b) Practical length = 0.95 × 1.027 = \textbf{0.976 m} (97.6 cm). Each
arm is 48.8 cm from the feed point.

(c) Radiation resistance: R\textsubscript{rad} = \textbf{73 Ω} (the
standard value for a resonant half-wave dipole). With the shortened
length eliminating the +j42.5 Ω reactance, Z\textsubscript{in} ≈ 73 + j0
Ω.

(d) The gain of a half-wave dipole is 2.15 dBi by definition, so
relative to itself: \textbf{0 dBd}. The dBd unit (decibels relative to a
dipole) is commonly used in amateur radio and commercial antenna
specifications, where 0 dBd = 2.15 dBi.

\end{examplebox}

\subsection{16.2.2 Monopole and Ground Plane
Antennas}\label{monopole-and-ground-plane-antennas}

A monopole antenna is one half of a dipole mounted perpendicular to a
conducting ground plane, which acts as a mirror to create the equivalent
of a full dipole through image theory. The quarter-wave monopole (L =
λ/4) has an input impedance of approximately 36.5 + j21 Ω --- exactly
half the dipole impedance because the ground plane eliminates the lower
hemisphere of radiation, concentrating all power into the upper
half-space. This doubles the directivity compared to a dipole, giving
the monopole a gain of 5.15 dBi (3 dBd), while the radiation pattern is
omnidirectional in azimuth with a maximum at the horizon.

The ground plane size and quality significantly affect monopole
performance. An infinite perfect ground plane produces the ideal 36.5 Ω
impedance, but practical ground planes (vehicle roofs, metal enclosures,
or radial wire systems) are finite and imperfect. For VHF/UHF
applications, a ground plane extending at least λ/4 in radius is
adequate. AM broadcast towers use extensive buried radial wire ground
systems (typically 120 radials, each λ/4 long) to minimize ground
losses. Whip antennas on vehicles are practical monopoles using the
vehicle body as the ground plane, while ground-plane antennas with
drooping radials are popular for base stations because angling the
radials downward raises the input impedance closer to 50 Ω.

\begin{examplebox}

\textbf{Example 16.2.2:} Design a quarter-wave monopole antenna for the
900 MHz GSM cellular band. Determine (a) the element length, (b) the
input impedance, (c) the gain, and (d) the minimum ground plane radius.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 900 × 10⁶ = 0.333 m. Quarter-wave length =
0.333/4 = \textbf{83.3 mm} (approximately 8.3 cm).

(b) Input impedance: Z\textsubscript{in} ≈ \textbf{36.5 Ω} (resistive at
resonance). This is a reasonable match to 50 Ω coax (VSWR ≈ 1.37:1,
return loss = 16 dB), which is acceptable for most applications without
additional matching.

(c) Gain: \textbf{5.15 dBi} (or 3.0 dBd) --- 3 dB more than a half-wave
dipole due to the ground plane concentrating radiation into the upper
hemisphere.

(d) Minimum ground plane radius ≈ λ/4 = \textbf{83.3 mm}. This is
compact enough for integration into cellular base station equipment or
handheld device enclosures.

\end{examplebox}

\subsection{16.2.3 Loop Antennas}\label{loop-antennas}

Loop antennas consist of one or more turns of wire forming a closed
loop, and their behavior depends dramatically on the loop circumference
relative to the wavelength. A small loop (circumference C
\textless\textless{} λ, typically C \textless{} λ/10) behaves as a
magnetic dipole, with a radiation pattern identical in shape to an
electric dipole but rotated 90° --- maximum radiation is in the plane of
the loop, with nulls along the loop axis. The radiation resistance of a
small loop is R\textsubscript{rad} = 320π⁴(A/λ²)², where A is the loop
area, which is extremely small for electrically small loops (\textless{}
1 Ω), making efficiency a major challenge without ferrite loading.

A full-wave loop (circumference C = λ) is a resonant antenna with gain
of approximately 3.4 dBi (1.3 dB above a dipole), input impedance around
100 Ω, and a radiation pattern with maximum broadside to the plane of
the loop. Full-wave loops are popular in HF amateur radio for their
quiet receive characteristics and modest gain. At low frequencies and
for near-field applications, small loops serve as the basis for RFID tag
antennas and NFC inductive coupling, where the mutual inductance between
reader and tag coils enables wireless power transfer and data
communication at ranges of a few centimeters to a meter.

\begin{examplebox}

\textbf{Example 16.2.3:} An NFC reader antenna is a circular loop with
radius 25 mm and 3 turns, operating at 13.56 MHz. Determine (a) the loop
circumference in wavelengths, (b) the radiation resistance for a single
turn, (c) the total radiation resistance for 3 turns, and (d) whether
this qualifies as a small loop.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 13.56 × 10⁶ = 22.12 m. Circumference = 2π ×
0.025 = 0.157 m.\\
C/λ = 0.157 / 22.12 = \textbf{0.0071} --- far less than 0.1.

(b) Loop area A = π × 0.025² = 1.963 × 10⁻³ m².\\
R\textsubscript{rad} = 320π⁴(A/λ²)² = 320 × 97.41 × (1.963 × 10⁻³ /
489.3)² = 31,171 × (4.01 × 10⁻⁶)² = 31,171 × 1.61 × 10⁻¹¹ = \textbf{5.01
× 10⁻⁷ Ω}

(c) For N turns, R\textsubscript{rad} scales as N²:
R\textsubscript{total} = 9 × 5.01 × 10⁻⁷ = \textbf{4.51 × 10⁻⁶ Ω} (4.51
μΩ).

(d) \textbf{Yes}, with C/λ = 0.0071, this is an extremely small loop.
The negligible radiation resistance confirms that NFC operates by
near-field inductive coupling (mutual inductance), not radiation --- the
antenna functions as a coupling coil, not a radiator.

\end{examplebox}

\subsection{16.2.4 Yagi-Uda Antennas}\label{yagi-uda-antennas}

The Yagi-Uda antenna is a directional wire array consisting of a single
driven element (typically a half-wave dipole or folded dipole), one or
more parasitic reflector elements behind the driven element, and one or
more parasitic director elements in front. The parasitic elements are
not electrically connected to the feedline --- they receive energy by
mutual coupling from the driven element and reradiate it with specific
phase relationships that create constructive interference in the forward
direction and destructive interference rearward. The reflector element
is slightly longer than λ/2 (typically 5\% longer, making it inductively
loaded), which causes its reradiated field to add constructively in the
forward direction. Director elements are slightly shorter than λ/2
(typically 5--10\% shorter, capacitively loaded), and each successive
director adds approximately 1 dB of gain while narrowing the beamwidth.
The spacing between elements is typically 0.15λ to 0.25λ for the
reflector-to-driven distance and 0.2λ to 0.35λ between directors. A
typical 3-element Yagi (one reflector, one driven, one director)
achieves approximately 7.5 dBi gain with a front-to-back ratio of 15--20
dB, while a 10-element design reaches approximately 13 dBi with a
front-to-back ratio exceeding 25 dB. The input impedance of a Yagi drops
as more elements are added due to mutual coupling --- a simple
dipole-driven Yagi may have an impedance of 20--30 Ω, while a folded
dipole driven element provides the 4:1 impedance transformation that
brings the input closer to 50 Ω and increases bandwidth. Yagi-Uda
antennas are the standard design for terrestrial television reception
(VHF/UHF), amateur radio directional communication, point-to-point
wireless links, and radio astronomy at meter wavelengths.

\begin{examplebox}

\textbf{Example 16.2.4:} Design a 5-element Yagi-Uda antenna for the 2 m
amateur radio band at 144 MHz. Determine (a) the wavelength and
approximate total boom length, (b) the element lengths (reflector,
driven, and 3 directors), (c) the expected gain, and (d) the input
impedance improvement using a folded dipole driven element.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 144 × 10⁶ = 2.083 m.\\
Element spacings: reflector-to-driven = 0.20λ = 0.417 m; director
spacing = 0.25λ = 0.521 m.\\
Total boom length = 0.417 + 3 × 0.521 = 0.417 + 1.563 = \textbf{1.98 m}
(approximately 1λ).

(b) Element lengths: reflector = 1.05 × λ/2 = 0.525λ = 1.094 m
(\textbf{109.4 cm}); driven element = 0.95 × λ/2 = 0.475λ = 0.989 m
(\textbf{98.9 cm}); director 1 = 0.45λ = 0.937 m (\textbf{93.8 cm});
director 2 = 0.44λ = 0.917 m (\textbf{91.7 cm}); director 3 = 0.43λ =
0.896 m (\textbf{89.6 cm}).\\
Directors are progressively shorter to maintain proper phasing.

(c) A 5-element Yagi typically achieves approximately \textbf{10.5 dBi}
(8.3 dBd) gain with a front-to-back ratio of 20--22 dB and a 3 dB
beamwidth of approximately 52° in the E-plane and 62° in the H-plane.

(d) With a simple dipole driven element, Z\textsubscript{in} ≈ 24 Ω (due
to mutual coupling lowering the impedance).\\
Using a folded dipole: Z\textsubscript{in} ≈ 4 × 24 = \textbf{96 Ω},
which can be matched to a 50 Ω feedline with a simple beta or gamma
match.\\
The folded dipole also increases the usable bandwidth from approximately
2\% to 5\% of the center frequency.

\end{examplebox}

\section{16.3 Aperture Antennas}\label{aperture-antennas}

Aperture antennas radiate through an open area (aperture) over which the
electromagnetic field distribution determines the radiation pattern.
These antennas are used at microwave and millimeter-wave frequencies
where their physical dimensions are manageable relative to the
wavelength.

\subsection{16.3.1 Horn Antennas}\label{horn-antennas}

A horn antenna is formed by flaring the end of a rectangular or circular
waveguide, creating a gradual transition from the guided wave in the
waveguide to free-space radiation. The three basic types are the E-plane
sectoral horn (flared in the E-field direction), H-plane sectoral horn
(flared in the H-field direction), and pyramidal horn (flared in both
planes). The pyramidal horn is most common, with gain approximately G =
(4πA\textsubscript{e})/λ² = (4π × η\textsubscript{ap} × a × b)/λ², where
a and b are the aperture dimensions and η\textsubscript{ap} ≈ 0.51 for
an optimum-gain pyramidal horn.

Horn antennas are valued for their predictable performance, moderate
gain (10--25 dBi), wide bandwidth (typically \textgreater{} 2:1), and
low VSWR. They serve as primary feeds for parabolic reflectors, as
standard gain reference antennas for calibrating other antennas, and as
direct radiators in EMC testing chambers. The optimum horn maximizes
gain for a given horn length by balancing the aperture size against the
phase error across the aperture --- too large an aperture for a given
length introduces destructive phase variations that reduce the effective
gain.

\begin{examplebox}

\textbf{Example 16.3.1:} Design a pyramidal horn antenna operating at 10
GHz (X-band) with a target gain of 20 dBi. Determine (a) the required
effective aperture area, (b) the physical aperture dimensions assuming a
square aperture with η\textsubscript{ap} = 0.51, and (c) the HPBW.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 10 × 10⁹ = 0.03 m. G = 10\textsuperscript{20/10}
= 100 (linear).\\
A\textsubscript{e} = Gλ²/(4π) = 100 × 0.03² / (4π) = 100 × 9 × 10⁻⁴ /
12.566 = \textbf{7.16 × 10⁻³ m²} (71.6 cm²)

(b) Physical aperture: A\textsubscript{phys} = A\textsubscript{e} /
η\textsubscript{ap} = 7.16 × 10⁻³ / 0.51 = 1.40 × 10⁻² m².\\
For a square aperture: a = b = √(1.40 × 10⁻²) = \textbf{0.119 m} (11.9
cm × 11.9 cm).

(c) HPBW ≈ 70λ/a = 70 × 0.03 / 0.119 = \textbf{17.6°} in both planes
(symmetric for a square aperture).

\end{examplebox}

\subsection{16.3.2 Parabolic Reflector
Antennas}\label{parabolic-reflector-antennas}

The parabolic reflector antenna uses a paraboloidal dish to focus
incoming plane waves to a single focal point (or equivalently, to
collimate radiation from a feed antenna at the focus into a narrow
beam). The dish gain is G = η(πD/λ)², where D is the dish diameter and
the aperture efficiency η typically ranges from 0.55 to 0.70, accounting
for spillover, illumination taper, surface roughness, and blockage
losses. The half-power beamwidth is approximately θ ≈ 70λ/D degrees,
showing that larger dishes produce narrower beams. The f/D ratio (focal
length to diameter) is a key design parameter: typical values of
0.3--0.5 provide a good compromise between feed illumination angle,
spillover loss, and mechanical depth.

Three common feed configurations are used. Prime focus places the feed
at the focal point, which is simple but causes aperture blockage. The
Cassegrain design adds a convex hyperbolic subreflector near the focal
point that redirects the feed radiation back to the main reflector,
reducing feed line losses and allowing the feed electronics to be
mounted behind the dish. The offset reflector uses a section of a larger
paraboloid so the feed and support structure do not block the aperture,
eliminating blockage losses and improving sidelobe performance --- this
is the standard configuration for consumer satellite TV dishes and
modern earth station antennas.

\begin{examplebox}

\textbf{Example 16.3.2:} A Ku-band satellite TV dish has a diameter of
1.2 m and operates at 12 GHz. Assuming an aperture efficiency of 0.60,
determine (a) the gain, (b) the HPBW, (c) the effective aperture, and
(d) the pointing accuracy required to keep the gain within 1 dB of peak.

\textbf{Solution:}

(a) λ = 0.025 m. G = 0.60 × (π × 1.2 / 0.025)² = 0.60 × (150.80)² = 0.60
× 22,740 = 13,644\\
G(dBi) = 10 log₁₀(13,644) = \textbf{41.3 dBi}

(b) HPBW ≈ 70 × 0.025 / 1.2 = \textbf{1.46°}

(c) A\textsubscript{e} = η × π(D/2)² = 0.60 × π × 0.36 = \textbf{0.679
m²}

(d) The 1 dB beamwidth is approximately 0.58 × HPBW ≈ 0.85°. To keep the
gain within 1 dB of peak, the pointing accuracy must be within
\textbf{±0.42°} --- this explains why satellite dishes require precise
alignment and why wind loading is a design concern.

\end{examplebox}

\subsection{16.3.3 Slot and Cavity-Backed
Antennas}\label{slot-and-cavity-backed-antennas}

A slot antenna is formed by cutting a narrow rectangular opening in a
conducting ground plane and exciting it with a transmission line or
waveguide. By Babinet's principle, the radiation pattern of a slot is
complementary to that of a dipole of the same dimensions --- a half-wave
slot (length ≈ λ/2) radiates broadside with a pattern identical to a
dipole but with the E-plane and H-plane interchanged. The input
impedance of a slot is related to its complementary dipole by
Z\textsubscript{slot} × Z\textsubscript{dipole} = η²/4, where η = 377 Ω
is the impedance of free space. For a half-wave slot, this gives
Z\textsubscript{slot} = 377²/(4 × 73) ≈ 486 Ω, which is a high impedance
that requires a matching network for 50 Ω systems. Slots are fed by
microstrip lines, coplanar waveguide (CPW), or waveguide coupling
apertures. A major advantage is that slot antennas can be flush-mounted
in metallic surfaces --- aircraft fuselages, vehicle bodies, and array
ground planes --- without protruding elements that create aerodynamic
drag or mechanical vulnerability.

A cavity-backed slot places a metallic cavity behind the slot,
eliminating backward radiation and increasing gain by 2--3 dB compared
to an unbacked slot. The cavity dimensions are chosen so that no cavity
modes resonate near the operating frequency, ensuring clean impedance
behavior. Typical cavity depth is λ/4, creating a short-circuit back
wall that reflects energy forward. Cavity-backed slots achieve gains of
5--7 dBi with bandwidths of 5--15\% depending on cavity volume and slot
shape. Variations include the cavity-backed annular slot (for circular
polarization), the T-shaped slot (for dual-band operation), and
dielectric-loaded cavities that reduce physical depth while maintaining
performance.

\begin{examplebox}

\textbf{Example 16.3.3:} A half-wave slot antenna is cut into an
aluminum ground plane for an aircraft L-band transponder at 1.09 GHz.
Determine (a) the slot length, (b) the slot impedance from Babinet's
principle, (c) the impedance with a λ/4 deep cavity backing, and (d) a
suitable matching approach for 50 Ω coax.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 1.09 × 10⁹ = 0.2752 m. Slot length = λ/2 =
\textbf{137.6 mm}. Slot width is typically λ/20 to λ/10, so w ≈ 14--28
mm.

(b) From Babinet's principle: Z\textsubscript{slot} = η²/(4 ×
Z\textsubscript{dipole}) = 377²/(4 × 73) = 142,129/292 = \textbf{486.7
Ω}.

(c) The cavity backing eliminates the back lobe, effectively doubling
the forward radiation. The cavity modifies the impedance --- for a λ/4
deep cavity, the impedance drops to approximately
Z\textsubscript{slot}/2 = \textbf{243 Ω} because the short-circuit back
wall at λ/4 presents an open circuit at the slot plane, maintaining slot
resonance while doubling the radiation conductance --- the in-phase
image source at λ/2 distance constructively doubles the forward-radiated
power for the same slot voltage, halving the radiation resistance.

(d) A 243 Ω to 50 Ω transformation requires an impedance ratio of
4.86:1. A quarter-wave transformer with Z\textsubscript{match} = √(50 ×
243) = √12,150 = \textbf{110.2 Ω} provides the match. Alternatively, an
offset microstrip feed positioned at a point along the slot where the
impedance is lower can achieve a direct 50 Ω match without external
components.

\end{examplebox}

\section{16.4 Printed and Microstrip
Antennas}\label{printed-and-microstrip-antennas}

Microstrip (patch) antennas are fabricated on printed circuit board
substrates, making them lightweight, low-profile, conformable to
surfaces, and inexpensive to mass-produce. These properties have made
them the dominant antenna type for mobile devices, GPS receivers, Wi-Fi
equipment, and phased array systems.

\subsection{16.4.1 Rectangular Patch
Antennas}\label{rectangular-patch-antennas}

A rectangular microstrip patch antenna consists of a conducting patch on
one side of a dielectric substrate with a ground plane on the other
side. The patch acts as a resonant cavity bounded by the ground plane
below, the patch above, and open-circuit radiating edges on the sides.
The resonant length is approximately L ≈
c/(2f\textsubscript{r}√ε\textsubscript{r,eff}) − 2ΔL, where
ε\textsubscript{r,eff} is the effective dielectric constant (accounting
for fringing fields extending into air) and ΔL is the length extension
due to fringing at each radiating edge.

The patch width W affects radiation efficiency and impedance, with a
typical choice of W = c/(2f\textsubscript{r}) × √(2/(ε\textsubscript{r}
+ 1)) providing good radiation efficiency. The input impedance at the
radiating edge is typically 150--300 Ω, which can be matched to 50 Ω
through inset feeding (cutting a notch from the edge toward the center)
or probe feeding at the appropriate position. Patch antenna bandwidth is
inherently narrow (1--5\% for standard substrates) because the resonant
cavity has a high Q factor, but thicker substrates with lower
ε\textsubscript{r} increase bandwidth at the cost of larger size.
Typical gain ranges from 6 to 9 dBi for a single patch element.

\begin{examplebox}

\textbf{Example 16.4.1:} Design a rectangular patch antenna on FR-4
substrate (ε\textsubscript{r} = 4.4, thickness h = 1.6 mm) for 2.4 GHz
Wi-Fi. Determine (a) the patch width, (b) the effective dielectric
constant, (c) the fringing length extension, and (d) the patch length.

\textbf{Solution:}

(a) Patch width: W = c/(2f\textsubscript{r}) × √(2/(ε\textsubscript{r} +
1)) = (3 × 10⁸)/(2 × 2.4 × 10⁹) × √(2/5.4)\\
W = 0.0625 × 0.6086 = \textbf{38.0 mm}

(b) Effective dielectric constant:\\
ε\textsubscript{r,eff} = (ε\textsubscript{r} + 1)/2 +
(ε\textsubscript{r} − 1)/2 × (1 + 12h/W)⁻⁰·⁵\\
ε\textsubscript{r,eff} = 5.4/2 + 3.4/2 × (1 + 12 × 1.6/38.0)⁻⁰·⁵ = 2.7 +
1.7 × (1.505)⁻⁰·⁵ = 2.7 + 1.7 × 0.815 = \textbf{4.09}

(c) Length extension: ΔL = 0.412h × (ε\textsubscript{r,eff} + 0.3)(W/h +
0.264) / ((ε\textsubscript{r,eff} − 0.258)(W/h + 0.8))\\
ΔL = 0.412 × 1.6 × (4.39)(24.014) / ((3.832)(24.55)) = 0.659 × 105.42 /
94.07 = \textbf{0.740 mm}

(d) Patch length: L = c/(2f\textsubscript{r}√ε\textsubscript{r,eff}) −
2ΔL = (3 × 10⁸)/(2 × 2.4 × 10⁹ × √4.09) − 2 × 0.740\\
L = 0.0625/2.022 − 1.480 = 30.91 − 1.48 = \textbf{29.4 mm}

The final patch dimensions are approximately 38.0 mm × 29.4 mm on
standard 1.6 mm FR-4 --- compact enough for integration into Wi-Fi
routers and access points.

\end{examplebox}

\subsection{16.4.2 Patch Antenna
Variations}\label{patch-antenna-variations}

The circular patch antenna resonates when its effective radius satisfies
the condition a\textsubscript{eff} =
1.8412c/(2πf\textsubscript{r}√ε\textsubscript{r}), where the factor
1.8412 corresponds to the first zero of the derivative of the Bessel
function J₁. Circular patches are commonly used for GPS receivers
because they can easily generate circular polarization, which matches
the RHCP signal transmitted by GPS satellites. The physical radius
requires a fringing correction similar to the rectangular patch.

Circular polarization from a patch antenna can be achieved by two
primary methods. The first uses a square (or nearly square) patch with
truncated opposite corners, which excites two orthogonal modes with
equal amplitude and 90° phase difference. The second uses dual
orthogonal feeds with a 90° hybrid coupler to excite two orthogonal
modes simultaneously. Stacked patches --- multiple patch layers
separated by foam or air --- increase bandwidth to 10--25\% by creating
multiple coupled resonances. Patch antenna arrays combine multiple
elements with a corporate or series feed network to achieve higher gain
(18--25 dBi) and beam shaping, forming the basis of 5G panel antennas
and Wi-Fi sector antennas.

\begin{examplebox}

\textbf{Example 16.4.2:} Design a circularly polarized square patch
antenna with truncated corners for GPS L1 reception at 1.575 GHz on a
substrate with ε\textsubscript{r} = 2.2 and h = 3.175 mm (Rogers
RT/duroid 5880). Determine (a) the patch side length for a square patch,
and (b) the approximate truncation dimension (truncation length is
typically ΔC ≈ L/(2Q), where Q ≈
c√ε\textsubscript{r}/(4hf\textsubscript{r}) for the patch quality
factor).

\textbf{Solution:}

(a) For a square patch at resonance:\\
L = c/(2f\textsubscript{r}√ε\textsubscript{r,eff}). With
ε\textsubscript{r} = 2.2, h = 3.175 mm, and assuming W = L (square):\\
ε\textsubscript{r,eff} ≈ (2.2 + 1)/2 + (2.2 − 1)/2 × (1 + 12 ×
3.175/L)⁻⁰·⁵

Starting with an estimate: L ≈
c/(2f\textsubscript{r}√ε\textsubscript{r}) = 3 × 10⁸/(2 × 1.575 × 10⁹ ×
1.483) = \textbf{64.2 mm}\\
After fringing correction and iteration: L ≈ \textbf{62.0 mm} (62.0 mm ×
62.0 mm square patch).

(b) Patch quality factor: Q ≈
c√ε\textsubscript{r}/(4hf\textsubscript{r}) = 3 × 10⁸ × 1.483 / (4 ×
3.175 × 10⁻³ × 1.575 × 10⁹) = 22.3\\
Truncation: ΔC ≈ L/(2Q) = 62.0 / (2 × 22.3) = \textbf{1.39 mm}. Each
truncated corner removes a right triangle with legs of approximately 1.4
mm, creating the two orthogonal degenerate modes needed for circular
polarization.

\end{examplebox}

\section{16.5 Antenna Arrays}\label{antenna-arrays-1}

Antenna arrays combine multiple radiating elements to achieve higher
gain, beam steering capability, and adaptive pattern control that single
elements cannot provide. Arrays are fundamental to modern radar,
satellite communications, 5G cellular, and Wi-Fi MIMO systems.

\subsection{16.5.1 Array Theory and Pattern
Multiplication}\label{array-theory-and-pattern-multiplication}

The total radiation pattern of an antenna array equals the product of
the individual element pattern and the array factor (AF), a principle
known as pattern multiplication. For a uniform linear array (ULA) of N
identical elements spaced d apart along a line, the array factor is AF =
sin(Nψ/2) / (N sin(ψ/2)), where ψ = kd cos θ + β, k = 2π/λ is the
wavenumber, θ is the angle from the array axis, and β is the progressive
phase shift between elements. The main beam direction θ₀ is determined
by ψ = 0, giving cos θ₀ = −β/(kd).

A broadside array (β = 0) radiates perpendicular to the array axis,
while an end-fire array (β = −kd) radiates along the array axis. The
first-null beamwidth for a broadside array is approximately FNBW ≈
2λ/(Nd), and the directivity is D ≈ 2Nd/λ. Grating lobes ---
full-strength replicas of the main beam at undesired angles --- appear
when the element spacing d exceeds λ/(1 + \textbar sin
θ\textsubscript{s}\textbar), where θ\textsubscript{s} is the scan angle
from broadside. For an unsteered broadside array, the condition d
\textless{} λ prevents grating lobes; for arrays that must scan to ±60°,
the spacing must be reduced to d \textless{} 0.536λ.

\begin{examplebox}

\textbf{Example 16.5.1:} A 10-element uniform linear broadside array
operates at 3 GHz with half-wavelength spacing (d = λ/2). Determine (a)
the array factor first-null beamwidth, (b) the directivity of the array
factor, (c) the maximum scan angle before a grating lobe appears, and
(d) the directivity if the elements are half-wave dipoles.

\textbf{Solution:}

(a) λ = c/f = 0.10 m, d = 0.05 m.\\
FNBW ≈ 2λ/(Nd) = 2 × 0.10 / (10 × 0.05) = \textbf{0.40 radians =
22.9°}\\
HPBW ≈ 0.886λ/(Nd) = 0.886 × 0.10 / 0.50 = \textbf{0.177 radians =
10.2°}

(b) Array factor directivity: D\textsubscript{AF} = 2Nd/λ = 2 × 10 ×
0.05 / 0.10 = \textbf{10.0 (10.0 dB)}

(c) Grating lobe condition: d \textless{} λ/(1 + \textbar sin
θ\textsubscript{s}\textbar). With d = λ/2:\\
0.5 \textless{} 1/(1 + sin θ\textsubscript{s}), so 1 + sin
θ\textsubscript{s} \textless{} 2, giving sin θ\textsubscript{s}
\textless{} 1, meaning θ\textsubscript{s} \textless{} 90°.\\
\textbf{The array can scan the full visible range (±90°) without grating
lobes at d = λ/2 spacing.}

(d) Total directivity ≈ D\textsubscript{AF} × D\textsubscript{element} =
10.0 × 1.64 (dipole) = 16.4 = \textbf{12.1 dBi}. In practice, mutual
coupling between closely-spaced elements modifies the element patterns,
and the actual directivity will differ slightly from this simple
product.

\end{examplebox}

\subsection{16.5.2 Beamforming and Smart
Antennas}\label{beamforming-and-smart-antennas}

Beamforming electronically steers and shapes an antenna array's beam by
controlling the amplitude and phase (or time delay) of each element's
signal. Analog beamforming uses RF phase shifters at each element to
steer the beam in one direction at a time --- simple and cost-effective,
used in radar and early 5G systems. Digital beamforming digitizes the
signal at each element and applies complex weights in the digital
domain, enabling simultaneous formation of multiple independent beams
pointing in different directions. Hybrid beamforming combines analog
subarrays with digital processing, balancing performance and cost for
massive MIMO deployments.

MIMO (Multiple-Input Multiple-Output) antenna systems use multiple
antennas at both transmitter and receiver to exploit multipath
propagation rather than fighting it. Spatial multiplexing MIMO transmits
independent data streams on different spatial channels, multiplying
throughput by the number of parallel streams (up to
min(N\textsubscript{t}, N\textsubscript{r})). Massive MIMO, deployed in
5G NR, uses 64 to 256 antenna elements at the base station to
simultaneously serve many users through spatial division, achieving
spectral efficiencies 5--10× higher than conventional systems. The array
gain of a massive MIMO system is approximately 10 log₁₀(N) dB, where N
is the number of elements, providing both coverage improvement and
interference suppression.

\begin{examplebox}

\textbf{Example 16.5.2:} A 5G base station uses a 64-element massive
MIMO antenna panel operating at 3.5 GHz, arranged as an 8 × 8 planar
array with λ/2 spacing. Determine (a) the physical panel dimensions, (b)
the broadside array gain assuming 2.15 dBi element gain and 90\% array
efficiency, (c) the HPBW in azimuth and elevation, and (d) the number of
simultaneous user beams possible.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 3.5 × 10⁹ = 0.0857 m. Spacing d = λ/2 = 42.9
mm.\\
Panel size = 8 × 42.9 mm = 343 mm per side ≈ \textbf{34.3 cm × 34.3 cm}.

(b) Array gain: G = η × N × G\textsubscript{element} = 0.90 × 64 × 1.64
= 94.5 (linear)\\
G(dBi) = 10 log₁₀(94.5) = \textbf{19.8 dBi}. Alternatively: 10 log₁₀(64)
+ 2.15 − 0.46 = 18.06 + 2.15 − 0.46 = 19.8 dBi.

(c) For an 8-element linear array at λ/2: HPBW ≈ 0.886λ/(8 × λ/2) =
0.886/4 = 0.222 rad = \textbf{12.7°} in both azimuth and elevation
(symmetric for a square array).

(d) With digital beamforming, the maximum number of independent beams
equals the number of RF chains. With full digital beamforming (one RF
chain per element), up to \textbf{64 simultaneous beams} are possible,
though practical deployments typically serve 8--16 users simultaneously
due to inter-user interference and processing constraints.

\end{examplebox}

\subsection{16.5.3 Phased Array Scanning and Grating
Lobes}\label{phased-array-scanning-and-grating-lobes}

Phased array antennas steer the main beam electronically by applying a
progressive phase shift β between adjacent elements, directing the beam
to an angle θ₀ from broadside where sin θ₀ = −βλ/(2πd). The scan volume
is the range of angles over which the array can steer while maintaining
acceptable performance --- typically ±60° from broadside for most
systems, limited by element pattern roll-off, impedance mismatch, and
grating lobe onset. As the beam scans away from broadside, the projected
aperture decreases as cos θ₀, reducing the effective gain by
approximately 10 log₁₀(cos θ₀) dB. At 60° scan, this represents a 3 dB
gain reduction, and the beamwidth broadens by a factor of 1/cos θ₀.

Grating lobes are secondary main beams that appear when the element
spacing is large enough for a second solution to the array factor
maximum condition. For a ULA scanning to angle θ₀, grating lobes appear
at angles θ\textsubscript{GL} where sin θ\textsubscript{GL} = sin θ₀ +
nλ/d (for integer n ≠ 0). To keep the first grating lobe outside the
visible region (\textbar sin θ\textbar{} ≤ 1), the spacing must satisfy
d \textless{} λ/(1 + \textbar sin θ₀\textbar). For a maximum scan of
±60°, this requires d \textless{} 0.536λ; for ±90° (full hemisphere), d
\textless{} λ/2. In practice, element spacing of 0.5λ to 0.6λ is
standard, with 0.5λ being the safe choice for wide-scan applications.
Phase shifters at each element introduce quantization errors due to
their discrete phase states (typically 3-bit = 8 states to 6-bit = 64
states). The average sidelobe level due to phase quantization is
approximately −6B dB below the main beam for B-bit phase shifters --- a
4-bit shifter produces quantization sidelobes at approximately −24 dB,
which is adequate for most radar and communication systems.

\begin{examplebox}

\textbf{Example 16.5.3:} A phased array radar operates at 10 GHz with 32
elements spaced at d = 0.55λ. The beam is steered to θ₀ = 45° from
broadside. Determine (a) the progressive phase shift β required, (b)
whether a grating lobe enters the visible region, (c) the grating lobe
angle if one exists, and (d) the gain reduction due to scanning.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 10 × 10⁹ = 0.03 m. d = 0.55 × 0.03 = 0.0165 m.\\
β = −kd sin θ₀ = −(2π/0.03) × 0.0165 × sin 45° = −209.44 × 0.0165 ×
0.7071 = \textbf{−2.443 rad (−139.9°)}.

(b) Grating lobe condition: sin θ\textsubscript{GL} = sin 45° + λ/d =
0.7071 + 1/0.55 = 0.7071 + 1.818 = 2.525. Since \textbar sin
θ\textsubscript{GL}\textbar{} \textgreater{} 1 for n = +1, the first
positive-order grating lobe is outside visible space. For n = −1: sin
θ\textsubscript{GL} = 0.7071 − 1.818 = −1.111. Since
\textbar−1.111\textbar{} \textgreater{} 1, this grating lobe is also
just outside visible space but \textbf{very close to entering} (only
0.111 beyond the boundary). At slightly larger scan angles or
frequencies, it would appear.

(c) The n = −1 grating lobe would enter visible space when sin θ₀ − λ/d
= −1, or sin θ₀ = λ/d − 1 = 1.818 − 1 = 0.818, giving θ₀ =
\textbf{54.9°}. Beyond this scan angle, a grating lobe appears at −90°
and sweeps inward. The maximum grating-lobe-free scan angle is therefore
±54.9° for this 0.55λ spacing.

(d) Gain reduction at θ₀ = 45°: ΔG = 10 log₁₀(cos 45°) = 10
log₁₀(0.7071) = \textbf{−1.5 dB}. The broadside beamwidth of 0.886λ/(Nd)
= 0.886 × 0.03/(32 × 0.0165) = 0.0503 rad = 2.88° broadens to 2.88°/cos
45° = \textbf{4.07°} at the scanned angle.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-16-5-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch16_phased_array.png}

\caption{Figure 16.5.3: Phased Array Pattern}

\end{figure}

\section{16.6 Impedance Matching and Practical
Design}\label{impedance-matching-and-practical-design}

Practical antenna design requires not only understanding the radiation
characteristics but also ensuring efficient power transfer between the
antenna and the transmission line, and verifying performance through
measurement.

\subsection{16.6.1 Antenna Impedance
Matching}\label{antenna-impedance-matching}

The voltage standing wave ratio (VSWR) quantifies the impedance mismatch
between an antenna and its feedline: VSWR = (1 + \textbar Γ\textbar)/(1
− \textbar Γ\textbar), where Γ = (Z\textsubscript{ant} −
Z₀)/(Z\textsubscript{ant} + Z₀) is the reflection coefficient. The
return loss RL = −20 log₁₀\textbar Γ\textbar{} represents the fraction
of power reflected back toward the transmitter in dB, with RL
\textgreater{} 10 dB (VSWR \textless{} 2:1) considered acceptable and RL
\textgreater{} 15 dB (VSWR \textless{} 1.43:1) considered good. The
mismatch loss --- the fraction of power actually delivered to the
antenna --- is ML = −10 log₁₀(1 − \textbar Γ\textbar²); at VSWR = 2:1,
only 11\% of power is reflected and mismatch loss is just 0.51 dB.

Matching networks transform the antenna impedance to the characteristic
impedance of the feedline (typically 50 Ω). The L-network (one series
and one shunt reactive element) is the simplest, matching any impedance
at a single frequency with the component values determined by Q =
√(R\textsubscript{high}/R\textsubscript{low} − 1). The quarter-wave
transformer uses a transmission line section of impedance
Z\textsubscript{match} = √(Z₀ × Z\textsubscript{ant}) and length λ/4 to
provide a broadband match. A balun (balanced-to-unbalanced transformer)
is required when connecting a balanced antenna (dipole, loop) to an
unbalanced feedline (coaxial cable), with common types including the
sleeve balun, folded balun, and ferrite-core balun.

\begin{examplebox}

\textbf{Example 16.6.1:} A half-wave dipole (Z\textsubscript{ant} = 73
Ω) is to be matched to a 50 Ω coaxial feedline at 145 MHz using an
L-network. Determine (a) the VSWR without matching, (b) the return loss
without matching, (c) the L-network component values, and (d) an
alternative quarter-wave transformer impedance.

\textbf{Solution:}

(a) Γ = (73 − 50)/(73 + 50) = 23/123 = 0.187\\
VSWR = (1 + 0.187)/(1 − 0.187) = 1.187/0.813 = \textbf{1.46:1}

(b) RL = −20 log₁₀(0.187) = −20 × (−0.728) = \textbf{14.6 dB} ---
already acceptable without matching, but an L-network can improve it.

(c) L-network with series L and shunt C (matching 50 Ω to 73 Ω):\\
Q = √(73/50 − 1) = √(0.46) = 0.678\\
X\textsubscript{L} = Q × R\textsubscript{low} = 0.678 × 50 = 33.9 Ω → L
= 33.9/(2π × 145 × 10⁶) = \textbf{37.2 nH}\\
X\textsubscript{C} = R\textsubscript{high}/Q = 73/0.678 = 107.7 Ω → C =
1/(2π × 145 × 10⁶ × 107.7) = \textbf{10.2 pF}

(d) Quarter-wave transformer: Z\textsubscript{match} = √(50 × 73) =
√(3,650) = \textbf{60.4 Ω}. A 60.4 Ω transmission line section of length
λ/4 = 0.517 m at 145 MHz provides the match, though finding or
fabricating this impedance is less convenient than standard 50 or 75 Ω
cable.

\end{examplebox}

\subsection{16.6.2 Antenna Measurement and
Testing}\label{antenna-measurement-and-testing}

Antenna radiation pattern measurement requires controlled environments
to eliminate reflections and interference. An anechoic chamber lined
with RF-absorbing material (typically pyramidal foam absorbers effective
from 100 MHz to 40+ GHz) provides a reflection-free test zone, and is
the standard for precision measurements of gain, pattern, polarization,
and efficiency. Outdoor antenna ranges measure larger antennas using an
elevated range (transmit and receive antennas on towers) or a slant
range, with the test distance satisfying the far-field criterion d
\textgreater{} 2D²/λ to ensure plane-wave illumination. Near-field
scanning measures the amplitude and phase of the antenna's field on a
surface close to the antenna (planar, cylindrical, or spherical scan)
and mathematically transforms the data to compute the far-field pattern
--- essential for large arrays that would require impractically long
far-field distances.

Antenna impedance is measured using a vector network analyzer (VNA),
which measures the complex reflection coefficient S₁₁ at the antenna
input port across frequency. The VNA displays return loss, VSWR, and
impedance (on a Smith Chart) versus frequency, revealing the resonant
frequency (where the impedance is purely resistive), the impedance
bandwidth, and any parasitic resonances. For a two-port system (such as
an antenna with separate transmit and receive feeds), S₂₁ provides the
isolation or coupling between ports. Gain measurement uses either the
comparison method (comparing the antenna under test to a reference
antenna of known gain) or the three-antenna method (measuring all three
pairs of unknown antennas to solve for individual gains without a
reference standard).

\begin{examplebox}

\textbf{Example 16.6.2:} A VNA measurement of a patch antenna shows S₁₁
= −14 dB at the design frequency of 2.45 GHz. Determine (a) the
reflection coefficient magnitude, (b) the VSWR, (c) the percentage of
incident power reflected, and (d) the mismatch loss.

\textbf{Solution:}

(a) \textbar Γ\textbar{} = 10\textsuperscript{−14/20} = 10⁻⁰·⁷ =
\textbf{0.200}

(b) VSWR = (1 + 0.200)/(1 − 0.200) = 1.200/0.800 = \textbf{1.50:1}

(c) Reflected power = \textbar Γ\textbar² = 0.200² = 0.040 =
\textbf{4.0\%} --- meaning 96\% of incident power is delivered to the
antenna.

(d) Mismatch loss = −10 log₁₀(1 − \textbar Γ\textbar²) = −10
log₁₀(0.960) = −10 × (−0.0177) = \textbf{0.18 dB}. This is a
well-matched antenna --- the 0.18 dB mismatch loss is negligible in most
link budgets, confirming that S₁₁ = −14 dB represents good performance.

\end{examplebox}

\chapter{Chapter 17}\label{chapter-17}

\chapter{Radar Systems}\label{radar-systems}

Radar (Radio Detection And Ranging) uses electromagnetic waves to
detect, locate, and measure the velocity of objects at distances ranging
from centimeters to hundreds of kilometers. A radar system transmits a
known waveform toward a target, then analyzes the reflected echo to
extract information about the target's range, direction, speed, and
physical characteristics. Since its development during World War II,
radar has become essential to aviation safety, weather forecasting,
military defense, autonomous vehicles, and scientific remote sensing.
This chapter covers the fundamental principles of radar operation, the
major waveform types and signal processing techniques, and practical
radar applications with comparisons of system parameters across
different use cases.

\section{17.1 Radar Fundamentals}\label{radar-fundamentals}

The performance of any radar system is governed by a set of fundamental
relationships between transmitted power, antenna characteristics, target
properties, and receiver sensitivity. These equations determine the
maximum detection range, range and velocity resolution, and the ability
to distinguish targets from noise and clutter.

\subsection{17.1.1 Radar Range Equation}\label{radar-range-equation}

The radar range equation relates the received echo power to the system
and target parameters: P\textsubscript{r} =
P\textsubscript{t}G\textsubscript{t}G\textsubscript{r}λ²σ / ((4π)³R⁴),
where P\textsubscript{t} is the peak transmit power, G\textsubscript{t}
and G\textsubscript{r} are the transmit and receive antenna gains (often
the same antenna, so G² replaces G\textsubscript{t}G\textsubscript{r}),
λ is the wavelength, σ is the radar cross section (RCS) of the target in
m², and R is the range to the target. The R⁴ dependence is the defining
characteristic of radar --- doubling the detection range requires 16
times the transmit power, making radar inherently power-hungry for
long-range applications.

The maximum detection range occurs when the received power equals the
minimum detectable signal S\textsubscript{min}, giving:
R\textsubscript{max} = (P\textsubscript{t}G²λ²σ /
((4π)³S\textsubscript{min}))\textsuperscript{1/4}. The minimum
detectable signal depends on the receiver noise floor
(kT\textsubscript{s}B\textsubscript{n}, where T\textsubscript{s} is the
system noise temperature and B\textsubscript{n} is the noise bandwidth)
and the required signal-to-noise ratio SNR\textsubscript{min} for a
given probability of detection P\textsubscript{d} and false alarm
probability P\textsubscript{fa}. For a typical surveillance radar with
P\textsubscript{d} = 0.9 and P\textsubscript{fa} = 10⁻⁶, the required
single-pulse SNR is approximately 13.2 dB.

\begin{examplebox}

\textbf{Example 17.1.1:} An airport surveillance radar operates at 2.8
GHz (S-band) with a peak transmit power of 1.4 MW, antenna gain of 34
dBi, and system noise temperature of 600 K. The noise bandwidth is 1 MHz
and the required SNR is 13 dB. Determine (a) the wavelength, (b) the
minimum detectable signal, (c) the maximum detection range for an
aircraft with RCS σ = 10 m², and (d) the range for a small drone with σ
= 0.01 m².

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 2.8 × 10⁹ = \textbf{0.107 m}

(b) S\textsubscript{min} = kT\textsubscript{s}B\textsubscript{n} ×
SNR\textsubscript{min} = 1.381 × 10⁻²³ × 600 × 10⁶ ×
10\textsuperscript{13/10}\\
S\textsubscript{min} = 8.286 × 10⁻¹⁵ × 19.95 = \textbf{1.65 × 10⁻¹³ W}
(−97.8 dBm)

(c) G = 10\textsuperscript{34/10} = 2,512 (linear).\\
R\textsubscript{max} = (1.4 × 10⁶ × 2,512² × 0.107² × 10 / ((4π)³ × 1.65
× 10⁻¹³))\textsuperscript{1/4}\\
Numerator = 1.4 × 10⁶ × 6.31 × 10⁶ × 0.01145 × 10 = 1.011 × 10¹²\\
Denominator = 1,984 × 1.65 × 10⁻¹³ = 3.274 × 10⁻¹⁰\\
R\textsubscript{max} = (1.011 × 10¹² / 3.274 ×
10⁻¹⁰)\textsuperscript{1/4} = (3.088 × 10²¹)\textsuperscript{1/4} =
\textbf{236 km}

(d) For σ = 0.01 m²: the range scales as σ\textsuperscript{1/4}, so
R\textsubscript{drone} = 236 / (1000)\textsuperscript{1/4} = 236 / 5.62
= \textbf{42.0 km}. The 1,000× smaller RCS reduces detection range by a
factor of (1000)\textsuperscript{1/4} = 5.62 --- illustrating why small
drones are difficult to detect with conventional surveillance radar.

\end{examplebox}

\subsection{17.1.2 Radar Cross Section}\label{radar-cross-section}

Radar cross section (RCS) quantifies how effectively a target reflects
radar energy back toward the transmitter, defined as σ = 4πR² ×
(P\textsubscript{reflected}/P\textsubscript{incident}), where the ratio
represents the reflected power density at the target normalized to the
incident power density. RCS depends on the target's size, shape,
material, orientation relative to the radar, and the radar frequency.
Common reference values include: a flat plate of area A has peak RCS of
σ = 4πA²/λ² (when perpendicular to the beam), a sphere of radius a
\textgreater\textgreater{} λ has σ = πa² (independent of frequency), and
a corner reflector with face dimension L has σ = 12πL⁴/λ² (very large
for its size due to triple-bounce retroreflection).

Typical RCS values span many orders of magnitude: insects
\textasciitilde10⁻⁵ m² (−50 dBsm), birds \textasciitilde10⁻² m² (−20
dBsm), small drones \textasciitilde0.01 m² (−20 dBsm), humans
\textasciitilde1 m² (0 dBsm), automobiles \textasciitilde10--200 m²
(10--23 dBsm), small aircraft \textasciitilde1--10 m² (0--10 dBsm),
commercial jetliners \textasciitilde10--100 m² (10--20 dBsm), and large
ships \textasciitilde10,000--100,000 m² (40--50 dBsm). Stealth aircraft
use shaping (angled surfaces to deflect energy away from the radar),
radar-absorbing materials (RAM), and edge treatments to reduce RCS to
0.001--0.01 m² (−30 to −20 dBsm). RCS fluctuation models (Swerling
models I--IV) describe how RCS varies over time due to target aspect
changes, with Swerling I/II assuming scan-to-scan or pulse-to-pulse
independence.

\begin{examplebox}

\textbf{Example 17.1.2:} A metallic sphere with a radius of 0.5 m is
used as a radar calibration target at 10 GHz. Determine (a) whether the
sphere is in the optical region (a \textgreater\textgreater{} λ), (b)
the RCS, (c) the RCS in dBsm, and (d) compare to a 0.5 m × 0.5 m flat
plate oriented perpendicular to the beam.

\textbf{Solution:}

(a) λ = c/f = 0.03 m. a/λ = 0.5/0.03 = 16.7 \textgreater\textgreater{}
1, so \textbf{yes}, the sphere is in the optical region.

(b) Sphere RCS: σ\textsubscript{sphere} = πa² = π × 0.25 = \textbf{0.785
m²}

(c) σ (dBsm) = 10 log₁₀(0.785) = \textbf{−1.05 dBsm}

(d) Flat plate RCS: A = 0.25 m², σ\textsubscript{plate} = 4πA²/λ² = 4π ×
0.0625 / 9 × 10⁻⁴ = \textbf{873 m² (29.4 dBsm)}. The flat plate has
1,112× larger RCS than the sphere of comparable size because it
coherently reflects energy back toward the radar. This illustrates why
corner reflectors (which act as retroreflecting flat plates) are used to
enhance the radar visibility of small boats, buoys, and calibration
targets.

\end{examplebox}

\subsection{17.1.3 Doppler Effect and Velocity
Measurement}\label{doppler-effect-and-velocity-measurement}

When a target moves relative to the radar, the reflected signal
experiences a frequency shift proportional to the radial velocity. The
Doppler frequency shift is f\textsubscript{d} = 2v\textsubscript{r}f₀/c
= 2v\textsubscript{r}/λ, where v\textsubscript{r} is the radial
component of the target's velocity (positive for approaching targets),
f₀ is the transmit frequency, and the factor of 2 accounts for the
round-trip path. This Doppler shift is the basis for measuring target
velocity and for distinguishing moving targets from stationary clutter.

The maximum unambiguous velocity (without aliasing) for a pulsed radar
is v\textsubscript{max} = λ × PRF / 4, where PRF is the pulse repetition
frequency. Higher PRF allows measurement of faster targets but reduces
the maximum unambiguous range (R\textsubscript{ua} = c/(2 × PRF)),
creating the fundamental range-Doppler ambiguity: a radar cannot
simultaneously have long unambiguous range and high unambiguous velocity
with a single PRF. Medium-PRF radars (8--30 kHz) resolve this by using
multiple staggered PRFs and processing the returns jointly. The velocity
resolution of a radar is Δv = λ/(2T\textsubscript{dwell}), where
T\textsubscript{dwell} is the coherent integration time --- longer
observation times yield finer velocity resolution.

\begin{examplebox}

\textbf{Example 17.1.3:} An X-band police speed radar operates at 10.525
GHz in CW (continuous wave) mode. Determine (a) the wavelength, (b) the
Doppler shift for a vehicle approaching at 120 km/h, (c) the minimum
detectable velocity if the Doppler filter has a 3 dB bandwidth of 25 Hz,
and (d) the Doppler shift for a vehicle receding at 60 km/h.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 10.525 × 10⁹ = \textbf{0.02850 m} (28.50 mm)

(b) v\textsubscript{r} = 120 km/h = 33.33 m/s. f\textsubscript{d} = 2 ×
33.33 / 0.02850 = \textbf{2,339 Hz} (2.34 kHz)

(c) Minimum detectable velocity: v\textsubscript{min} = λ × Δf / 2 =
0.02850 × 25 / 2 = \textbf{0.356 m/s} (1.28 km/h). This allows detection
of walking-speed targets.

(d) v\textsubscript{r} = −60 km/h = −16.67 m/s (negative for receding).
f\textsubscript{d} = 2 × (−16.67) / 0.02850 = \textbf{−1,170 Hz}. The
negative frequency shift indicates the target is moving away. The radar
distinguishes approaching and receding targets by the sign of the
Doppler shift, typically using I/Q (quadrature) demodulation.

\end{examplebox}

\subsection{17.1.4 Radar Clutter and
Noise}\label{radar-clutter-and-noise}

Clutter is the unwanted radar return from objects other than the target
of interest --- ground surfaces, sea waves, precipitation, birds,
insects, and chaff. Unlike receiver noise, which is independent of the
transmitted signal, clutter power scales directly with transmit power
and cannot be reduced by increasing the radar's energy budget. Surface
clutter (ground and sea returns) enters the radar through the antenna's
sidelobes and mainlobe when the beam intersects the earth's surface. The
clutter RCS per unit area is characterized by the normalized clutter
coefficient σ⁰ (sigma-zero), measured in m²/m² or dB, which depends on
grazing angle, surface roughness, frequency, and polarization. Typical
values range from −40 dB for smooth calm sea at low grazing angles to
−10 dB for rough terrain at steep angles.

Sea clutter presents particular challenges because it is non-stationary
and has heavy-tailed amplitude statistics. At low sea states and high
grazing angles, sea clutter follows a Rayleigh distribution, but at low
grazing angles and high sea states the amplitude follows a Weibull or
K-distribution with occasional very large returns (``sea spikes'') that
mimic small boat targets. The signal-to-clutter ratio (SCR) for a target
in surface clutter is SCR = σ\textsubscript{target} / (σ⁰ ×
A\textsubscript{c}), where A\textsubscript{c} is the clutter cell area
illuminated by the radar (A\textsubscript{c} = R × θ\textsubscript{az} ×
cτ/(2 cos ψ) for a pulsed radar at grazing angle ψ). Volume clutter from
precipitation fills the radar resolution cell with a distributed
reflectivity that is proportional to the cell volume.

The system noise temperature T\textsubscript{sys} = T\textsubscript{ant}
+ T\textsubscript{r} determines the receiver noise floor, where
T\textsubscript{ant} is the antenna noise temperature (including sky,
ground, and atmospheric contributions) and T\textsubscript{r} = T₀(F −
1) is the receiver noise temperature derived from the noise figure F. A
low-noise amplifier (LNA) with a noise figure of 1.5 dB at the antenna
port gives T\textsubscript{r} = 290 × (1.413 − 1) = 120 K. The system
noise figure of a cascaded receiver chain follows the Friis noise
formula: F\textsubscript{sys} = F₁ + (F₂ − 1)/G₁ + (F₃ − 1)/(G₁G₂) +
\ldots, emphasizing that the first-stage LNA dominates overall noise
performance.

\begin{examplebox}

\textbf{Example 17.1.4:} A coastal surveillance radar operates at X-band
(9.4 GHz) with a pulse width of 100 ns and azimuth beamwidth of 1.5°. A
small boat with RCS σ = 3 m² is at a range of 8 km at a grazing angle of
2°. The normalized sea clutter coefficient at sea state 3 is σ⁰ = −30 dB
(0.001 m²/m²). Determine (a) the clutter cell area, (b) the total
clutter RCS in the cell, (c) the signal-to-clutter ratio, and (d)
whether MTI processing with 25 dB improvement factor can detect the
boat.

\textbf{Solution:}

(a) Clutter cell area: A\textsubscript{c} = R × θ\textsubscript{az} ×
cτ/(2 cos ψ) = 8,000 × (1.5 × π/180) × (3 × 10⁸ × 100 × 10⁻⁹)/(2 × cos
2°)\\
A\textsubscript{c} = 8,000 × 0.02618 × 30/1.9994 = 8,000 × 0.02618 ×
15.005 = \textbf{3,143 m²}

(b) Total clutter RCS: σ\textsubscript{c} = σ⁰ × A\textsubscript{c} =
0.001 × 3,143 = \textbf{3.14 m²} (5.0 dBsm)

(c) SCR = σ\textsubscript{target}/σ\textsubscript{c} = 3/3.14 =
\textbf{0.955 (−0.2 dB)}. The boat return is approximately equal to the
clutter --- it cannot be detected by amplitude alone.

(d) With 25 dB MTI improvement: output SCR = −0.2 + 25 = \textbf{24.8
dB}. Since a typical detection threshold requires SCR \textgreater{} 13
dB, the boat is now \textbf{clearly detectable} after MTI processing.
The boat's motion (even at low speed) produces a Doppler shift that
separates it from stationary sea clutter.

\end{examplebox}

\section{17.2 Radar Waveforms and
Modulation}\label{radar-waveforms-and-modulation}

The choice of transmitted waveform determines a radar's range
resolution, velocity resolution, and ability to suppress clutter and
interference. Each waveform type represents a different trade-off
between these capabilities, hardware complexity, and signal processing
requirements.

\subsection{17.2.1 Pulsed Radar}\label{pulsed-radar}

Pulsed radar transmits short bursts of RF energy and measures the time
delay of the echo to determine target range: R = cτ/2, where τ is the
round-trip time delay and the factor of 2 accounts for the two-way path.
The range resolution --- the ability to distinguish two targets at
different ranges --- is ΔR = cτ\textsubscript{p}/2, where
τ\textsubscript{p} is the pulse width. A 1 μs pulse gives ΔR = 150 m,
while a 10 ns pulse gives ΔR = 1.5 m. The maximum unambiguous range is
R\textsubscript{ua} = c/(2 × PRF), limited by the requirement that each
echo must return before the next pulse is transmitted.

The peak power of a pulsed radar can be very high (kilowatts to
megawatts), but the average power P\textsubscript{avg} =
P\textsubscript{peak} × τ\textsubscript{p} × PRF = P\textsubscript{peak}
× duty cycle is much lower (typically 0.1--10\% duty cycle). The pulse
energy E = P\textsubscript{peak} × τ\textsubscript{p} determines the
detection capability: a longer pulse contains more energy for detection
but has poorer range resolution. This conflict between detection range
(favoring long pulses with high energy) and range resolution (favoring
short pulses) motivates pulse compression techniques (§17.2.3). Pulse
integration --- averaging N return pulses --- improves the detection SNR
by a factor of N for coherent integration or approximately √N for
non-coherent integration.

\begin{examplebox}

\textbf{Example 17.2.1:} A marine navigation radar operates at 9.4 GHz
(X-band) with a peak power of 25 kW, pulse width of 0.5 μs, and PRF of
2,000 Hz. Determine (a) the range resolution, (b) the maximum
unambiguous range, (c) the duty cycle, (d) the average transmit power,
and (e) the detection range improvement from non-coherent integration of
20 pulses.

\textbf{Solution:}

(a) Range resolution: ΔR = cτ\textsubscript{p}/2 = 3 × 10⁸ × 0.5 × 10⁻⁶
/ 2 = \textbf{75 m}

(b) Maximum unambiguous range: R\textsubscript{ua} = c/(2 × PRF) = 3 ×
10⁸ / (2 × 2,000) = \textbf{75 km}

(c) Duty cycle = τ\textsubscript{p} × PRF = 0.5 × 10⁻⁶ × 2,000 =
\textbf{0.001 (0.1\%)}

(d) Average power: P\textsubscript{avg} = 25,000 × 0.001 = \textbf{25 W}

(e) Non-coherent integration gain ≈ √N = √20 = 4.47 (6.5 dB). Since
range scales as SNR\textsuperscript{1/4}, the range improvement factor =
4.47\textsuperscript{1/4} = \textbf{1.45×} (45\% increase in detection
range).

\end{examplebox}

\subsection{17.2.2 Continuous Wave (CW) and FMCW
Radar}\label{continuous-wave-cw-and-fmcw-radar}

Continuous wave (CW) radar transmits a constant-frequency signal and
measures the Doppler shift of the echo to determine target velocity, but
it cannot measure range because there is no timing reference in the
unmodulated waveform. CW radar is the simplest radar type, requiring
only a stable oscillator, a transmit/receive antenna (or separate
antennas), and a mixer that produces the Doppler frequency as a beat
note. CW radars are used in police speed radars, industrial motion
detectors, and missile seekers where velocity is the primary
measurement.

Frequency Modulated Continuous Wave (FMCW) radar adds range measurement
capability by sweeping the transmit frequency linearly over a bandwidth
B during a sweep time T\textsubscript{sweep}. The received echo is mixed
with the current transmit signal, producing a beat frequency
f\textsubscript{b} = (2RB)/(cT\textsubscript{sweep}) that is
proportional to range. The range resolution is ΔR = c/(2B) ---
determined by the sweep bandwidth, not the pulse width --- so a 1 GHz
bandwidth FMCW radar achieves 15 cm range resolution with milliwatts of
transmit power. FMCW radar can simultaneously measure range and velocity
using triangular modulation (alternating up-sweep and down-sweep), where
the sum of beat frequencies gives range and the difference gives
velocity. FMCW is the dominant technology for automotive radar (77 GHz),
drone altitude sensors, level measurement in industrial tanks, and
short-range surveillance.

\begin{examplebox}

\textbf{Example 17.2.2:} An automotive FMCW radar operates at 77 GHz
with a sweep bandwidth of 4 GHz and sweep time of 40 μs. Determine (a)
the range resolution, (b) the beat frequency for a vehicle at 50 m
range, (c) the maximum unambiguous range for a 12-bit ADC sampling at 40
MHz, and (d) the maximum beat frequency.

\textbf{Solution:}

(a) Range resolution: ΔR = c/(2B) = 3 × 10⁸ / (2 × 4 × 10⁹) =
\textbf{3.75 cm}. This fine resolution enables the radar to distinguish
individual pedestrians, vehicles, and road features.

(b) Beat frequency: f\textsubscript{b} = 2RB/(cT\textsubscript{sweep}) =
2 × 50 × 4 × 10⁹ / (3 × 10⁸ × 40 × 10⁻⁶) = 4 × 10¹¹ / 1.2 × 10⁴ =
\textbf{33.3 MHz}

(c) Maximum beat frequency = f\textsubscript{s}/2 = 20 MHz (Nyquist
limit).\\
R\textsubscript{max} = f\textsubscript{b,max} × cT\textsubscript{sweep}
/ (2B) = 20 × 10⁶ × 3 × 10⁸ × 40 × 10⁻⁶ / (2 × 4 × 10⁹) = \textbf{30 m}

(d) The beat frequency for 50 m (33.3 MHz) exceeds the 20 MHz Nyquist
limit at this ADC rate, so the ADC sample rate would need to be
increased to at least 67 MHz, or the sweep time lengthened. With
T\textsubscript{sweep} = 80 μs: f\textsubscript{b} = 16.7 MHz, safely
within the ADC bandwidth, and R\textsubscript{max} = 60 m --- sufficient
for automotive forward-collision applications.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-17-2-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch17_fmcw_beat.png}

\caption{Figure 17.2.2: FMCW Beat Frequency vs Range}

\end{figure}

\subsection{17.2.3 Pulse Compression}\label{pulse-compression}

Pulse compression resolves the conflict between detection range (which
requires high pulse energy, favoring long pulses) and range resolution
(which requires short pulses) by transmitting a long, coded pulse and
compressing it in the receiver to achieve the resolution of a much
shorter pulse. The compression ratio equals the time-bandwidth product:
CR = Bτ\textsubscript{p}, where B is the bandwidth of the coded waveform
and τ\textsubscript{p} is the pulse duration. The compressed pulse width
is 1/B, giving a range resolution of ΔR = c/(2B) regardless of the
transmitted pulse length.

The most common pulse compression waveform is the linear frequency
modulation (LFM) chirp, where the frequency sweeps linearly across
bandwidth B during pulse duration τ\textsubscript{p}. A matched filter
(dispersive delay line or digital correlator) in the receiver compresses
the chirp to a narrow pulse with a peak power gain equal to the
compression ratio. For example, a 10 μs chirp with 10 MHz bandwidth has
CR = 100 (20 dB), producing the same range resolution as a 0.1 μs pulse
but with 100× more energy. Phase-coded pulses (e.g., Barker codes,
polyphase codes) achieve similar compression by modulating the phase of
the transmitted pulse in a pseudo-random pattern. Barker codes of length
N provide compression ratios up to N with sidelobe levels of 1/N, but
the longest known Barker code has only N = 13.

\begin{examplebox}

\textbf{Example 17.2.3:} A military surveillance radar transmits a 50 μs
LFM chirp pulse with 5 MHz bandwidth at a peak power of 100 kW.
Determine (a) the compression ratio, (b) the range resolution, (c) the
equivalent short-pulse peak power (the effective peak power after
compression), (d) the compressed pulse width, and (e) compare to an
uncompressed 50 μs pulse.

\textbf{Solution:}

(a) Compression ratio: CR = Bτ\textsubscript{p} = 5 × 10⁶ × 50 × 10⁻⁶ =
\textbf{250} (24 dB)

(b) Range resolution: ΔR = c/(2B) = 3 × 10⁸ / (2 × 5 × 10⁶) = \textbf{30
m}

(c) Effective peak power after compression: P\textsubscript{eff} =
P\textsubscript{peak} × CR = 100 × 10³ × 250 = \textbf{25 MW
equivalent}. The matched filter concentrates the energy of the long
pulse into the compressed pulse width.

(d) Compressed pulse width: τ\textsubscript{compressed} = 1/B = 1 / (5 ×
10⁶) = \textbf{0.2 μs}

(e) Without compression, the 50 μs pulse has range resolution ΔR =
cτ\textsubscript{p}/2 = 3 × 10⁸ × 50 × 10⁻⁶ / 2 = 7,500 m ---
\textbf{250× worse} than with compression. To achieve 30 m resolution
without compression would require a 0.2 μs pulse with 25 MW peak power,
which is impractical. Pulse compression provides the detection energy of
a long pulse with the resolution of a short pulse.

\end{examplebox}

\section{17.3 Radar Signal Processing}\label{radar-signal-processing}

Signal processing transforms raw radar returns into useful target
information by extracting echoes from noise, suppressing clutter from
stationary objects, and forming images. Modern radars rely heavily on
digital signal processing (DSP) to achieve performance that would be
impossible with analog techniques alone.

\subsection{17.3.1 Moving Target Indication (MTI) and Clutter
Rejection}\label{moving-target-indication-mti-and-clutter-rejection}

Moving Target Indication (MTI) exploits the Doppler shift to distinguish
moving targets from stationary clutter (ground returns, buildings,
weather). A basic MTI filter subtracts consecutive pulse returns ---
since stationary clutter produces identical echoes from pulse to pulse,
the subtraction cancels clutter while preserving the Doppler-shifted
returns from moving targets. The MTI improvement factor quantifies
clutter suppression: I = (S/C)\textsubscript{out} /
(S/C)\textsubscript{in}, where S/C is the signal-to-clutter ratio. A
single-delay canceller achieves 20--25 dB improvement, while a double
canceller reaches 30--40 dB.

MTI has ``blind speeds'' at velocities where the Doppler shift is a
multiple of the PRF (f\textsubscript{d} = n × PRF), causing the target
return to look identical to clutter. The first blind speed is
v\textsubscript{blind} = λ × PRF / 2. Staggered PRF techniques eliminate
blind speeds by using two or more alternating PRFs. Moving Target
Detection (MTD) extends MTI by using a bank of Doppler filters
(typically an FFT across N pulses in a coherent processing interval) to
provide both clutter rejection and velocity measurement, forming the
basis of modern air traffic control radars like the ASR-9 and ASR-11.

\begin{examplebox}

\textbf{Example 17.3.1:} An S-band air surveillance radar operates at
3.0 GHz with a PRF of 1,000 Hz and uses a 2-pulse MTI canceller.
Determine (a) the first blind speed, (b) the second blind speed, (c) the
improvement factor if the clutter-to-noise ratio (CNR) is 40 dB and the
canceller provides 25 dB of improvement, and (d) a staggered PRF ratio
to eliminate the first blind speed.

\textbf{Solution:}

(a) λ = 0.10 m. First blind speed: v\textsubscript{blind1} = λ × PRF / 2
= 0.10 × 1,000 / 2 = \textbf{50 m/s} (180 km/h)

(b) Second blind speed: v\textsubscript{blind2} = 2 ×
v\textsubscript{blind1} = \textbf{100 m/s} (360 km/h). Aircraft at these
speeds would be invisible to the MTI filter.

(c) With 25 dB clutter improvement: output S/C = input S/C + 25 dB. If
input CNR = 40 dB (clutter 40 dB above noise) and the target is at noise
level (S/C = −40 dB input), then output S/C = −40 + 25 = \textbf{−15
dB}. The target is still below clutter, requiring additional integration
or MTD processing to detect.

(d) Using PRFs of 1,000 Hz and 1,250 Hz (ratio 4:5): The blind speeds of
PRF₁ are 50, 100, 150\ldots{} m/s. The blind speeds of PRF₂ are 62.5,
125, 187.5\ldots{} m/s. The first common blind speed is \textbf{250 m/s}
(900 km/h) --- well above typical aircraft speeds, effectively
eliminating the blind speed problem for normal targets.

\end{examplebox}

\subsection{17.3.2 Constant False Alarm Rate (CFAR)
Detection}\label{constant-false-alarm-rate-cfar-detection}

In a radar receiver, the detection threshold must adapt to varying noise
and clutter levels across range and angle to maintain a constant
probability of false alarm. A fixed threshold would produce excessive
false alarms in regions of high clutter and miss targets in quiet
regions. CFAR processors estimate the local noise/clutter level by
averaging the power in reference cells surrounding the cell under test
(CUT), then set the detection threshold as a multiple of this estimate:
threshold = α × P\textsubscript{noise,est}, where α is chosen to achieve
the desired P\textsubscript{fa}.

Cell-averaging CFAR (CA-CFAR) averages N reference cells on both sides
of the CUT (typically N = 16--32 total), excluding guard cells
immediately adjacent to the CUT to prevent target energy from biasing
the estimate. For N reference cells and a desired P\textsubscript{fa},
the threshold multiplier is α = N ×
(P\textsubscript{fa}\textsuperscript{−1/N} − 1). CA-CFAR works well in
homogeneous noise but degrades at clutter edges. Greatest-of CFAR
(GO-CFAR) selects the larger of the leading and trailing window
averages, providing better performance at clutter boundaries.
Ordered-statistics CFAR (OS-CFAR) ranks the reference cells by power and
selects the k-th largest value, offering robustness against multiple
interfering targets in the reference window.

\begin{examplebox}

\textbf{Example 17.3.2:} A CA-CFAR processor uses N = 16 reference cells
(8 leading, 8 trailing) with 2 guard cells on each side of the cell
under test. The desired false alarm probability is P\textsubscript{fa} =
10⁻⁶. Determine (a) the threshold multiplier α, (b) the threshold in dB
above the estimated noise floor, (c) the CFAR loss compared to an ideal
fixed-threshold detector, and (d) the total number of cells in the CFAR
window.

\textbf{Solution:}

(a) α = N × (P\textsubscript{fa}\textsuperscript{−1/N} − 1) = 16 ×
((10⁻⁶)\textsuperscript{−1/16} − 1) = 16 × (10\textsuperscript{6/16} −
1) = 16 × (10\textsuperscript{0.375} − 1)\\
α = 16 × (2.371 − 1) = 16 × 1.371 = \textbf{21.94}

(b) Threshold = 10 log₁₀(21.94) = \textbf{13.4 dB} above the estimated
noise floor.

(c) The CFAR loss (additional SNR required compared to a
known-noise-level detector) is approximately 10 log₁₀(1 + 2/N) dB, which
for N = 16 gives CFAR loss ≈ 10 log₁₀(1 + 2/16) = 10 log₁₀(1.125) =
\textbf{0.51 dB}. This small loss is the penalty for estimating the
noise level rather than knowing it exactly.

(d) Total cells = 1 (CUT) + 4 (guard cells) + 16 (reference cells) =
\textbf{21 range cells} in the sliding window.

\end{examplebox}

\subsection{17.3.3 Synthetic Aperture Radar
(SAR)}\label{synthetic-aperture-radar-sar}

Synthetic Aperture Radar (SAR) achieves fine azimuth (cross-range)
resolution from a moving platform by coherently processing echoes
collected over a distance along the flight path, synthesizing the effect
of a very large antenna. A real-aperture radar's azimuth resolution is
limited to θ\textsubscript{az} × R ≈ λR/D, where D is the antenna
length, requiring impractically large antennas for fine resolution at
long ranges. SAR overcomes this by recording the amplitude and phase of
echoes as the platform moves, then using matched filtering to focus the
synthetic aperture, achieving a cross-range resolution of
δ\textsubscript{cr} = D/2 --- remarkably independent of range and
wavelength.

This counterintuitive result means that a smaller antenna actually gives
finer SAR resolution, because a smaller antenna has a wider beam that
illuminates a target for a longer portion of the flight path, creating a
longer synthetic aperture. Stripmap SAR continuously images a swath
parallel to the flight path, while spotlight SAR steers the beam to
dwell on a specific area, achieving finer resolution at the expense of
area coverage. SAR is used for satellite Earth observation (Sentinel-1
at 5 m resolution, TerraSAR-X at 0.25 m), military reconnaissance,
terrain mapping, ocean monitoring, and interferometric applications
(InSAR) that measure ground displacement to millimeter accuracy for
earthquake and subsidence monitoring.

\begin{examplebox}

\textbf{Example 17.3.3:} An airborne SAR operates at 5.3 GHz (C-band)
from an altitude of 8 km with a velocity of 200 m/s. The antenna has a
length of 2 m and the transmitted bandwidth is 100 MHz. Determine (a)
the wavelength, (b) the cross-range (azimuth) resolution, (c) the range
resolution, (d) the synthetic aperture length for a target at 20 km
slant range, and (e) the coherent integration time.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 5.3 × 10⁹ = \textbf{0.0566 m}

(b) Cross-range resolution: δ\textsubscript{cr} = D/2 = 2/2 =
\textbf{1.0 m} --- independent of range.

(c) Range resolution: δ\textsubscript{r} = c/(2B) = 3 × 10⁸ / (2 × 100 ×
10⁶) = \textbf{1.5 m}

(d) Synthetic aperture length: L\textsubscript{SA} = λR/D = 0.0566 ×
20,000 / 2 = \textbf{566 m}. The radar must coherently process echoes
over a 566 m flight path segment to achieve 1.0 m resolution.

(e) Integration time: T\textsubscript{int} = L\textsubscript{SA}/v =
566/200 = \textbf{2.83 seconds}. During this time, the platform motion
must be known to a fraction of a wavelength (\textless{} λ/4 ≈ 14 mm)
for proper focusing, requiring precise inertial navigation or autofocus
algorithms.

\end{examplebox}

\subsection{17.3.4 Target Tracking and Data
Association}\label{target-tracking-and-data-association}

Radar detection produces a stream of plots (detections) at each scan ---
position measurements corrupted by noise and mixed with false alarms. A
tracker converts these plots into tracks, estimating each target's state
(position, velocity, acceleration) and predicting its future location.
Track-while-scan (TWS) processing maintains multiple target tracks
simultaneously by associating new detections with existing tracks at
each scan update. The tracking cycle consists of prediction (projecting
existing tracks forward to the time of the next scan), gating (defining
a region around each predicted position where an associated detection is
expected), association (assigning detections to tracks), and update
(refining the track state using the associated measurement).

The Kalman filter is the standard estimator for radar tracking,
providing the minimum-variance state estimate for linear systems with
Gaussian noise. The filter maintains a state vector x̂ (typically {[}x,
ẋ, y, ẏ{]} for 2D tracking) and a covariance matrix P that quantifies
the estimation uncertainty. At each update: x̂\textsubscript{k\textbar k}
= x̂\textsubscript{k\textbar k−1} + K(z\textsubscript{k} −
Hx̂\textsubscript{k\textbar k−1}), where K is the Kalman gain,
z\textsubscript{k} is the measurement, and H is the measurement matrix.
The innovation (z\textsubscript{k} − Hx̂\textsubscript{k\textbar k−1})
represents the difference between the actual measurement and the
predicted measurement. For maneuvering targets, the extended Kalman
filter (EKF) or interacting multiple model (IMM) filter handles
nonlinear dynamics and mode switching between straight-line and turning
motion.

Data association --- deciding which detection belongs to which track ---
becomes challenging in dense multi-target environments. The Global
Nearest Neighbor (GNN) algorithm assigns each detection to the closest
predicted track position (within the gate), minimizing the total
assignment cost. The Joint Probabilistic Data Association (JPDA) filter
handles ambiguous associations by computing the probability that each
detection originated from each track and using a weighted combination of
all possible associations. Track initiation uses M-of-N logic: a new
track is confirmed if M detections fall within a consistent trajectory
over N consecutive scans (typically 3-of-5 or 4-of-7).

\begin{examplebox}

\textbf{Example 17.3.4:} A surveillance radar tracks an aircraft at a
range of 100 km with a range accuracy of σ\textsubscript{R} = 50 m and
azimuth accuracy of σ\textsubscript{θ} = 0.3°. The scan interval is 5
seconds and the aircraft velocity is 250 m/s. Determine (a) the
cross-range position accuracy, (b) the predicted position uncertainty
after one scan (assuming constant velocity), (c) the gate size for 99\%
probability of containing the true target position, and (d) the number
of false alarms expected in the gate if P\textsubscript{fa} = 10⁻⁶ per
resolution cell.

\textbf{Solution:}

(a) Cross-range accuracy: σ\textsubscript{cr} = R × σ\textsubscript{θ} =
100,000 × (0.3 × π/180) = 100,000 × 0.00524 = \textbf{524 m}. The
cross-range accuracy is much worse than the range accuracy, as is
typical for surveillance radars.

(b) During one scan interval, the aircraft moves Δx = v × T = 250 × 5 =
1,250 m. The predicted position uncertainty grows due to velocity
estimation error. If the velocity accuracy is σ\textsubscript{v} ≈
σ\textsubscript{cr}/T = 524/5 = 105 m/s, then the position prediction
uncertainty after one scan is σ\textsubscript{pred} =
√(σ\textsubscript{cr}² + (σ\textsubscript{v} × T)²) = √(524² + 525²) =
\textbf{742 m} in cross-range. In range, σ\textsubscript{pred} ≈ √(50² +
(σ\textsubscript{vr} × 5)²), which is much smaller.

(c) For a 2D Gaussian distribution, 99\% probability requires a gate
radius of approximately 3.035σ (chi-squared with 2 DOF at p = 0.99).
Gate dimensions: range gate = 3.035 × 50 = 152 m; azimuth gate = 3.035 ×
742 = \textbf{2,252 m}. The gate area is approximately π × 152 × 2,252 =
\textbf{1.08 × 10⁶ m²}.

(d) Number of resolution cells in gate: approximately 1.08 × 10⁶ / (150
× 524) ≈ 13.7 cells. Expected false alarms per gate = 13.7 × 10⁻⁶ =
\textbf{1.37 × 10⁻⁵} --- essentially zero, confirming that association
is unambiguous in this scenario. In dense traffic or with higher false
alarm rates, multiple detections within the gate require JPDA or
multi-hypothesis tracking.

\end{examplebox}

\section{17.4 Radar Applications}\label{radar-applications}

Radar systems serve diverse applications spanning civil aviation,
meteorology, automotive safety, and subsurface imaging. Each application
domain drives unique requirements for frequency, resolution, update
rate, power, and cost, resulting in vastly different system
architectures.

\subsection{17.4.1 Air Traffic Control and Surveillance
Radar}\label{air-traffic-control-and-surveillance-radar}

Air Traffic Control (ATC) radar provides the position and identity of
aircraft in controlled airspace, forming the backbone of aviation
safety. Primary Surveillance Radar (PSR) detects aircraft by their radar
echoes without requiring any onboard equipment, operating at S-band
(2.7--2.9 GHz) for en-route surveillance with detection ranges of
100--450 km, or at L-band (1.2--1.4 GHz) for long-range air defense.
Secondary Surveillance Radar (SSR) interrogates aircraft transponders at
1,030 MHz and receives coded replies at 1,090 MHz, providing aircraft
identity (Mode A), altitude (Mode C), and full ADS-B data (Mode S).

Airport surveillance uses short-range S-band PSR (ASR-9, ASR-11) with 60
nmi range and 4.8 s rotation period, combined with SSR for
identification. Airport Surface Detection Equipment (ASDE-X) uses X-band
radar and multilateration to track aircraft and vehicles on runways and
taxiways with 1 m accuracy. Precision Approach Radar (PAR) provides
azimuth and elevation guidance for landing in poor visibility, using
Ku-band for high angular accuracy. Modern ATC systems are transitioning
to ADS-B (Automatic Dependent Surveillance-Broadcast), where aircraft
continuously broadcast GPS-derived position, reducing dependence on
ground-based radar.

\begin{examplebox}

\textbf{Example 17.4.1:} An ASR-11 airport surveillance radar has the
following parameters: frequency 2.8 GHz, peak power 25 kW (solid-state),
antenna rotation rate 12.5 RPM, azimuth beamwidth 1.4°, range 60 nmi
(111 km), and PRF 1,000 Hz. Determine (a) the scan time, (b) the number
of pulses on target per scan (hits per scan), (c) the integration gain
for non-coherent integration, and (d) the range resolution for a 1 μs
pulse width.

\textbf{Solution:}

(a) Scan time = 60/RPM = 60/12.5 = \textbf{4.8 seconds} per revolution.

(b) Hits per scan = PRF × θ\textsubscript{az} / (360° × RPM/60) = 1,000
× 1.4 / (360 × 12.5/60) = 1,400 / 75 = \textbf{18.7 ≈ 19 pulses} on
target per scan.

(c) Non-coherent integration gain ≈ √N = √19 = \textbf{4.36 (6.4 dB)}.
This improves the effective SNR beyond what a single pulse provides.

(d) Range resolution: ΔR = cτ/2 = 3 × 10⁸ × 10⁻⁶ / 2 = \textbf{150 m}.
This is adequate for separating aircraft in terminal airspace, where
minimum radar separation is 3 nmi (5.6 km) laterally.

\end{examplebox}

\subsection{17.4.2 Weather Radar}\label{weather-radar}

Weather radar detects precipitation (rain, snow, hail) by measuring the
radar reflectivity of hydrometeors --- water droplets and ice particles
in the atmosphere. The weather radar equation modifies the standard
radar range equation by replacing the discrete target RCS with a
distributed reflectivity factor Z (measured in mm⁶/m³), giving
P\textsubscript{r} = C × Z / R², where C is a system constant. The
reflectivity factor Z is related to rainfall rate R\textsubscript{r} by
the Marshall-Palmer relation Z =
200R\textsubscript{r}\textsuperscript{1.6}, where R\textsubscript{r} is
in mm/h and Z is in mm⁶/m³. Reflectivity is commonly expressed in dBZ,
where dBZ = 10 log₁₀(Z).

The NEXRAD (WSR-88D) network of 160 S-band (2.7--3.0 GHz) Doppler
weather radars covers the continental United States, operating with 750
kW peak power, a 28-foot (8.5 m) parabolic antenna (gain ≈ 45 dBi), and
Doppler processing to measure wind speeds within storms.
Dual-polarization capability (transmitting both horizontal and vertical
polarizations) allows NEXRAD to distinguish rain from hail, snow, and
debris, significantly improving precipitation estimation and tornado
detection. X-band (9.3--9.5 GHz) weather radars are used for gap-filling
in urban areas and at airports, while airborne weather radars (C-band or
X-band) in commercial aircraft detect turbulence and thunderstorms along
the flight path.

\begin{examplebox}

\textbf{Example 17.4.2:} A NEXRAD WSR-88D radar detects a thunderstorm
cell at 100 km range with a measured reflectivity of 55 dBZ. Determine
(a) the reflectivity in linear units, (b) the estimated rainfall rate
using the Marshall-Palmer relation, (c) the classification of the storm
(light rain \textless{} 20 dBZ, moderate rain 20--40 dBZ, heavy rain
40--50 dBZ, very heavy rain/hail \textgreater{} 50 dBZ), and (d) the
Doppler velocity resolution if the dwell time is 50 ms.

\textbf{Solution:}

(a) Z = 10\textsuperscript{55/10} = 10\textsuperscript{5.5} =
\textbf{316,228 mm⁶/m³}

(b) Z = 200R\textsubscript{r}\textsuperscript{1.6}, so
R\textsubscript{r} = (Z/200)\textsuperscript{1/1.6} =
(316,228/200)\textsuperscript{0.625} = (1,581)\textsuperscript{0.625}\\
ln(1,581) = 7.366, × 0.625 = 4.604, R\textsubscript{r} =
e\textsuperscript{4.604} = \textbf{100 mm/h} (3.9 inches/hour)

(c) At 55 dBZ, this is classified as \textbf{very heavy rain, likely
containing hail}. NWS severe thunderstorm warnings are typically issued
for reflectivities \textgreater{} 50 dBZ.

(d) λ = 0.107 m (at 2.8 GHz). Velocity resolution: Δv =
λ/(2T\textsubscript{dwell}) = 0.107 / (2 × 0.050) = \textbf{1.07 m/s}
(3.9 km/h). This resolution is sufficient to detect the rotational
signatures within mesocyclones (tornado precursors), which typically
have velocity differentials of 15+ m/s.

\end{examplebox}

\subsection{17.4.3 Automotive Radar}\label{automotive-radar}

Automotive radar enables advanced driver assistance systems (ADAS) and
autonomous driving by detecting vehicles, pedestrians, cyclists, and
road infrastructure in all weather conditions. The 77 GHz band (76--81
GHz) has become the global standard for automotive radar, offering a
good balance of range resolution (\textless{} 10 cm with 4 GHz
bandwidth), compact antenna size (λ ≈ 3.9 mm), and regulatory
availability. FMCW is the dominant waveform because it provides
simultaneous range and velocity measurement with low transmit power
(typically 10--13 dBm EIRP) and low-cost silicon germanium (SiGe) or
CMOS integrated circuits.

Modern automotive radar systems use multiple operating modes on a single
platform. Long-range radar (LRR) at 77 GHz covers 150--300 m with a
narrow beam (3--4° azimuth) for adaptive cruise control and highway
collision avoidance. Medium-range radar (MRR) covers 30--100 m with
moderate beamwidth (15--30°) for cross-traffic alerts and lane-change
assistance. Short-range radar (SRR) covers 0.2--30 m with wide beamwidth
(60--150°) for parking assistance, blind-spot detection, and rear
collision warning. A typical Level 2+ ADAS vehicle uses 5--6 radar
sensors (1 forward LRR, 2 front-corner MRR, 2 rear-corner SRR) combined
with cameras and ultrasonic sensors in a sensor fusion architecture.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1324}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2794}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2941}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2941}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Long-Range (LRR)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Medium-Range (MRR)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Short-Range (SRR)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Range & 150--300 m & 30--100 m & 0.2--30 m \\
Azimuth FOV & ±8° & ±40° & ±75° \\
Range resolution & 0.3--1.0 m & 0.1--0.5 m & 0.05--0.1 m \\
Bandwidth & 500 MHz--1 GHz & 1--2 GHz & 4 GHz \\
Application & ACC, AEB & Cross-traffic, lane change & Parking, blind
spot \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example 17.4.3:} A 77 GHz FMCW long-range automotive radar has a
bandwidth of 1 GHz, sweep time of 50 μs, maximum range of 200 m, and
transmit antenna array gain of 20 dBi. Determine (a) the range
resolution, (b) the velocity resolution using 128 chirps in a frame
(frame time = 128 × 50 μs), (c) the beat frequency for a target at 100
m, and (d) the maximum unambiguous velocity.

\textbf{Solution:}

(a) Range resolution: ΔR = c/(2B) = 3 × 10⁸ / (2 × 10⁹) = \textbf{15 cm}

(b) λ = 3.9 mm. Frame time T\textsubscript{frame} = 128 × 50 × 10⁻⁶ =
6.4 ms.\\
Velocity resolution: Δv = λ/(2T\textsubscript{frame}) = 3.9 × 10⁻³ / (2
× 6.4 × 10⁻³) = \textbf{0.30 m/s} (1.1 km/h)

(c) Beat frequency: f\textsubscript{b} = 2RB/(cT\textsubscript{sweep}) =
2 × 100 × 10⁹ / (3 × 10⁸ × 50 × 10⁻⁶) = 2 × 10¹¹ / 1.5 × 10⁴ =
\textbf{13.3 MHz}

(d) Maximum unambiguous velocity: v\textsubscript{max} =
λ/(4T\textsubscript{sweep}) = 3.9 × 10⁻³ / (4 × 50 × 10⁻⁶) =
\textbf{19.5 m/s} (70.2 km/h). For highway speeds exceeding this,
velocity ambiguity is resolved by varying the chirp repetition interval
or using multiple chirp slopes.

\end{examplebox}

\subsection{17.4.4 Ground-Penetrating Radar
(GPR)}\label{ground-penetrating-radar-gpr}

Ground-Penetrating Radar (GPR) transmits electromagnetic pulses into the
ground and records reflections from subsurface interfaces where the
dielectric properties change --- such as boundaries between soil layers,
buried pipes, voids, or embedded objects. GPR typically operates at
frequencies from 10 MHz to 4 GHz, with the choice of frequency
representing a fundamental trade-off between penetration depth (which
decreases with frequency due to soil attenuation) and resolution (which
improves with frequency). Low-frequency GPR (10--100 MHz) can penetrate
10--50 m in dry sand or rock but achieves only meter-scale resolution,
while high-frequency GPR (1--4 GHz) offers centimeter resolution but
penetrates only 0.1--1 m in typical soils.

GPR uses ultra-wideband (UWB) impulse waveforms --- very short pulses
(0.5--5 ns) containing energy across a wide bandwidth --- rather than
the narrowband waveforms used in conventional radar. The reflection
coefficient at a dielectric interface depends on the contrast in
relative permittivity: Γ = (√ε\textsubscript{r2} − √ε\textsubscript{r1})
/ (√ε\textsubscript{r2} + √ε\textsubscript{r1}). Typical permittivity
values are: air ε\textsubscript{r} = 1, dry sand 3--5, wet soil 10--30,
concrete 6--11, water 81, and metal ∞ (perfect reflector). Applications
include utility mapping (locating buried pipes and cables before
excavation), road and bridge inspection (detecting voids and rebar
corrosion), archaeology, forensic investigation, and military landmine
detection.

\begin{examplebox}

\textbf{Example 17.4.4:} A 400 MHz GPR system is used to locate a buried
water pipe in clay soil (ε\textsubscript{r} = 12, attenuation α = 5
dB/m). The pipe is at a depth of 1.5 m. Determine (a) the propagation
velocity in the soil, (b) the round-trip time to the pipe, (c) the
two-way attenuation, (d) the vertical resolution for a pulse bandwidth
of 400 MHz, and (e) whether the pipe is detectable if the system dynamic
range is 90 dB.

\textbf{Solution:}

(a) Velocity: v = c/√ε\textsubscript{r} = 3 × 10⁸ / √12 = 3 × 10⁸ /
3.464 = \textbf{8.66 × 10⁷ m/s} (29\% of the speed of light)

(b) Round-trip time: t = 2d/v = 2 × 1.5 / 8.66 × 10⁷ = \textbf{34.6 ns}

(c) Two-way attenuation: L = 2 × α × d = 2 × 5 × 1.5 = \textbf{15 dB}

(d) Vertical resolution: δ\textsubscript{v} = v/(2B) = 8.66 × 10⁷ / (2 ×
400 × 10⁶) = \textbf{10.8 cm}. This is sufficient to resolve the pipe
diameter (typically 10--30 cm for water mains).

(e) The 15 dB two-way soil attenuation is well within the 90 dB dynamic
range, so \textbf{yes}, the pipe is easily detectable. The maximum
penetration depth at this attenuation rate is approximately 90/(2 × 5) =
9 m, though the practical limit in wet clay is typically 2--4 m due to
additional scattering and dispersion losses.

\end{examplebox}

\subsection{17.4.5 Missile Defense and Space Surveillance
Radar}\label{missile-defense-and-space-surveillance-radar}

Ballistic missile defense requires radar systems with extraordinary
range, precision, and discrimination capability to detect, track, and
classify warheads and decoys during the midcourse phase of flight in the
exoatmospheric environment. The AN/FPS-132 Upgraded Early Warning Radar
(UEWR) operates at UHF (420--450 MHz) with a 32 m × 32 m phased array
face producing approximately 40 dBi gain and peak power of 30 MW,
detecting ballistic missiles at ranges exceeding 5,000 km. The Sea-Based
X-Band Radar (SBX) operates at X-band (9.5 GHz) with a 12.8 m diameter
phased array containing approximately 45,000 transmit/receive modules,
producing a pencil beam of 0.1° that can track a baseball-sized object
at 4,000 km range and discriminate warheads from decoys by measuring
fine target features.

The AN/TPY-2 radar, the sensor for the THAAD (Terminal High Altitude
Area Defense) system, operates at X-band with an active electronically
scanned array (AESA) of approximately 25,000 gallium arsenide T/R
modules. In forward-based mode it provides early detection and tracking
of ballistic missiles during boost phase at ranges exceeding 1,000 km;
in terminal mode it provides fire-control quality tracks for THAAD
interceptor guidance. The Space Fence (AN/FSY-3) at Kwajalein Atoll is
an S-band phased array radar designed to detect and catalog small
objects in low Earth orbit (LEO), tracking items as small as 5 cm at
ranges up to 40,000 km to maintain the space debris catalog. These
systems share common features: AESA architecture with thousands of
solid-state T/R modules, digital beamforming for multiple simultaneous
beams, wideband waveforms for high range resolution and target feature
extraction, and sophisticated discrimination algorithms that analyze
RCS, polarization, micro-Doppler, and ballistic trajectory to
distinguish warheads from decoys and debris.

\begin{examplebox}

\textbf{Example 17.4.5:} A ground-based X-band missile defense radar
(similar to SBX) has an antenna diameter of 12.8 m, aperture efficiency
of 0.65, peak transmit power of 2 MW, and system noise temperature of
400 K. The target is a warhead with RCS σ = 0.01 m² at a range of 2,000
km. Determine (a) the antenna gain, (b) the received signal power for a
single pulse, (c) the single-pulse SNR for a 1 MHz noise bandwidth, and
(d) the number of pulses required for coherent integration to achieve 20
dB SNR.

\textbf{Solution:}

(a) λ = c/f = 3 × 10⁸ / 9.5 × 10⁹ = 0.03158 m.\\
G = 0.65 × (π × 12.8/0.03158)² = 0.65 × 1,273.3² = 0.65 × 1,621,300 =
1,053,800\\
G(dBi) = 10 log₁₀(1,053,800) = \textbf{60.2 dBi}

(b) P\textsubscript{r} = P\textsubscript{t}G²λ²σ / ((4π)³R⁴) = 2 × 10⁶ ×
(1,053,800)² × 0.03158² × 0.01 / ((4π)³ × (2 × 10⁶)⁴)\\
Numerator = 2 × 10⁶ × 1.110 × 10¹² × 9.97 × 10⁻⁴ × 0.01 = 2.213 × 10¹³\\
Denominator = 1,984 × 1.6 × 10²⁵ = 3.174 × 10²⁸\\
P\textsubscript{r} = 2.213 × 10¹³ / 3.174 × 10²⁸ = \textbf{6.97 × 10⁻¹⁶
W} (−151.6 dBW)

(c) Noise power: N = kT\textsubscript{s}B\textsubscript{n} = 1.381 ×
10⁻²³ × 400 × 10⁶ = 5.52 × 10⁻¹⁵ W.\\
Single-pulse SNR = 6.97 × 10⁻¹⁶ / 5.52 × 10⁻¹⁵ = \textbf{0.126 (−9.0
dB)}. The target is well below the noise floor on a single pulse.

(d) Coherent integration gain required: 20 − (−9.0) = 29.0 dB. For
coherent integration, gain = 10 log₁₀(N), so N =
10\textsuperscript{29.0/10} = \textbf{794 pulses}. At a PRF of 10 kHz,
this requires a dwell time of 0.079 seconds. This illustrates why
missile defense radars use long coherent integration times and extremely
high-gain antennas to detect small targets at extreme ranges.

\end{examplebox}

\subsection{17.4.6 LiDAR (Light Detection and
Ranging)}\label{lidar-light-detection-and-ranging}

LiDAR uses laser pulses --- typically at near-infrared wavelengths (905
nm or 1550 nm) --- rather than radio-frequency waves to measure the
range, velocity, and reflectivity of targets with centimeter-level
accuracy. The operating principle is identical to pulsed radar: a short
laser pulse is transmitted, the round-trip time of flight (ToF) to a
reflective surface is measured, and range is computed as R = ct/2.
Because the wavelength is approximately 10,000× shorter than microwave
radar (1 μm vs.~1 cm), LiDAR achieves angular resolution orders of
magnitude finer for a given aperture size, enabling dense 3D point cloud
generation with millions of points per second. The range equation for
LiDAR follows the same form as radar: P\textsubscript{r} =
P\textsubscript{t}ρA\textsubscript{r}/(πR²) for a diffuse (Lambertian)
target, where ρ is the target reflectivity (0.1--0.9 depending on
surface) and A\textsubscript{r} is the receiver aperture area.

Three main scanning architectures are used. Mechanical LiDAR rotates a
laser/detector assembly (or a spinning mirror) through 360° to create a
full surround point cloud, achieving 100--300 m range with 0.1° angular
resolution (Velodyne, Ouster). Solid-state LiDAR uses MEMS mirrors,
optical phased arrays (OPA), or flash illumination to scan without
moving parts, offering greater reliability and lower cost but typically
with a narrower field of view (60--120°). Flash LiDAR illuminates the
entire scene simultaneously with a single wide-beam laser pulse and uses
a 2D detector array (similar to a camera sensor) to capture range at
every pixel simultaneously --- ideal for very fast 3D imaging at short
range but limited in range by the eye-safe power distributed across the
full field.

The choice of wavelength involves a safety-performance trade-off. The
905 nm systems use inexpensive silicon avalanche photodiode (APD)
detectors and low-cost GaAs/InGaAs laser diodes, but the wavelength
falls within the retinal hazard zone, limiting transmit power to Class 1
eye-safe levels (\textasciitilde1 mW average for a narrow beam). The
1550 nm systems are eye-safe at much higher power levels (the cornea
absorbs 1550 nm before it reaches the retina), enabling longer range,
but require more expensive InGaAs detectors and erbium-doped fiber laser
sources. Frequency-modulated continuous wave (FMCW) LiDAR --- analogous
to FMCW radar --- is an emerging approach that achieves simultaneous
range and velocity measurement with coherent detection, providing
shot-noise-limited sensitivity and immunity to ambient sunlight
interference.

\begin{examplebox}

\textbf{Example 17.4.6:} A 905 nm pulsed LiDAR for autonomous vehicles
has a transmit pulse energy of 4 μJ, pulse width of 5 ns, receiver
aperture diameter of 25 mm, and detector NEP (noise-equivalent power) of
0.2 nW/√Hz. A vehicle with reflectivity ρ = 0.3 is at a range of 150 m.
Determine (a) the range resolution, (b) the received power for a
Lambertian target, (c) the receiver SNR assuming a detection bandwidth
of 200 MHz, and (d) the maximum detection range for SNR = 10.

\textbf{Solution:}

(a) Range resolution: ΔR = cτ/2 = 3 × 10⁸ × 5 × 10⁻⁹ / 2 = \textbf{0.75
m}. In practice, timing electronics with sub-nanosecond precision
achieve 1--5 cm range accuracy using threshold or peak detection on the
return pulse.

(b) Received power for a Lambertian target: P\textsubscript{r} =
P\textsubscript{t} × ρ × A\textsubscript{r} / (π × R²)\\
P\textsubscript{t} = E/τ = 4 × 10⁻⁶ / 5 × 10⁻⁹ = 800 W (peak power).\\
A\textsubscript{r} = π(0.0125)² = 4.91 × 10⁻⁴ m².\\
P\textsubscript{r} = 800 × 0.3 × 4.91 × 10⁻⁴ / (π × 150²) = 0.1178 /
70,686 = \textbf{1.67 × 10⁻⁶ W} (1.67 μW)

(c) Noise floor: N = NEP × √B = 0.2 × 10⁻⁹ × √(200 × 10⁶) = 0.2 × 10⁻⁹ ×
14,142 = 2.83 × 10⁻⁶ W.\\
SNR = P\textsubscript{r}/N = 1.67 × 10⁻⁶ / 2.83 × 10⁻⁶ = \textbf{0.59
(−2.3 dB)}. The target is just below the noise floor at 150 m.

(d) For SNR = 10: P\textsubscript{r} must equal 10 × N = 2.83 × 10⁻⁵ W.
Since P\textsubscript{r} ∝ 1/R², R\textsubscript{max} = R ×
√(P\textsubscript{r}/(10 × N)) = 150 × √(1.67 × 10⁻⁶ / 2.83 × 10⁻⁵) =
150 × √0.059 = 150 × 0.243 = \textbf{36.4 m}. For 150 m range at SNR =
10, the system would need approximately (150/36.4)² = 17× more pulse
energy (68 μJ) or averaging of \textasciitilde17 pulses, which at a
pulse rate of 500 kHz takes only 34 μs --- well within the scan time per
point.

\end{examplebox}

\section{17.5 Radar System Comparison}\label{radar-system-comparison}

Selecting the appropriate radar technology requires matching the system
parameters to the application requirements. Frequency band, waveform
type, power level, antenna configuration, and signal processing all
interact to determine what a radar system can and cannot do.

\subsection{17.5.1 Frequency Band
Selection}\label{frequency-band-selection}

Radar frequency bands are designated by letter codes established during
WWII and standardized by IEEE. Lower frequencies provide longer range
and better penetration through weather and foliage but require larger
antennas for a given beamwidth. Higher frequencies offer finer
resolution and more compact hardware but suffer greater atmospheric
attenuation, particularly from rain and atmospheric gases.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1818}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2424}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3182}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Band
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Frequency
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Wavelength
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Properties
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Primary Applications
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
HF & 3--30 MHz & 10--100 m & Over-the-horizon propagation, ionospheric
reflection & OTH radar, ocean surveillance \\
VHF & 30--300 MHz & 1--10 m & Foliage penetration, long range, low
resolution & Early warning, stealth detection \\
UHF & 300 MHz--1 GHz & 30 cm--1 m & Good range, moderate resolution &
Wind profilers, foliage penetration \\
L & 1--2 GHz & 15--30 cm & Good range, weather tolerance & Long-range
surveillance, ATC (SSR) \\
S & 2--4 GHz & 7.5--15 cm & Balance of range and resolution & ATC (PSR),
weather radar (NEXRAD) \\
C & 4--8 GHz & 3.75--7.5 cm & Good resolution, moderate range & Weather
radar, satellite SAR \\
X & 8--12 GHz & 2.5--3.75 cm & High resolution, moderate rain
attenuation & Marine radar, airborne radar, fire control \\
Ku & 12--18 GHz & 1.7--2.5 cm & Fine resolution, significant rain
attenuation & Satellite altimetry, mapping \\
K & 18--27 GHz & 1.1--1.7 cm & Water vapor absorption at 22.24 GHz &
Rarely used (absorption band) \\
Ka & 27--40 GHz & 7.5--11 mm & Very fine resolution, high rain
attenuation & Airport surface radar, cloud radar \\
W & 75--110 GHz & 2.7--4 mm & Extremely fine resolution, compact &
Automotive (77 GHz), security screening \\
\end{longtable}
}

The atmospheric attenuation window at 77 GHz (between the oxygen
absorption line at 60 GHz and oxygen absorption line at 118.75 GHz)
makes this frequency ideal for automotive radar: it provides
millimeter-wave resolution with acceptable atmospheric loss for ranges
up to 300 m. Rain attenuation becomes significant above X-band --- at 10
mm/h rainfall, the attenuation (per ITU-R P.838-3) is approximately
0.002 dB/km at S-band, 0.22 dB/km at X-band, and \textasciitilde1.3
dB/km at Ka-band, which is why weather radars use S-band or C-band to
see through heavy precipitation.

\begin{examplebox}

\textbf{Example 17.5.1:} A radar system must detect aircraft at 200 km
range with 100 m range resolution. The antenna aperture is limited to 3
m. Determine (a) the minimum bandwidth required, (b) the beamwidth at
S-band (3 GHz), X-band (10 GHz), and Ku-band (15 GHz), (c) which band
offers the best compromise, and (d) the rain attenuation at each band
for moderate rain (4 mm/h) over 200 km.

\textbf{Solution:}

(a) Minimum bandwidth: B = c/(2ΔR) = 3 × 10⁸ / (2 × 100) = \textbf{1.5
MHz}

(b) Beamwidth (θ ≈ 70λ/D):\\
S-band: θ = 70 × 0.10 / 3 = \textbf{2.33°}\\
X-band: θ = 70 × 0.03 / 3 = \textbf{0.70°}\\
Ku-band: θ = 70 × 0.02 / 3 = \textbf{0.47°}

(c) \textbf{S-band} offers the best compromise: the 2.33° beamwidth
provides adequate angular resolution for aircraft tracking, atmospheric
attenuation is minimal, and the frequency is allocated for surveillance
radar. X-band would give a narrower beam but suffers more rain
attenuation, limiting all-weather performance.

(d) Approximate two-way rain attenuation for 4 mm/h over 200 km:\\
S-band: 0.00075 dB/km × 400 km = \textbf{0.30 dB} (negligible)\\
X-band: 0.071 dB/km × 400 km = \textbf{28 dB} (severe --- reduces
detection range by \textasciitilde80\%, from 200 km to \textasciitilde40
km)\\
Ku-band: 0.2 dB/km × 400 km = \textbf{80 dB} (completely blocks the
signal in heavy rain)

\end{examplebox}

\subsection{17.5.2 Radar Systems
Comparison}\label{radar-systems-comparison}

The following table summarizes key parameters across common radar
applications, illustrating how different requirements drive
fundamentally different system designs.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1170}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1383}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1915}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1277}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2234}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1489}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0532}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Parameter
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
ATC (ASR-11)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weather (NEXRAD)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Marine Nav
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Automotive (77 GHz)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Police Speed
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
GPR
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Frequency} & 2.8 GHz (S) & 2.8 GHz (S) & 9.4 GHz (X) & 77 GHz
(W) & 10.5 GHz (X) & 400 MHz--4 GHz \\
\textbf{Waveform} & Pulsed & Pulsed & Pulsed & FMCW & CW & Impulse
(UWB) \\
\textbf{Peak power} & 25 kW & 750 kW & 25 kW & 10 mW & 100 mW & 10--100
mW \\
\textbf{Range} & 111 km & 460 km & 75 km & 300 m & 300 m & 0.1--50 m \\
\textbf{Range resolution} & 150 m & 250 m & 75 m & 4 cm & N/A (CW) &
5--50 cm \\
\textbf{Antenna} & Reflector (5 m) & Dish (8.5 m) & Slotted array &
Patch array & Horn/patch & Bowtie/horn \\
\textbf{Scan} & Mechanical 360° & Mechanical 360° & Mechanical 360° &
Electronic ±8° & Fixed beam & Manual sweep \\
\textbf{Doppler} & Yes (MTD) & Yes (dual-pol) & Optional & Yes & Yes
(primary) & No \\
\textbf{Cost} & \$2--5M & \$5--10M & \$2--20K & \$10--50 & \$200--2K &
\$10--50K \\
\textbf{Key metric} & P\textsubscript{d} at range & Reflectivity (dBZ) &
Target detection & Range, velocity & Velocity accuracy & Depth,
resolution \\
\end{longtable}
}

Key observations from the comparison:

\textbf{Power spans 8 orders of magnitude} --- from 10 mW (automotive
FMCW) to 750 kW (NEXRAD) --- driven by the R⁴ range dependence. The
NEXRAD radar must detect weak distributed targets (raindrops) at
hundreds of kilometers, while automotive radar needs only 300 m range
with strong reflectors (vehicles).

\textbf{Waveform matches the application} --- Pulsed radar dominates
long-range systems where high peak power and unambiguous range are
critical. FMCW dominates short-range applications where low cost, high
resolution, and simultaneous range-velocity are needed. CW is sufficient
when only velocity measurement is required.

\textbf{Antenna size is proportional to range/frequency} --- The NEXRAD
8.5 m dish produces a 1° beam at S-band for precise storm cell location,
while the automotive 77 GHz patch array achieves a comparable 4° beam
from a package smaller than a smartphone.

\begin{examplebox}

\textbf{Example 17.5.2:} A system engineer must select a radar for a
harbor surveillance application requiring detection of small boats (RCS
= 2 m²) at 10 km range in moderate rain (4 mm/h), with a range
resolution of 10 m and a budget of \$50K. Evaluate whether (a) X-band
pulsed, (b) S-band pulsed, or (c) X-band FMCW is the better choice.

\textbf{Solution:}

(a) \textbf{X-band pulsed} (9.4 GHz): Well-established marine radar
technology. Range resolution = 10 m requires τ\textsubscript{p} = 67 ns
or pulse compression. Rain attenuation at X-band in 4 mm/h rain over 10
km (two-way, 20 km path) ≈ 0.06 × 20 = \textbf{1.2 dB} --- acceptable.
Commercial marine radars in this class cost \$5--20K. \textbf{Best
choice for this application.}

(b) \textbf{S-band pulsed} (3 GHz): Rain attenuation is negligible (0.1
dB two-way), but achieving 10 m resolution requires a bandwidth of 15
MHz (pulse width 67 ns) and the antenna must be 3× larger for the same
beamwidth. S-band harbor radars cost \$100--500K --- \textbf{over
budget}.

(c) \textbf{X-band FMCW}: Could achieve 10 m resolution with only 15 MHz
bandwidth and milliwatt power levels. However, achieving 10 km range
with FMCW requires careful design to manage transmitter-receiver leakage
and phase noise. Emerging solid-state X-band FMCW radars in the
\$20--50K range are becoming viable for this application.
\textbf{Possible alternative, but less proven than pulsed.}

\textbf{Recommendation:} X-band pulsed marine radar at \$10--15K, with
25 kW magnetron transmitter, 4-foot slotted waveguide array antenna, and
standard marine radar display. This is a mature, proven technology that
meets all requirements within budget.

\end{examplebox}

\chapter{Chapter 18}\label{chapter-18}

\chapter{Optics}\label{optics}

Optics is the branch of physics and engineering concerned with the
generation, propagation, manipulation, and detection of light ---
electromagnetic radiation in and near the visible spectrum (roughly
380--750 nm wavelength). For electrical engineers, optics is
foundational to fiber-optic communications, laser systems, imaging
sensors, lidar, photovoltaics, and display technologies. The field spans
geometric optics (ray-based analysis of lenses and mirrors), wave optics
(interference, diffraction, and polarization phenomena), and photonics
(the generation and detection of photons using semiconductor devices).
This chapter covers the optical principles most relevant to electrical
engineering practice, from Snell's law and lens equations to laser
operation, photodetector design, fiber-optic communication, and optical
system engineering.

\section{18.1 Geometric Optics}\label{geometric-optics}

Geometric optics treats light as rays that travel in straight lines
through uniform media, bending at interfaces according to the laws of
reflection and refraction. This approximation is valid when the optical
elements (lenses, mirrors, apertures) are much larger than the
wavelength of light, making it the primary design tool for imaging
systems, illumination optics, and optical instruments. Ray tracing
through sequences of surfaces allows engineers to predict image
location, magnification, and aberrations without solving Maxwell's
equations.

\subsection{18.1.1 Reflection and Refraction (Snell's
Law)}\label{reflection-and-refraction-snells-law}

When a light ray encounters the boundary between two media with
different refractive indices, part of the ray is reflected and part is
transmitted (refracted). The law of reflection states that the angle of
incidence equals the angle of reflection (θ\textsubscript{i} =
θ\textsubscript{r}), both measured from the surface normal. Snell's law
governs the refraction angle: n₁ sin(θ₁) = n₂ sin(θ₂), where n₁ and n₂
are the refractive indices of the incident and transmitted media. The
refractive index n = c/v relates the speed of light in vacuum (c = 3 ×
10⁸ m/s) to its speed v in the medium. Common refractive indices include
air (n ≈ 1.000), water (n ≈ 1.333), glass (n ≈ 1.5), and silicon (n ≈
3.5 at 1550 nm). When light passes from a denser to a less dense medium
(n₁ \textgreater{} n₂), total internal reflection occurs at angles
greater than the critical angle θ\textsubscript{c} = arcsin(n₂/n₁) ---
the principle underlying optical fiber waveguiding.

\begin{examplebox}

\textbf{Example 18.1.1:} A light ray in glass (n₁ = 1.52) strikes the
glass-air interface at an angle of 35° from the normal. Determine the
refraction angle in air and the critical angle for total internal
reflection.

\textbf{Solution:}\\
Applying Snell's law: n₁ sin(θ₁) = n₂ sin(θ₂), so 1.52 × sin(35°) = 1.00
× sin(θ₂).\\
sin(θ₂) = 1.52 × 0.5736 = 0.8719.\\
θ₂ = arcsin(0.8719) = 60.7°.\\
The refracted ray bends away from the normal as expected when entering a
less dense medium.\\
Critical angle: θ\textsubscript{c} = arcsin(n₂/n₁) = arcsin(1.00/1.52) =
arcsin(0.6579) = 41.1°.\\
Since 35° \textless{} 41.1°, the ray is below the critical angle and
refraction occurs. At angles ≥ 41.1°, total internal reflection would
occur.

\end{examplebox}

\subsection{18.1.2 Lenses and Imaging}\label{lenses-and-imaging}

A thin lens focuses or diverges light rays according to the thin lens
equation: 1/f = 1/d\textsubscript{o} + 1/d\textsubscript{i}, where f is
the focal length, d\textsubscript{o} is the object distance, and
d\textsubscript{i} is the image distance (all measured from the lens).
Converging (convex) lenses have positive focal lengths and bring
parallel rays to a real focus, while diverging (concave) lenses have
negative focal lengths and cause parallel rays to appear to diverge from
a virtual focus. The lateral magnification is m =
-d\textsubscript{i}/d\textsubscript{o}, where a negative value indicates
an inverted image. The lensmaker's equation relates the focal length to
the lens geometry: 1/f = (n - 1){[}1/R₁ - 1/R₂{]}, where n is the
refractive index and R₁, R₂ are the radii of curvature of the two
surfaces. For multi-element lens systems, the combined focal length of
two thin lenses separated by distance d is found from:
1/f\textsubscript{total} = 1/f₁ + 1/f₂ - d/(f₁ × f₂). The f-number (f/\#
= f/D, where D is the aperture diameter) determines the light-gathering
ability and depth of field of the lens.

\begin{examplebox}

\textbf{Example 18.1.2:} A converging lens with focal length f = 50 mm
forms an image of an object placed 200 mm from the lens. Find the image
distance, magnification, and determine whether the image is real or
virtual, upright or inverted.

\textbf{Solution:}\\
Using the thin lens equation: 1/d\textsubscript{i} = 1/f -
1/d\textsubscript{o} = 1/50 - 1/200 = (4 - 1)/200 = 3/200.\\
d\textsubscript{i} = 200/3 = 66.7 mm.\\
Since d\textsubscript{i} is positive, the image is real (formed on the
opposite side of the lens from the object).\\
Magnification: m = -d\textsubscript{i}/d\textsubscript{o} = -66.7/200 =
-0.333.\\
The negative magnification indicates the image is inverted, and
\textbar m\textbar{} = 0.333 means the image is one-third the size of
the object.\\
This is the typical configuration for a camera lens imaging a distant
scene.

\end{examplebox}

\subsection{18.1.3 Mirrors and Curved
Surfaces}\label{mirrors-and-curved-surfaces}

Curved mirrors follow the mirror equation: 1/f = 1/d\textsubscript{o} +
1/d\textsubscript{i}, which is identical in form to the thin lens
equation but with different sign conventions. For a spherical mirror,
the focal length is f = R/2, where R is the radius of curvature
(positive for concave mirrors, negative for convex). Concave
(converging) mirrors focus parallel rays to a real focal point in front
of the mirror, making them useful for telescopes, solar concentrators,
and satellite dish feeds. Convex (diverging) mirrors produce virtual,
upright, reduced images and are used for wide-angle viewing (vehicle
side mirrors, security mirrors). Parabolic mirrors eliminate spherical
aberration for on-axis rays by ensuring all parallel rays converge to a
single focal point, making them the preferred shape for astronomical
telescopes and high-power laser focusing systems. The reflectance at a
surface depends on the materials and angle of incidence; metallic
coatings (aluminum, silver, gold) provide broadband reflectivity, while
dielectric multilayer coatings achieve very high reflectivity
(\textgreater{} 99.9\%) at specific wavelengths.

\begin{examplebox}

\textbf{Example 18.1.3:} A concave mirror has a radius of curvature R =
40 cm. An object is placed 30 cm from the mirror. Find the image
distance, magnification, and describe the image.

\textbf{Solution:}\\
Focal length: f = R/2 = 40/2 = 20 cm.\\
Mirror equation: 1/d\textsubscript{i} = 1/f - 1/d\textsubscript{o} =
1/20 - 1/30 = (3 - 2)/60 = 1/60.\\
d\textsubscript{i} = 60 cm. The positive image distance means the image
is real (in front of the mirror).\\
Magnification: m = -d\textsubscript{i}/d\textsubscript{o} = -60/30 =
-2.0.\\
The image is inverted (negative m) and twice the size of the object
(\textbar m\textbar{} = 2).\\
The object is between f and 2f from the mirror, producing a magnified
real image beyond 2f. This configuration is used in dental examination
mirrors and projectors where a real, enlarged image is needed. Shaving
and makeup mirrors instead require the object inside the focal length
(d\textsubscript{o} \textless{} f), which produces a virtual, upright,
magnified image.

\end{examplebox}

\subsection{18.1.4 Prisms and Dispersive
Elements}\label{prisms-and-dispersive-elements}

A prism separates white light into its constituent wavelengths by
exploiting the wavelength dependence of the refractive index (material
dispersion). When a collimated beam enters a prism at angle
θ\textsubscript{i}, each wavelength refracts by a different amount
according to Snell's law, producing an angular spread of colors at the
exit face. The angular dispersion of a prism is dθ/dλ = (t/d)(dn/dλ),
where t is the base length, d is the beam diameter, and dn/dλ is the
material dispersion of the glass. For a prism at minimum deviation
(where the ray passes symmetrically through the prism), the deviation
angle is δ\textsubscript{min} = 2 arcsin(n sin(α/2)) − α, where α is the
prism apex angle. Common prism materials include BK7 glass (n ≈ 1.517 at
546 nm, low dispersion), SF11 flint glass (n ≈ 1.785, high dispersion
for greater spectral separation), and fused silica (n ≈ 1.458, excellent
UV transmission for spectrometry). Prisms are used in spectrometers,
wavelength tuning of lasers, beam steering, and binoculars (Porro and
roof prisms for image inversion without dispersion).

Diffraction gratings provide much higher spectral resolution than prisms
by exploiting the interference of light diffracted from thousands of
periodic grooves. The grating equation d sin(θ\textsubscript{m}) = mλ
(where d is the groove spacing, m is the diffraction order) determines
the angles at which constructive interference occurs for each
wavelength. The resolving power R = mN (where N is the total number of
illuminated grooves) determines the ability to distinguish closely
spaced wavelengths: Δλ\textsubscript{min} = λ/R. A typical
research-grade grating with 1200 grooves/mm and 50 mm illuminated width
has N = 60,000 grooves and resolving power R = 60,000 in first order,
separating wavelengths as close as 0.009 nm at 550 nm. Blazed gratings
concentrate most of the diffracted energy into a single order by angling
the groove facets, achieving efficiencies of 60--90\% at the blaze
wavelength. Volume holographic gratings and arrayed waveguide gratings
(AWGs) are the key dispersive elements in DWDM fiber-optic systems for
wavelength multiplexing and demultiplexing.

\begin{examplebox}

\textbf{Example 18.1.4:} A spectrometer uses a diffraction grating with
600 grooves/mm and a 25 mm illuminated width. Light at λ = 589.0 nm and
λ = 589.6 nm (the sodium D doublet) is analyzed in first order.
Determine (a) the grating spacing, (b) the diffraction angle for 589.0
nm, (c) the resolving power, and (d) whether the grating can resolve the
sodium D doublet.

\textbf{Solution:}

(a) Grating spacing: d = 1/600 mm = 1.667 μm.

(b) Diffraction angle: sin(θ₁) = mλ/d = 1 × 589.0 × 10⁻⁹ / 1.667 × 10⁻⁶
= 0.3534. θ₁ = arcsin(0.3534) = \textbf{20.69°}.

(c) Total grooves: N = 600 × 25 = 15,000. Resolving power: R = mN = 1 ×
15,000 = \textbf{15,000}. Minimum resolvable wavelength difference:
Δλ\textsubscript{min} = λ/R = 589.0/15,000 = 0.0393 nm.

(d) The sodium D doublet separation is Δλ = 589.6 − 589.0 = 0.6 nm.
Since 0.6 nm \textgreater\textgreater{} 0.039 nm, the grating
\textbf{easily resolves} the doublet. The required resolving power would
be only R = 589/0.6 = 982, which needs just 982 grooves --- even a small
grating section would suffice. This grating could resolve lines as close
as 0.039 nm apart, making it suitable for analyzing fine spectral
structure in atomic emission and absorption spectra.

\end{examplebox}

\section{18.2 Wave Optics}\label{wave-optics}

Wave optics treats light as an electromagnetic wave, accounting for
phenomena that geometric optics cannot explain: interference
(constructive and destructive combination of waves), diffraction
(bending of light around obstacles and through apertures), and
polarization (the orientation of the electric field oscillation). These
effects become significant when feature sizes approach the wavelength of
light (hundreds of nanometers for visible light) and are critical to the
design of optical coatings, diffraction gratings, interferometric
sensors, and photolithography systems used in semiconductor fabrication.

\subsection{18.2.1 Interference}\label{interference}

Interference occurs when two or more coherent light waves overlap,
producing a pattern of alternating bright (constructive) and dark
(destructive) regions determined by the phase difference between the
waves. In Young's double-slit experiment, light passing through two
narrow slits separated by distance d produces an interference pattern on
a screen at distance L, with bright fringes at angles θ satisfying d
sin(θ) = mλ (m = 0, ±1, ±2, \ldots) and dark fringes at d sin(θ) = (m +
½)λ. The fringe spacing on the screen is Δy = λL/d.~Thin-film
interference occurs when light reflects from the top and bottom surfaces
of a thin transparent film (e.g., anti-reflection coatings, soap
bubbles), with constructive or destructive interference depending on the
film thickness, refractive index, and wavelength. Anti-reflection
coatings use a quarter-wave thickness (t = λ/4n\textsubscript{film})
with n\textsubscript{film} = √(n₁ × n₂) to cancel reflections by
destructive interference, reducing surface reflections from
\textasciitilde4\% to near zero at the design wavelength.

\begin{examplebox}

\textbf{Example 18.2.1:} A thin anti-reflection coating of MgF₂ (n =
1.38) is applied to a glass lens (n = 1.52). Design the coating for
minimum reflection at λ = 550 nm (green light). Calculate the coating
thickness and the residual reflectance.

\textbf{Solution:}\\
For a quarter-wave anti-reflection coating, the thickness is t = λ / (4
× n\textsubscript{film}) = 550 / (4 × 1.38) = 550 / 5.52 = 99.6 nm.\\
The ideal refractive index for zero reflectance would be
n\textsubscript{ideal} = √(1.00 × 1.52) = √1.52 = 1.233.\\
Since n\textsubscript{MgF₂} = 1.38 ≠ 1.233, the reflectance is not
perfectly zero.\\
The residual reflectance at normal incidence is R =
{[}(n\textsubscript{film}² - n₁ × n₂) / (n\textsubscript{film}² + n₁ ×
n₂){]}² = {[}(1.38² - 1.00 × 1.52) / (1.38² + 1.00 × 1.52){]}² =
{[}(1.904 - 1.52) / (1.904 + 1.52){]}² = {[}0.384 / 3.424{]}² = 0.1121²
= 0.0126 = 1.26\%.\\
This is a significant improvement over the uncoated reflectance of
\textasciitilde4.3\%.

\end{examplebox}

\subsection{18.2.2 Diffraction}\label{diffraction}

Diffraction is the bending and spreading of light waves as they pass
through apertures or around obstacles, a consequence of the
Huygens-Fresnel principle that every point on a wavefront acts as a
source of secondary wavelets. For a single slit of width a, the
far-field (Fraunhofer) diffraction pattern has intensity minima at
angles θ where a sin(θ) = mλ (m = ±1, ±2, \ldots). The angular width of
the central maximum is 2λ/a, which widens as the slit narrows. For a
circular aperture of diameter D (relevant to lenses and telescopes), the
diffraction pattern is an Airy disk with angular radius to the first
minimum of θ = 1.22λ/D. This sets the Rayleigh criterion for angular
resolution --- two point sources can just be resolved when separated by
this angle. Diffraction gratings consist of many equally spaced slits
(or grooves) and produce sharp spectral peaks at angles given by d
sin(θ) = mλ, where d is the grating spacing and m is the diffraction
order, enabling high-resolution wavelength measurement in spectrometers.

\begin{examplebox}

\textbf{Example 18.2.2:} A telescope has an objective lens diameter of D
= 200 mm. Determine the angular resolution limit at λ = 550 nm and the
minimum resolvable separation of two stars at a distance that subtends 1
arc-second.

\textbf{Solution:}\\
Rayleigh criterion: θ\textsubscript{min} = 1.22λ/D = 1.22 × 550 × 10⁻⁹ /
0.200 = 671 × 10⁻⁹ / 0.200 = 3.355 × 10⁻⁶ rad.\\
Converting to arc-seconds: θ = 3.355 × 10⁻⁶ × (206,265 arcsec/rad) =
0.692 arc-seconds.\\
Since 0.692 arcsec \textless{} 1 arcsec, the telescope can resolve two
stars separated by 1 arc-second --- the optics are not the limiting
factor.\\
In practice, atmospheric turbulence (seeing) typically limits
ground-based resolution to 1--2 arc-seconds, which is why adaptive
optics systems are used to correct wavefront distortion.

\end{examplebox}

\subsection{18.2.3 Polarization}\label{polarization-1}

Polarization describes the orientation of the electric field vector in
an electromagnetic wave. In unpolarized light (from the sun or an
incandescent bulb), the electric field oscillates in random directions
perpendicular to the propagation direction. A linear polarizer transmits
only the component of the electric field along its transmission axis,
reducing the intensity of unpolarized light by half (Malus's law: I = I₀
cos²(θ), where θ is the angle between the polarization direction and the
polarizer axis). Polarization by reflection occurs at Brewster's angle
θ\textsubscript{B} = arctan(n₂/n₁), where the reflected light is
completely polarized perpendicular to the plane of incidence. Circular
and elliptical polarization result from two perpendicular linear
components with a phase difference (90° for circular). Quarter-wave
plates convert between linear and circular polarization and are
essential components in optical isolators, CD/DVD readers, and 3D
display systems. Polarization-maintaining fibers and polarization beam
splitters are critical in fiber-optic communication and sensing systems.

\begin{examplebox}

\textbf{Example 18.2.3:} Unpolarized light with intensity I₀ = 100
mW/cm² passes through two linear polarizers. The first polarizer has its
transmission axis vertical, and the second is tilted 60° from vertical.
Find the intensity after each polarizer.

\textbf{Solution:}\\
After the first polarizer, unpolarized light is reduced by half: I₁ =
I₀/2 = 100/2 = 50 mW/cm².\\
The transmitted light is now vertically polarized.\\
After the second polarizer (Malus's law): I₂ = I₁ cos²(60°) = 50 ×
cos²(60°) = 50 × (0.5)² = 50 × 0.25 = 12.5 mW/cm².\\
The overall transmission is I₂/I₀ = 12.5/100 = 12.5\%.\\
If a third polarizer at 30° from vertical were inserted between the two,
it would actually increase the final output --- a counterintuitive
result demonstrating that polarizers can ``rotate'' polarization in
stages.

\end{examplebox}

\subsection{18.2.4 Thin-Film Optical
Coatings}\label{thin-film-optical-coatings}

Thin-film optical coatings exploit interference in multilayer dielectric
stacks to engineer the spectral reflectance and transmittance of optical
surfaces with high precision. While a single quarter-wave layer provides
a basic anti-reflection (AR) coating (§18.2.1), practical applications
require multilayer designs --- alternating high-index (H, e.g., TiO₂, n
≈ 2.3) and low-index (L, e.g., SiO₂, n ≈ 1.46) quarter-wave layers ---
to achieve broadband AR coatings, high-reflectivity (HR) mirrors,
bandpass filters, and dichroic beam splitters. A dielectric HR mirror
using a stack of (HL)\textsuperscript{N}H quarter-wave pairs achieves
reflectivity R =
{[}(n\textsubscript{H}/n\textsubscript{L})\textsuperscript{2N} - 1{]}² /
{[}(n\textsubscript{H}/n\textsubscript{L})\textsuperscript{2N} + 1{]}²,
approaching 99.99\% with sufficient layers (N ≥ 15). Bandpass filters
(also called interference filters) combine HR stacks with a spacer layer
to create a Fabry-Perot cavity that transmits only a narrow wavelength
band --- used in DWDM channel multiplexers, fluorescence microscopy, and
astronomical narrowband imaging. Dichroic mirrors (also called hot/cold
mirrors or color-separating mirrors) use carefully designed multilayer
stacks to reflect one wavelength band while transmitting another,
enabling beam combining in projectors, separating pump and signal
wavelengths in laser systems, and splitting RGB channels in 3-CCD
cameras. All thin-film coatings are deposited by physical vapor
deposition (PVD) techniques --- electron-beam evaporation, ion-beam
sputtering, or magnetron sputtering --- with in-situ optical monitoring
to control layer thicknesses to sub-nanometer precision.

\begin{examplebox}

\textbf{Example 18.2.4:} A dielectric HR mirror for a Nd:YAG laser (λ =
1064 nm) uses alternating quarter-wave layers of TiO₂
(n\textsubscript{H} = 2.30) and SiO₂ (n\textsubscript{L} = 1.46) on a
glass substrate. Calculate the reflectivity for N = 8 and N = 15 layer
pairs, and the physical thickness of each quarter-wave layer.

\textbf{Solution:}\\
Reflectivity for N = 8: ratio = n\textsubscript{H}/n\textsubscript{L} =
2.30/1.46 = 1.575.\\
R₈ = {[}(1.575¹⁶ - 1) / (1.575¹⁶ + 1){]}².\\
1.575¹⁶ = (1.575⁴)⁴ = (6.159)⁴ = (6.159²)² = (37.93)² = 1,438.7.\\
R₈ = {[}(1438.7 - 1) / (1438.7 + 1){]}² = {[}1437.7 / 1439.7{]}² =
{[}0.99861{]}² = 0.99722 = 99.72\%.\\
For N = 15: 1.575³⁰ = 1.575¹⁶ × 1.575¹⁴.\\
1.575¹⁴ = 1.575¹⁶ / 1.575² = 1438.7 / 2.481 = 579.9.\\
1.575³⁰ = 1438.7 × 579.9 = 834,190.\\
R₁₅ = {[}(834,190 - 1) / (834,190 + 1){]}² ≈ (0.999998)² = 99.9996\%.\\
Quarter-wave physical thicknesses: t\textsubscript{H} =
λ/(4n\textsubscript{H}) = 1064/(4 × 2.30) = 115.7 nm, t\textsubscript{L}
= λ/(4n\textsubscript{L}) = 1064/(4 × 1.46) = 182.2 nm.\\
Total stack thickness for 15 pairs (30 layers + 1): 15 × (115.7 + 182.2)
+ 115.7 = 15 × 297.9 + 115.7 = 4,584 nm ≈ 4.6 μm.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-18-2-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch18_mirror_reflectivity.png}

\caption{Figure 18.2.4: Dielectric Mirror Reflectivity}

\end{figure}

\section{18.3 Lasers}\label{lasers}

Lasers (Light Amplification by Stimulated Emission of Radiation) produce
coherent, monochromatic, and highly directional light through the
process of stimulated emission in a gain medium placed within an optical
resonator. Unlike thermal light sources, laser output has extremely
narrow spectral linewidth, spatial coherence across the entire beam, and
temporal coherence over long path lengths. These properties make lasers
indispensable in fiber-optic communications (transmitter sources),
manufacturing (cutting, welding, 3D printing), medicine (surgery,
diagnostics), metrology (interferometry, lidar), and semiconductor
fabrication (photolithography).

\subsection{18.3.1 Stimulated Emission and Laser
Operation}\label{stimulated-emission-and-laser-operation}

Laser operation requires three conditions: a gain medium with a
population inversion (more atoms in the excited state than the ground
state), an energy source (pump) to maintain the inversion, and an
optical resonator (cavity) to provide feedback. In stimulated emission,
an incoming photon with energy E = hf (matching the transition energy)
triggers an excited atom to emit a second photon with identical
frequency, phase, direction, and polarization --- this is the
amplification mechanism. The gain medium can be a gas (HeNe, CO₂,
argon), solid crystal (Nd:YAG, Ti:sapphire), semiconductor (GaAs,
InGaAsP), liquid dye, or optical fiber doped with rare earth ions
(erbium, ytterbium). The optical cavity, typically formed by two mirrors
(one highly reflective, one partially transmitting as the output
coupler), provides the feedback that allows stimulated emission to build
up into a coherent beam. The threshold condition requires that the
round-trip gain equals the round-trip losses (mirror transmission,
scattering, absorption). Above threshold, the output power increases
linearly with pump power, characterized by the slope efficiency
η\textsubscript{s}.

\begin{examplebox}

\textbf{Example 18.3.1:} A Nd:YAG laser (λ = 1064 nm) has a cavity with
mirrors of reflectivity R₁ = 99.9\% and R₂ = 95\% (output coupler),
internal round-trip loss of 2\%, and a small-signal gain coefficient of
g₀ = 0.5 cm⁻¹ in a 10 cm gain medium. Determine whether the laser
reaches threshold.

\textbf{Solution:}\\
Round-trip gain: G = exp(2 × g₀ × L) = exp(2 × 0.5 × 10) = exp(10) =
22,026 (expressed as single-pass gain, the gain is exp(g₀L) = exp(5) =
148.4).\\
Round-trip loss factor: the light must reflect from both mirrors and
survive internal losses: δ = R₁ × R₂ × (1 - internal loss) = 0.999 ×
0.95 × 0.98 = 0.930.\\
The threshold condition requires that the single-pass gain squared times
the loss factor equals 1: G²\textsubscript{threshold} × δ = 1, so
G\textsubscript{threshold} = 1/√δ = 1/√0.930 = 1.037.\\
The actual single-pass gain is exp(5) = 148.4 \textgreater\textgreater{}
1.037.\\
The laser is far above threshold, so it will oscillate strongly. In
practice, gain saturation will clamp the intracavity gain to the
threshold value.

\end{examplebox}

\subsection{18.3.2 Laser Types and
Characteristics}\label{laser-types-and-characteristics}

Lasers are categorized by their gain medium, which determines the output
wavelength, power capability, efficiency, and beam quality. \textbf{Gas
lasers} include the helium-neon (HeNe, 632.8 nm, milliwatts, excellent
beam quality for alignment and interferometry), CO₂ (10.6 μm, kilowatts,
industrial cutting and welding), and excimer lasers (UV, 193--351 nm,
photolithography and eye surgery). \textbf{Solid-state lasers} use
crystalline or glass hosts doped with ions: Nd:YAG (1064 nm, Q-switched
for pulsed applications), Ti:sapphire (tunable 650--1100 nm, ultrafast
pulses), and fiber lasers (ytterbium or erbium-doped, highly efficient,
scalable to multi-kilowatt CW power). \textbf{Semiconductor lasers}
(laser diodes) are the most widely used laser type by volume, spanning
wavelengths from UV (GaN, 405 nm) to mid-IR (InGaAsSb), with direct
electrical pumping, compact size, high efficiency (\textgreater{} 50\%),
and modulation bandwidth exceeding 10 GHz --- making them the standard
source for fiber-optic communications, barcode scanners, laser printers,
and optical disc drives. \textbf{VCSELs} (Vertical-Cavity
Surface-Emitting Lasers) emit perpendicular to the chip surface,
enabling wafer-level testing and 2D array fabrication for high-speed
data links and 3D sensing (face recognition, lidar).

\begin{examplebox}

\textbf{Example 18.3.2:} A semiconductor laser diode emits 20 mW of
optical power at λ = 1550 nm when driven with 50 mA at 1.5 V. Calculate
the wall-plug efficiency, the photon energy, and the number of photons
emitted per second.

\textbf{Solution:}\\
Electrical input power: P\textsubscript{elec} = I × V = 0.050 × 1.5 = 75
mW.\\
Wall-plug efficiency: η = P\textsubscript{opt}/P\textsubscript{elec} =
20/75 = 26.7\%.\\
Photon energy: E = hc/λ = (6.626 × 10⁻³⁴ × 3 × 10⁸) / (1550 × 10⁻⁹) =
1.988 × 10⁻²⁵ / 1.55 × 10⁻⁶ = 1.282 × 10⁻¹⁹ J = 0.80 eV.\\
Photon rate: N = P\textsubscript{opt}/E = 20 × 10⁻³ / 1.282 × 10⁻¹⁹ =
1.56 × 10¹⁷ photons/s.\\
Each photon carries very little energy, so even modest optical power
involves enormous photon counts.

\end{examplebox}

\subsection{18.3.3 Laser Safety
Classifications}\label{laser-safety-classifications}

Lasers are classified by their potential to cause eye or skin injury,
following the IEC 60825-1 / ANSI Z136.1 standards. \textbf{Class 1}
lasers are safe under all conditions of normal use (e.g., enclosed
CD/DVD players, laser printers). \textbf{Class 1M} are safe for the
unaided eye but may be hazardous when viewed with optical instruments
(magnifiers or telescopes). \textbf{Class 2} emit visible light
(400--700 nm) up to 1 mW, relying on the blink reflex (0.25 s) for eye
protection. \textbf{Class 3R} (formerly 3A) emit up to 5 mW visible or
higher power at other wavelengths, posing a slight risk of eye injury.
\textbf{Class 3B} lasers (5--500 mW CW) can cause immediate eye injury
from direct or specular reflection and require protective eyewear and
controlled access. \textbf{Class 4} lasers exceed 500 mW and can cause
eye and skin burns, ignite materials, and produce hazardous fumes ---
requiring full engineering controls, interlocks, eyewear, and training.
The Maximum Permissible Exposure (MPE) depends on wavelength, exposure
duration, and beam characteristics. The Nominal Ocular Hazard Distance
(NOHD) is the distance beyond which the beam irradiance falls below the
MPE.

\begin{examplebox}

\textbf{Example 18.3.3:} A Class 3B laser emits a 100 mW beam at 532 nm
with a beam divergence of 1.5 mrad. The MPE for a 0.25 s exposure at 532
nm is 2.5 mW/cm². Calculate the NOHD.

\textbf{Solution:}\\
The beam diameter at distance r from the laser is approximately d(r) =
d₀ + θ × r, where d₀ is the initial beam diameter (assume small,
\textasciitilde1 mm) and θ is the full-angle divergence.\\
The beam area is A = π(d/2)².\\
At the NOHD, the irradiance equals the MPE: P/(πr²θ²/4) = MPE
(approximating d ≈ θr for large r).\\
Solving: r = √(4P/(π × θ² × MPE)) = √(4 × 0.1 / (π × (1.5 × 10⁻³)² × 25
W/m²)) = √(0.4 / (π × 2.25 × 10⁻⁶ × 25)) = √(0.4 / 1.767 × 10⁻⁴) =
√(2264) = 47.6 m.\\
(MPE = 2.5 mW/cm² = 25 W/m² in SI units.)\\
The laser beam remains hazardous to the naked eye for approximately 48
meters.\\
Protective eyewear rated OD ≥ 2 at 532 nm is typically required for
Class 3B green lasers within the NOHD; the exact OD depends on working
distance and actual beam irradiance at that point (OD =
log₁₀(I\textsubscript{beam}/MPE)).

\end{examplebox}

\subsection{18.3.4 Fiber Lasers and Ultrafast
Lasers}\label{fiber-lasers-and-ultrafast-lasers}

Fiber lasers use an optical fiber doped with rare-earth ions (ytterbium,
erbium, thulium) as the gain medium, pumped by semiconductor laser
diodes coupled into the fiber cladding. The fiber geometry provides
excellent thermal management (high surface-area-to-volume ratio), long
interaction length (meters of gain fiber), and inherent single-mode beam
quality (M² ≈ 1.0) because the fiber core acts as a spatial filter.
Ytterbium-doped fiber lasers operating at 1060--1080 nm dominate
industrial laser cutting, welding, and additive manufacturing, with CW
powers now exceeding 100 kW from a single fiber and wall-plug
efficiencies of 30--50\% --- far superior to CO₂ lasers (10--15\%
efficiency) for metal processing. The beam is delivered through a
flexible fiber cable (50--200 μm core), eliminating the complex
mirror-based beam delivery systems required by CO₂ lasers. Erbium-doped
fiber lasers and amplifiers (EDFAs) at 1530--1565 nm are the backbone of
optical telecommunications (§18.5.3), while thulium-doped fibers
(1900--2100 nm) serve medical and materials processing applications in
the ``eye-safe'' mid-IR band.

Ultrafast lasers produce pulses as short as femtoseconds (10⁻¹⁵ s)
through the technique of mode-locking, in which a large number of
longitudinal cavity modes are forced to oscillate in phase. The
resulting pulse width is inversely proportional to the laser bandwidth:
τ\textsubscript{p} ≈ 0.44/Δf (for transform-limited Gaussian pulses). A
Ti:sapphire laser with a 100 nm bandwidth centered at 800 nm produces
pulses as short as \textasciitilde10 fs, with peak powers exceeding
gigawatts despite pulse energies of only nanojoules. Chirped pulse
amplification (CPA) --- invented by Strickland and Mourou (2018 Nobel
Prize) --- stretches the ultrashort pulse temporally before
amplification (to avoid fiber/crystal damage), amplifies the stretched
pulse, then compresses it back to femtosecond duration, achieving peak
powers up to petawatts (10¹⁵ W). Applications of ultrafast lasers
include precision micromachining (cold ablation with minimal
heat-affected zone), multiphoton microscopy in biology, attosecond
science, optical coherence tomography (OCT) in ophthalmology, and
frequency comb generation for precision spectroscopy and optical clocks.

\begin{examplebox}

\textbf{Example 18.3.4:} A mode-locked ytterbium fiber laser produces
200 fs pulses at a repetition rate of 80 MHz with an average output
power of 1.6 W at λ = 1040 nm. Calculate (a) the pulse energy, (b) the
peak power, (c) the spectral bandwidth required for transform-limited
pulses, and (d) the number of longitudinal modes locked together (cavity
length = 1.875 m).

\textbf{Solution:}

(a) Pulse energy: E = P\textsubscript{avg}/f\textsubscript{rep} = 1.6 /
(80 × 10⁶) = \textbf{20 nJ} per pulse.

(b) Peak power: P\textsubscript{peak} = E/τ\textsubscript{p} = 20 × 10⁻⁹
/ 200 × 10⁻¹⁵ = \textbf{100 kW}. From just 20 nJ of energy, the
ultrashort pulse duration concentrates the energy into an enormous peak
power.

(c) Transform-limited bandwidth: Δf = 0.44/τ\textsubscript{p} = 0.44 /
(200 × 10⁻¹⁵) = 2.2 × 10¹² Hz = \textbf{2.2 THz}. In wavelength: Δλ =
λ²Δf/c = (1040 × 10⁻⁹)² × 2.2 × 10¹² / (3 × 10⁸) = \textbf{7.93 nm}. The
laser must support at least this bandwidth for the pulses to be
transform-limited.

(d) Cavity mode spacing: Δf\textsubscript{mode} = c/(2L) = 3 × 10⁸/(2 ×
1.875) = 80 MHz (matching the repetition rate, as expected). Number of
locked modes: N = Δf/Δf\textsubscript{mode} = 2.2 × 10¹²/(80 × 10⁶) =
\textbf{27,500 modes} oscillating in phase. The coherent addition of
27,500 modes at a single instant is what creates the enormous peak power
relative to the average power.

\end{examplebox}

\section{18.4 Photodetectors}\label{photodetectors}

Photodetectors convert optical signals into electrical signals, forming
the receiver side of any optical system --- from fiber-optic
communication links to digital cameras and solar cells. The fundamental
mechanism is the absorption of photons by a semiconductor material,
generating electron-hole pairs that produce a photocurrent proportional
to the incident optical power. Key performance parameters include
responsivity (A/W), quantum efficiency (percentage of photons that
generate carriers), bandwidth (speed of response), dark current (noise
current without illumination), and noise-equivalent power (NEP, the
minimum detectable optical power).

\subsection{18.4.1 Photodiodes (PIN and
Avalanche)}\label{photodiodes-pin-and-avalanche}

A PIN photodiode consists of a p-type, intrinsic (undoped), and n-type
semiconductor layer. Photons absorbed in the wide intrinsic region
generate electron-hole pairs that are swept out by the reverse-bias
electric field, producing a photocurrent. The responsivity is R =
ηqλ/(hc), where η is the quantum efficiency, q is the electron charge, λ
is the wavelength, h is Planck's constant, and c is the speed of light.
Silicon PIN photodiodes cover the visible to near-IR range (400--1100
nm), while InGaAs devices cover the telecom bands (900--1700 nm). The
bandwidth is limited by the carrier transit time across the intrinsic
region and the RC time constant: f\textsubscript{3dB} ≈ 1/(2π ×
max(t\textsubscript{transit}, RC)). Avalanche photodiodes (APDs) provide
internal gain M (typically 10--100) through impact ionization, where
accelerated carriers create additional electron-hole pairs. The APD
responsivity is R\textsubscript{APD} = M × R\textsubscript{PIN}, but the
avalanche process adds excess noise characterized by the excess noise
factor F(M). APDs are used in long-haul fiber receivers and lidar where
the internal gain improves the signal-to-noise ratio.

\begin{examplebox}

\textbf{Example 18.4.1:} An InGaAs PIN photodiode has a quantum
efficiency of 85\% at λ = 1550 nm. Calculate the responsivity and the
photocurrent generated by 10 μW of incident optical power.

\textbf{Solution:}\\
Responsivity: R = ηqλ/(hc) = 0.85 × 1.602 × 10⁻¹⁹ × 1550 × 10⁻⁹ / (6.626
× 10⁻³⁴ × 3 × 10⁸) = 0.85 × 1.602 × 10⁻¹⁹ × 1.55 × 10⁻⁶ / (1.988 ×
10⁻²⁵) = 0.85 × 1.249 = 1.062 A/W.\\
Photocurrent: I\textsubscript{ph} = R × P = 1.062 × 10 × 10⁻⁶ = 10.62
μA.\\
For comparison, a silicon detector at 850 nm with η = 0.7 would have R =
0.7 × 1.602 × 10⁻¹⁹ × 850 × 10⁻⁹ / (1.988 × 10⁻²⁵) = 0.48 A/W --- lower
responsivity because each photon carries more energy at shorter
wavelengths.

\end{examplebox}

\subsection{18.4.2 Phototransistors and
Photomultipliers}\label{phototransistors-and-photomultipliers}

Phototransistors combine a photodiode with a transistor amplifier in a
single device, providing current gain (β, typically 100--1000) at the
expense of bandwidth (usually limited to tens of kHz). The
base-collector junction acts as the photodiode, and the photocurrent is
amplified by the transistor action, making phototransistors suitable for
low-speed applications such as optocouplers, light barriers, and ambient
light sensing. Photomultiplier tubes (PMTs) are vacuum-tube devices that
achieve extremely high gain (10⁶--10⁸) through a cascade of
secondary-emission dynodes. An incident photon strikes the photocathode,
releasing a photoelectron, which is accelerated and multiplied through a
chain of 8--14 dynodes, each multiplying the electron count by a factor
of 3--6. PMTs offer single-photon sensitivity, very low dark current
when cooled, and nanosecond time resolution, making them the detector of
choice for scintillation counters (nuclear physics), fluorescence
spectroscopy, astronomy, and photon-counting applications.

\begin{examplebox}

\textbf{Example 18.4.2:} A photomultiplier tube has 10 dynodes, each
with a secondary emission ratio of δ = 4. Calculate the total gain and
the anode current for an incident photon rate of 10⁶ photons/s, assuming
a photocathode quantum efficiency of 25\%.

\textbf{Solution:}\\
Total gain: M = δ¹⁰ = 4¹⁰ = 1,048,576 ≈ 10⁶.\\
Photoelectron rate: N\textsubscript{pe} = η × photon rate = 0.25 × 10⁶ =
250,000 photoelectrons/s.\\
Anode current: I\textsubscript{anode} = N\textsubscript{pe} × M × q =
2.5 × 10⁵ × 1.049 × 10⁶ × 1.602 × 10⁻¹⁹ = 42.0 × 10⁻⁹ A = 42.0 nA.\\
This measurable current is produced from just 10⁶ photons/s incident on
the cathode, demonstrating the extraordinary sensitivity of PMTs.\\
At this gain, the signal from a single photon produces a pulse of
\textasciitilde10⁶ electrons (160 fC), easily detected by standard
electronics.

\end{examplebox}

\subsection{18.4.3 Image Sensors (CCD and
CMOS)}\label{image-sensors-ccd-and-cmos}

Image sensors are two-dimensional arrays of photodetectors that capture
spatial light patterns for digital imaging. \textbf{CCD} (Charge-Coupled
Device) sensors accumulate photogenerated charge in potential wells
during exposure, then shift the charge packet sequentially through the
array to a single output amplifier for readout. CCDs achieve excellent
noise performance (low read noise), high fill factor, and uniform
response, making them the standard for scientific imaging, astronomy,
and medical imaging. \textbf{CMOS} (Complementary
Metal-Oxide-Semiconductor) image sensors integrate a photodiode and
amplifier circuit at each pixel, enabling parallel readout, lower power
consumption, on-chip signal processing (ADC, noise reduction,
auto-exposure), and integration with other digital circuits on the same
chip. CMOS sensors dominate consumer electronics (smartphones, webcams,
DSLRs) due to lower cost, faster readout, lower power, and the ability
to fabricate the sensor and processing on a single die. Key
specifications include pixel count (megapixels), pixel size (μm),
full-well capacity (electrons), read noise (electrons RMS), dynamic
range (dB), and quantum efficiency as a function of wavelength.

\begin{examplebox}

\textbf{Example 18.4.3:} A CMOS image sensor has 12-megapixel resolution
with 1.4 μm pixel pitch, full-well capacity of 8000 electrons, and read
noise of 2 electrons RMS. Calculate the sensor active area dimensions
(assuming 4:3 aspect ratio) and the dynamic range.

\textbf{Solution:}\\
Total pixels: 12 × 10⁶. For 4:3 aspect ratio: N\textsubscript{x} ×
N\textsubscript{y} = 12 × 10⁶ with N\textsubscript{x}/N\textsubscript{y}
= 4/3.\\
N\textsubscript{y} = √(12 × 10⁶ × 3/4) = √(9 × 10⁶) = 3000.
N\textsubscript{x} = 4000.\\
Sensor dimensions: W = 4000 × 1.4 μm = 5.6 mm, H = 3000 × 1.4 μm = 4.2
mm (a 1/2.3'' class sensor).\\
Dynamic range: DR = 20 × log₁₀(full-well / read noise) = 20 ×
log₁₀(8000/2) = 20 × log₁₀(4000) = 20 × 3.602 = 72.0 dB.\\
This corresponds to approximately 12 stops (72/6.02), meaning the sensor
can capture detail from the darkest shadows to the brightest highlights
across a 4000:1 intensity range.

\end{examplebox}

\subsection{18.4.4 Noise in Optical
Detection}\label{noise-in-optical-detection}

Photodetector noise determines the minimum optical power that can be
reliably detected, setting fundamental limits on fiber-optic link reach,
lidar range, and imaging sensor sensitivity. The dominant noise sources
in optical receivers are \textbf{shot noise}, \textbf{thermal noise},
and \textbf{dark current noise}. Shot noise arises from the discrete
nature of photon arrival and carrier generation: i\textsubscript{shot} =
√(2qI\textsubscript{ph}B), where q is the electron charge,
I\textsubscript{ph} is the photocurrent, and B is the electrical
bandwidth. Thermal (Johnson) noise is generated by the receiver's load
resistance and transimpedance amplifier: i\textsubscript{thermal} =
√(4k\textsubscript{B}TB/R\textsubscript{L}), where k\textsubscript{B} is
Boltzmann's constant, T is the absolute temperature, and
R\textsubscript{L} is the load resistance. Dark current noise behaves as
additional shot noise: i\textsubscript{dark} = √(2qI\textsubscript{d}B).
The total RMS noise current is i\textsubscript{n} =
√(i\textsubscript{shot}² + i\textsubscript{thermal}² +
i\textsubscript{dark}²). The \textbf{noise-equivalent power} (NEP) is
the optical power that produces a signal-to-noise ratio of 1 in a 1 Hz
bandwidth: NEP = i\textsubscript{n}/(R × √B), in units of W/√Hz. The
\textbf{specific detectivity} D* = √A/NEP (where A is the detector area)
allows comparison across detector sizes. For avalanche photodiodes, the
noise is multiplied by the excess noise factor:
i\textsubscript{shot,APD} = M × √(2qI\textsubscript{ph}F(M)B), where
F(M) = M\textsuperscript{x} (x = 0.2--0.7 depending on material). The
optimal APD gain balances the signal amplification against the excess
noise to maximize the SNR.

\begin{examplebox}

\textbf{Example 18.4.4:} An InGaAs PIN photodiode with responsivity R =
1.0 A/W and dark current I\textsubscript{d} = 5 nA is used in a 10 Gbps
receiver with bandwidth B = 7.5 GHz, load resistance R\textsubscript{L}
= 50 Ω, and temperature T = 300 K. Calculate the thermal noise, the
minimum detectable power for SNR = 1 (NEP), and the receiver sensitivity
for BER = 10⁻⁹ (requiring Q = 6, or SNR = Q² ≈ 36).

\textbf{Solution:}\\
Thermal noise: i\textsubscript{thermal} =
√(4k\textsubscript{B}TB/R\textsubscript{L}) = √(4 × 1.381 × 10⁻²³ × 300
× 7.5 × 10⁹ / 50) = √(4 × 1.381 × 10⁻²³ × 300 × 1.5 × 10⁸) = √(2.486 ×
10⁻¹²) = 1.577 μA RMS.\\
Dark current noise: i\textsubscript{dark} = √(2 × 1.602 × 10⁻¹⁹ × 5 ×
10⁻⁹ × 7.5 × 10⁹) = √(1.201 × 10⁻¹⁷) = 3.47 nA (negligible versus
thermal noise).\\
In the thermal-noise-limited regime, minimum detectable power (SNR = 1)
over bandwidth B: P\textsubscript{min} = i\textsubscript{thermal} / R =
1.577 × 10⁻⁶ / 1.0 = 1.577 μW = -28.0 dBm.\\
For BER = 10⁻⁹ (Q = 6): P\textsubscript{sensitivity} = Q ×
i\textsubscript{thermal} / R = 6 × 1.577 × 10⁻⁶ / 1.0 = 9.46 μW = -20.2
dBm.\\
A transimpedance amplifier (TIA) with higher effective
R\textsubscript{L} (e.g., 500 Ω) would reduce thermal noise by √10 and
improve sensitivity by 5 dB.

\end{examplebox}

\section{18.5 Optical Fiber and
Communication}\label{optical-fiber-and-communication}

Optical fiber communication transmits information as modulated light
through glass or plastic fibers, offering enormous bandwidth (terabits
per second), immunity to electromagnetic interference, low attenuation
(\textless{} 0.2 dB/km at 1550 nm), and physical security against
tapping. Optical fibers form the backbone of the global
telecommunications infrastructure, carrying over 95\% of
intercontinental data traffic. While Chapter 15 covers fiber from a
networking perspective (cable types, link budgets, OTDR), this section
examines the underlying optical physics of fiber propagation,
dispersion, and amplification.

\subsection{18.5.1 Fiber Modes and
Propagation}\label{fiber-modes-and-propagation}

An optical fiber guides light by total internal reflection at the
core-cladding boundary, where the core (refractive index n₁) has a
slightly higher index than the surrounding cladding (n₂). The numerical
aperture NA = √(n₁² - n₂²) determines the maximum acceptance angle for
light entering the fiber: θ\textsubscript{max} = arcsin(NA). The V
number (normalized frequency) V = (πd/λ) × NA determines the number of
guided modes, where d is the core diameter. Single-mode fiber (SMF)
operates with V \textless{} 2.405, requiring a small core diameter
(typically 8--10 μm at 1550 nm), and supports only the fundamental LP₀₁
mode --- eliminating intermodal dispersion and enabling long-distance,
high-bandwidth transmission. Multimode fiber (MMF) has a larger core (50
or 62.5 μm), supports hundreds of modes, and is used for shorter links
(\textless{} 2 km) due to modal dispersion limiting bandwidth.
Graded-index multimode fiber uses a parabolic refractive index profile
in the core to equalize the group velocities of different modes,
significantly reducing modal dispersion compared to step-index fiber.

\begin{examplebox}

\textbf{Example 18.5.1:} A step-index single-mode fiber has core
diameter d = 9 μm, core index n₁ = 1.4677, and cladding index n₂ =
1.4624. Calculate the numerical aperture, maximum acceptance angle, and
verify single-mode operation at λ = 1550 nm.

\textbf{Solution:}\\
Numerical aperture: NA = √(n₁² - n₂²) = √(1.4677² - 1.4624²) =
√(0.01553) = 0.1246.\\
Maximum acceptance angle: θ\textsubscript{max} = arcsin(0.1246) =
7.16°.\\
V number: V = πd × NA / λ = π × 9 × 10⁻⁶ × 0.1246 / (1550 × 10⁻⁹) =
3.523 × 10⁻⁶ / 1.55 × 10⁻⁶ = 2.273.\\
Since V = 2.273 \textless{} 2.405, the fiber is single-mode at 1550
nm.\\
At 1310 nm, V = 2.273 × (1550/1310) = 2.690 \textgreater{} 2.405, so the
fiber would support two modes at 1310 nm (though in practice it is
designed to be single-mode at both telecom windows).

\end{examplebox}

\subsection{18.5.2 Attenuation and
Dispersion}\label{attenuation-and-dispersion}

Fiber attenuation is measured in dB/km and limits the maximum
transmission distance before signal regeneration or amplification is
needed. Silica fiber has three low-loss transmission windows: the O-band
centered at 1310 nm (\textasciitilde0.35 dB/km), the C-band at 1550 nm
(\textasciitilde0.20 dB/km, the absolute minimum), and the L-band at
1575--1625 nm (\textasciitilde0.22 dB/km). Attenuation is caused by
Rayleigh scattering (proportional to 1/λ⁴, dominant at shorter
wavelengths), absorption by OH⁻ ions and silica (water peak at 1383 nm,
eliminated in modern low-water-peak fibers), and bending losses
(macro-bends and micro-bends). \textbf{Chromatic dispersion} causes
pulse broadening because different wavelength components travel at
different velocities; it has two contributions: material dispersion
(wavelength dependence of the refractive index) and waveguide dispersion
(wavelength dependence of the mode propagation constant). Standard SMF
has zero chromatic dispersion near 1310 nm and \textasciitilde17
ps/(nm·km) at 1550 nm. Dispersion-shifted fiber (DSF) moves the
zero-dispersion wavelength to 1550 nm. \textbf{Polarization mode
dispersion} (PMD) arises from fiber birefringence causing the two
polarization modes to travel at slightly different velocities, typically
0.1--1.0 ps/√km.

\begin{examplebox}

\textbf{Example 18.5.2:} A single-mode fiber link operates at 1550 nm
over 80 km with fiber attenuation of 0.22 dB/km and chromatic dispersion
of 17 ps/(nm·km). The laser source has a spectral width of 0.1 nm.
Calculate the total attenuation and the pulse broadening due to
chromatic dispersion.

\textbf{Solution:}\\
Total attenuation: α\textsubscript{total} = 0.22 × 80 = 17.6 dB.\\
Chromatic dispersion broadening: Δτ = D × L × Δλ = 17 × 80 × 0.1 = 136
ps.\\
For a 10 Gbps NRZ signal (bit period = 100 ps), this 136 ps broadening
exceeds the bit period, causing severe intersymbol interference.\\
Solutions include: (1) using a narrower linewidth source (DFB laser, Δλ
\textless{} 0.01 nm), reducing broadening to 13.6 ps; (2)
dispersion-compensating fiber (DCF) with negative dispersion to cancel
the accumulated dispersion; or (3) digital signal processing (DSP) at
the receiver for coherent detection systems.

\end{examplebox}

\subsection{18.5.3 Optical Amplifiers and
WDM}\label{optical-amplifiers-and-wdm}

Optical amplifiers boost the signal directly in the optical domain
without converting to electrical and back (O-E-O), enabling long-haul
transmission over thousands of kilometers. The \textbf{erbium-doped
fiber amplifier} (EDFA) is the dominant technology, providing 20--40 dB
gain across the C-band (1530--1565 nm) by pumping a section of
erbium-doped fiber with 980 nm or 1480 nm laser diodes. EDFAs amplify
all wavelength channels simultaneously, making them ideal for
wavelength-division multiplexing (WDM) systems. \textbf{Raman
amplifiers} use stimulated Raman scattering in the transmission fiber
itself (pumped at a wavelength \textasciitilde13 THz below the signal),
providing distributed gain that improves the signal-to-noise ratio.
\textbf{Semiconductor optical amplifiers} (SOAs) are compact and
integrable but suffer from crosstalk between WDM channels due to gain
dynamics. WDM combines multiple wavelength channels onto a single fiber,
with Dense WDM (DWDM) systems carrying 80--160 channels at 50 GHz or 100
GHz spacing, achieving aggregate capacities exceeding 10 Tbps per fiber.
The noise figure of an EDFA is typically 4--6 dB, setting a fundamental
limit on the achievable optical signal-to-noise ratio (OSNR) after
cascaded amplifier spans.

\begin{examplebox}

\textbf{Example 18.5.3:} A DWDM system uses 80 channels at 100 GHz
spacing in the C-band, each modulated at 100 Gbps using coherent
DP-QPSK. The link has 10 amplifier spans of 80 km each, with EDFAs
having 16 dB gain and 5 dB noise figure. Calculate the total capacity
and the OSNR after 10 spans (assuming 0 dBm launch power per channel and
0.2 dB/km fiber loss).

\textbf{Solution:}\\
Total capacity: 80 channels × 100 Gbps = 8 Tbps aggregate.\\
Span loss: 0.2 × 80 = 16 dB (matched by the 16 dB EDFA gain).\\
Using the standard EDFA cascade formula: OSNR = 58 +
P\textsubscript{launch}(dBm) − L\textsubscript{span}(dB) − NF(dB) −
10log₁₀(N) = 58 + 0 − 16 − 5 − 10 = 27 dB.\\
(The 58 dB constant equals −10log₁₀(hfB\textsubscript{ref}) =
−10log₁₀(6.626 × 10⁻³⁴ × 193.1 × 10¹² × 12.5 × 10⁹ × 10³) =
−10log₁₀(1.599 × 10⁻⁶ mW) = +58.0, for reference bandwidth
B\textsubscript{ref} = 12.5 GHz = 0.1 nm at 1550 nm; the ×10³ factor
converts watts to milliwatts, consistent with P\textsubscript{launch} in
dBm.)\\
For DP-QPSK at 100 Gbps, the required OSNR is approximately 12--14 dB,
so the system has 13--15 dB of OSNR margin --- sufficient for reliable
operation.

\end{examplebox}

\subsection{18.5.4 Coherent Optical
Communication}\label{coherent-optical-communication}

Coherent optical communication uses a local oscillator (LO) laser at the
receiver to mix with the incoming signal, recovering both amplitude and
phase information --- unlike direct detection receivers that measure
only optical power (intensity). By preserving the full optical field
(amplitude, phase, and polarization), coherent detection enables
advanced modulation formats that encode multiple bits per symbol,
dramatically increasing spectral efficiency and capacity. The coherent
receiver uses a 90° optical hybrid to split the signal and LO into
in-phase (I) and quadrature (Q) components on both X and Y polarization
tributaries, producing four electrical outputs that are digitized by
high-speed ADCs (typically 64--100 GS/s, 8-bit resolution). Digital
signal processing (DSP) in the receiver ASIC then performs chromatic
dispersion compensation, polarization demultiplexing, carrier frequency
and phase recovery, equalization, and forward error correction (FEC)
decoding --- all in the digital domain.

The key modulation formats are dual-polarization quadrature phase-shift
keying (DP-QPSK, 4 bits/symbol, SE ≈ 2 b/s/Hz), DP-16QAM (8 bits/symbol,
SE ≈ 4 b/s/Hz), and DP-64QAM (12 bits/symbol, SE ≈ 6 b/s/Hz).
Higher-order formats carry more bits per symbol but require higher OSNR
--- DP-QPSK needs approximately 12 dB OSNR at BER = 10⁻² (pre-FEC),
while DP-16QAM needs approximately 18 dB and DP-64QAM approximately 24
dB. Modern coherent transceivers (400G ZR, 400G ZR+, and 800G) operate
at 400--800 Gbps per wavelength on a single fiber pair. The 400G-ZR
standard uses DP-16QAM at \textasciitilde60 GBaud on a single wavelength
in a QSFP-DD pluggable form factor, targeting data center interconnects
(DCI) up to 120 km. Long-haul submarine systems use probabilistic
constellation shaping (PCS) to approach the Shannon limit, adjusting the
symbol probability distribution to maximize mutual information for a
given OSNR.

\begin{examplebox}

\textbf{Example 18.5.4:} A coherent optical transceiver operates at 64
GBaud using DP-16QAM modulation at 1550 nm. Each polarization carries
16QAM (4 bits/symbol), and both X and Y polarizations are used.
Determine (a) the raw data rate before FEC overhead, (b) the net data
rate with 25\% FEC overhead, (c) the spectral efficiency for a 75 GHz
channel spacing, and (d) the required OSNR for BER = 4 × 10⁻²
(soft-decision FEC threshold) assuming 1.5 dB implementation penalty.

\textbf{Solution:}

(a) Raw data rate: 64 GBaud × 4 bits/symbol × 2 polarizations =
\textbf{512 Gbps}.

(b) Net data rate: 512 / 1.25 = \textbf{409.6 Gbps} (approximately 400G
net). The 25\% FEC overhead provides powerful error correction that
allows operation at pre-FEC BER up to \textasciitilde4 × 10⁻²,
correcting to post-FEC BER \textless{} 10⁻¹⁵.

(c) Spectral efficiency: SE = 409.6 / 75 = \textbf{5.46 b/s/Hz}. This
approaches the theoretical maximum for 16QAM (8 b/s/Hz with both
polarizations), reduced by FEC overhead, guard bands, and Nyquist
filtering.

(d) Theoretical required OSNR for DP-16QAM at BER = 4 × 10⁻² is
approximately 15.5 dB (in 0.1 nm reference bandwidth). With 1.5 dB
implementation penalty: required OSNR = 15.5 + 1.5 = \textbf{17.0 dB}.
For a link with EDFAs (NF = 5 dB) and 80 km spans at 0 dBm launch power,
the maximum number of spans is limited by: OSNR = 58 + 0 − 16 − 5 − 10
log₁₀(N) ≥ 17, giving 10 log₁₀(N) ≤ 20, so N ≤ 100 spans or
\textbf{8,000 km} --- sufficient for transoceanic submarine links.

\end{examplebox}

\section{18.6 Optical System Design}\label{optical-system-design}

Optical system design integrates the principles of geometric optics,
wave optics, and photonics to create functional imaging and illumination
systems. Engineers must balance competing requirements: resolution
(limited by diffraction), field of view, light-gathering ability
(f-number), aberration correction, size, weight, and cost. Modern
optical design relies heavily on ray-tracing software (Zemax, Code V)
that propagates thousands of rays through multi-element systems and
optimizes surface curvatures, spacings, and glass types to minimize
aberrations.

\subsection{18.6.1 Optical Power and
Radiometry}\label{optical-power-and-radiometry}

Radiometry quantifies the propagation of electromagnetic radiation
through optical systems using a hierarchy of related quantities.
\textbf{Radiant flux} (Φ, watts) is the total power emitted,
transmitted, or received. \textbf{Irradiance} (E, W/m²) is the power
incident per unit area on a surface. \textbf{Radiant intensity} (I,
W/sr) is the power emitted per unit solid angle from a point source.
\textbf{Radiance} (L, W/(m²·sr)) is the power per unit area per unit
solid angle, and is conserved through lossless optical systems (a
consequence of the brightness theorem). For imaging systems, the image
irradiance is E\textsubscript{image} = (π/4) × L × (1/f\#²), showing
that lower f-numbers produce brighter images. \textbf{Photometry}
weights radiometric quantities by the human eye's spectral response (the
luminous efficiency function V(λ), peaking at 555 nm), producing
quantities measured in lumens, lux, and candela. The luminous efficacy
of radiation relates lumens to watts: 683 lm/W at 555 nm for
monochromatic light, and typically 80--200 lm/W for practical white LED
sources.

\begin{examplebox}

\textbf{Example 18.6.1:} A point source emits 100 W of radiant flux
uniformly into a hemisphere (2π steradians). Calculate the radiant
intensity and the irradiance at a distance of 2 m on axis.

\textbf{Solution:}\\
Radiant intensity: I = Φ / Ω = 100 / (2π) = 15.92 W/sr.\\
Irradiance at distance r follows the inverse-square law: E = I / r² =
15.92 / (2²) = 15.92 / 4 = 3.98 W/m².\\
Alternatively, the total flux through a hemisphere at r = 2 m must still
be 100 W: E = Φ / (2πr²) = 100 / (2π × 4) = 3.98 W/m².\\
At 5 m: E = 15.92 / 25 = 0.637 W/m².\\
The inverse-square law is fundamental to all optical link budget
calculations.

\end{examplebox}

\subsection{18.6.2 Optical Link Budget}\label{optical-link-budget}

An optical link budget accounts for all gains and losses between the
transmitter and receiver to verify that a fiber-optic or free-space
optical link will operate with adequate margin. The link equation is:
P\textsubscript{received} = P\textsubscript{transmit} -
α\textsubscript{fiber} × L - L\textsubscript{connectors} -
L\textsubscript{splices} - L\textsubscript{other} +
G\textsubscript{amplifiers}, where all quantities are in dB or dBm. The
link operates correctly when P\textsubscript{received} ≥
P\textsubscript{sensitivity} + M\textsubscript{system}, where
P\textsubscript{sensitivity} is the receiver's minimum detectable power
at the required BER and M\textsubscript{system} is the system margin
(typically 3--6 dB to account for component aging, temperature
variations, repair splices, and future degradation). For fiber links,
loss contributions include fiber attenuation (0.2--0.35 dB/km depending
on wavelength), connector losses (0.3--0.5 dB per mated pair for PC/APC
connectors), fusion splice losses (0.05--0.1 dB each), and passive
component insertion losses (WDM mux/demux, optical switches, splitters).
Chromatic dispersion and PMD impose bandwidth-distance limits separate
from the power budget, requiring a dispersion budget check for
high-speed links (≥ 10 Gbps). For amplified links, the OSNR budget
replaces the simple power budget, tracking the accumulated amplified
spontaneous emission (ASE) noise through cascaded EDFAs. Free-space
optical links additionally account for geometric spreading loss
(proportional to distance squared), atmospheric absorption and
scattering, and pointing/tracking losses.

\begin{examplebox}

\textbf{Example 18.6.2:} Design a single-mode fiber link operating at
1550 nm over 40 km with the following components: DFB laser transmit
power = +3 dBm, fiber attenuation = 0.25 dB/km, 4 connectors at 0.5 dB
each, 2 fusion splices at 0.1 dB each, and receiver sensitivity = -28
dBm at 2.5 Gbps (BER = 10⁻¹²). Calculate the total loss, received power,
and system margin.

\textbf{Solution:}\\
Fiber loss: 0.25 × 40 = 10.0 dB.\\
Connector losses: 4 × 0.5 = 2.0 dB.\\
Splice losses: 2 × 0.1 = 0.2 dB.\\
Total link loss: 10.0 + 2.0 + 0.2 = 12.2 dB.\\
Received power: P\textsubscript{rx} = P\textsubscript{tx} -
L\textsubscript{total} = +3 - 12.2 = -9.2 dBm.\\
System margin: M = P\textsubscript{rx} - P\textsubscript{sensitivity} =
-9.2 - (-28) = 18.8 dB.\\
This exceeds the typical 3--6 dB requirement, providing substantial
margin for future splices, connector aging, and cable repairs.\\
The link is power-budget limited at approximately (P\textsubscript{tx} -
P\textsubscript{sensitivity} - M\textsubscript{required}) / α = (3 + 28
- 6) / 0.25 = 100 km maximum reach.\\
Dispersion check: Δτ = D × L × Δλ = 17 × 40 × 0.01 = 6.8 ps (with DFB
laser Δλ = 0.01 nm), well within the 400 ps bit period at 2.5 Gbps.

\end{examplebox}

\subsection{18.6.3 Lens Design and
Aberrations}\label{lens-design-and-aberrations}

Real lenses deviate from the ideal thin-lens behavior due to aberrations
--- systematic errors in how rays are focused. The five primary (Seidel)
monochromatic aberrations are: \textbf{Spherical aberration} (marginal
rays focus closer to the lens than paraxial rays, producing a blurred
image), \textbf{Coma} (off-axis points form comet-shaped blur patterns),
\textbf{Astigmatism} (tangential and sagittal rays focus at different
distances for off-axis points), \textbf{Field curvature} (the image
surface is curved rather than flat), and \textbf{Distortion} (straight
lines in the object map to curved lines in the image --- barrel or
pincushion). \textbf{Chromatic aberration} arises because the refractive
index varies with wavelength (dispersion), causing different colors to
focus at different points; it is corrected using achromatic doublets (a
combination of crown and flint glass elements with different
dispersions). Aspherical surfaces (departing from a simple sphere) can
dramatically reduce spherical aberration with fewer elements, and are
commonly produced by precision molding of glass or polymer optics.
Modern camera lenses use 6--15 elements to correct these aberrations
across the entire field of view and wavelength range.

\begin{examplebox}

\textbf{Example 18.6.3:} A singlet lens with focal length f = 100 mm and
diameter D = 25 mm is used to focus a collimated beam. The lens has a
longitudinal spherical aberration of LSA = 0.5 mm (marginal rays focus
0.5 mm closer). Estimate the blur circle diameter at the paraxial focus
and the f-number.

\textbf{Solution:}\\
f-number: f/\# = f/D = 100/25 = f/4.\\
The marginal rays converge to a point 0.5 mm in front of the paraxial
focus.\\
At the paraxial focal plane, the marginal rays form a cone with
half-angle θ ≈ (D/2)/f = 12.5/100 = 0.125 rad.\\
The blur circle diameter at the paraxial focus is approximately
d\textsubscript{blur} = LSA × (D/f) = 0.5 × (25/100) = 0.5 × 0.25 =
0.125 mm = 125 μm.\\
For comparison, the diffraction-limited Airy disk diameter at λ = 550 nm
is d\textsubscript{Airy} = 2.44 × λ × f/\# = 2.44 × 0.55 × 10⁻³ × 4 =
5.37 μm.\\
The aberration blur (125 μm) is 23× the diffraction limit, confirming
that this simple lens is severely aberration-limited.\\
Stopping down to f/8 (halving the aperture from D = 25 mm to 12.5 mm)
would reduce the spherical aberration by approximately 8× --- since
transverse blur scales as D³, halving D reduces it by 2³ = 8.

\end{examplebox}

\chapter{Chapter 19}\label{chapter-19}

\chapter{Engineering Economics}\label{engineering-economics}

Engineering economics applies quantitative techniques to evaluate the
financial viability of engineering projects and investments. It provides
a systematic framework for comparing alternatives that differ in timing,
magnitude, and duration of cash flows --- enabling engineers to make
rational decisions about equipment purchases, infrastructure upgrades,
and capital investments. These methods are essential for electrical
engineers who must justify projects ranging from substation upgrades and
cable replacements to renewable energy installations and power plant
construction.

\section{19.1 Time Value of Money}\label{time-value-of-money}

The time value of money is the fundamental principle that a dollar
available today is worth more than a dollar received in the future,
because today's dollar can be invested to earn interest. This concept
underlies all engineering economic analysis --- it is the reason cash
flows occurring at different times cannot simply be added together.
Instead, they must be converted to equivalent values at a common point
in time using an appropriate interest rate. The interest rate reflects
the opportunity cost of capital: the return that could be earned by
investing the money elsewhere.

\subsection{19.1.1 Simple Interest}\label{simple-interest}

Simple interest is calculated only on the original principal amount, not
on any accumulated interest. The total interest earned is I = P × i × n,
where P is the principal, i is the interest rate per period, and n is
the number of periods. The total amount owed after n periods is F = P(1
+ i × n). Simple interest is rarely used in engineering economic
analysis but provides an important conceptual foundation for
understanding compound interest.

\begin{examplebox}

\textbf{Example 19.1.1:} A utility borrows \$500,000 for a substation
capacitor bank upgrade at 6\% simple annual interest for 3 years.
Determine (a) the total interest paid and (b) the total amount owed at
maturity.

\textbf{Solution:}

(a) Total interest: I = P × i × n = 500,000 × 0.06 × 3 =
\textbf{\$90,000}

(b) Total amount owed: F = P + I = 500,000 + 90,000 = \textbf{\$590,000}

\end{examplebox}

\subsection{19.1.2 Compound Interest}\label{compound-interest}

Compound interest is calculated on both the original principal and any
previously accumulated interest. The future value after n periods is F =
P(1 + i)ⁿ, where interest earned in each period is added to the
principal and earns interest in subsequent periods. Compounding causes
exponential growth rather than linear growth, and the difference between
simple and compound interest becomes significant over long time
horizons. Nearly all engineering economic analyses use compound
interest.

\begin{examplebox}

\textbf{Example 19.1.2:} An electrical contractor invests \$100,000 in a
certificate of deposit at 5\% annual interest compounded quarterly.
Determine (a) the account balance after 4 years and (b) the total
interest earned.

\textbf{Solution:}

(a) Quarterly interest rate: i = 0.05/4 = 0.0125. Number of periods: n =
4 × 4 = 16.\\
F = P(1 + i)ⁿ = 100,000 × (1.0125)¹⁶ = 100,000 × 1.2199 =
\textbf{\$121,989}

(b) Total interest earned: I = F − P = 121,989 − 100,000 =
\textbf{\$21,989}

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-19-1-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch19_compound_interest.png}

\caption{Figure 19.1.2: Simple vs Compound vs Continuous Interest Growth}

\end{figure}

\subsection{19.1.3 Nominal and Effective Interest
Rates}\label{nominal-and-effective-interest-rates}

When interest is compounded more frequently than once per year, the
stated annual rate is the nominal rate (r), and the actual annual yield
is the effective rate (i\textsubscript{eff}). The relationship is
i\textsubscript{eff} = (1 + r/m)ᵐ − 1, where m is the number of
compounding periods per year. The effective rate is always greater than
or equal to the nominal rate, with equality only when m = 1. Engineers
must convert to effective rates when comparing financing options with
different compounding frequencies.

\begin{examplebox}

\textbf{Example 19.1.3:} A utility equipment lease quotes 12\% annual
interest compounded monthly. Determine (a) the effective annual interest
rate and (b) the effective semiannual rate.

\textbf{Solution:}

(a) Effective annual rate: i\textsubscript{eff} = (1 + 0.12/12)¹² − 1 =
(1.01)¹² − 1 = 1.12683 − 1 = \textbf{12.68\%}

(b) Effective semiannual rate: i\textsubscript{semi} = (1 + 0.12/12)⁶ −
1 = (1.01)⁶ − 1 = 1.06152 − 1 = \textbf{6.15\%}

\end{examplebox}

\subsection{19.1.4 Continuous Compounding}\label{continuous-compounding}

Continuous compounding represents the theoretical limit as the number of
compounding periods per year approaches infinity. The future value is F
= Pe\textsuperscript{rn}, where r is the nominal annual rate and n is
the number of years. The effective annual rate under continuous
compounding is i\textsubscript{eff} = e\textsuperscript{r} − 1.
Continuous compounding is used in some financial models, bond pricing,
and as a mathematical convenience in economic analysis.

\begin{examplebox}

\textbf{Example 19.1.4:} A power company invests \$2,000,000 in an
infrastructure fund at 8\% continuously compounded interest. Determine
(a) the fund value after 5 years, (b) the effective annual interest
rate, and (c) the total interest earned.

\textbf{Solution:}

(a) F = Pe\textsuperscript{rn} = 2,000,000 × e\textsuperscript{0.08 × 5}
= 2,000,000 × e\textsuperscript{0.40} = 2,000,000 × 1.4918 =
\textbf{\$2,983,649}

(b) i\textsubscript{eff} = e\textsuperscript{0.08} − 1 = 1.08329 − 1 =
\textbf{8.33\%}

(c) Total interest: I = 2,983,649 − 2,000,000 = \textbf{\$983,649}

\end{examplebox}

\section{19.2 Cash Flow Diagrams and Economic
Equivalence}\label{cash-flow-diagrams-and-economic-equivalence}

Cash flow diagrams and economic equivalence are the two foundational
tools for structuring and solving engineering economic problems. A cash
flow diagram provides a visual timeline of all monetary inflows and
outflows, while equivalence allows comparison of cash flows occurring at
different points in time. Together they transform complex financial
scenarios into systematic calculations that support rational
decision-making.

\subsection{19.2.1 Cash Flow Diagram
Conventions}\label{cash-flow-diagram-conventions}

A cash flow diagram is a horizontal timeline where the x-axis represents
time periods (usually years) and vertical arrows represent cash flows.
Upward arrows indicate cash inflows (revenues, savings, salvage values),
and downward arrows indicate cash outflows (costs, investments,
expenses). Time zero is the present, and cash flows are assumed to occur
at the end of each period unless stated otherwise. The diagram provides
a clear visual summary that prevents errors in setting up economic
equations.

\begin{examplebox}

\textbf{Example 19.2.1:} A distribution utility purchases a \$150,000
pad-mounted transformer that generates \$35,000/year in reduced losses
over 6 years, with a \$10,000 salvage value at the end of year 6.
Describe the cash flow diagram.

\textbf{Solution:}\\
Time 0: ↓ \$150,000 (initial cost, downward arrow)\\
Years 1--6: ↑ \$35,000/year (annual savings, upward arrows)\\
Year 6: ↑ \$10,000 (salvage value, additional upward arrow)

The net cash flow in year 6 is \$35,000 + \$10,000 = \textbf{\$45,000}
upward. Total undiscounted inflows = 6 × 35,000 + 10,000 =
\textbf{\$220,000}, which exceeds the \$150,000 cost, but a
time-value-of-money analysis is needed to determine true profitability.

\end{examplebox}

\subsection{19.2.2 Economic Equivalence}\label{economic-equivalence}

Two cash flow patterns are economically equivalent if they have the same
value when converted to a common point in time at a given interest rate.
Equivalence means the decision-maker is indifferent between the two
patterns. This concept allows engineers to compare lump-sum payments
against installment plans, evaluate lease-versus-buy decisions, and
convert irregular cash flows into uniform series for easier comparison.
The equivalence relationship depends on the interest rate --- cash flows
that are equivalent at one rate are generally not equivalent at another.

\begin{examplebox}

\textbf{Example 19.2.2:} A municipality can pay \$800,000 now or
\$250,000 per year for 4 years for a distribution feeder upgrade. At i =
8\%, determine (a) the present value of the installment plan and (b)
which option is more economical.

\textbf{Solution:}

(a) P = A × (P/A, 8\%, 4) = 250,000 × {[}(1.08⁴ − 1) / (0.08 ×
1.08⁴){]}\\
= 250,000 × {[}(1.3605 − 1) / (0.08 × 1.3605){]}\\
= 250,000 × {[}0.3605 / 0.10884{]}\\
= 250,000 × 3.3121 = \textbf{\$828,028}

(b) The lump-sum payment of \$800,000 is less than the present value of
the installment plan (\$828,028), so the \textbf{lump-sum payment is
more economical} by \$28,028.

\end{examplebox}

\section{19.3 Single Payment and Uniform Series
Factors}\label{single-payment-and-uniform-series-factors}

Engineering economic analysis uses six standard compound interest
factors to convert between present, future, and annual values. These
factors --- F/P, P/F, P/A, A/P, F/A, and A/F --- form the computational
backbone of all equivalence calculations. Gradient series factors extend
the analysis to cash flows that increase by a constant amount
(arithmetic gradient) or a constant percentage (geometric gradient) each
period. Mastering these factors enables rapid evaluation of virtually
any cash flow pattern encountered in engineering practice.

\subsection{19.3.1 Single Payment Factors (F/P and
P/F)}\label{single-payment-factors-fp-and-pf}

The single payment compound amount factor (F/P, i, n) = (1 + i)ⁿ
converts a present value to a future value. Its reciprocal, the single
payment present worth factor (P/F, i, n) = 1/(1 + i)ⁿ, converts a future
value to a present value. These are the simplest and most frequently
used factors in engineering economics. The F/P factor answers ``what
will this investment grow to?'' while the P/F factor answers ``what is a
future payment worth today?''

\begin{examplebox}

\textbf{Example 19.3.1:} A solar farm developer needs \$5,000,000 in 7
years for a panel replacement cycle. If funds earn 6\% annually,
determine (a) the amount that must be invested today, and (b) the amount
of interest earned over the 7 years.

\textbf{Solution:}

(a) P = F × (P/F, 6\%, 7) = 5,000,000 × 1/(1.06)⁷ = 5,000,000 × 1/1.5036
= 5,000,000 × 0.6651 = \textbf{\$3,325,500}

(b) Interest earned: I = F − P = 5,000,000 − 3,325,500 =
\textbf{\$1,674,500}

\end{examplebox}

\subsection{19.3.2 Uniform Series Factors (P/A and
A/P)}\label{uniform-series-factors-pa-and-ap}

The uniform series present worth factor (P/A, i, n) = {[}(1 + i)ⁿ − 1{]}
/ {[}i(1 + i)ⁿ{]} converts a series of equal annual payments into a
single present value. Its reciprocal, the capital recovery factor (A/P,
i, n) = {[}i(1 + i)ⁿ{]} / {[}(1 + i)ⁿ − 1{]}, converts a present value
into a series of equal annual payments. The A/P factor is widely used
for loan amortization and for expressing the annual cost of owning an
asset (capital recovery cost).

\begin{examplebox}

\textbf{Example 19.3.2:} A manufacturing plant installs a \$400,000
variable frequency drive system financed over 10 years at 7\% annual
interest. Determine (a) the annual payment and (b) the total amount paid
over the loan term.

\textbf{Solution:}

(a) A = P × (A/P, 7\%, 10) = 400,000 × {[}0.07 × 1.07¹⁰{]} / {[}1.07¹⁰ −
1{]}\\
= 400,000 × {[}0.07 × 1.9672{]} / {[}1.9672 − 1{]}\\
= 400,000 × 0.13771 / 0.9672\\
= 400,000 × 0.14238 = \textbf{\$56,952/year}

(b) Total paid: 56,952 × 10 = \textbf{\$569,520}, of which \$169,520 is
interest.

\end{examplebox}

\subsection{19.3.3 Sinking Fund and Compound Amount (A/F and
F/A)}\label{sinking-fund-and-compound-amount-af-and-fa}

The sinking fund factor (A/F, i, n) = i / {[}(1 + i)ⁿ − 1{]} determines
the uniform annual deposit needed to accumulate a target future amount.
Its reciprocal, the uniform series compound amount factor (F/A, i, n) =
{[}(1 + i)ⁿ − 1{]} / i, finds the future value of a series of equal
annual deposits. Sinking funds are commonly used by utilities to
accumulate reserves for major equipment replacements, plant
decommissioning, or regulatory compliance upgrades.

\begin{examplebox}

\textbf{Example 19.3.3:} A utility must accumulate \$3,000,000 in 12
years for a generator overhaul. At 5\% interest, determine (a) the
required uniform annual deposit and (b) the total interest earned by the
sinking fund.

\textbf{Solution:}

(a) A = F × (A/F, 5\%, 12) = 3,000,000 × 0.05 / {[}(1.05)¹² − 1{]}\\
= 3,000,000 × 0.05 / {[}1.7959 − 1{]}\\
= 3,000,000 × 0.05 / 0.7959\\
= 3,000,000 × 0.06283 = \textbf{\$188,476/year}

(b) Total deposits: 188,476 × 12 = \$2,261,712. Interest earned:
3,000,000 − 2,261,712 = \textbf{\$738,288}

\end{examplebox}

\subsection{19.3.4 Arithmetic Gradient
Series}\label{arithmetic-gradient-series}

An arithmetic gradient series has cash flows that increase by a constant
amount G each period: the cash flow in period t is A₁ + (t − 1)G, where
A₁ is the base amount in period 1. The present worth of the gradient
component alone is P\textsubscript{G} = G × {[}(1 + i)ⁿ − in − 1{]} /
{[}i²(1 + i)ⁿ{]}, often written as G × (P/G, i, n). The total present
worth is P = A₁ × (P/A, i, n) + G × (P/G, i, n). Arithmetic gradients
model maintenance costs that increase by a fixed dollar amount each year
due to aging equipment.

\begin{examplebox}

\textbf{Example 19.3.4:} Maintenance costs for a backup generator start
at \$5,000 in year 1 and increase by \$1,200/year thereafter. At i = 8\%
over 10 years, determine (a) the maintenance cost in year 10 and (b) the
present worth of all maintenance costs.

\textbf{Solution:}

(a) Cost in year 10: A₁₀ = 5,000 + (10 − 1) × 1,200 = 5,000 + 10,800 =
\textbf{\$15,800}

(b) P = A₁ × (P/A, 8\%, 10) + G × (P/G, 8\%, 10)\\
(P/A, 8\%, 10) = {[}(1.08)¹⁰ − 1{]} / {[}0.08 × (1.08)¹⁰{]} = {[}2.1589
− 1{]} / {[}0.08 × 2.1589{]} = 1.1589 / 0.17271 = 6.7101\\
(P/G, 8\%, 10) = {[}(1.08)¹⁰ − 0.08 × 10 − 1{]} / {[}0.08² × (1.08)¹⁰{]}
= {[}2.1589 − 0.8 − 1{]} / {[}0.0064 × 2.1589{]} = 0.3589 / 0.013817 =
25.977\\
P = 5,000 × 6.7101 + 1,200 × 25.977 = 33,551 + 31,172 =
\textbf{\$64,723}

\end{examplebox}

\subsection{19.3.5 Geometric Gradient
Series}\label{geometric-gradient-series}

A geometric gradient series has cash flows that increase by a constant
percentage g each period: the cash flow in period t is A₁(1 +
g)\textsuperscript{t−1}. When g ≠ i, the present worth is P = A₁ × {[}1
− (1 + g)ⁿ(1 + i)⁻ⁿ{]} / (i − g). When g = i, the present worth
simplifies to P = A₁ × n / (1 + i). Geometric gradients model costs that
escalate at a fixed percentage rate, such as energy prices, labor costs,
and material costs subject to inflation.

\begin{examplebox}

\textbf{Example 19.3.5:} Electricity costs for a data center are
\$200,000 in year 1 and escalate at 4\%/year. At i = 9\%, determine the
present worth of 15 years of electricity costs.

\textbf{Solution:}\\
P = A₁ × {[}1 − (1 + g)ⁿ(1 + i)⁻ⁿ{]} / (i − g)\\
= 200,000 × {[}1 − (1.04)¹⁵(1.09)⁻¹⁵{]} / (0.09 − 0.04)\\
(1.04)¹⁵ = 1.8009, (1.09)¹⁵ = 3.6425\\
= 200,000 × {[}1 − 1.8009/3.6425{]} / 0.05\\
= 200,000 × {[}1 − 0.4944{]} / 0.05\\
= 200,000 × 0.5056 / 0.05\\
= 200,000 × 10.112 = \textbf{\$2,022,400}

\end{examplebox}

\section{19.4 Present Worth Analysis}\label{present-worth-analysis}

Present worth (PW) analysis converts all cash flows to their equivalent
values at time zero using a minimum attractive rate of return (MARR). A
project is economically justified if its net present value (NPV) is
positive --- meaning the present value of benefits exceeds the present
value of costs. For mutually exclusive alternatives, the option with the
highest NPV is preferred. PW analysis is the most widely used evaluation
method in engineering economics because it provides a direct measure of
the economic value added by a project.

\subsection{19.4.1 Net Present Value (NPV)}\label{net-present-value-npv}

The net present value of a project is the sum of all cash flows
discounted to time zero: NPV = Σ CF\textsubscript{t} / (1 +
i)\textsuperscript{t}, where CF\textsubscript{t} is the net cash flow in
period t and i is the MARR. A positive NPV indicates the project earns
more than the MARR and should be accepted. A negative NPV means the
project does not meet the minimum return requirement. For a single
project, the accept/reject criterion is simply NPV ≥ 0.

\begin{examplebox}

\textbf{Example 19.4.1:} A utility evaluates a \$2,500,000 battery
energy storage system that saves \$450,000/year in peak demand charges
over 10 years with a \$200,000 salvage value. At MARR = 10\%, determine
(a) the NPV and (b) whether the project is justified.

\textbf{Solution:}

(a) NPV = −2,500,000 + 450,000 × (P/A, 10\%, 10) + 200,000 × (P/F, 10\%,
10)\\
(P/A, 10\%, 10) = {[}(1.10)¹⁰ − 1{]} / {[}0.10 × (1.10)¹⁰{]} = {[}2.5937
− 1{]} / {[}0.10 × 2.5937{]} = 1.5937 / 0.25937 = 6.1446\\
(P/F, 10\%, 10) = 1/(1.10)¹⁰ = 1/2.5937 = 0.3855\\
NPV = −2,500,000 + 450,000 × 6.1446 + 200,000 × 0.3855\\
= −2,500,000 + 2,765,070 + 77,100 = \textbf{\$342,170}

(b) Since NPV = \$342,170 \textgreater{} 0, the project \textbf{is
justified} --- it earns more than the 10\% MARR.

\end{examplebox}

\subsection{19.4.2 Comparing Alternatives with Equal
Lives}\label{comparing-alternatives-with-equal-lives}

When two or more mutually exclusive alternatives have the same service
life, PW analysis compares them directly by computing the NPV of each
alternative at the same MARR. The alternative with the highest (least
negative) NPV is selected. For cost-only alternatives where revenues are
identical, the analysis minimizes the present worth of costs. All
alternatives must be compared over the same time period and at the same
MARR.

\begin{examplebox}

\textbf{Example 19.4.2:} Compare two cable insulation options for a
5-mile distribution line over 20 years at i = 8\%. Option A: \$1,200,000
first cost, \$40,000/year maintenance. Option B: \$900,000 first cost,
\$70,000/year maintenance. Determine which option is more economical.

\textbf{Solution:}\\
PW\textsubscript{A} = −1,200,000 − 40,000 × (P/A, 8\%, 20)\\
(P/A, 8\%, 20) = {[}(1.08)²⁰ − 1{]} / {[}0.08 × (1.08)²⁰{]} = {[}4.6610
− 1{]} / {[}0.08 × 4.6610{]} = 3.6610 / 0.37288 = 9.8181\\
PW\textsubscript{A} = −1,200,000 − 40,000 × 9.8181 = −1,200,000 −
392,724 = \textbf{−\$1,592,724}

PW\textsubscript{B} = −900,000 − 70,000 × 9.8181 = −900,000 − 687,267 =
\textbf{−\$1,587,267}

\textbf{Option B is more economical} by \$5,457 in present worth,
despite higher annual maintenance, because the lower first cost more
than compensates.

\end{examplebox}

\subsection{19.4.3 Comparing Alternatives with Unequal
Lives}\label{comparing-alternatives-with-unequal-lives}

When mutually exclusive alternatives have different service lives,
direct PW comparison is invalid because the alternatives provide service
for different durations. The least common multiple (LCM) method repeats
each alternative over the LCM of their lives so that all alternatives
span the same total period. Alternatively, the annual worth method
(§19.5) avoids this complication entirely. The LCM approach assumes
identical replacement at the same cost, which may not hold if technology
or prices change.

\begin{examplebox}

\textbf{Example 19.4.3:} Compare a 15-year overhead line rebuild
(\$600,000, \$25,000/year maintenance) with a 30-year underground cable
(\$1,800,000, \$8,000/year maintenance) at i = 6\%. Use the LCM method
to select the more economical option.

\textbf{Solution:}\\
LCM of 15 and 30 is 30 years. The overhead line is repeated twice (years
0--15 and 15--30).

PW\textsubscript{overhead} = −600,000 − 600,000 × (P/F, 6\%, 15) −
25,000 × (P/A, 6\%, 30)\\
(P/F, 6\%, 15) = 1/(1.06)¹⁵ = 1/2.3966 = 0.4173\\
(P/A, 6\%, 30) = {[}(1.06)³⁰ − 1{]} / {[}0.06 × (1.06)³⁰{]} = {[}5.7435
− 1{]} / {[}0.06 × 5.7435{]} = 4.7435 / 0.34461 = 13.765\\
PW\textsubscript{overhead} = −600,000 − 600,000 × 0.4173 − 25,000 ×
13.765\\
= −600,000 − 250,380 − 344,125 = \textbf{−\$1,194,505}

PW\textsubscript{underground} = −1,800,000 − 8,000 × (P/A, 6\%, 30)\\
= −1,800,000 − 8,000 × 13.765 = −1,800,000 − 110,120 =
\textbf{−\$1,910,120}

The \textbf{overhead line rebuild is more economical} by \$715,615 in
present worth over the 30-year study period.

\end{examplebox}

\section{19.5 Annual Worth Analysis}\label{annual-worth-analysis}

Annual worth (AW) analysis converts all cash flows into an equivalent
uniform annual amount. The AW method is particularly convenient for
comparing alternatives with different service lives because the AW of
one life cycle is the same as the AW for any number of repeating life
cycles, provided the costs and revenues remain unchanged. A project is
economically justified if its AW ≥ 0. For mutually exclusive
alternatives, the one with the highest AW (or least negative AW for
cost-only comparisons) is selected.

\subsection{19.5.1 Capital Recovery and Annual
Worth}\label{capital-recovery-and-annual-worth}

The annual cost of owning an asset has two components: the capital
recovery cost (the equivalent annual cost of the initial investment
minus salvage value) and the annual operating cost. Capital recovery
cost is CR = (P − S) × (A/P, i, n) + S × i, where P is the first cost, S
is the salvage value, n is the useful life, and i is the interest rate.
The total AW is AW = −CR − Annual O\&M + Annual Revenue.

\begin{examplebox}

\textbf{Example 19.5.1:} A 500 kW diesel generator costs \$350,000, has
a 12-year life, annual O\&M of \$28,000, and a salvage value of
\$40,000. At i = 9\%, determine (a) the capital recovery cost and (b)
the total annual worth.

\textbf{Solution:}

(a) CR = (P − S) × (A/P, 9\%, 12) + S × i\\
(A/P, 9\%, 12) = {[}0.09 × (1.09)¹²{]} / {[}(1.09)¹² − 1{]} = {[}0.09 ×
2.8127{]} / {[}2.8127 − 1{]} = 0.25314 / 1.8127 = 0.13965\\
CR = (350,000 − 40,000) × 0.13965 + 40,000 × 0.09\\
= 310,000 × 0.13965 + 3,600 = 43,292 + 3,600 = \textbf{\$46,892/year}

(b) AW = −CR − Annual O\&M = −46,892 − 28,000 = \textbf{−\$74,892/year}

\end{examplebox}

\subsection{19.5.2 Comparing Alternatives by Annual
Worth}\label{comparing-alternatives-by-annual-worth}

The AW method is the simplest approach for comparing alternatives with
different service lives because no LCM calculation is needed --- each
alternative is evaluated over its own life. The alternative with the
numerically highest (least negative) AW is preferred. This method
implicitly assumes that each alternative can be replaced at the same
cost at the end of its life.

\begin{examplebox}

\textbf{Example 19.5.2:} Compare two motor choices for a pump station at
i = 7\%. Standard motor: \$8,000, 10-year life, \$3,200/year energy
cost. Premium motor: \$12,000, 10-year life, \$2,400/year energy cost.
Neither has salvage value. Determine which is more economical.

\textbf{Solution:}\\
(A/P, 7\%, 10) = {[}0.07 × (1.07)¹⁰{]} / {[}(1.07)¹⁰ − 1{]} = {[}0.07 ×
1.9672{]} / {[}1.9672 − 1{]} = 0.13770 / 0.9672 = 0.14238

AW\textsubscript{standard} = −8,000 × 0.14238 − 3,200 = −1,139 − 3,200 =
\textbf{−\$4,339/year}

AW\textsubscript{premium} = −12,000 × 0.14238 − 2,400 = −1,709 − 2,400 =
\textbf{−\$4,109/year}

The \textbf{premium efficiency motor is more economical} by \$230/year.
The energy savings of \$800/year more than offsets the higher capital
recovery cost of \$570/year.

\end{examplebox}

\section{19.6 Rate of Return Analysis}\label{rate-of-return-analysis}

Rate of return (ROR) analysis finds the interest rate at which the net
present value of a project's cash flows equals zero. This rate, called
the internal rate of return (IRR), represents the effective yield of the
investment. A project is accepted if its IRR exceeds the MARR. For
comparing mutually exclusive alternatives, incremental rate of return
analysis must be used --- comparing alternatives by their individual
IRRs can lead to incorrect decisions. The IRR method is popular because
it expresses economic merit as a percentage, which is intuitive and easy
to communicate to decision-makers.

\subsection{19.6.1 Internal Rate of Return (IRR) for Single
Projects}\label{internal-rate-of-return-irr-for-single-projects}

The IRR is the interest rate i* that satisfies Σ CF\textsubscript{t} /
(1 + i*)\textsuperscript{t} = 0, where CF\textsubscript{t} is the net
cash flow in period t. For simple investments (one sign change in the
cash flow sequence), a unique positive IRR exists and can be found by
trial and error, interpolation, or numerical methods. If IRR ≥ MARR, the
project is economically justified.

\begin{examplebox}

\textbf{Example 19.6.1:} A \$180,000 power factor correction system
saves \$38,000/year in utility demand charges for 8 years with no
salvage value. Determine (a) the IRR and (b) whether the project is
acceptable at MARR = 12\%.

\textbf{Solution:}

(a) Set NPV = 0: 0 = −180,000 + 38,000 × (P/A, i\emph{, 8) (P/A, i}, 8)
= 180,000/38,000 = 4.7368

Try i = 12\%: (P/A, 12\%, 8) = 4.9676 (NPV \textgreater{} 0)\\
Try i = 15\%: (P/A, 15\%, 8) = 4.4873 (NPV \textless{} 0)\\
Interpolate: i* = 12\% + 3\% × (4.9676 − 4.7368)/(4.9676 − 4.4873) =
12\% + 3\% × 0.2308/0.4803 = 12\% + 1.44\% = \textbf{13.44\%}

(b) Since IRR = 13.44\% \textgreater{} MARR = 12\%, the project
\textbf{is acceptable}.

\end{examplebox}

\subsection{19.6.2 Incremental Rate of Return for Mutually Exclusive
Alternatives}\label{incremental-rate-of-return-for-mutually-exclusive-alternatives}

When comparing mutually exclusive alternatives, the alternative with the
higher IRR is not necessarily the better choice. Instead, incremental
analysis evaluates the rate of return on the additional investment
required by the more expensive alternative. The incremental cash flow is
ΔCF = CF\textsubscript{B} − CF\textsubscript{A}, where B has the higher
first cost. If the incremental IRR (ΔIRR) exceeds the MARR, the extra
investment is justified and the more expensive alternative is selected.

\begin{examplebox}

\textbf{Example 19.6.2:} Two relay protection upgrade options over 8
years. Option A: \$60,000 cost, \$15,000/year savings. Option B:
\$100,000 cost, \$23,000/year savings. Neither has salvage value. Use
incremental IRR analysis at MARR = 10\% to select the better option.

\textbf{Solution:}\\
Incremental cash flow (B − A): ΔCost = −\$40,000, ΔSavings =
+\$8,000/year.\\
Set NPV of increment = 0: 0 = −40,000 + 8,000 × (P/A, Δi\emph{, 8) (P/A,
Δi}, 8) = 40,000/8,000 = 5.0000

Try i = 10\%: (P/A, 10\%, 8) = 5.3349 (NPV \textgreater{} 0)\\
Try i = 12\%: (P/A, 12\%, 8) = 4.9676 (NPV \textless{} 0)\\
Interpolate: Δi* = 10\% + 2\% × (5.3349 − 5.0000)/(5.3349 − 4.9676) =
10\% + 2\% × 0.3349/0.3673 = 10\% + 1.82\% = \textbf{11.82\%}

Since ΔIRR = 11.82\% \textgreater{} MARR = 10\%, the extra \$40,000
investment is justified. \textbf{Select Option B.}

\end{examplebox}

\subsection{19.6.3 Multiple Rate of Return and Modified
IRR}\label{multiple-rate-of-return-and-modified-irr}

When a cash flow sequence has more than one sign change, multiple IRR
values may exist (Descartes' rule of signs). This occurs in projects
with large intermediate expenditures or end-of-life decommissioning
costs. The modified internal rate of return (MIRR) resolves this
ambiguity by separating the financing rate (for negative cash flows)
from the reinvestment rate (for positive cash flows), producing a single
unique rate.

\begin{examplebox}

\textbf{Example 19.6.3:} A cogeneration project has an initial cost of
\$5,000,000, net revenues of \$1,200,000/year for years 1--8, then a
\$3,000,000 decommissioning cost in year 9. Determine (a) the number of
sign changes, and (b) the MIRR using a reinvestment rate of 10\% and a
finance rate of 8\%.

\textbf{Solution:}

(a) Cash flow signs: − + + + + + + + + −. There are \textbf{2 sign
changes} (−→+ and +→−), so up to 2 IRR values may exist.

(b) Future value of positive cash flows at reinvestment rate (10\%):\\
FV\textsubscript{positive} = 1,200,000 × (F/A, 10\%, 8) × (F/P, 10\%,
1)\\
(F/A, 10\%, 8) = {[}(1.10)⁸ − 1{]} / 0.10 = {[}2.1436 − 1{]} / 0.10 =
11.436\\
FV\textsubscript{positive} = 1,200,000 × 11.436 × 1.10 = 1,200,000 ×
12.580 = \$15,095,520

Present value of negative cash flows at finance rate (8\%):\\
PV\textsubscript{negative} = 5,000,000 + 3,000,000 × (P/F, 8\%, 9) =
5,000,000 + 3,000,000 / (1.08)⁹\\
= 5,000,000 + 3,000,000 / 1.9990 = 5,000,000 + 1,500,750 = \$6,500,750

MIRR = (FV\textsubscript{positive} /
PV\textsubscript{negative})\textsuperscript{1/9} − 1 = (15,095,520 /
6,500,750)\textsuperscript{1/9} − 1\\
= (2.3222)\textsuperscript{1/9} − 1 = 1.0981 − 1 = \textbf{9.81\%}

\end{examplebox}

\section{19.7 Benefit-Cost Analysis}\label{benefit-cost-analysis}

Benefit-cost (B/C) analysis is the standard evaluation method for
public-sector projects such as utility infrastructure, grid
modernization, and government-funded energy programs. The B/C ratio
compares the present worth (or annual worth) of benefits to the present
worth (or annual worth) of costs. A project is justified when B/C ≥ 1.0.
For comparing multiple alternatives, incremental B/C analysis ensures
that each additional increment of investment produces benefits that
exceed costs. Unlike private-sector analysis, public projects consider
societal benefits such as reduced outage costs, environmental
improvements, and public safety enhancements.

\subsection{19.7.1 Conventional Benefit-Cost
Ratio}\label{conventional-benefit-cost-ratio}

The conventional B/C ratio is defined as B/C = (Benefits − Disbenefits)
/ Costs, where all terms are expressed in present worth or annual worth.
Benefits are advantages to the public, disbenefits are disadvantages,
and costs are expenditures by the government or utility. A modified B/C
ratio moves operating and maintenance costs to the numerator:
B/C\textsubscript{modified} = (Benefits − Disbenefits − O\&M) / Initial
Investment. Both formulations give the same accept/reject decision.

\begin{examplebox}

\textbf{Example 19.7.1:} A city invests \$4,000,000 in a smart grid
system that reduces outage costs by \$700,000/year and saves
\$150,000/year in operations over 15 years. At i = 5\%, determine the
conventional B/C ratio.

\textbf{Solution:}\\
Annual benefits: B = \$700,000 + \$150,000 = \$850,000/year\\
AW of cost: C = 4,000,000 × (A/P, 5\%, 15) = 4,000,000 × {[}0.05 ×
(1.05)¹⁵{]} / {[}(1.05)¹⁵ − 1{]}\\
= 4,000,000 × {[}0.05 × 2.0789{]} / {[}2.0789 − 1{]}\\
= 4,000,000 × 0.10395 / 1.0789\\
= 4,000,000 × 0.09634 = \$385,360/year

B/C = 850,000 / 385,360 = \textbf{2.21}

Since B/C = 2.21 \textgreater{} 1.0, the project \textbf{is justified}.

\end{examplebox}

\subsection{19.7.2 Incremental B/C Analysis for Multiple
Alternatives}\label{incremental-bc-analysis-for-multiple-alternatives}

When comparing mutually exclusive public-sector alternatives,
incremental B/C analysis is required. Alternatives are ranked by
increasing cost, and each increment of investment is evaluated. Starting
with the lowest-cost alternative as the base, the incremental B/C ratio
ΔB/ΔC is computed for each successive alternative. If ΔB/ΔC ≥ 1.0, the
higher-cost alternative is selected as the new base; otherwise, it is
eliminated.

\begin{examplebox}

\textbf{Example 19.7.2:} Three substation automation levels are proposed
over 20 years at i = 6\%. Level 1: \$1,000,000 cost, \$180,000/year
benefits. Level 2: \$2,500,000 cost, \$400,000/year benefits. Level 3:
\$4,000,000 cost, \$600,000/year benefits. Use incremental B/C analysis
to select the best alternative.

\textbf{Solution:}\\
(A/P, 6\%, 20) = {[}0.06 × (1.06)²⁰{]} / {[}(1.06)²⁰ − 1{]} = {[}0.06 ×
3.2071{]} / {[}3.2071 − 1{]} = 0.19243 / 2.2071 = 0.08718

AW of costs: C₁ = 1,000,000 × 0.08718 = \$87,180; C₂ = 2,500,000 ×
0.08718 = \$217,950; C₃ = 4,000,000 × 0.08718 = \$348,720

Level 1 vs.~do-nothing: B/C = 180,000/87,180 = 2.06 ≥ 1.0 →
\textbf{Level 1 justified} (new base).

Level 2 vs.~Level 1: ΔB/ΔC = (400,000 − 180,000)/(217,950 − 87,180) =
220,000/130,770 = 1.68 ≥ 1.0 → \textbf{Level 2 justified} (new base).

Level 3 vs.~Level 2: ΔB/ΔC = (600,000 − 400,000)/(348,720 − 217,950) =
200,000/130,770 = 1.53 ≥ 1.0 → \textbf{Level 3 justified}.

\textbf{Select Level 3} --- each incremental investment is justified.

\end{examplebox}

\section{19.8 Depreciation}\label{depreciation}

Depreciation is the systematic allocation of an asset's cost over its
useful life for accounting and tax purposes. It recognizes that physical
assets lose value over time due to wear, obsolescence, and
deterioration. Depreciation is not a cash flow itself, but it affects
cash flow through its impact on taxable income --- higher depreciation
charges reduce taxes and increase after-tax cash flow. Engineers must
understand depreciation methods to perform accurate after-tax economic
analyses and to comply with tax regulations governing capital asset
recovery.

\subsection{19.8.1 Straight-Line
Depreciation}\label{straight-line-depreciation}

Straight-line (SL) depreciation allocates an equal amount of the asset's
depreciable cost to each year of its useful life. The annual
depreciation charge is D = (P − S)/n, where P is the cost basis, S is
the salvage value, and n is the useful life. The book value at the end
of year t is BV\textsubscript{t} = P − t × D. Straight-line depreciation
is the simplest method and is commonly used for financial reporting and
for assets that lose value uniformly over time.

\begin{examplebox}

\textbf{Example 19.8.1:} A 2 MVA pad-mounted transformer costs \$85,000
with a salvage value of \$5,000 and a useful life of 20 years. Determine
(a) the annual depreciation charge and (b) the book value after 8 years.

\textbf{Solution:}

(a) D = (P − S)/n = (85,000 − 5,000)/20 = 80,000/20 =
\textbf{\$4,000/year}

(b) BV₈ = P − 8 × D = 85,000 − 8 × 4,000 = 85,000 − 32,000 =
\textbf{\$53,000}

\end{examplebox}

\subsection{19.8.2 Declining Balance
Depreciation}\label{declining-balance-depreciation}

Declining balance (DB) depreciation applies a fixed percentage rate to
the current book value each year, producing larger charges in early
years and smaller charges later. The depreciation in year t is
D\textsubscript{t} = d × BV\textsubscript{t−1}, where d is the
depreciation rate (typically 1.5/n for 150\% DB or 2/n for 200\% double
declining balance). The book value is BV\textsubscript{t} = P(1 −
d)\textsuperscript{t}. Declining balance methods never depreciate below
the salvage value; a switch to straight-line may be made when SL
produces a larger deduction.

\begin{examplebox}

\textbf{Example 19.8.2:} A \$120,000 CNC wire-bending machine for motor
winding production uses 200\% declining balance (DDB) depreciation over
a 10-year life. Determine the depreciation and book value for years 1
through 4.

\textbf{Solution:}\\
DDB rate: d = 2/n = 2/10 = 0.20

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Year & Book Value (start) & Depreciation (20\%) & Book Value (end) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \$120,000 & \$24,000 & \$96,000 \\
2 & \$96,000 & \$19,200 & \$76,800 \\
3 & \$76,800 & \$15,360 & \$61,440 \\
4 & \$61,440 & \$12,288 & \$49,152 \\
\end{longtable}
}

After 4 years, the book value is \textbf{\$49,152} and total
depreciation charged is \$120,000 − \$49,152 = \textbf{\$70,848}.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-19-8-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch19_depreciation.png}

\caption{Figure 19.8.2: Depreciation Methods: Book Value Comparison}

\end{figure}

\subsection{19.8.3 MACRS Depreciation}\label{macrs-depreciation}

The Modified Accelerated Cost Recovery System (MACRS) is the
depreciation method required by U.S. tax law for most business assets.
MACRS uses prescribed recovery periods and percentage tables based on
declining balance switching to straight-line. Common recovery periods
are 3, 5, 7, 10, 15, and 20 years. MACRS assumes zero salvage value and
uses a half-year convention (only half a year's depreciation in the
first and last years). The MACRS percentages for common recovery periods
are published by the IRS.

\begin{examplebox}

\textbf{Example 19.8.3:} A utility installs a \$1,200,000 natural gas
turbine classified as 15-year MACRS property. Using the MACRS percentage
table, determine the depreciation charges for years 1 through 5.

\textbf{Solution:}\\
MACRS 15-year percentages: Year 1 = 5.00\%, Year 2 = 9.50\%, Year 3 =
8.55\%, Year 4 = 7.70\%, Year 5 = 6.93\%

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Year & MACRS \% & Depreciation & Cumulative \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 5.00\% & \$60,000 & \$60,000 \\
2 & 9.50\% & \$114,000 & \$174,000 \\
3 & 8.55\% & \$102,600 & \$276,600 \\
4 & 7.70\% & \$92,400 & \$369,000 \\
5 & 6.93\% & \$83,160 & \$452,160 \\
\end{longtable}
}

After 5 years, the cumulative depreciation is \textbf{\$452,160},
representing 37.68\% of the cost basis.

\end{examplebox}

\subsection{19.8.4 Units-of-Production
Depreciation}\label{units-of-production-depreciation}

Units-of-production (UOP) depreciation allocates cost based on actual
usage rather than time elapsed. The depreciation rate per unit is
d\textsubscript{unit} = (P − S) / Total units, and the depreciation in
any period is D = d\textsubscript{unit} × Units produced. This method is
appropriate for assets whose wear is driven by usage rather than age,
such as test equipment, generators measured by operating hours, or
production machinery measured by output quantity.

\begin{examplebox}

\textbf{Example 19.8.4:} A \$60,000 test instrument rated for 50,000
test cycles has a salvage value of \$5,000. It is used for 7,500 cycles
in year 1 and 9,200 cycles in year 2. Determine (a) the depreciation
rate per cycle and (b) the depreciation for each year.

\textbf{Solution:}

(a) d\textsubscript{unit} = (P − S) / Total units = (60,000 − 5,000) /
50,000 = 55,000 / 50,000 = \textbf{\$1.10/cycle}

(b) Year 1: D₁ = 1.10 × 7,500 = \textbf{\$8,250}\\
Year 2: D₂ = 1.10 × 9,200 = \textbf{\$10,120}

Book value after year 2: BV₂ = 60,000 − 8,250 − 10,120 =
\textbf{\$41,630}

\end{examplebox}

\section{19.9 Taxes and After-Tax
Analysis}\label{taxes-and-after-tax-analysis}

Income taxes significantly affect the economic viability of engineering
projects because they reduce the net cash flow from revenues and
savings. After-tax analysis accounts for the tax impact of operating
income, depreciation deductions, and gains or losses on asset disposal.
The after-tax cash flow (ATCF) in any year equals the before-tax cash
flow (BTCF) minus the income tax: ATCF = BTCF − Tax, where Tax =
(Taxable Income) × Tax Rate. Since depreciation is a non-cash deduction
that reduces taxable income, the choice of depreciation method directly
affects the timing and magnitude of after-tax cash flows.

\subsection{19.9.1 After-Tax Cash Flow
Analysis}\label{after-tax-cash-flow-analysis}

The after-tax cash flow for each year is computed as ATCF = BTCF − (BTCF
− D) × T, where BTCF is the before-tax cash flow, D is the depreciation
charge, and T is the marginal tax rate. This simplifies to ATCF = BTCF ×
(1 − T) + D × T, showing that depreciation provides a tax shield equal
to D × T. The after-tax NPV is computed using the after-tax MARR, which
is lower than the before-tax MARR.

\begin{examplebox}

\textbf{Example 19.9.1:} A \$500,000 power monitoring system generates
\$120,000/year in energy savings over 7 years with straight-line
depreciation and no salvage value. At a 25\% tax rate and after-tax MARR
of 8\%, determine the after-tax NPV.

\textbf{Solution:}\\
Annual depreciation: D = 500,000/7 = \$71,429/year\\
Taxable income: TI = 120,000 − 71,429 = \$48,571\\
Tax: T = 48,571 × 0.25 = \$12,143\\
ATCF = 120,000 − 12,143 = \$107,857/year

Alternatively: ATCF = 120,000 × (1 − 0.25) + 71,429 × 0.25 = 90,000 +
17,857 = \$107,857 ✓

After-tax NPV = −500,000 + 107,857 × (P/A, 8\%, 7)\\
(P/A, 8\%, 7) = {[}(1.08)⁷ − 1{]} / {[}0.08 × (1.08)⁷{]} = {[}1.7138 −
1{]} / {[}0.08 × 1.7138{]} = 0.7138 / 0.13710 = 5.2064\\
After-tax NPV = −500,000 + 107,857 × 5.2064 = −500,000 + 561,547 =
\textbf{\$61,547}

The project is justified on an after-tax basis (NPV \textgreater{} 0).

\end{examplebox}

\subsection{19.9.2 Tax Credits and
Incentives}\label{tax-credits-and-incentives}

Tax credits directly reduce the tax liability dollar-for-dollar, unlike
deductions that only reduce taxable income. The Investment Tax Credit
(ITC) for solar energy, for example, allows a percentage of the system
cost to be subtracted from taxes owed. Tax credits are treated as a
positive cash flow in the year they are applied. When combined with
accelerated depreciation (such as MACRS), tax incentives can
significantly improve project economics --- particularly for renewable
energy installations.

\begin{examplebox}

\textbf{Example 19.9.2:} A commercial building installs a \$300,000
rooftop solar array qualifying for a 30\% investment tax credit. Annual
energy savings are \$45,000 over 25 years. Using simplified 5-year
straight-line depreciation (on 85\% of cost after ITC adjustment), a
24\% tax rate, and after-tax MARR of 6\%, determine the after-tax NPV
for the first 5 years of cash flows plus the PW of remaining savings.

\textbf{Solution:}\\
ITC: 300,000 × 0.30 = \$90,000 (received in year 1)\\
Depreciable basis: 300,000 × 0.85 = \$255,000 (ITC reduces basis by half
the credit under some rules; using 85\% here)\\
Annual depreciation (years 1--5): D = 255,000/5 = \$51,000

Years 1--5 ATCF: BTCF = \$45,000; TI = 45,000 − 51,000 = −\$6,000 (tax
savings)\\
Tax = −6,000 × 0.24 = −\$1,440 (tax benefit); ATCF = 45,000 + 1,440 =
\$46,440\\
Year 1 additional: +\$90,000 ITC → Year 1 ATCF = 46,440 + 90,000 =
\$136,440

Years 6--25 ATCF: No depreciation; ATCF = 45,000 × (1 − 0.24) =
\$34,200/year

NPV = −300,000 + 136,440/(1.06) + 46,440 × (P/A, 6\%, 4) × (P/F, 6\%, 1)
+ 34,200 × (P/A, 6\%, 20) × (P/F, 6\%, 5)\\
= −300,000 + 128,717 + 46,440 × 3.4651 × 0.9434 + 34,200 × 11.470 ×
0.7473\\
= −300,000 + 128,717 + 151,811 + 293,146 = \textbf{\$273,674}

The solar array is highly justified with the tax credit.

\end{examplebox}

\subsection{19.9.3 Gain and Loss on
Disposal}\label{gain-and-loss-on-disposal}

When an asset is sold for more than its book value, the difference is a
taxable gain; when sold for less, the difference is a deductible loss.
The tax on disposal is Tax = (Selling Price − Book Value) × Tax Rate. A
gain increases tax liability, and a loss provides a tax benefit. The
after-tax salvage value is S\textsubscript{AT} = Selling Price − Tax on
gain (or + Tax benefit from loss). Disposal tax effects must be included
in the final year's cash flow for accurate after-tax analysis.

\begin{examplebox}

\textbf{Example 19.9.3:} A \$200,000 testing system is depreciated using
5-year MACRS and sold after 3 years for \$90,000. Determine (a) the book
value at disposal, (b) the gain or loss, and (c) the after-tax salvage
value at a 25\% tax rate.

\textbf{Solution:}

(a) MACRS 5-year percentages: Year 1 = 20\%, Year 2 = 32\%, Year 3 =
19.2\%\\
Cumulative depreciation: (0.20 + 0.32 + 0.192) × 200,000 = 0.712 ×
200,000 = \$142,400\\
BV₃ = 200,000 − 142,400 = \textbf{\$57,600}

(b) Selling price (\$90,000) \textgreater{} Book value (\$57,600) →
\textbf{Gain of \$32,400}

(c) Tax on gain: 32,400 × 0.25 = \$8,100\\
After-tax salvage: S\textsubscript{AT} = 90,000 − 8,100 =
\textbf{\$81,900}

\end{examplebox}

\section{19.10 Replacement Analysis}\label{replacement-analysis}

Replacement analysis determines the optimal time to retire existing
equipment (the defender) and replace it with new equipment (the
challenger). The key insight is that the defender's current market value
--- not its original cost --- is the relevant investment for keeping it.
The economic service life (ESL) is the number of years that minimizes
the equivalent uniform annual cost, and it provides the basis for
comparing the defender and challenger on an annual-cost basis.
Replacement decisions arise when maintenance costs are rising,
efficiency is declining, or newer technology offers better performance.

\subsection{19.10.1 Economic Service Life}\label{economic-service-life}

The economic service life is the number of years n that minimizes the
total equivalent uniform annual cost (EUAC), which includes capital
recovery and annual operating costs. As an asset ages, its capital
recovery cost decreases (the asset has already been largely paid for)
but operating costs typically increase. The ESL occurs at the crossover
point where the sum is minimized. For the challenger, the ESL determines
the AW used in comparison; for the defender, only the remaining economic
life is relevant.

\begin{examplebox}

\textbf{Example 19.10.1:} A 20-year-old distribution transformer has a
current market value of \$8,000 and annual maintenance costs that start
at \$3,000 in year 1 and increase by \$800/year. At i = 10\%, find the
economic service life by computing the EUAC for 1 through 5 years of
additional service (assume zero salvage in all cases).

\textbf{Solution:}\\
(A/P, 10\%, n) values: n=1: 1.1000; n=2: 0.57619; n=3: 0.40211; n=4:
0.31547; n=5: 0.26380

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Years & CR = 8,000 × (A/P) & AW of Maint. & EUAC \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \$8,800 & \$3,000 & \$11,800 \\
2 & \$4,610 & \$3,381 & \$7,991 \\
3 & \$3,217 & \$3,749 & \$6,966 \\
4 & \$2,524 & \$4,105 & \$6,629 \\
5 & \$2,110 & \$4,448 & \$6,558 \\
\end{longtable}
}

AW of maintenance for n years uses the gradient: AW = 3,000 + 800 ×
(A/G, 10\%, n)\\
(A/G, 10\%, n): n=1: 0; n=2: 0.4762; n=3: 0.9366; n=4: 1.3812; n=5:
1.8101

The EUAC continues to decrease through 5 years, so the ESL is \textbf{≥
5 years} (at 5 years, EUAC = \textbf{\$6,558/year}). In practice, the
ESL would be found by extending the analysis until EUAC begins to
increase.

\end{examplebox}

\subsection{19.10.2 Defender-Challenger
Comparison}\label{defender-challenger-comparison}

The defender is the existing equipment with its current market value as
the ``investment'' in keeping it, and the challenger is the new
replacement. The decision rule is: if the challenger's EUAC at its ESL
is less than the defender's EUAC at its ESL, replace now. If the
defender has a lower EUAC, keep it --- but re-evaluate annually as the
defender ages and its costs increase. The sunk cost of the original
purchase is irrelevant; only the current market value matters.

\begin{examplebox}

\textbf{Example 19.10.2:} A utility's existing switchgear (defender) has
a market value of \$25,000 and an EUAC of \$18,000/year for its
remaining economic life of 3 years. A new solid-state switchgear
(challenger) costs \$120,000 with an EUAC of \$15,500/year over a
15-year life. At i = 10\%, determine whether to replace now.

\textbf{Solution:}\\
Defender EUAC: \textbf{\$18,000/year} (for remaining ESL of 3 years)\\
Challenger EUAC: \textbf{\$15,500/year} (for 15-year ESL)

Since the challenger EUAC (\$15,500) \textless{} defender EUAC
(\$18,000), the annual savings from replacement are \$2,500/year.
\textbf{Replace now.} The new switchgear costs less on an annualized
basis than keeping the old equipment.

\end{examplebox}

\subsection{19.10.3 Replacement with a Study
Period}\label{replacement-with-a-study-period}

When management imposes a fixed planning horizon (study period), the
analysis must consider what happens at the end of the period. If the
defender cannot serve the full study period, a replacement (possibly the
challenger) must fill the remaining years. All feasible combinations of
defender and challenger service over the study period are evaluated, and
the combination with the lowest total EUAC or PW of costs is selected.

\begin{examplebox}

\textbf{Example 19.10.3:} Management sets a 10-year study period. The
defender can serve 4 more years with EUAC = \$22,000/year, and the
challenger has a 10-year life with EUAC = \$19,000/year. Compare (a)
replacing now versus (b) replacing at year 4. Use i = 8\%.

\textbf{Solution:}

(a) Replace now: Challenger serves all 10 years.\\
PW = 19,000 × (P/A, 8\%, 10) = 19,000 × 6.7101 = \textbf{\$127,492}

(b) Replace at year 4: Defender serves years 1--4, challenger serves
years 5--10.\\
PW = 22,000 × (P/A, 8\%, 4) + 19,000 × (P/A, 8\%, 6) × (P/F, 8\%, 4)\\
(P/A, 8\%, 4) = 3.3121; (P/A, 8\%, 6) = 4.6229; (P/F, 8\%, 4) = 0.7350\\
PW = 22,000 × 3.3121 + 19,000 × 4.6229 × 0.7350\\
= 72,867 + 64,559 = \textbf{\$137,426}

\textbf{Replace now} --- it saves \$137,426 − \$127,492 = \$9,934 in
present worth over the study period.

\end{examplebox}

\section{19.11 Inflation and Price
Changes}\label{inflation-and-price-changes}

Inflation is the sustained increase in the general price level, causing
purchasing power to decline over time. Engineering economic analysis
must account for inflation to avoid overstating the real value of future
cash flows. Two approaches exist: the actual-dollar (current-dollar)
method uses the market interest rate and cash flows stated in nominal
terms, while the constant-dollar (real-dollar) method uses the real
interest rate and cash flows stated in today's purchasing power. Both
approaches yield the same present worth when applied correctly. The
relationship between the market rate i\textsubscript{f}, real rate
i\textsubscript{r}, and inflation rate f is (1 + i\textsubscript{f}) =
(1 + i\textsubscript{r})(1 + f).

\subsection{19.11.1 Inflation-Adjusted
Analysis}\label{inflation-adjusted-analysis}

When inflation is present, the market (nominal) interest rate includes
an inflation premium. The real interest rate can be found from
i\textsubscript{r} = (i\textsubscript{f} − f) / (1 + f). In the
actual-dollar approach, future cash flows are escalated at the inflation
rate and discounted at the market rate. In the constant-dollar approach,
cash flows remain in today's dollars and are discounted at the real
rate. Both methods must produce the same present worth.

\begin{examplebox}

\textbf{Example 19.11.1:} A utility budgets \$50,000/year in today's
dollars for cable maintenance. With 3\% annual inflation and a market
MARR of 10\%, compute the present worth of 8 years of maintenance using
(a) the constant-dollar approach and (b) the actual-dollar approach.

\textbf{Solution:}

(a) Constant-dollar approach: Real rate i\textsubscript{r} = (0.10 −
0.03)/(1.03) = 0.07/1.03 = 6.796\%\\
PW = 50,000 × (P/A, 6.796\%, 8)\\
(P/A, 6.796\%, 8) = {[}(1.06796)⁸ − 1{]} / {[}0.06796 × (1.06796)⁸{]} =
{[}1.6922 − 1{]} / {[}0.06796 × 1.6922{]} = 0.6922 / 0.11501 = 6.019\\
PW = 50,000 × 6.019 = \textbf{\$300,950}

(b) Actual-dollar approach: Each year's cost is escalated at 3\%.\\
PW = Σ {[}50,000 × (1.03)\textsuperscript{t} /
(1.10)\textsuperscript{t}{]} for t = 1 to 8\\
= 50,000 × Σ {[}(1.03/1.10)\textsuperscript{t}{]} = 50,000 × Σ
{[}(0.93636)\textsuperscript{t}{]}\\
This is a geometric series with ratio 0.93636:\\
PW = 50,000 × 0.93636 × {[}1 − (0.93636)⁸{]} / {[}1 − 0.93636{]}\\
= 50,000 × 0.93636 × {[}1 − 0.5910{]} / 0.06364\\
= 50,000 × 0.93636 × 6.428 = \textbf{\$300,900}

The two approaches agree within rounding (≈ \$300,950), confirming
consistency.

\end{examplebox}

\subsection{19.11.2 Differential
Escalation}\label{differential-escalation}

Differential escalation occurs when the price of a specific commodity
increases faster or slower than the general inflation rate. The
differential escalation rate e\textsubscript{d} is the rate above
inflation: the actual escalation rate is approximately f +
e\textsubscript{d}. When a cost component escalates at a rate different
from general inflation, it must be treated as a geometric gradient
series using its specific escalation rate rather than the general
inflation rate.

\begin{examplebox}

\textbf{Example 19.11.2:} Copper conductor costs are escalating at
5\%/year while general inflation is 3\%/year. A project requires
\$200,000 of copper in year 1. At a market rate of 11\%, find the
present worth of copper purchases over 6 years.

\textbf{Solution:}\\
This is a geometric gradient with g = 5\% (copper escalation) and i =
11\% (market rate).\\
P = A₁ × {[}1 − (1 + g)ⁿ(1 + i)⁻ⁿ{]} / (i − g)\\
= 200,000 × {[}1 − (1.05)⁶(1.11)⁻⁶{]} / (0.11 − 0.05)\\
(1.05)⁶ = 1.3401; (1.11)⁶ = 1.8704\\
= 200,000 × {[}1 − 1.3401/1.8704{]} / 0.06\\
= 200,000 × {[}1 − 0.7165{]} / 0.06\\
= 200,000 × 0.2835 / 0.06\\
= 200,000 × 4.725 = \textbf{\$945,000}

The differential escalation rate above inflation is e\textsubscript{d} =
5\% − 3\% = 2\%/year, meaning copper is becoming more expensive in real
terms.

\end{examplebox}

\section{19.12 Capital Budgeting and Project
Selection}\label{capital-budgeting-and-project-selection}

Capital budgeting is the process of selecting which engineering projects
to fund when the total investment capital is limited. Unlike mutually
exclusive alternatives where exactly one must be chosen, capital
budgeting involves selecting a portfolio of independent projects that
maximizes the total economic value within a budget constraint. The
minimum attractive rate of return (MARR) serves as the hurdle rate that
separates acceptable from unacceptable investments, and it reflects the
opportunity cost of capital, the cost of borrowing, and a risk premium
appropriate to the project type.

\subsection{19.12.1 Independent Project Selection Under Budget
Constraints}\label{independent-project-selection-under-budget-constraints}

When capital is limited, the optimal portfolio is the combination of
independent projects that maximizes total NPV without exceeding the
budget. The approach is to compute the NPV of each project, then
evaluate all feasible combinations (bundles) that fit within the budget.
For small numbers of projects, enumeration is practical; for large
portfolios, the projects can be ranked by the profitability index (PI =
NPV/Investment) and selected in order until the budget is exhausted.

\begin{examplebox}

\textbf{Example 19.12.1:} A utility has \$3,000,000 in capital and five
independent project proposals. Select the portfolio that maximizes total
NPV within the budget.

\end{examplebox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Project & Investment & NPV \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A --- Substation upgrade & \$800,000 & \$120,000 \\
B --- Feeder reconductoring & \$1,200,000 & \$210,000 \\
C --- SCADA upgrade & \$600,000 & \$95,000 \\
D --- Capacitor banks & \$400,000 & \$55,000 \\
E --- Battery storage & \$1,500,000 & \$190,000 \\
\end{longtable}
}

\textbf{Solution:} Profitability index (PI = NPV/Investment): A = 0.150,
B = 0.175, C = 0.158, D = 0.138, E = 0.127

Rank by PI: B (0.175), C (0.158), A (0.150), D (0.138), E (0.127)

Select in order: B (\$1,200,000) + C (\$600,000) + A (\$800,000) + D
(\$400,000) = \$3,000,000 ✓ Total NPV = 210,000 + 95,000 + 120,000 +
55,000 = \textbf{\$480,000}

Verify no better combination: B + E = \$2,700,000 (NPV \$400,000) + C or
D fits → B + E + C = \$3,300,000 (exceeds budget) → B + E + D =
\$3,100,000 (exceeds budget). So B + C + A + D at \textbf{\$480,000 NPV}
is the optimal portfolio.

\subsection{19.12.2 Minimum Attractive Rate of Return
(MARR)}\label{minimum-attractive-rate-of-return-marr}

The MARR is the minimum return that a project must earn to be considered
acceptable. It is typically set above the cost of capital to account for
project risk, opportunity cost, and management expectations. The MARR
may be set as the weighted average cost of capital (WACC) plus a risk
premium, or based on the rate earned by the company's best rejected
project. A project is accepted if its IRR exceeds the MARR or its NPV at
the MARR is positive.

\begin{examplebox}

\textbf{Example 19.12.2:} A company can borrow at 7\% and earns 12\% on
its best current investments. With a risk premium of 3\% for a new power
electronics product line, determine (a) the appropriate MARR and (b)
whether a \$500,000 project returning \$95,000/year for 8 years is
acceptable.

\textbf{Solution:}

(a) The opportunity cost of capital is 12\% (best current return), plus
a 3\% risk premium → MARR = 12\% + 3\% = \textbf{15\%}

(b) NPV = −500,000 + 95,000 × (P/A, 15\%, 8)\\
(P/A, 15\%, 8) = {[}(1.15)⁸ − 1{]} / {[}0.15 × (1.15)⁸{]} = {[}3.0590 −
1{]} / {[}0.15 × 3.0590{]} = 2.0590 / 0.45885 = 4.4873\\
NPV = −500,000 + 95,000 × 4.4873 = −500,000 + 426,294 =
\textbf{−\$73,706}

Since NPV \textless{} 0, the project \textbf{does not meet the 15\%
MARR} and should be rejected.

\end{examplebox}

\section{19.13 Breakeven and Sensitivity
Analysis}\label{breakeven-and-sensitivity-analysis}

Breakeven and sensitivity analysis address the inherent uncertainty in
engineering economic estimates. Breakeven analysis finds the critical
value of a parameter (such as production volume, operating hours, or
energy price) at which two alternatives are equally attractive or a
single project's NPV equals zero. Sensitivity analysis systematically
varies one or more input parameters to determine how much the economic
outcome changes, revealing which parameters most influence the decision.
These techniques help engineers assess risk and make more robust
investment decisions.

\subsection{19.13.1 Breakeven Analysis}\label{breakeven-analysis}

Breakeven analysis determines the value of a key variable at which two
alternatives have equal annual worth, equal NPV, or equal total cost.
This critical value defines the threshold above or below which one
alternative becomes preferable. Breakeven analysis is commonly used to
evaluate energy-efficient equipment upgrades, make-versus-buy decisions,
and minimum production volume requirements.

\begin{examplebox}

\textbf{Example 19.13.1:} A factory considers replacing a 92\%-efficient
motor (\$6,000) with a 96\%-efficient motor (\$10,000) for a 50 HP load
running at 80\% average loading. Electricity costs \$0.10/kWh and i =
8\% over a 10-year life with no salvage value. Find the breakeven
operating hours per year.

\textbf{Solution:}\\
Power input (standard): P₁ = 50 × 0.746 × 0.80 / 0.92 = 32.43 kW\\
Power input (premium): P₂ = 50 × 0.746 × 0.80 / 0.96 = 31.08 kW\\
Power savings: ΔP = 32.43 − 31.08 = 1.35 kW

Annual energy savings for H hours: ΔE = 1.35 × H × \$0.10 = \$0.135 × H

Capital recovery of extra cost: ΔCR = (10,000 − 6,000) × (A/P, 8\%, 10)
= 4,000 × 0.14903 = \$596.12/year

Breakeven: 0.135 × H = 596.12\\
H = 596.12 / 0.135 = \textbf{4,416 hours/year}

If the motor operates more than 4,416 hours/year, the premium motor is
more economical. At 6,000 hours/year, annual savings exceed the cost
difference.

\end{examplebox}

\subsection{19.13.2 Single-Parameter Sensitivity
Analysis}\label{single-parameter-sensitivity-analysis}

Single-parameter sensitivity (or ``what-if'') analysis varies one input
at a time while holding all others at their base values. For each
parameter, the NPV (or AW) is recalculated over a range of values
(typically ±10\% to ±30\%). The results are often plotted on a spider
diagram, where steeper slopes indicate higher sensitivity. Parameters
with the greatest impact on the economic outcome deserve the most
careful estimation and risk management.

\begin{examplebox}

\textbf{Example 19.13.2:} A \$1,000,000 solar carport project has
expected annual savings of \$160,000 over 15 years with no salvage
value. At MARR = 8\%, determine (a) the base-case NPV, and (b) the NPV
if annual savings vary by ±20\%.

\textbf{Solution:}

(a) (P/A, 8\%, 15) = {[}(1.08)¹⁵ − 1{]} / {[}0.08 × (1.08)¹⁵{]} =
{[}3.1722 − 1{]} / {[}0.08 × 3.1722{]} = 2.1722 / 0.25378 = 8.5595\\
Base NPV = −1,000,000 + 160,000 × 8.5595 = −1,000,000 + 1,369,520 =
\textbf{\$369,520}

(b) At −20\% savings (\$128,000/year):\\
NPV = −1,000,000 + 128,000 × 8.5595 = −1,000,000 + 1,095,616 =
\textbf{\$95,616} (still positive)

At +20\% savings (\$192,000/year):\\
NPV = −1,000,000 + 192,000 × 8.5595 = −1,000,000 + 1,643,424 =
\textbf{\$643,424}

The NPV swings from \$95,616 to \$643,424 --- a range of \$547,808 ---
for a ±20\% change in savings. The project remains viable even at the
pessimistic estimate.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-19-13-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/ch19_sensitivity.png}

\caption{Figure 19.13.2: NPV Sensitivity Analysis}

\end{figure}

\subsection{19.13.3 Scenario Analysis}\label{scenario-analysis}

Scenario analysis evaluates a project under several coherent sets of
assumptions (typically pessimistic, most likely, and optimistic) where
multiple parameters vary simultaneously. Unlike single-parameter
sensitivity, scenario analysis captures the combined effect of changes
in related variables. Each scenario produces a distinct NPV, providing
decision-makers with a range of possible outcomes and their associated
assumptions.

\begin{examplebox}

\textbf{Example 19.13.3:} A wind turbine installation (\$3,000,000,
20-year life, no salvage) has annual revenues dependent on capacity
factor: pessimistic (25\%, \$280,000/year), most likely (32\%,
\$360,000/year), optimistic (38\%, \$430,000/year). At i = 9\%, compute
the NPV for each scenario.

\textbf{Solution:}\\
(P/A, 9\%, 20) = {[}(1.09)²⁰ − 1{]} / {[}0.09 × (1.09)²⁰{]} = {[}5.6044
− 1{]} / {[}0.09 × 5.6044{]} = 4.6044 / 0.50440 = 9.1285

Pessimistic: NPV = −3,000,000 + 280,000 × 9.1285 = −3,000,000 +
2,555,980 = \textbf{−\$444,020} (not viable)

Most likely: NPV = −3,000,000 + 360,000 × 9.1285 = −3,000,000 +
3,286,260 = \textbf{\$286,260} (viable)

Optimistic: NPV = −3,000,000 + 430,000 × 9.1285 = −3,000,000 + 3,925,255
= \textbf{\$925,255} (highly viable)

The project is viable in the most-likely and optimistic scenarios but
not in the pessimistic case. The decision depends on confidence in the
capacity factor estimate and risk tolerance.

\end{examplebox}

\section{19.14 Life Cycle Cost Analysis}\label{life-cycle-cost-analysis}

Life cycle cost (LCC) analysis evaluates the total cost of owning,
operating, maintaining, and disposing of an asset over its entire useful
life. Unlike simple first-cost comparisons, LCC captures the long-term
economic impact of design decisions, material choices, and maintenance
strategies. It is the standard method for major infrastructure
procurement in utilities, government agencies, and industrial
facilities. The levelized cost of energy (LCOE) is a specialized form of
LCC used to compare electricity generation technologies on a
per-unit-energy basis.

\subsection{19.14.1 Life Cycle Cost
Components}\label{life-cycle-cost-components}

The major LCC categories are: (1) acquisition costs (purchase price,
installation, commissioning), (2) operating costs (energy, labor,
consumables), (3) maintenance costs (preventive and corrective), (4)
periodic overhaul or replacement costs, and (5) disposal costs
(decommissioning, removal, environmental remediation). All costs are
converted to present worth at the discount rate for comparison. The
option with the lowest total LCC is preferred.

\begin{examplebox}

\textbf{Example 19.14.1:} Compare two UPS systems for a hospital data
center over 15 years at i = 6\%.

\end{examplebox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Cost Category & System A & System B \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Purchase & \$80,000 & \$120,000 \\
Installation & \$15,000 & \$10,000 \\
Annual maintenance & \$4,000/year & \$2,000/year \\
Battery replacement & \$12,000 at years 5, 10 & \$8,000 at years 7,
14 \\
Disposal & \$3,000 at year 15 & \$2,000 at year 15 \\
\end{longtable}
}

\textbf{Solution:} (P/A, 6\%, 15) = 9.7122; (P/F, 6\%, 5) = 0.7473;
(P/F, 6\%, 7) = 0.6651 (P/F, 6\%, 10) = 0.5584; (P/F, 6\%, 14) = 0.4423;
(P/F, 6\%, 15) = 0.4173

LCC\textsubscript{A} = 80,000 + 15,000 + 4,000 × 9.7122 + 12,000 ×
(0.7473 + 0.5584) + 3,000 × 0.4173 = 95,000 + 38,849 + 12,000 × 1.3057 +
1,252 = 95,000 + 38,849 + 15,668 + 1,252 = \textbf{\$150,769}

LCC\textsubscript{B} = 120,000 + 10,000 + 2,000 × 9.7122 + 8,000 ×
(0.6651 + 0.4423) + 2,000 × 0.4173 = 130,000 + 19,424 + 8,000 × 1.1074 +
835 = 130,000 + 19,424 + 8,859 + 835 = \textbf{\$159,118}

\textbf{System A has a lower life cycle cost} by \$8,349, despite the
higher annual maintenance, because its lower purchase price and
installation cost more than compensate.

\subsection{19.14.2 Levelized Cost of Energy
(LCOE)}\label{levelized-cost-of-energy-lcoe}

The levelized cost of energy is the constant per-unit cost of
electricity that equates the present worth of all lifetime costs with
the present worth of all lifetime energy production: LCOE = PW(Costs) /
PW(Energy). It allows direct comparison of generation technologies with
different capital costs, operating characteristics, and lifetimes. LCOE
is expressed in \$/MWh or ¢/kWh and is widely used in utility planning
and renewable energy project evaluation.

\begin{examplebox}

\textbf{Example 19.14.2:} A 10 MW solar PV plant costs \$12,000,000, has
annual O\&M of \$150,000 escalating at 2\%/year, produces 18,000
MWh/year with 0.5\%/year degradation, and has a 25-year life. At a
discount rate of 7\%, compute the LCOE.

\textbf{Solution:}\\
PW of capital: \$12,000,000

PW of O\&M (geometric gradient, g = 2\%, i = 7\%):\\
PW\textsubscript{O\&M} = 150,000 × {[}1 − (1.02)²⁵(1.07)⁻²⁵{]} / (0.07 −
0.02)\\
(1.02)²⁵ = 1.6406; (1.07)²⁵ = 5.4274\\
= 150,000 × {[}1 − 1.6406/5.4274{]} / 0.05\\
= 150,000 × {[}1 − 0.3023{]} / 0.05\\
= 150,000 × 0.6977 / 0.05 = 150,000 × 13.954 = \$2,093,100

PW of total costs: 12,000,000 + 2,093,100 = \$14,093,100

PW of energy production (geometric gradient with g = −0.5\%, i = 7\%):\\
PW\textsubscript{energy} = 18,000 × {[}1 − (0.995)²⁵(1.07)⁻²⁵{]} / (0.07
− (−0.005))\\
(0.995)²⁵ = 0.8822\\
= 18,000 × {[}1 − 0.8822/5.4274{]} / 0.075\\
= 18,000 × {[}1 − 0.1626{]} / 0.075\\
= 18,000 × 0.8374 / 0.075 = 18,000 × 11.165 = 200,970 MWh (present-worth
equivalent)

LCOE = 14,093,100 / 200,970 = \textbf{\$70.12/MWh}

\end{examplebox}

\chapter{Appendix A}\label{appendix-a}

\chapter{Imaginary Numbers and
Phasors}\label{imaginary-numbers-and-phasors}

Imaginary numbers and phasors are essential mathematical tools that
appear throughout electrical engineering. Complex numbers provide a
natural way to represent quantities that have both magnitude and
direction, such as AC voltages, currents, and impedances. Phasors extend
this concept by encoding the amplitude and phase of sinusoidal signals
as complex numbers, transforming differential equations into simple
algebraic operations. This appendix establishes the mathematical
foundations used extensively in circuit analysis, signal processing,
power systems, and control theory.

\section{A.1 Imaginary Numbers}\label{a.1-imaginary-numbers}

\subsection{A.1.1 The Imaginary Unit}\label{a.1.1-the-imaginary-unit}

The imaginary unit j is defined as the square root of negative one: j =
√(−1), or equivalently, j² = −1. In electrical engineering, the letter j
is used instead of i (which is reserved for current) to avoid confusion.
The imaginary unit enables the representation of numbers that have no
position on the real number line but are indispensable for describing
oscillatory and rotational phenomena. Any imaginary number is a real
number multiplied by j, such as j3, j7.5, or −j4.2.

\begin{examplebox}

\textbf{Example A.1.1:} Simplify √(−49) and express the result as an
imaginary number.

\textbf{Solution:}\\
√(−49) = √(49 × (−1)) = √49 × √(−1) = 7 × j = j7.\\
The result is the imaginary number j7, which lies on the imaginary axis
at a distance of 7 units from the origin.

\end{examplebox}

\subsection{A.1.2 Powers of j}\label{a.1.2-powers-of-j}

The powers of j follow a repeating cycle of four: j¹ = j, j² = −1, j³ =
−j, j⁴ = 1, and then the cycle repeats with j⁵ = j, j⁶ = −1, and so on.
This cyclic property means that any power of j can be reduced by
dividing the exponent by 4 and using the remainder: jⁿ =
j\textsuperscript{(n mod 4)}. Negative powers follow the same pattern:
j⁻¹ = −j, j⁻² = −1, j⁻³ = j. Understanding this cycle is essential for
simplifying expressions that arise in AC circuit analysis and signal
processing.

\begin{examplebox}

\textbf{Example A.1.2:} Simplify j⁷ + j¹⁰ + j⁻³.

\textbf{Solution:}\\
j⁷: 7 mod 4 = 3, so j⁷ = j³ = −j.\\
j¹⁰: 10 mod 4 = 2, so j¹⁰ = j² = −1.\\
j⁻³: −3 mod 4 = 1, so j⁻³ = j¹ = j.\\
Therefore j⁷ + j¹⁰ + j⁻³ = −j + (−1) + j = −1.

\end{examplebox}

\section{A.2 Complex Numbers}\label{a.2-complex-numbers}

\subsection{A.2.1 Rectangular Form}\label{a.2.1-rectangular-form}

A complex number in rectangular form is written as Z = a + jb, where a
is the real part (Re\{Z\}) and b is the imaginary part (Im\{Z\}).
Geometrically, complex numbers are represented on the complex plane with
the real part plotted on the horizontal axis and the imaginary part on
the vertical axis. The real part and imaginary part are extracted as a =
Re\{Z\} and b = Im\{Z\}. In circuit analysis, the real part of an
impedance represents resistance and the imaginary part represents
reactance, making rectangular form a direct representation of physical
circuit properties.

\begin{examplebox}

\textbf{Example A.2.1:} An impedance is Z = 47 + j22 Ω. Identify the
resistance and reactance, and determine the magnitude and angle.

\textbf{Solution:}\\
The resistance is R = Re\{Z\} = 47 Ω and the reactance is X = Im\{Z\} =
22 Ω (inductive, since positive).\\
The magnitude is \textbar Z\textbar{} = √(47² + 22²) = √(2209 + 484) =
√2693 = 51.89 Ω.\\
The angle is θ = arctan(22/47) = arctan(0.4681) = 25.08°.\\
So Z = 51.89∠25.08° Ω.

\end{examplebox}

\subsection{A.2.2 Complex Arithmetic}\label{a.2.2-complex-arithmetic}

Complex numbers are added and subtracted by combining their real and
imaginary parts separately: (a + jb) + (c + jd) = (a + c) + j(b + d).
Multiplication uses the distributive property and the fact that j² = −1:
(a + jb)(c + jd) = (ac − bd) + j(ad + bc). Division is performed by
multiplying the numerator and denominator by the complex conjugate of
the denominator: (a + jb)/(c + jd) = (a + jb)(c − jd)/(c² + d²).
Addition and subtraction are most efficient in rectangular form, while
multiplication and division are often easier in polar form.

\begin{examplebox}

\textbf{Example A.2.2:} Given Z₁ = 3 + j4 and Z₂ = 6 − j2, compute Z₁ +
Z₂, Z₁ × Z₂, and Z₁ / Z₂.

\textbf{Solution:}\\
Addition: Z₁ + Z₂ = (3 + 6) + j(4 + (−2)) = 9 + j2.\\
Multiplication: Z₁ × Z₂ = (3)(6) − (4)(−2) + j((3)(−2) + (4)(6)) = 18 +
8 + j(−6 + 24) = 26 + j18.\\
Division: Z₁ / Z₂ = (3 + j4)(6 + j2) / (6² + 2²) = ((18 − 8) + j(6 +
24)) / 40 = (10 + j30) / 40 = 0.25 + j0.75.

\end{examplebox}

\subsection{A.2.3 Complex Conjugate}\label{a.2.3-complex-conjugate}

The complex conjugate of Z = a + jb is Z* = a − jb, obtained by negating
the imaginary part. Geometrically, conjugation reflects a complex number
across the real axis. The product of a complex number and its conjugate
yields a real number: Z × Z* = a² + b² = \textbar Z\textbar². This
property is fundamental in circuit analysis for rationalizing complex
fractions (dividing complex numbers) and in power calculations where
complex power is S = V × I\emph{, with I} being the conjugate of the
current phasor.

\begin{examplebox}

\textbf{Example A.2.3:} Given Z = 5 + j12, find Z\emph{, the product Z ×
Z}, and verify that Z × Z* = \textbar Z\textbar².

\textbf{Solution:}\\
Z* = 5 − j12.\\
Z × Z* = (5 + j12)(5 − j12) = 25 − j60 + j60 − j²144 = 25 + 144 = 169.\\
Magnitude: \textbar Z\textbar{} = √(5² + 12²) = √(25 + 144) = √169 =
13.\\
Therefore \textbar Z\textbar² = 169, which confirms Z × Z* =
\textbar Z\textbar².

\end{examplebox}

\section{A.3 Polar and Exponential
Forms}\label{a.3-polar-and-exponential-forms}

\subsection{A.3.1 Polar Form}\label{a.3.1-polar-form}

A complex number can be expressed in polar form as Z =
\textbar Z\textbar∠θ, where \textbar Z\textbar{} = √(a² + b²) is the
magnitude and θ = arctan(b/a) is the angle (phase) measured from the
positive real axis. When computing θ, care must be taken with the
quadrant: if a \textless{} 0, the angle must be adjusted by adding 180°
(or π radians). Multiplication in polar form is straightforward: Z₁ × Z₂
= \textbar Z₁\textbar\textbar Z₂\textbar∠(θ₁ + θ₂), and division is Z₁ /
Z₂ = (\textbar Z₁\textbar/\textbar Z₂\textbar)∠(θ₁ − θ₂). Polar form is
the preferred representation for expressing AC voltages, currents, and
impedances because it directly displays the magnitude and phase shift.

\begin{examplebox}

\textbf{Example A.3.1:} Convert Z = −3 + j4 to polar form and express
the result in degrees.

\textbf{Solution:}\\
Magnitude: \textbar Z\textbar{} = √((−3)² + 4²) = √(9 + 16) = √25 = 5.\\
The reference angle is arctan(4/3) = 53.13°.\\
Since the real part is negative and the imaginary part is positive, Z
lies in the second quadrant, so θ = 180° − 53.13° = 126.87°.\\
Therefore Z = 5∠126.87°.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-a-3-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_a_polar_form.png}

\caption{Figure A.3.1: Complex Plane: Polar Form}

\end{figure}

\subsection{A.3.2 Euler's Formula}\label{a.3.2-eulers-formula}

Euler's formula states that e\textsuperscript{jθ} = cos(θ) + j sin(θ),
establishing a direct connection between exponential functions and
trigonometric functions. This relationship allows a complex number to be
written in exponential form as Z = \textbar Z\textbar{} ×
e\textsuperscript{jθ}, which is mathematically equivalent to polar form.
Euler's formula is the foundation of phasor analysis: a sinusoidal
signal v(t) = V\textsubscript{m} cos(ωt + φ) is represented by the
phasor V = V\textsubscript{m} × e\textsuperscript{jφ}. The special case
e\textsuperscript{jπ} + 1 = 0 (Euler's identity) connects the five most
fundamental constants in mathematics.

\begin{examplebox}

\textbf{Example A.3.2:} Express 10∠60° in exponential form and verify by
converting back to rectangular form.

\textbf{Solution:}\\
Exponential form: Z = 10 × e\textsuperscript{j60°} = 10 ×
e\textsuperscript{jπ/3}.\\
Converting to rectangular: Z = 10(cos 60° + j sin 60°) = 10(0.5 +
j0.866) = 5 + j8.66.\\
Verification: \textbar Z\textbar{} = √(5² + 8.66²) = √(25 + 75) = √100 =
10 and θ = arctan(8.66/5) = arctan(1.732) = 60°.\\
The result matches the original polar form.

\end{examplebox}

\subsection{A.3.3 Conversion Between
Forms}\label{a.3.3-conversion-between-forms}

Converting between rectangular and polar forms is a routine operation in
AC analysis. Rectangular to polar: given Z = a + jb, the magnitude is
\textbar Z\textbar{} = √(a² + b²) and the angle is θ = atan2(b, a),
where the atan2 function correctly handles all four quadrants. Polar to
rectangular: given Z = \textbar Z\textbar∠θ, the real part is a =
\textbar Z\textbar{} cos(θ) and the imaginary part is b =
\textbar Z\textbar{} sin(θ). Engineers frequently switch between forms
during a single analysis: using polar form for multiplication/division
steps and rectangular form for addition/subtraction steps.

\begin{examplebox}

\textbf{Example A.3.3:} Two impedances in series are Z₁ = 20∠45° Ω and
Z₂ = 15∠−30° Ω. Find the total impedance in both rectangular and polar
form.

\textbf{Solution:}\\
Convert to rectangular for addition.\\
Z₁ = 20 cos 45° + j20 sin 45° = 14.14 + j14.14 Ω.\\
Z₂ = 15 cos(−30°) + j15 sin(−30°) = 12.99 − j7.5 Ω.\\
Total: Z\textsubscript{total} = (14.14 + 12.99) + j(14.14 − 7.5) = 27.13
+ j6.64 Ω.\\
Converting back to polar: \textbar Z\textsubscript{total}\textbar{} =
√(27.13² + 6.64²) = √(736.0 + 44.1) = √780.1 = 27.93 Ω.\\
θ = arctan(6.64 / 27.13) = 13.76°.\\
Therefore Z\textsubscript{total} = 27.93∠13.76° Ω.

\end{examplebox}

\section{A.4 Phasors}\label{a.4-phasors}

\subsection{A.4.1 Sinusoidal
Representation}\label{a.4.1-sinusoidal-representation}

A sinusoidal signal in the time domain is described by v(t) =
V\textsubscript{m} cos(ωt + φ), where V\textsubscript{m} is the peak
amplitude, ω = 2πf is the angular frequency in rad/s, and φ is the phase
angle in degrees or radians. Since all voltages and currents in a linear
AC circuit operate at the same frequency, the frequency information (ωt)
is redundant once established and can be suppressed. This key insight
allows the time-domain sinusoid to be represented compactly as a phasor:
a complex number that captures only the amplitude and phase,
dramatically simplifying AC circuit analysis.

\begin{examplebox}

\textbf{Example A.4.1:} A voltage waveform is v(t) = 170 cos(377t + 30°)
V. Identify the peak amplitude, frequency, period, and phase angle.

\textbf{Solution:}\\
Peak amplitude: V\textsubscript{m} = 170 V.\\
Angular frequency: ω = 377 rad/s, so the frequency is f = ω / (2π) = 377
/ 6.2832 = 60 Hz.\\
Period: T = 1/f = 1/60 = 16.67 ms.\\
Phase angle: φ = 30° (leading the reference cosine by 30°).\\
The RMS value is V\textsubscript{rms} = V\textsubscript{m} / √2 = 170 /
1.414 = 120.2 V.

\end{examplebox}

\subsection{A.4.2 Phasor Notation}\label{a.4.2-phasor-notation}

A phasor is a complex number that represents a sinusoidal quantity by
its amplitude and phase angle, with the time-varying component (ωt)
implicit. The time-domain signal v(t) = V\textsubscript{m} cos(ωt + φ)
is represented by the phasor V = V\textsubscript{m}∠φ (using peak
values) or V = V\textsubscript{rms}∠φ (using RMS values). In power
engineering, RMS phasors are standard because they simplify power
calculations (P = V\textsubscript{rms} × I\textsubscript{rms} × cos(φ)).
Phasor notation transforms calculus operations into algebra:
differentiation in time (d/dt) becomes multiplication by jω, and
integration becomes division by jω, enabling AC circuit analysis using
the same techniques as DC analysis.

\begin{examplebox}

\textbf{Example A.4.2:} Express v(t) = 311 cos(314t − 45°) V as an RMS
phasor, and convert the phasor V = 24∠60° V\textsubscript{rms} back to a
time-domain expression at 50 Hz.

\textbf{Solution:}\\
For v(t) = 311 cos(314t − 45°): V\textsubscript{rms} = 311 / √2 = 219.9
V, so the phasor is V = 219.9∠−45° V\textsubscript{rms}.\\
For the reverse: V = 24∠60° V\textsubscript{rms}, so V\textsubscript{m}
= 24 × √2 = 33.94 V.\\
At 50 Hz, ω = 2π × 50 = 314.16 rad/s.\\
The time-domain expression is v(t) = 33.94 cos(314.16t + 60°) V.

\end{examplebox}

\subsection{A.4.3 Phasor Arithmetic}\label{a.4.3-phasor-arithmetic}

Phasor addition and subtraction are performed in rectangular form by
adding or subtracting the real and imaginary components separately.
Phasor multiplication and division are performed in polar form by
multiplying/dividing magnitudes and adding/subtracting angles. When
combining voltages in series (KVL) or currents at a node (KCL), phasors
must be added as vectors, not as scalar magnitudes. The resultant
magnitude of two phasors at different angles is always less than or
equal to the sum of their individual magnitudes, with equality occurring
only when both phasors are in phase.

\begin{examplebox}

\textbf{Example A.4.3:} Two voltage sources in series produce V₁ =
100∠0° V and V₂ = 60∠90° V. Find the total voltage phasor and its
magnitude.

\textbf{Solution:}\\
Convert to rectangular: V₁ = 100 + j0 V, V₂ = 0 + j60 V.\\
Total: V\textsubscript{total} = 100 + j60 V.\\
Magnitude: \textbar V\textsubscript{total}\textbar{} = √(100² + 60²) =
√(10,000 + 3,600) = √13,600 = 116.6 V.\\
Angle: θ = arctan(60/100) = 30.96°.\\
So V\textsubscript{total} = 116.6∠30.96° V.\\
Note that the combined voltage (116.6 V) is less than the arithmetic sum
(100 + 60 = 160 V) because the sources are 90° out of phase.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-a-4-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_a_phasor_addition.png}

\caption{Figure A.4.3: Phasor Addition}

\end{figure}

\subsection{A.4.4 Phasor Diagrams}\label{a.4.4-phasor-diagrams}

A phasor diagram is a graphical representation of phasors plotted on the
complex plane, with the real axis horizontal and the imaginary axis
vertical. Each phasor is drawn as an arrow from the origin, with its
length proportional to the magnitude and its angle measured
counterclockwise from the positive real axis. Phasor diagrams provide
visual insight into phase relationships between voltages and currents:
in a purely resistive circuit, voltage and current phasors are aligned;
in an inductive circuit, current lags voltage; in a capacitive circuit,
current leads voltage. They are particularly useful for understanding
power factor, resonance conditions, and the effect of adding reactive
compensation.

\begin{examplebox}

\textbf{Example A.4.4:} A series RL circuit carries I = 5∠0° A through R
= 30 Ω and X\textsubscript{L} = 40 Ω. Find the voltage across each
element and the total voltage, then describe the phasor diagram.

\textbf{Solution:}\\
V\textsubscript{R} = I × R = 5∠0° × 30 = 150∠0° V (in phase with
current).\\
V\textsubscript{L} = I × jX\textsubscript{L} = 5∠0° × 40∠90° = 200∠90° V
(leads current by 90°).\\
Total: V\textsubscript{total} = 150 + j200 V = 250∠53.13° V.\\
On the phasor diagram, the current phasor (reference) points along the
positive real axis. V\textsubscript{R} is aligned with the current,
V\textsubscript{L} points straight up (90° ahead), and
V\textsubscript{total} is the diagonal of the rectangle formed by
V\textsubscript{R} and V\textsubscript{L}, at 53.13° above the real
axis.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-a-4-4}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_a_phasor_diagram.png}

\caption{Figure A.4.4: Series RL Phasor Diagram}

\end{figure}

\section{A.5 Applications in Circuit
Analysis}\label{a.5-applications-in-circuit-analysis}

\subsection{A.5.1 Impedance and
Admittance}\label{a.5.1-impedance-and-admittance}

Impedance Z = R + jX generalizes resistance to AC circuits, where R is
resistance and X is reactance (positive for inductors, negative for
capacitors). The impedance of a resistor is Z\textsubscript{R} = R, an
inductor is Z\textsubscript{L} = jωL, and a capacitor is
Z\textsubscript{C} = 1/(jωC) = −j/(ωC). Admittance Y = 1/Z = G + jB is
the reciprocal of impedance, where G is conductance and B is
susceptance. Impedances in series add directly (Z\textsubscript{total} =
Z₁ + Z₂ + \ldots), while admittances in parallel add directly
(Y\textsubscript{total} = Y₁ + Y₂ + \ldots), exactly analogous to
resistances and conductances in DC circuits.

\begin{examplebox}

\textbf{Example A.5.1:} A 100 Ω resistor, a 10 mH inductor, and a 50 μF
capacitor are connected in series at 1 kHz. Find the total impedance and
admittance.

\textbf{Solution:}\\
ω = 2π × 1000 = 6283.2 rad/s.\\
Z\textsubscript{R} = 100 Ω.\\
Z\textsubscript{L} = jωL = j × 6283.2 × 0.010 = j62.83 Ω.\\
Z\textsubscript{C} = −j/(ωC) = −j/(6283.2 × 50 × 10⁻⁶) = −j/(0.31416) =
−j3.18 Ω.\\
Total: Z\textsubscript{total} = 100 + j62.83 − j3.18 = 100 + j59.65 Ω =
116.4∠30.82° Ω.\\
Admittance: Y = 1/Z\textsubscript{total} = 1/116.4∠30.82° = 8.59 ×
10⁻³∠−30.82° S = (7.38 − j4.40) × 10⁻³ S.

\end{examplebox}

\subsection{A.5.2 Voltage and Current
Phasors}\label{a.5.2-voltage-and-current-phasors}

In phasor-domain circuit analysis, Ohm's law becomes V = I × Z, and all
DC analysis methods (KVL, KCL, nodal analysis, mesh analysis,
superposition, Thevenin/Norton) apply directly with complex-valued
voltages, currents, and impedances. The voltage across an element and
the current through it are related by the impedance of that element: the
magnitude ratio \textbar V\textbar/\textbar I\textbar{} =
\textbar Z\textbar{} determines the amplitude relationship, while the
angle difference ∠V − ∠I = ∠Z determines the phase relationship. In a
resistor the voltage and current are in phase, across an inductor the
voltage leads the current by 90°, and across a capacitor the voltage
lags the current by 90°.

\begin{examplebox}

\textbf{Example A.5.2:} A source V\textsubscript{s} = 120∠0°
V\textsubscript{rms} at 60 Hz drives a series circuit of R = 20 Ω and C
= 100 μF. Find the current phasor and the voltage across the capacitor.

\textbf{Solution:}\\
ω = 2π × 60 = 376.99 rad/s.\\
Z\textsubscript{C} = −j/(ωC) = −j/(376.99 × 100 × 10⁻⁶) = −j26.53 Ω.\\
Z\textsubscript{total} = 20 − j26.53 Ω.\\
\textbar Z\textsubscript{total}\textbar{} = √(20² + 26.53²) = √(400 +
703.84) = √1103.8 = 33.22 Ω.\\
θ = arctan(−26.53/20) = −52.99°.\\
Current: I = V\textsubscript{s} / Z\textsubscript{total} = 120∠0° /
33.22∠−52.99° = 3.61∠52.99° A\textsubscript{rms} (current leads voltage,
confirming capacitive circuit).\\
Voltage across capacitor: V\textsubscript{C} = I × Z\textsubscript{C} =
3.61∠52.99° × 26.53∠−90° = 95.77∠−37.01° V\textsubscript{rms}.

\end{examplebox}

\subsection{A.5.3 Power in Phasor
Form}\label{a.5.3-power-in-phasor-form}

Complex power is defined as S = V × I* = P + jQ, where I* is the complex
conjugate of the current phasor, P is real power in watts (W), and Q is
reactive power in volt-amperes reactive (VAR). The magnitude
\textbar S\textbar{} = V\textsubscript{rms} × I\textsubscript{rms} is
the apparent power in volt-amperes (VA). The power factor is pf =
P/\textbar S\textbar{} = cos(θ), where θ is the angle of the complex
power (equivalently, the phase difference between voltage and current).
A positive Q indicates a lagging (inductive) load that absorbs reactive
power, while a negative Q indicates a leading (capacitive) load that
supplies reactive power. The complex power formulation unifies all power
relationships into a single expression and enables systematic power
analysis of multi-element circuits.

\begin{examplebox}

\textbf{Example A.5.3:} A load draws I = 10∠−25° A\textsubscript{rms}
from a source V = 240∠0° V\textsubscript{rms}. Calculate the complex
power, real power, reactive power, apparent power, and power factor.

\textbf{Solution:}\\
Complex power: S = V × I* = 240∠0° × 10∠25° = 2400∠25° VA. (Note: I* =
10∠+25° since the conjugate negates the angle.)\\
Real power: P = \textbar S\textbar{} cos(25°) = 2400 × 0.9063 = 2175
W.\\
Reactive power: Q = \textbar S\textbar{} sin(25°) = 2400 × 0.4226 = 1014
VAR (positive, so inductive/lagging).\\
Apparent power: \textbar S\textbar{} = 2400 VA.\\
Power factor: pf = cos(25°) = 0.906 lagging.\\
The load consumes 2175 W of real power while exchanging 1014 VAR of
reactive power with the source.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-a-5-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_a_power_triangle.png}

\caption{Figure A.5.3: Power Triangle}

\end{figure}

\chapter{Appendix B}\label{appendix-b}

\chapter{Arctangent and atan2}\label{arctangent-and-atan2}

Computing angles from rectangular coordinates is one of the most common
operations in AC circuit analysis, yet it contains a subtle pitfall that
can produce incorrect results. The standard arctangent function (atan)
returns angles in only two quadrants, making it unable to distinguish
between points in opposite quadrants that share the same tangent ratio.
The two-argument arctangent function (atan2) resolves this ambiguity by
considering the signs of both coordinates independently, returning the
correct angle in all four quadrants. This appendix explains the
difference between these two functions and demonstrates why atan2 is the
reliable choice for electrical engineering calculations.

\section{B.1 The Arctangent Function}\label{b.1-the-arctangent-function}

\subsection{B.1.1 Definition and
Range}\label{b.1.1-definition-and-range}

The arctangent function, written as arctan(x) or tan⁻¹(x), is the
inverse of the tangent function. Given a ratio x = b/a (imaginary part
divided by real part), arctan(x) returns the angle θ whose tangent
equals x. The range of arctan is limited to −90° \textless{} θ
\textless{} +90° (or −π/2 \textless{} θ \textless{} +π/2 in radians),
corresponding to quadrants I and IV of the complex plane. This
restricted range ensures that arctan is a proper function
(single-valued), but it means the output is always between −90° and +90°
regardless of where the original complex number actually lies.

\begin{examplebox}

\textbf{Example B.1.1:} Calculate arctan(1) and arctan(−1), and identify
which quadrant each result falls in.

\textbf{Solution:}\\
arctan(1) = 45°, which lies in quadrant I (positive real, positive
imaginary).\\
arctan(−1) = −45°, which lies in quadrant IV (positive real, negative
imaginary).\\
Both results fall within the range −90° to +90°, confirming that arctan
can only return angles in quadrants I and IV.

\end{examplebox}

\subsection{B.1.2 Quadrant Ambiguity}\label{b.1.2-quadrant-ambiguity}

The fundamental problem with arctan is that tan(θ) = b/a produces the
same ratio for two angles that are 180° apart. For example, a phasor at
135° has components a = −1 (real) and b = +1 (imaginary), so b/a =
(+1)/(−1) = −1, and arctan(−1) = −45°, missing the true angle by 180°.
This occurs because dividing b by a discards the individual signs: the
ratio (−4)/(−3) is indistinguishable from 4/3, and (−4)/3 is
indistinguishable from 4/(−3). In circuit analysis, this means an
impedance in the second quadrant (negative resistance with positive
reactance) or third quadrant (both negative) would be assigned an
incorrect angle if only arctan(X/R) is used. Engineers using arctan must
manually inspect the signs of the real and imaginary parts and add or
subtract 180° to correct the angle when the real part is negative.

\begin{examplebox}

\textbf{Example B.1.2:} Two impedances have the same tangent ratio: Z₁ =
3 + j4 Ω and Z₂ = −3 − j4 Ω. Show that arctan gives the same angle for
both and determine the correct angles.

\textbf{Solution:}\\
For Z₁: arctan(4/3) = arctan(1.333) = 53.13°.\\
For Z₂: arctan(−4/−3) = arctan(1.333) = 53.13°.\\
Both return 53.13°, but Z₁ is in quadrant I while Z₂ is in quadrant
III.\\
The correct angle for Z₂ is 53.13° − 180° = −126.87° (or equivalently
233.13°).\\
Using arctan alone without checking the signs of the real and imaginary
parts gives a 180° error for Z₂.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-b-1-2}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_b_quadrant_ambiguity.png}

\caption{Figure B.1.2: Quadrant Ambiguity: arctan vs atan2}

\end{figure}

\section{B.2 The Two-Argument
Arctangent}\label{b.2-the-two-argument-arctangent}

\subsection{B.2.1 Definition and Full-Circle
Range}\label{b.2.1-definition-and-full-circle-range}

The two-argument arctangent function atan2(b, a) takes the imaginary
part b and the real part a as separate arguments, preserving their
individual signs. It returns the angle θ in the range −180° \textless{}
θ ≤ +180° (or −π \textless{} θ ≤ +π in radians), covering all four
quadrants of the complex plane. The function is defined for all (a, b)
pairs except (0, 0) and is equivalent to arctan(b/a) with automatic
quadrant correction. In most programming languages and scientific
calculators, atan2 is available as a built-in function: atan2(y, x) in
C/Python/MATLAB, or ATAN2(y, x) in spreadsheets.

\begin{examplebox}

\textbf{Example B.2.1:} Compute atan2(4, 3), atan2(−4, −3), atan2(4,
−3), and atan2(−4, 3), and verify that each returns the correct
quadrant.

\textbf{Solution:}\\
atan2(4, 3) = 53.13° (quadrant I: a \textgreater{} 0, b \textgreater{}
0).\\
atan2(−4, −3) = −126.87° (quadrant III: a \textless{} 0, b \textless{}
0).\\
atan2(4, −3) = 126.87° (quadrant II: a \textless{} 0, b \textgreater{}
0).\\
atan2(−4, 3) = −53.13° (quadrant IV: a \textgreater{} 0, b \textless{}
0).\\
All four results are distinct and correctly identify the quadrant,
unlike arctan which would return only 53.13° or −53.13° for all four
cases.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-b-2-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_b_four_quadrants.png}

\caption{Figure B.2.1: atan2 in All Four Quadrants}

\end{figure}

\subsection{B.2.2 Quadrant Resolution}\label{b.2.2-quadrant-resolution}

The atan2 function determines the correct quadrant by examining the
signs of a and b independently before computing the angle. When a
\textgreater{} 0, the angle is simply arctan(b/a) (quadrants I and IV).
When a \textless{} 0 and b ≥ 0, the angle is arctan(b/a) + 180°
(quadrant II). When a \textless{} 0 and b \textless{} 0, the angle is
arctan(b/a) − 180° (quadrant III). When a = 0, the angle is +90° if b
\textgreater{} 0 or −90° if b \textless{} 0. This logic is built into
the atan2 function, so the engineer does not need to perform manual
quadrant checks --- the function always returns the geometrically
correct angle.

\begin{examplebox}

\textbf{Example B.2.2:} An impedance Z = −10 + j5 Ω lies in quadrant II.
Compute the angle using both arctan and atan2, and show the correction
needed for arctan.

\textbf{Solution:}\\
Using arctan: θ = arctan(5/(−10)) = arctan(−0.5) = −26.57°. This
incorrectly places Z in quadrant IV.\\
Manual correction: since a \textless{} 0, add 180°: θ = −26.57° + 180° =
153.43° (quadrant II, correct).\\
Using atan2: θ = atan2(5, −10) = 153.43° directly, with no manual
correction needed.\\
The magnitude is \textbar Z\textbar{} = √(100 + 25) = √125 = 11.18 Ω, so
Z = 11.18∠153.43° Ω.

\end{examplebox}

\subsection{B.2.3 Special Cases and Axis
Points}\label{b.2.3-special-cases-and-axis-points}

The atan2 function handles points on the real and imaginary axes
correctly, where arctan(b/a) would encounter division by zero or
ambiguity. For a purely real positive number (a \textgreater{} 0, b =
0), atan2 returns 0°. For a purely real negative number (a \textless{}
0, b = 0), atan2 returns 180° (or ±180°). For a purely imaginary
positive number (a = 0, b \textgreater{} 0), atan2 returns 90°. For a
purely imaginary negative number (a = 0, b \textless{} 0), atan2 returns
−90°. These axis cases arise frequently in circuit analysis: a pure
resistance has 0° impedance angle, a pure inductance has +90°, and a
pure capacitance has −90°.

\begin{examplebox}

\textbf{Example B.2.3:} Find the impedance angle for a 50 mH inductor
and a 100 μF capacitor at 60 Hz using atan2.

\textbf{Solution:}\\
For the inductor: Z\textsubscript{L} = jωL = j × 2π × 60 × 0.050 =
j18.85 Ω, so a = 0 and b = 18.85.\\
atan2(18.85, 0) = 90°, confirming the inductor impedance has a +90°
angle (voltage leads current).\\
For the capacitor: Z\textsubscript{C} = −j/(ωC) = −j/(2π × 60 × 100 ×
10⁻⁶) = −j26.53 Ω, so a = 0 and b = −26.53.\\
atan2(−26.53, 0) = −90°, confirming the capacitor impedance has a −90°
angle (voltage lags current).

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-b-2-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_b_axis_points.png}

\caption{Figure B.2.3: atan2 Special Cases: Axis Points}

\end{figure}

\section{B.3 Applications in Electrical
Engineering}\label{b.3-applications-in-electrical-engineering}

\subsection{B.3.1 Impedance Angle
Calculation}\label{b.3.1-impedance-angle-calculation}

When converting an impedance from rectangular form Z = R + jX to polar
form Z = \textbar Z\textbar∠θ, the angle θ should be computed using
atan2(X, R) rather than arctan(X/R). For passive circuits where R ≥ 0,
arctan(X/R) happens to give correct results because the impedance always
lies in quadrants I or IV (inductive or capacitive with positive
resistance). However, in circuits with negative resistance (such as
active circuits with oscillators, tunnel diodes, or negative impedance
converters), the impedance can fall in quadrants II or III, and atan2
becomes essential for correctness.

\begin{examplebox}

\textbf{Example B.3.1:} A negative impedance converter produces an
effective impedance of Z = −50 + j30 Ω. Calculate the polar form using
atan2 and show the error that arctan would produce.

\textbf{Solution:}\\
Magnitude: \textbar Z\textbar{} = √((−50)² + 30²) = √(2500 + 900) =
√3400 = 58.31 Ω.\\
Using atan2: θ = atan2(30, −50) = 180° − arctan(30/50) = 180° − 30.96° =
149.04°. So Z = 58.31∠149.04° Ω (quadrant II, correct).\\
Using arctan: θ = arctan(30/(−50)) = arctan(−0.6) = −30.96° (quadrant
IV, wrong quadrant).\\
The arctan result has a 180° error because it cannot distinguish between
(−50, 30) in quadrant II and (50, −30) in quadrant IV.

\end{examplebox}

\subsection{B.3.2 Phasor Angle from Rectangular
Components}\label{b.3.2-phasor-angle-from-rectangular-components}

When measuring or computing AC voltages and currents, the in-phase
(real) and quadrature (imaginary) components are often obtained
separately --- for example, from an I/Q demodulator, a lock-in
amplifier, or a digital signal processing algorithm. Converting these
rectangular components to a magnitude-and-angle phasor requires atan2 to
correctly determine the phase angle across all four quadrants. This is
especially important in communications engineering where phase angles
span the full 360° range, and in power systems where current phasors can
lag or lead the voltage reference by any angle.

\begin{examplebox}

\textbf{Example B.3.2:} A lock-in amplifier measures a signal with
in-phase component I = −2.5 mV and quadrature component Q = −4.33 mV.
Find the signal magnitude and phase angle.

\textbf{Solution:}\\
Magnitude: \textbar V\textbar{} = √((−2.5)² + (−4.33)²) = √(6.25 +
18.75) = √25 = 5.0 mV.\\
Phase angle: θ = atan2(−4.33, −2.5) = −(180° − arctan(4.33/2.5)) =
−(180° − 60°) = −120° (quadrant III).\\
The phasor is V = 5.0∠−120° mV.\\
Using arctan(−4.33/−2.5) = arctan(1.732) = 60° would incorrectly place
the phasor in quadrant I, a 180° error.

\end{examplebox}

\subsection{B.3.3 Power Factor Angle}\label{b.3.3-power-factor-angle}

The power factor angle φ between voltage and current phasors determines
whether a load is inductive (lagging) or capacitive (leading). When
complex power S = P + jQ is computed from real power P and reactive
power Q, the power factor angle is φ = atan2(Q, P). For typical loads
where P \textgreater{} 0, arctan(Q/P) gives the correct result. However,
in systems with regenerative loads (motors returning energy to the
grid), P can be negative, and atan2 is needed to correctly identify the
power flow direction and the associated angle in quadrants II or III.

\begin{examplebox}

\textbf{Example B.3.3:} A regenerative drive returns power to the grid
during braking, producing S = −800 + j600 VA (negative real power,
positive reactive power). Find the power factor angle and compare the
arctan and atan2 results.

\textbf{Solution:}\\
Using atan2: φ = atan2(600, −800) = 180° − arctan(600/800) = 180° −
36.87° = 143.13°. This correctly indicates the operating point is in
quadrant II (power flowing back to the source with inductive reactive
power).\\
Using arctan: φ = arctan(600/(−800)) = arctan(−0.75) = −36.87°, which
incorrectly suggests quadrant IV (consuming power with capacitive
reactive power).\\
The apparent power is \textbar S\textbar{} = √(800² + 600²) = √1,000,000
= 1000 VA, and the power factor is cos(143.13°) = −0.8, where the
negative sign indicates reverse power flow.

\end{examplebox}

\chapter{Appendix C}\label{appendix-c}

\chapter{Decibels}\label{decibels}

The decibel (dB) is a logarithmic unit used throughout electrical
engineering to express ratios of power, voltage, or current. Because
engineering systems routinely span many orders of magnitude --- from
microvolt sensor signals to megawatt transmitters, or from nanovolt
noise floors to volt-level outputs --- linear scales become unwieldy.
The logarithmic decibel scale compresses these enormous ranges into
manageable numbers and converts multiplication and division of gains and
losses into simple addition and subtraction. This appendix covers the
definition, common reference levels, useful rules of thumb, and
practical applications of decibels in electrical engineering.

\section{C.1 Definition and
Fundamentals}\label{c.1-definition-and-fundamentals}

\subsection{C.1.1 Power Ratios}\label{c.1.1-power-ratios}

The decibel was originally defined as a ratio of two power levels: dB =
10 × log₁₀(P₂/P₁), where P₁ is the reference power and P₂ is the
measured power. A positive dB value indicates a gain (P₂ \textgreater{}
P₁), while a negative dB value indicates a loss or attenuation (P₂
\textless{} P₁). A ratio of 0 dB means the two power levels are equal.
The factor of 10 in the formula scales the unit so that 1 dB represents
a power ratio of approximately 1.259:1, which is a conveniently small
increment for practical measurements.

\begin{examplebox}

\textbf{Example C.1.1:} An amplifier receives 5 mW of input power and
delivers 800 mW of output power. Express the power gain in decibels.

\textbf{Solution:} G = 10 ×
log₁₀(P\textsubscript{out}/P\textsubscript{in}) = 10 × log₁₀(800/5) = 10
× log₁₀(160) = 10 × 2.204 = 22.04 dB. The amplifier provides 22.04 dB of
power gain.

\end{examplebox}

\subsection{C.1.2 Voltage and Current
Ratios}\label{c.1.2-voltage-and-current-ratios}

Since power is proportional to voltage squared (P = V²/R) and current
squared (P = I²R), the decibel formula for voltage and current ratios
includes a factor of 20 instead of 10: dB = 20 × log₁₀(V₂/V₁) or dB = 20
× log₁₀(I₂/I₁). This ensures consistency with the power definition ---
doubling the voltage across the same impedance quadruples the power,
which is 6.02 dB by either formula. The voltage/current form assumes
equal impedances at the measurement points; when impedances differ, the
power ratio formula should be used directly.

\begin{examplebox}

\textbf{Example C.1.2:} A filter attenuates a 2 V\textsubscript{rms}
input signal to 0.35 V\textsubscript{rms} at the output. Express the
voltage gain in decibels.

\textbf{Solution:} A\textsubscript{v} = 20 ×
log₁₀(V\textsubscript{out}/V\textsubscript{in}) = 20 × log₁₀(0.35/2) =
20 × log₁₀(0.175) = 20 × (−0.757) = −15.14 dB. The filter attenuates the
signal by 15.14 dB.

\end{examplebox}

\subsection{C.1.3 Common Decibel
Values}\label{c.1.3-common-decibel-values}

Several decibel values appear so frequently that engineers memorize them
as rules of thumb. A 3 dB increase represents a doubling of power (ratio
2:1), while −3 dB represents halving the power --- this is why filter
cutoff frequencies are called ``3 dB points.'' A 10 dB increase
represents a tenfold increase in power, and 20 dB represents a
hundredfold increase. For voltage, 6 dB represents a doubling (ratio
2:1) and 20 dB represents a tenfold increase. These reference points
allow engineers to quickly estimate gains and losses without a
calculator.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
dB & Power Ratio & Voltage Ratio \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 & 1 \\
1 & 1.259 & 1.122 \\
3 & 2 & 1.414 (√2) \\
6 & 4 & 2 \\
10 & 10 & 3.162 \\
20 & 100 & 10 \\
30 & 1,000 & 31.62 \\
40 & 10,000 & 100 \\
−3 & 0.5 & 0.707 (1/√2) \\
−10 & 0.1 & 0.316 \\
−20 & 0.01 & 0.1 \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example C.1.3:} An amplifier has a gain of 23 dB. Using the
rules of thumb, estimate the power gain without a calculator.

\textbf{Solution:}\\
23 dB = 20 dB + 3 dB.\\
A 20 dB gain is a power ratio of 100, and a 3 dB gain doubles the
power.\\
Therefore the total power gain is approximately 100 × 2 = 200.\\
The exact value is 10\textsuperscript{23/10} = 10\textsuperscript{2.3} =
199.5, confirming the estimate.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-c-1-3}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_c_db_scale.png}

\caption{Figure C.1.3: Decibel Scale: Power and Voltage Ratios}

\end{figure}

\section{C.2 Absolute Reference
Levels}\label{c.2-absolute-reference-levels}

\subsection{C.2.1 dBm --- Decibels Referenced to 1
mW}\label{c.2.1-dbm-decibels-referenced-to-1-mw}

dBm expresses absolute power referenced to 1 milliwatt: P(dBm) = 10 ×
log₁₀(P/1 mW). A value of 0 dBm equals exactly 1 mW, +30 dBm equals 1 W,
and −30 dBm equals 1 μW. dBm is the most widely used absolute power unit
in RF engineering, telecommunications, and fiber optics. It is
independent of impedance --- 0 dBm is always 1 mW regardless of whether
the system impedance is 50 Ω, 75 Ω, or 600 Ω. When converting to
voltage, the impedance must be specified: in a 50 Ω system, 0 dBm
corresponds to 224 mV\textsubscript{rms}.

\begin{examplebox}

\textbf{Example C.2.1:} A wireless transmitter outputs +20 dBm into a 50
Ω antenna. Find the output power in watts and the RMS voltage across the
antenna.

\textbf{Solution:} Power: P = 1 mW × 10\textsuperscript{20/10} = 1 mW ×
100 = 100 mW = 0.1 W. Voltage: V\textsubscript{rms} = √(P × R) = √(0.1 ×
50) = √5 = 2.236 V.

\end{examplebox}

\subsection{C.2.2 dBW --- Decibels Referenced to 1
W}\label{c.2.2-dbw-decibels-referenced-to-1-w}

dBW expresses absolute power referenced to 1 watt: P(dBW) = 10 ×
log₁₀(P/1 W). Since dBW and dBm share the same logarithmic scale but
differ by a factor of 1000 in the reference, the conversion is simply
dBW = dBm − 30. dBW is commonly used in high-power applications such as
broadcast transmitters, satellite links, and power systems, where
milliwatt references would produce inconveniently large numbers. For
example, a 50 kW broadcast transmitter is +47 dBW (or equivalently +77
dBm).

\begin{examplebox}

\textbf{Example C.2.2:} A satellite transponder has an output power of
20 W. Express this in dBW and dBm.

\textbf{Solution:}\\
dBW: P = 10 × log₁₀(20/1) = 10 × 1.301 = 13.01 dBW.\\
dBm: P = 13.01 + 30 = 43.01 dBm.\\
Verification: 10\textsuperscript{43.01/10} × 1 mW =
10\textsuperscript{4.301} mW = 20,000 mW = 20 W.

\end{examplebox}

\subsection{C.2.3 dBV and dBμV --- Voltage
References}\label{c.2.3-dbv-and-dbux3bcv-voltage-references}

dBV expresses voltage referenced to 1 volt: V(dBV) = 20 × log₁₀(V/1 V).
dBμV (decibels referenced to 1 microvolt) is used for small signals:
V(dBμV) = 20 × log₁₀(V/1 μV). The conversion between them is dBμV = dBV
+ 120. dBV is common in audio engineering, where 0 dBV = 1
V\textsubscript{rms} is a standard reference level. dBμV is prevalent in
EMC (electromagnetic compatibility) testing and antenna measurements,
where signal levels are typically in the microvolt to millivolt range.
The related unit dBmV (referenced to 1 millivolt) is standard in cable
television systems.

\begin{examplebox}

\textbf{Example C.2.3:} An EMC test measures a radiated emission of 42
dBμV/m at 100 MHz. Convert this to dBV/m and find the field strength in
V/m.

\textbf{Solution:}\\
dBV = dBμV − 120 = 42 − 120 = −78 dBV/m.\\
Field strength: E = 1 μV/m × 10\textsuperscript{42/20} = 10⁻⁶ ×
10\textsuperscript{2.1} = 10⁻⁶ × 125.9 = 125.9 μV/m.\\
This is a relatively weak emission typical of unintentional radiators.

\end{examplebox}

\section{C.3 Decibel Arithmetic}\label{c.3-decibel-arithmetic}

\subsection{C.3.1 Cascaded Gains and
Losses}\label{c.3.1-cascaded-gains-and-losses}

The primary advantage of decibels is that gains and losses in a cascaded
system are simply added. If a signal passes through stages with gains
G₁, G₂, and G₃ in dB, the total system gain is G\textsubscript{total} =
G₁ + G₂ + G₃. This replaces multiplication of linear ratios with
addition, making system-level calculations straightforward. For example,
a transmitter chain with a +20 dB amplifier, a −3 dB cable loss, and a
+12 dBi antenna gain has a total gain of 20 + (−3) + 12 = +29 dB
relative to the input.

\begin{examplebox}

\textbf{Example C.3.1:} A fiber optic link consists of a +3 dBm laser
source, a −0.5 dB connector loss, 20 km of fiber with 0.3 dB/km
attenuation, a −0.5 dB connector loss, and a receiver with −28 dBm
sensitivity. Determine the received power and the link margin.

\textbf{Solution:}\\
Fiber loss: 20 × 0.3 = 6 dB.\\
Total loss: 0.5 + 6 + 0.5 = 7 dB.\\
Received power: +3 dBm − 7 dB = −4 dBm.\\
Link margin: received power − sensitivity = −4 − (−28) = 24 dB.\\
The link has 24 dB of margin above the minimum receiver sensitivity,
providing a comfortable buffer for aging and environmental degradation.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-c-3-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_c_link_budget.png}

\caption{Figure C.3.1: Fiber Optic Link Budget}

\end{figure}

\subsection{C.3.2 Converting Between Linear and
Decibel}\label{c.3.2-converting-between-linear-and-decibel}

Converting from decibels to linear ratios reverses the logarithm: for
power, the linear ratio is 10\textsuperscript{dB/10}; for voltage or
current, the linear ratio is 10\textsuperscript{dB/20}. Converting from
linear to decibels applies the logarithm: for power, dB = 10 ×
log₁₀(ratio); for voltage, dB = 20 × log₁₀(ratio). A common mistake is
using the wrong formula --- applying the factor of 20 to a power ratio
or 10 to a voltage ratio. The rule is: use 10 for power (and energy,
intensity), use 20 for field quantities (voltage, current, electric
field, pressure).

\begin{examplebox}

\textbf{Example C.3.2:} A receiver specification states a noise figure
of 4.5 dB. Convert this to a linear noise factor F, and compute the
equivalent noise temperature (T₀ = 290 K).

\textbf{Solution:}\\
Linear noise factor: F = 10\textsuperscript{4.5/10} =
10\textsuperscript{0.45} = 2.818.\\
Equivalent noise temperature: T\textsubscript{e} = T₀ × (F − 1) = 290 ×
(2.818 − 1) = 290 × 1.818 = 527.2 K.\\
The receiver adds 527.2 K of equivalent noise to the signal.

\end{examplebox}

\subsection{C.3.3 Adding Powers in
Decibels}\label{c.3.3-adding-powers-in-decibels}

When two or more signals combine (such as noise from independent sources
or signals arriving at a combiner), their powers add in the linear
domain, not in decibels. To add powers expressed in dBm, each must first
be converted to milliwatts, summed, and then converted back to dBm:
P\textsubscript{total}(dBm) = 10 × log₁₀(10\textsuperscript{P₁/10} +
10\textsuperscript{P₂/10}). Two equal power levels combine to produce a
result 3 dB higher than either one (doubling of power). This distinction
between adding dB (for cascaded stages) and adding powers (for combining
signals) is a frequent source of errors.

\begin{examplebox}

\textbf{Example C.3.3:} Two uncorrelated noise sources produce −90 dBm
and −87 dBm at the input of a receiver. Find the total noise power.

\textbf{Solution:}\\
Convert to linear: P₁ = 10\textsuperscript{−90/10} mW = 10⁻⁹ mW = 1.000
pW.\\
P₂ = 10\textsuperscript{−87/10} mW = 1.995 × 10⁻⁹ mW = 1.995 pW.\\
Total: P\textsubscript{total} = 1.000 + 1.995 = 2.995 pW = 2.995 × 10⁻⁹
mW.\\
P\textsubscript{total} = 10 × log₁₀(2.995 × 10⁻⁹) = 10 × (−8.524) =
−85.24 dBm.\\
The combined noise is −85.24 dBm, which is 1.76 dB above the stronger
source alone --- less than 3 dB because the two sources are not equal in
power.

\end{examplebox}

\section{C.4 Applications in Electrical
Engineering}\label{c.4-applications-in-electrical-engineering}

\subsection{C.4.1 Amplifier Gain and Frequency
Response}\label{c.4.1-amplifier-gain-and-frequency-response}

Amplifier gain is universally expressed in decibels, whether for voltage
gain (A\textsubscript{v} in dB), current gain, or power gain. The
frequency response of an amplifier is plotted as gain in dB versus
frequency on a logarithmic scale (Bode plot), where the bandwidth is
defined by the frequencies at which the gain drops 3 dB below the
midband value. A gain roll-off of −20 dB/decade indicates a first-order
response (single pole), while −40 dB/decade indicates a second-order
response (two poles). The gain-bandwidth product (GBW) of an op-amp is
constant: if the gain is halved (−6 dB), the bandwidth doubles.

\begin{examplebox}

\textbf{Example C.4.1:} An op-amp has an open-loop gain of 100 dB and a
gain-bandwidth product of 10 MHz. Find the closed-loop bandwidth when
configured for a gain of 40 dB.

\textbf{Solution:}\\
Open-loop gain in linear: A\textsubscript{OL} =
10\textsuperscript{100/20} = 10⁵ = 100,000.\\
Closed-loop gain in linear: A\textsubscript{CL} =
10\textsuperscript{40/20} = 10² = 100.\\
Closed-loop bandwidth: BW = GBW / A\textsubscript{CL} = 10 MHz / 100 =
100 kHz.\\
The unity-gain frequency (0 dB) equals the GBW: f\textsubscript{unity} =
10 MHz.\\
At 40 dB gain, the amplifier is usable up to 100 kHz before the gain
begins to roll off.

\end{examplebox}

\begin{figure}[H]

\hypertarget{fig-c-4-1}{}

\centering

\includegraphics[width=\linewidth,keepaspectratio]{images/app_c_bode_plot.png}

\caption{Figure C.4.1: Op-Amp Bode Plot}

\end{figure}

\subsection{C.4.2 Signal-to-Noise
Ratio}\label{c.4.2-signal-to-noise-ratio}

Signal-to-noise ratio (SNR) is the ratio of signal power to noise power,
expressed in decibels: SNR = 10 ×
log₁₀(P\textsubscript{signal}/P\textsubscript{noise}) or equivalently 20
× log₁₀(V\textsubscript{signal}/V\textsubscript{noise}). A higher SNR
indicates a cleaner signal. In audio systems, a 90 dB SNR means the
signal power is 10⁹ times the noise power. In digital communications,
the bit error rate (BER) depends on the SNR per bit
(E\textsubscript{b}/N₀), with typical requirements ranging from 7 dB for
basic QPSK to over 20 dB for 256-QAM. Dynamic range, the ratio of the
largest to smallest signal a system can handle, is also expressed in dB.

\begin{examplebox}

\textbf{Example C.4.2:} An ADC has a full-scale voltage of 3.3 V and an
RMS noise floor of 0.5 mV. Calculate the SNR in dB and the effective
number of bits (ENOB).

\textbf{Solution:}\\
SNR = 20 × log₁₀(V\textsubscript{signal}/V\textsubscript{noise}) = 20 ×
log₁₀(3.3/0.0005) = 20 × log₁₀(6600) = 20 × 3.8195 = 76.39 dB.\\
ENOB = (SNR − 1.76) / 6.02 = (76.39 − 1.76) / 6.02 = 74.63 / 6.02 = 12.4
bits.\\
The ADC performs equivalently to an ideal 12.4-bit converter, meaning
roughly 12 bits of useful resolution.

\end{examplebox}

\subsection{C.4.3 Link Budgets}\label{c.4.3-link-budgets}

A link budget is a systematic accounting of all gains and losses in a
communication system from transmitter to receiver, expressed entirely in
decibels. The received power is computed as: P\textsubscript{rx} =
P\textsubscript{tx} + G\textsubscript{tx} − L\textsubscript{path} +
G\textsubscript{rx} − L\textsubscript{misc}, where all terms are in dB
or dBm. Free-space path loss for a radio link is L\textsubscript{path} =
20 × log₁₀(4πd/λ), where d is the distance and λ is the wavelength. Link
budgets allow engineers to predict system performance, determine
required transmit power, and evaluate the feasibility of a communication
link before deployment.

\begin{examplebox}

\textbf{Example C.4.3:} A 5.8 GHz point-to-point wireless link spans 2
km. The transmitter outputs +24 dBm, the transmit antenna has +18 dBi
gain, and the receive antenna has +18 dBi gain. Cable losses total 2 dB
at each end. Calculate the free-space path loss and received power.

\textbf{Solution:}\\
Wavelength: λ = c/f = 3 × 10⁸ / 5.8 × 10⁹ = 0.05172 m.\\
Free-space path loss: L\textsubscript{path} = 20 × log₁₀(4π × 2000 /
0.05172) = 20 × log₁₀(4.856 × 10⁵) = 20 × 5.686 = 113.7 dB.\\
Received power: P\textsubscript{rx} = +24 + 18 − 2 − 113.7 + 18 − 2 =
−57.7 dBm.\\
Converting: P\textsubscript{rx} = 10\textsuperscript{−57.7/10} × 1 mW =
1.7 × 10⁻⁶ mW = 1.7 nW.\\
This is a typical received power level for a short-range microwave link.

\end{examplebox}

\chapter{Appendix D}\label{appendix-d}

\chapter{Unit Prefixes and SI Units}\label{unit-prefixes-and-si-units}

Electrical engineering relies on the International System of Units (SI)
to express physical quantities consistently and unambiguously. Because
EE spans an extraordinary range of magnitudes --- from femtofarad
capacitances in integrated circuits to gigawatt power plants, and from
nanosecond switching times to megahertz frequencies --- the SI prefix
system is indispensable for writing compact, readable values. This
appendix provides a reference for the SI base and derived units most
relevant to electrical engineering, the complete set of SI prefixes, and
the conventions for correct usage.

\section{D.1 SI Base Units}\label{d.1-si-base-units}

\subsection{D.1.1 The Seven Base
Units}\label{d.1.1-the-seven-base-units}

The SI system is built on seven base units from which all other units
are derived. The four most frequently encountered in electrical
engineering are the meter (m) for length, the kilogram (kg) for mass,
the second (s) for time, and the ampere (A) for electric current. The
ampere is defined by fixing the elementary charge to exactly 1.602176634
× 10⁻¹⁹ coulombs, making it the fundamental electrical quantity in SI.
The kelvin (K) for temperature, the mole (mol) for amount of substance,
and the candela (cd) for luminous intensity complete the set but appear
less often in core EE work.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Base Unit & Symbol & Quantity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
meter & m & length \\
kilogram & kg & mass \\
second & s & time \\
ampere & A & electric current \\
kelvin & K & temperature \\
mole & mol & amount of substance \\
candela & cd & luminous intensity \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example D.1.1:} A copper wire has a length of 250 m, a
cross-sectional area of 2.5 mm², and carries a current of 15 A. Express
the cross-sectional area in base SI units (m²).

\textbf{Solution:}\\
1 mm = 10⁻³ m, so 1 mm² = (10⁻³)² = 10⁻⁶ m².\\
Therefore 2.5 mm² = 2.5 × 10⁻⁶ m².\\
The resistivity of copper is ρ = 1.68 × 10⁻⁸ Ω·m, giving R = ρL/A =
(1.68 × 10⁻⁸ × 250) / (2.5 × 10⁻⁶) = (4.2 × 10⁻⁶) / (2.5 × 10⁻⁶) = 1.68
Ω.\\
The voltage drop is V = IR = 15 × 1.68 = 25.2 V.

\end{examplebox}

\subsection{D.1.2 The Ampere and Electrical
Quantities}\label{d.1.2-the-ampere-and-electrical-quantities}

The ampere is the SI base unit for electric current, defined since 2019
by fixing the elementary charge e = 1.602176634 × 10⁻¹⁹ C exactly. One
ampere equals one coulomb of charge per second (1 A = 1 C/s). All other
electrical units derive from the ampere combined with the meter,
kilogram, and second: the volt is kg·m²·s⁻³·A⁻¹, the ohm is
kg·m²·s⁻³·A⁻², and the farad is s⁴·A²·kg⁻¹·m⁻². While engineers rarely
need these base-unit decompositions, they are essential for dimensional
analysis and verifying that equations are physically consistent.

\begin{examplebox}

\textbf{Example D.1.2:} Verify that the unit of power (watt) is
consistent in the equation P = V × I by expressing both sides in SI base
units.

\textbf{Solution:} The watt is defined as W = kg·m²·s⁻³. The volt is V =
kg·m²·s⁻³·A⁻¹, and the ampere is A. Therefore V × A = (kg·m²·s⁻³·A⁻¹) ×
A = kg·m²·s⁻³ = W. The units are consistent, confirming that P = V × I
is dimensionally correct.

\end{examplebox}

\section{D.2 SI Derived Units for Electrical
Engineering}\label{d.2-si-derived-units-for-electrical-engineering}

\subsection{D.2.1 Voltage, Resistance, and
Power}\label{d.2.1-voltage-resistance-and-power}

The volt (V) is the unit of electric potential difference and
electromotive force, defined as one watt per ampere (1 V = 1 W/A). The
ohm (Ω) is the unit of electrical resistance, defined as one volt per
ampere (1 Ω = 1 V/A). The watt (W) is the unit of power, defined as one
joule per second (1 W = 1 J/s). The siemens (S) is the unit of
electrical conductance, the reciprocal of the ohm (1 S = 1/Ω = 1 A/V).
These four units, together with the ampere, form the core set used in
virtually every circuit analysis problem.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Unit & Symbol & Quantity & Definition \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
volt & V & voltage, EMF & W/A = kg·m²·s⁻³·A⁻¹ \\
ohm & Ω & resistance & V/A = kg·m²·s⁻³·A⁻² \\
watt & W & power & J/s = kg·m²·s⁻³ \\
siemens & S & conductance & A/V = Ω⁻¹ \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example D.2.1:} A 12 V battery is connected to a 4 Ω load.
Calculate the current, power, and conductance, verifying the units at
each step.

\textbf{Solution:}\\
Current: I = V/R = 12 V / 4 Ω = 3 A.\\
Power: P = V × I = 12 V × 3 A = 36 W, or equivalently P = I² × R = 9 × 4
= 36 W, or P = V²/R = 144/4 = 36 W.\\
Conductance: G = 1/R = 1/4 Ω = 0.25 S.\\
Verification using conductance: I = G × V = 0.25 S × 12 V = 3 A.

\end{examplebox}

\subsection{D.2.2 Capacitance, Inductance, and
Charge}\label{d.2.2-capacitance-inductance-and-charge}

The farad (F) is the unit of capacitance, defined as one coulomb per
volt (1 F = 1 C/V). The henry (H) is the unit of inductance, defined as
one volt-second per ampere (1 H = 1 V·s/A). The coulomb (C) is the unit
of electric charge, defined as one ampere-second (1 C = 1 A·s).
Practical capacitors range from picofarads (pF) in RF circuits to
millifarads (mF) in power supply filters, while practical inductors
range from nanohenries (nH) in RF circuits to henries (H) in power
transformers. The weber (Wb) for magnetic flux and the tesla (T) for
magnetic flux density are also derived from these units.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Unit & Symbol & Quantity & Definition \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
farad & F & capacitance & C/V = s⁴·A²·kg⁻¹·m⁻² \\
henry & H & inductance & V·s/A = kg·m²·s⁻²·A⁻² \\
coulomb & C & charge & A·s \\
weber & Wb & magnetic flux & V·s = kg·m²·s⁻²·A⁻¹ \\
tesla & T & magnetic flux density & Wb/m² = kg·s⁻²·A⁻¹ \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example D.2.2:} A 470 μF capacitor is charged to 25 V. Calculate
the stored charge and energy, expressing the results with appropriate SI
prefixes.

\textbf{Solution:}\\
Charge: Q = C × V = 470 × 10⁻⁶ F × 25 V = 11.75 × 10⁻³ C = 11.75 mC.\\
Energy: E = ½CV² = 0.5 × 470 × 10⁻⁶ × 25² = 0.5 × 470 × 10⁻⁶ × 625 =
146.9 × 10⁻³ J = 146.9 mJ.

\end{examplebox}

\subsection{D.2.3 Frequency and Time}\label{d.2.3-frequency-and-time}

The hertz (Hz) is the unit of frequency, defined as one cycle per second
(1 Hz = 1 s⁻¹). Electrical engineering uses frequencies from millihertz
(mHz) in seismology and power system oscillations to terahertz (THz) in
optical communications. The radian per second (rad/s) is the unit of
angular frequency, related to hertz by ω = 2πf. Time-related quantities
include the period T = 1/f and the time constant τ for exponential
transients. The second is the SI base unit for time, but engineers
commonly work with milliseconds, microseconds, nanoseconds, and
picoseconds.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Unit & Symbol & Quantity & Typical EE Range \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
hertz & Hz & frequency & mHz to THz \\
rad/s & --- & angular frequency & mrad/s to Trad/s \\
second & s & time, period & ps to ks \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example D.2.3:} A microcontroller operates at a clock frequency
of 168 MHz. Find the clock period in nanoseconds and the angular
frequency.

\textbf{Solution:}\\
Period: T = 1/f = 1/(168 × 10⁶) = 5.952 × 10⁻⁹ s = 5.952 ns.\\
Angular frequency: ω = 2πf = 2π × 168 × 10⁶ = 1.0556 × 10⁹ rad/s ≈ 1.056
Grad/s.\\
Each clock cycle is approximately 6 ns, meaning instructions that take
multiple cycles complete in tens of nanoseconds.

\end{examplebox}

\section{D.3 SI Prefixes}\label{d.3-si-prefixes}

\subsection{D.3.1 Prefix Table}\label{d.3.1-prefix-table}

SI prefixes represent powers of 10, allowing any unit to be scaled to a
convenient magnitude. The prefixes range from quecto (10⁻³⁰) to quetta
(10³⁰), though electrical engineering most commonly uses pico through
giga. Each prefix is a fixed power of 10³ (or 10⁻³), with the exception
of deci, centi, deca, and hecto, which are rarely used in EE. Prefixes
attach directly to the unit symbol without a space or separator: 4.7 kΩ,
100 pF, 50 μH.

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Prefix & Symbol & Factor & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
tera & T & 10¹² & THz (terahertz) \\
giga & G & 10⁹ & GHz (gigahertz) \\
mega & M & 10⁶ & MΩ (megohm), MW (megawatt) \\
kilo & k & 10³ & kΩ (kilohm), kHz (kilohertz) \\
--- & --- & 10⁰ & V, A, Ω, F, H \\
milli & m & 10⁻³ & mA (milliamp), mV (millivolt) \\
micro & μ & 10⁻⁶ & μF (microfarad), μH (microhenry) \\
nano & n & 10⁻⁹ & nF (nanofarad), ns (nanosecond) \\
pico & p & 10⁻¹² & pF (picofarad), pW (picowatt) \\
femto & f & 10⁻¹⁵ & fF (femtofarad), fs (femtosecond) \\
\end{longtable}
}

\begin{examplebox}

\textbf{Example D.3.1:} Express 0.0000047 F, 2,200,000 Ω, and
0.000000033 H using appropriate SI prefixes.

\textbf{Solution:}\\
0.0000047 F = 4.7 × 10⁻⁶ F = 4.7 μF.\\
2,200,000 Ω = 2.2 × 10⁶ Ω = 2.2 MΩ.\\
0.000000033 H = 33 × 10⁻⁹ H = 33 nH.\\
The convention is to choose the prefix that places the numeric value
between 1 and 999, keeping one to three significant digits before the
decimal point.

\end{examplebox}

\subsection{D.3.2 Prefix Arithmetic}\label{d.3.2-prefix-arithmetic}

When performing calculations with prefixed units, each prefix must be
converted to its power of 10 before arithmetic operations. A common
approach is to convert all values to base SI units, perform the
calculation, and then apply the appropriate prefix to the result. For
frequently combined prefixes, shortcuts are useful: kilo × milli = 1
(10³ × 10⁻³), mega × micro = 1, and milli × milli = micro. When
dividing, prefixes subtract as exponents: milli / kilo = micro (10⁻³ /
10³ = 10⁻⁶). Dimensional analysis with prefixes prevents
order-of-magnitude errors, which are among the most common mistakes in
engineering calculations.

\begin{examplebox}

\textbf{Example D.3.2:} Calculate the current through a 4.7 kΩ resistor
with 3.3 V across it, and the time constant of that resistor with a 100
nF capacitor.

\textbf{Solution:}\\
Current: I = V/R = 3.3 V / 4.7 kΩ = 3.3 / (4.7 × 10³) = 0.702 × 10⁻³ A =
702 μA.\\
Time constant: τ = RC = 4.7 kΩ × 100 nF = 4.7 × 10³ × 100 × 10⁻⁹ = 4.7 ×
10⁻⁴ s = 470 μs.\\
Using the shortcut: kΩ × nF = 10³ × 10⁻⁹ = 10⁻⁶ = μs, so τ = 4.7 × 100
μs = 470 μs.

\end{examplebox}

\subsection{D.3.3 Engineering
Notation}\label{d.3.3-engineering-notation}

Engineering notation is a convention where numbers are expressed with
exponents that are multiples of 3, aligning directly with SI prefixes.
For example, 0.0022 A is written as 2.2 × 10⁻³ A = 2.2 mA, not 22 × 10⁻⁴
A or 0.22 × 10⁻² A. This differs from scientific notation, which allows
any exponent. Engineering notation keeps the mantissa between 1 and
999.999 and the exponent as a multiple of 3 (\ldots, 10⁻⁶, 10⁻³, 10⁰,
10³, 10⁶, \ldots). Most scientific calculators have an ENG mode that
displays results in this format, and it is the standard practice in
electrical engineering for expressing results clearly.

\begin{examplebox}

\textbf{Example D.3.3:} Convert the following scientific notation values
to engineering notation with SI prefixes: 5.6 × 10⁻⁵ V, 3.2 × 10⁷ Hz,
and 8.1 × 10⁻¹¹ F.

\textbf{Solution:}\\
5.6 × 10⁻⁵ V = 56 × 10⁻⁶ V = 56 μV.\\
3.2 × 10⁷ Hz = 32 × 10⁶ Hz = 32 MHz.\\
8.1 × 10⁻¹¹ F = 81 × 10⁻¹² F = 81 pF.\\
In each case, the exponent is shifted to the nearest multiple of 3, and
the mantissa is adjusted accordingly.

\end{examplebox}

\section{D.4 Common Unit Conversions}\label{d.4-common-unit-conversions}

\subsection{D.4.1 Energy and Charge
Units}\label{d.4.1-energy-and-charge-units}

The joule (J) is the SI unit of energy, but electrical engineers also
encounter the watt-hour (Wh) and kilowatt-hour (kWh) for energy billing,
and the electron-volt (eV) in semiconductor physics. The conversions
are: 1 Wh = 3600 J, 1 kWh = 3.6 × 10⁶ J, and 1 eV = 1.602 × 10⁻¹⁹ J.
Battery capacity is commonly rated in ampere-hours (Ah) or
milliampere-hours (mAh), where 1 Ah = 3600 C. The energy stored in a
battery is approximately E = capacity × nominal voltage, so a 3000 mAh
battery at 3.7 V stores about 11.1 Wh.

\begin{examplebox}

\textbf{Example D.4.1:} A lithium-ion battery pack is rated at 5000 mAh
and 11.1 V (3S configuration). Calculate the stored energy in
watt-hours, joules, and kilowatt-hours.

\textbf{Solution:}\\
Energy: E = 5000 mAh × 11.1 V = 55,500 mWh = 55.5 Wh.\\
In joules: 55.5 × 3600 = 199,800 J ≈ 200 kJ.\\
In kilowatt-hours: 55.5 / 1000 = 0.0555 kWh.\\
For comparison, this is enough energy to power a 10 W LED light for
about 5.5 hours.

\end{examplebox}

\subsection{D.4.2 Temperature Scales}\label{d.4.2-temperature-scales}

Electrical engineering uses three temperature scales: Celsius (°C) for
ambient and operating temperatures, Kelvin (K) for absolute temperatures
in noise calculations and thermodynamics, and occasionally Fahrenheit
(°F) for component datasheets from American manufacturers. The
conversions are: K = °C + 273.15, °F = °C × 9/5 + 32, and °C = (°F − 32)
× 5/9. Thermal resistance in datasheets is given in °C/W (equivalent to
K/W since the scale divisions are identical), and junction temperature
calculations require consistent units throughout.

\begin{examplebox}

\textbf{Example D.4.2:} A power MOSFET has a maximum junction
temperature of 175°C, the ambient temperature is 45°C, and the thermal
resistance from junction to ambient is R\textsubscript{θJA} = 62°C/W.
Find the maximum allowable power dissipation and express the junction
temperature in Kelvin.

\textbf{Solution:}\\
Maximum power: P\textsubscript{max} = (T\textsubscript{j,max} −
T\textsubscript{ambient}) / R\textsubscript{θJA} = (175 − 45) / 62 = 130
/ 62 = 2.097 W.\\
Junction temperature in Kelvin: T\textsubscript{j} = 175 + 273.15 =
448.15 K.\\
The MOSFET can dissipate approximately 2.1 W before reaching its maximum
rated junction temperature.

\end{examplebox}

\chapter{Appendix E}\label{appendix-e}

\chapter{Getting Started with Python and
marimo}\label{getting-started-with-python-and-marimo}

The \texttt{scripts/} directory in this book contains interactive
notebooks built with marimo, a reactive Python notebook framework. These
notebooks visualize the example problems from the chapters with graphs
and plots, making it easier to build intuition about circuit behavior,
signal processing, and other EE concepts. This appendix walks through
installing Python and marimo from scratch, running the notebooks, and
understanding how they work.

\section{E.1 Installing Python}\label{e.1-installing-python}

\subsection{E.1.1 Download and
Install}\label{e.1.1-download-and-install}

Python is a free, open-source programming language available for
Windows, macOS, and Linux. Visit
\href{https://www.python.org/downloads/}{python.org/downloads} and
download the latest stable release (Python 3.12 or newer is
recommended). On Windows, check the box ``Add Python to PATH'' during
installation --- this allows you to run Python from any command prompt.
On macOS, Python can also be installed via Homebrew with
\texttt{brew\ install\ python}. To verify the installation, open a
terminal (Command Prompt on Windows, Terminal on macOS/Linux) and type
\texttt{python3\ -\/-version}, which should display the installed
version number.

\begin{examplebox}

\textbf{Example E.1.1:} Verify that Python is installed and check the
version.

\textbf{Solution:} Open a terminal and run:

\begin{verbatim}
python3 --version
\end{verbatim}

Expected output: \texttt{Python\ 3.12.x} (or similar). If you see
``command not found,'' Python is not installed or not in your PATH. On
Windows, try \texttt{python\ -\/-version} instead (without the
\texttt{3}).

\end{examplebox}

\subsection{E.1.2 Virtual
Environments}\label{e.1.2-virtual-environments}

A virtual environment is an isolated Python installation that keeps
project dependencies separate from your system Python. This prevents
version conflicts between projects. Create a virtual environment in the
\texttt{scripts/} directory, activate it, and install dependencies
there. The virtual environment lives in a folder (typically
\texttt{.venv}) that should not be committed to version control.

\begin{examplebox}

\textbf{Example E.1.2:} Create and activate a virtual environment, then
install the required packages.

\textbf{Solution:}

\begin{verbatim}
cd scripts
python3 -m venv .venv
\end{verbatim}

Activate it:\\
- macOS/Linux: \texttt{source\ .venv/bin/activate}\\
- Windows: \texttt{.venv\textbackslash{}Scripts\textbackslash{}activate}

Your terminal prompt will show \texttt{(.venv)} indicating the
environment is active. Then install dependencies:

\begin{verbatim}
pip install -r requirements.txt
\end{verbatim}

This installs marimo, numpy, and matplotlib into the virtual
environment.

\end{examplebox}

\section{E.2 Installing and Running
marimo}\label{e.2-installing-and-running-marimo}

\subsection{E.2.1 What is marimo}\label{e.2.1-what-is-marimo}

marimo is a reactive Python notebook where cells automatically re-run
when their dependencies change. Unlike traditional Jupyter notebooks
(stored as JSON), marimo notebooks are pure Python files (\texttt{.py})
that can be version-controlled with Git, run as scripts, and edited with
any text editor. Each cell is a Python function decorated with
\texttt{@app.cell}, and marimo automatically tracks which cells depend
on which variables. When you modify a cell, all downstream cells update
instantly.

\begin{examplebox}

\textbf{Example E.2.1:} Install marimo and verify the installation.

\textbf{Solution:}

\begin{verbatim}
pip install marimo
marimo --version
\end{verbatim}

Expected output: \texttt{marimo\ 0.19.4} (or newer). marimo is included
in the \texttt{requirements.txt} file, so if you followed the virtual
environment setup in E.1.2, it is already installed.

\end{examplebox}

\subsection{E.2.2 Running a Notebook}\label{e.2.2-running-a-notebook}

marimo notebooks can be opened in two modes: edit mode (for modifying
code) and run mode (read-only, like a presentation). Edit mode opens the
notebook in your browser with an interactive code editor. Run mode
displays the outputs without showing the code cells, which is useful for
viewing the graphs without the underlying Python code.

\begin{examplebox}

\textbf{Example E.2.2:} Open the Chapter 7 Circuit Analysis notebook in
edit mode.

\textbf{Solution:}

\begin{verbatim}
cd scripts
marimo edit 07_circuit_analysis.py
\end{verbatim}

This opens your default web browser with the marimo editor. You will see
markdown cells with descriptions and code cells with matplotlib graphs.
To run in read-only mode instead:

\begin{verbatim}
marimo run 07_circuit_analysis.py
\end{verbatim}

\end{examplebox}

\subsection{E.2.3 Navigating the
Interface}\label{e.2.3-navigating-the-interface}

The marimo editor displays cells vertically in order. Markdown cells
show formatted text, and code cells show Python code with their outputs
(graphs, tables, or text) below. The cell dependency graph (accessible
from the menu) shows how cells are connected --- if cell B uses a
variable defined in cell A, then changing cell A will automatically
re-run cell B. You can add new cells, reorder cells, or modify existing
code. Changes are saved to the \texttt{.py} file when you press Ctrl+S
(or Cmd+S on macOS).

\begin{examplebox}

\textbf{Example E.2.3:} Modify a parameter in the Chapter 7 notebook and
observe the graph update.

\textbf{Solution:} Open \texttt{07\_circuit\_analysis.py} in edit mode.
In the RC Circuit cell, change \texttt{R\_rc\ =\ 47e3} to
\texttt{R\_rc\ =\ 100e3} (increasing the resistance by about 2.1×). The
time constant τ changes from 0.47 s to 1.0 s, and the charging curve
graph automatically updates to show a slower exponential rise. Press
Ctrl+Z to undo the change, or Ctrl+S to save.

\end{examplebox}

\section{E.3 Understanding the Script
Structure}\label{e.3-understanding-the-script-structure}

\subsection{E.3.1 Imports and App
Initialization}\label{e.3.1-imports-and-app-initialization}

Every marimo script begins with the same boilerplate: importing the
\texttt{marimo} module, declaring the version it was generated with, and
creating an \texttt{App} instance. The first cell imports the common
libraries (marimo as \texttt{mo}, numpy as \texttt{np},
matplotlib.pyplot as \texttt{plt}). These imports are available to all
subsequent cells through marimo's dependency tracking --- any cell that
lists \texttt{np} or \texttt{plt} in its function parameters
automatically receives the imported modules.

\begin{examplebox}

\textbf{Example E.3.1:} Examine the standard header of a marimo script.

\textbf{Solution:} The first lines of every script are:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ marimo}
\NormalTok{\_\_generated\_with }\OperatorTok{=} \StringTok{"0.19.4"}
\NormalTok{app }\OperatorTok{=}\NormalTok{ marimo.App()}
\end{Highlighting}
\end{Shaded}

Followed by the imports cell:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@app.cell}
\KeywordTok{def}\NormalTok{ \_():}
    \ImportTok{import}\NormalTok{ marimo }\ImportTok{as}\NormalTok{ mo}
    \ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
    \ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
    \ControlFlowTok{return}\NormalTok{ mo, np, plt}
\end{Highlighting}
\end{Shaded}

The \texttt{return} statement exports \texttt{mo}, \texttt{np}, and
\texttt{plt} for use by other cells.

\end{examplebox}

\subsection{E.3.2 Markdown and Code
Cells}\label{e.3.2-markdown-and-code-cells}

Markdown cells use \texttt{mo.md()} to display formatted text with
headings, bold text, and equations. Code cells perform computations and
generate graphs. A typical pattern is a markdown cell describing the
example, followed by a code cell that computes and plots the result. The
\texttt{@app.cell} decorator marks each function as a notebook cell, and
the function's parameters declare which variables it needs from other
cells.

\begin{examplebox}

\textbf{Example E.3.2:} Identify the cell pattern used for each example
problem.

\textbf{Solution:} Each example follows this pattern:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Markdown cell: description}
\AttributeTok{@app.cell}
\KeywordTok{def}\NormalTok{ \_(mo):}
\NormalTok{    mo.md(}\StringTok{"\#\# Section Title}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{Problem description..."}\NormalTok{)}
    \ControlFlowTok{return}

\CommentTok{\# Code cell: computation and graph}
\AttributeTok{@app.cell}
\KeywordTok{def}\NormalTok{ \_(np, plt):}
    \CommentTok{\# Set up parameters}
\NormalTok{    R }\OperatorTok{=} \DecValTok{100}  \CommentTok{\# Ω}
    \CommentTok{\# Compute values}
\NormalTok{    t }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\NormalTok{    v }\OperatorTok{=}\NormalTok{ R }\OperatorTok{*}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{t)}
    \CommentTok{\# Create graph}
\NormalTok{    fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{    ax.plot(t, v)}
\NormalTok{    ax.set\_xlabel(}\StringTok{"Time (s)"}\NormalTok{)}
\NormalTok{    fig}
    \ControlFlowTok{return}
\end{Highlighting}
\end{Shaded}

The last expression in the code cell (\texttt{fig}) is what marimo
displays as the cell output.

\end{examplebox}

\subsection{E.3.3 Running as a Python
Script}\label{e.3.3-running-as-a-python-script}

marimo notebooks can be executed as standard Python scripts from the
command line. The
\texttt{if\ \_\_name\_\_\ ==\ "\_\_main\_\_":\ app.run()} block at the
end of each file enables this. Running as a script executes all cells in
dependency order and launches the notebook viewer. This is useful for
batch processing, automated report generation, or running on a remote
server.

\begin{examplebox}

\textbf{Example E.3.3:} Run a notebook as a script and export it to
HTML.

\textbf{Solution:} Run as a script:

\begin{verbatim}
python 07_circuit_analysis.py
\end{verbatim}

Export to a static HTML file (no Python required to view):

\begin{verbatim}
marimo export html 07_circuit_analysis.py -o circuit_analysis.html
\end{verbatim}

The HTML file contains all the graphs and text and can be opened in any
web browser, shared by email, or hosted on a website.

\end{examplebox}

\section{E.4 Modifying and Extending
Scripts}\label{e.4-modifying-and-extending-scripts}

\subsection{E.4.1 Changing Parameters}\label{e.4.1-changing-parameters}

The simplest way to explore is to modify the numerical parameters in
existing cells. Each code cell begins with clearly labeled constants
(resistance, capacitance, frequency, etc.) that can be changed to see
how the graph responds. Because marimo is reactive, changing a parameter
value and pressing Shift+Enter immediately updates the graph. This is a
powerful way to build intuition --- for example, increasing the damping
ratio in an RLC circuit from 0.5 to 0.9 visually shows the transition
from oscillatory to nearly critically damped behavior.

\begin{examplebox}

\textbf{Example E.4.1:} Explore the effect of changing the quality
factor in the resonance example.

\textbf{Solution:} In \texttt{07\_circuit\_analysis.py}, find the
resonance cell and change \texttt{R\_rlc\_res\ =\ 10} to
\texttt{R\_rlc\_res\ =\ 50}. The quality factor Q drops from 31.62 to
6.32 and the resonance peak becomes broader (higher bandwidth). Change
it to \texttt{R\_rlc\_res\ =\ 1} to see Q = 316.2 with an extremely
sharp, narrow peak. Each change updates the graph in real time.

\end{examplebox}

\subsection{E.4.2 Adding New Cells}\label{e.4.2-adding-new-cells}

To add a new visualization, insert a new cell in the marimo editor
(click the + button between cells). Write a markdown cell for the
description and a code cell for the graph. Any variable defined in an
existing cell can be reused by listing it as a function parameter. New
cells are saved to the \texttt{.py} file along with the rest of the
notebook.

\begin{examplebox}

\textbf{Example E.4.2:} Add a cell that plots the current waveform
alongside the existing voltage graph in the RC circuit example.

\textbf{Solution:} In the marimo editor, add a new cell after the RC
charging graph:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@app.cell}
\KeywordTok{def}\NormalTok{ \_(np, plt):}
\NormalTok{    R\_rc }\OperatorTok{=} \FloatTok{47e3}
\NormalTok{    C\_rc }\OperatorTok{=} \FloatTok{10e{-}6}
\NormalTok{    Vs\_rc }\OperatorTok{=} \DecValTok{9}
\NormalTok{    tau\_rc }\OperatorTok{=}\NormalTok{ R\_rc }\OperatorTok{*}\NormalTok{ C\_rc}
\NormalTok{    t }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{5} \OperatorTok{*}\NormalTok{ tau\_rc, }\DecValTok{500}\NormalTok{)}
\NormalTok{    I\_rc }\OperatorTok{=}\NormalTok{ (Vs\_rc }\OperatorTok{/}\NormalTok{ R\_rc) }\OperatorTok{*}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{t }\OperatorTok{/}\NormalTok{ tau\_rc)}
\NormalTok{    fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{    ax.plot(t, I\_rc }\OperatorTok{*} \FloatTok{1e6}\NormalTok{, }\StringTok{"r{-}"}\NormalTok{, linewidth}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{    ax.set\_xlabel(}\StringTok{"Time (s)"}\NormalTok{)}
\NormalTok{    ax.set\_ylabel(}\StringTok{"Current (μA)"}\NormalTok{)}
\NormalTok{    ax.set\_title(}\StringTok{"RC Circuit Charging Current"}\NormalTok{)}
\NormalTok{    ax.grid(}\VariableTok{True}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.3}\NormalTok{)}
\NormalTok{    fig}
    \ControlFlowTok{return}
\end{Highlighting}
\end{Shaded}

The graph shows the exponential decay of charging current from 191 μA to
near zero.

\end{examplebox}

\chapter{Appendix F}\label{appendix-f}

\chapter{Matrix Operations}\label{matrix-operations}

Matrix algebra is a fundamental tool in electrical engineering, enabling
the compact representation and systematic solution of systems of linear
equations that arise throughout circuit analysis, control theory, signal
processing, and power systems. Nodal and mesh analysis of circuits with
many nodes or loops produce systems of simultaneous equations that are
naturally expressed in matrix form. State-space representations of
control systems use matrices to describe dynamic behavior, and digital
signal processing relies on matrix operations for filter design and
spectral analysis. This appendix covers the essential matrix operations
used in these applications.

\section{F.1 Matrix Fundamentals}\label{f.1-matrix-fundamentals}

\subsection{F.1.1 Definitions and
Notation}\label{f.1.1-definitions-and-notation}

A matrix is a rectangular array of numbers arranged in rows and columns,
written as A with dimensions m × n (m rows, n columns). The element in
row i, column j is denoted a\textsubscript{ij}. A square matrix has
equal rows and columns (m = n). A column vector is an n × 1 matrix, and
a row vector is a 1 × n matrix. In circuit analysis, the conductance
matrix (G) is square and symmetric, the unknown vector (V) contains node
voltages, and the source vector (I) contains current source values,
forming the system GV = I.

\begin{examplebox}

\textbf{Example F.1.1:} Write the nodal admittance matrix for a circuit
with three nodes where Y₁₂ = 0.1 S, Y₁₃ = 0.2 S, and Y₂₃ = 0.05 S
connect the node pairs, and a 0.25 S admittance connects node 1 to
ground.

\textbf{Solution:}\\
The diagonal entries are the sum of all admittances connected to each
node, and the off-diagonal entries are the negative of the admittance
between node pairs.\\
Y₁₁ = 0.25 + 0.1 + 0.2 = 0.55 S, Y₂₂ = 0.1 + 0.05 = 0.15 S, Y₃₃ = 0.2 +
0.05 = 0.25 S.\\
Off-diagonal: Y₁₂ = Y₂₁ = −0.1, Y₁₃ = Y₃₁ = −0.2, Y₂₃ = Y₃₂ = −0.05.\\
The matrix is:

Y = {[}0.55, −0.1, −0.2; −0.1, 0.15, −0.05; −0.2, −0.05, 0.25{]}

\end{examplebox}

\subsection{F.1.2 Special Matrices}\label{f.1.2-special-matrices}

Several special matrix types appear frequently in EE applications. The
identity matrix I has ones on the diagonal and zeros elsewhere;
multiplying by I leaves any matrix unchanged (AI = A). A diagonal matrix
has non-zero entries only on the main diagonal, useful for representing
independent scaling of variables. A symmetric matrix equals its own
transpose (A = A\textsuperscript{T}), which occurs in admittance and
impedance matrices of reciprocal networks. A sparse matrix has mostly
zero entries, typical of large power system networks where each bus
connects to only a few neighbors.

\begin{examplebox}

\textbf{Example F.1.2:} Given a 3 × 3 identity matrix I and a diagonal
matrix D = diag(2, 5, 10), compute D × I and verify the result.

\textbf{Solution:} D × I = D, since multiplying by the identity matrix
leaves any matrix unchanged. D × I = {[}2, 0, 0; 0, 5, 0; 0, 0, 10{]}.
This is the same as D. The diagonal matrix D could represent three
independent gain stages of 2, 5, and 10 in a signal processing chain.

\end{examplebox}

\section{F.2 Matrix Arithmetic}\label{f.2-matrix-arithmetic}

\subsection{F.2.1 Addition and
Subtraction}\label{f.2.1-addition-and-subtraction}

Matrices of the same dimensions are added (or subtracted) element by
element: if C = A + B, then c\textsubscript{ij} = a\textsubscript{ij} +
b\textsubscript{ij}. Matrix addition is commutative (A + B = B + A) and
associative (A + (B + C) = (A + B) + C). In circuit analysis,
superposition of multiple source contributions involves adding the
individual voltage or current vectors: V\textsubscript{total} = V₁ + V₂
+ V₃, where each V\textsubscript{k} is the response to source k acting
alone.

\begin{examplebox}

\textbf{Example F.2.1:} Two current source vectors for a three-node
circuit are I₁ = {[}0.5, 0, −0.2{]}\textsuperscript{T} A and I₂ = {[}0,
0.3, 0.1{]}\textsuperscript{T} A. Find the total source vector.

\textbf{Solution:} I\textsubscript{total} = I₁ + I₂ = {[}0.5 + 0, 0 +
0.3, −0.2 + 0.1{]}\textsuperscript{T} = {[}0.5, 0.3,
−0.1{]}\textsuperscript{T} A. Node 1 has 0.5 A injected, node 2 has 0.3
A injected, and node 3 has 0.1 A extracted (negative sign indicates
current leaving the node).

\end{examplebox}

\subsection{F.2.2 Scalar
Multiplication}\label{f.2.2-scalar-multiplication}

Multiplying a matrix by a scalar k scales every element: if B = kA, then
b\textsubscript{ij} = k × a\textsubscript{ij}. This operation is used
when scaling a system of equations, such as converting units or
normalizing values. In per-unit systems used in power engineering, all
quantities are divided by their base values, which is equivalent to
multiplying the system matrix by a scalar reciprocal.

\begin{examplebox}

\textbf{Example F.2.2:} A resistance matrix (in ohms) is R = {[}100, 20;
20, 50{]}. Convert to a conductance matrix G by computing R⁻¹, and also
express R in kilohms using scalar multiplication.

\textbf{Solution:} R in kilohms: R\textsubscript{kΩ} = (1/1000) × R =
{[}0.1, 0.02; 0.02, 0.05{]} kΩ. For the conductance matrix, we need the
inverse (covered in F.3.3), but the scalar multiplication simply divides
each element by 1000.

\end{examplebox}

\subsection{F.2.3 Matrix
Multiplication}\label{f.2.3-matrix-multiplication}

Matrix multiplication C = A × B requires that the number of columns in A
equals the number of rows in B. If A is m × p and B is p × n, then C is
m × n, with each element c\textsubscript{ij} = Σ(a\textsubscript{ik} ×
b\textsubscript{kj}) for k = 1 to p.~Matrix multiplication is not
commutative (AB ≠ BA in general) but is associative (A(BC) = (AB)C) and
distributive (A(B + C) = AB + AC). In circuit analysis, computing V = Z
× I multiplies the impedance matrix by the current vector to obtain node
voltages.

\begin{examplebox}

\textbf{Example F.2.3:} A 2-node circuit has impedance matrix Z = {[}10,
3; 3, 8{]} Ω and current vector I = {[}2, 1{]}\textsuperscript{T} A.
Find the voltage vector V = Z × I.

\textbf{Solution:}\\
V₁ = 10 × 2 + 3 × 1 = 20 + 3 = 23 V.\\
V₂ = 3 × 2 + 8 × 1 = 6 + 8 = 14 V.\\
Therefore V = {[}23, 14{]}\textsuperscript{T} V. Node 1 is at 23 V and
node 2 is at 14 V with respect to the reference node.

\end{examplebox}

\section{F.3 Matrix Operations}\label{f.3-matrix-operations}

\subsection{F.3.1 Transpose}\label{f.3.1-transpose}

The transpose of matrix A, written A\textsuperscript{T}, is formed by
interchanging rows and columns: the element in row i, column j of A
becomes the element in row j, column i of A\textsuperscript{T}. For an m
× n matrix, the transpose is n × m. Key properties include
(AB)\textsuperscript{T} = B\textsuperscript{T}A\textsuperscript{T} and
(A\textsuperscript{T})\textsuperscript{T} = A. In EE, the admittance
matrix of a reciprocal network (containing only R, L, C, and ideal
transformers) is symmetric, meaning Y = Y\textsuperscript{T}. The
transpose also appears in least-squares estimation
(A\textsuperscript{T}A) used in signal processing and system
identification.

\begin{examplebox}

\textbf{Example F.3.1:} Given A = {[}1, 4; 2, 5; 3, 6{]}, find
A\textsuperscript{T} and verify that
(A\textsuperscript{T})\textsuperscript{T} = A.

\textbf{Solution:} A is 3 × 2, so A\textsuperscript{T} is 2 × 3:
A\textsuperscript{T} = {[}1, 2, 3; 4, 5, 6{]}. Taking the transpose
again: (A\textsuperscript{T})\textsuperscript{T} = {[}1, 4; 2, 5; 3,
6{]} = A, confirming the double-transpose property.

\end{examplebox}

\subsection{F.3.2 Determinant}\label{f.3.2-determinant}

The determinant of a square matrix A, written det(A) or
\textbar A\textbar, is a scalar value that indicates whether the matrix
is invertible (det ≠ 0) or singular (det = 0). For a 2 × 2 matrix {[}a,
b; c, d{]}, the determinant is ad − bc. For larger matrices, the
determinant is computed by cofactor expansion along any row or column.
In circuit analysis, a zero determinant means the system of equations
has no unique solution, indicating a dependent or inconsistent set of
equations (for example, a circuit with a floating node or redundant
constraint).

\begin{examplebox}

\textbf{Example F.3.2:} Compute the determinant of the mesh impedance
matrix Z = {[}15, −10; −10, 30{]} from a two-mesh circuit.

\textbf{Solution:}\\
det(Z) = (15)(30) − (−10)(−10) = 450 − 100 = 350.\\
Since det(Z) ≠ 0, the system has a unique solution and the mesh currents
can be determined.\\
The determinant appears in Cramer's rule: I₁ = det(Z₁)/det(Z) and I₂ =
det(Z₂)/det(Z), where Z₁ and Z₂ are matrices with the source vector
substituted into the appropriate column.

\end{examplebox}

\subsection{F.3.3 Inverse}\label{f.3.3-inverse}

The inverse of a square matrix A, written A⁻¹, satisfies A × A⁻¹ = A⁻¹ ×
A = I (the identity matrix). A matrix has an inverse if and only if its
determinant is non-zero. For a 2 × 2 matrix {[}a, b; c, d{]}, the
inverse is (1/det) × {[}d, −b; −c, a{]}. The inverse is the primary tool
for solving linear systems: given AX = B, the solution is X = A⁻¹B. In
nodal analysis, YV = I is solved as V = Y⁻¹I, giving all node voltages
simultaneously.

\begin{examplebox}

\textbf{Example F.3.3:} Solve the system YV = I where Y = {[}0.15,
−0.05; −0.05, 0.25{]} S and I = {[}1, 2{]}\textsuperscript{T} A.

\textbf{Solution:}\\
det(Y) = (0.15)(0.25) − (−0.05)(−0.05) = 0.0375 − 0.0025 = 0.035.\\
Y⁻¹ = (1/0.035) × {[}0.25, 0.05; 0.05, 0.15{]} = {[}7.143, 1.429; 1.429,
4.286{]}.\\
V = Y⁻¹I: V₁ = 7.143 × 1 + 1.429 × 2 = 7.143 + 2.857 = 10.0 V.\\
V₂ = 1.429 × 1 + 4.286 × 2 = 1.429 + 8.571 = 10.0 V.\\
Both nodes are at 10.0 V.

\end{examplebox}

\section{F.4 Solving Linear Systems}\label{f.4-solving-linear-systems}

\subsection{F.4.1 Gaussian
Elimination}\label{f.4.1-gaussian-elimination}

Gaussian elimination transforms a system of equations into upper
triangular form through a sequence of row operations: swapping rows,
multiplying a row by a non-zero scalar, and adding a multiple of one row
to another. Once in upper triangular form, the unknowns are found by
back-substitution starting from the last equation. This method is
computationally efficient (O(n³) for n unknowns) and is the foundation
of numerical linear algebra. Partial pivoting (choosing the largest
element as the pivot) improves numerical stability.

\begin{examplebox}

\textbf{Example F.4.1:} Solve the system 2V₁ + V₂ = 5 and V₁ + 3V₂ = 10
using Gaussian elimination.

\textbf{Solution:}\\
Augmented matrix: {[}2, 1, 5; 1, 3, 10{]}.\\
Multiply row 2 by 2: {[}2, 1, 5; 2, 6, 20{]}.\\
Subtract row 1 from row 2: {[}2, 1, 5; 0, 5, 15{]}.\\
Back-substitute: 5V₂ = 15, so V₂ = 3. Then 2V₁ + 3 = 5, so V₁ = 1.\\
Verification: 2(1) + 3 = 5 and 1 + 3(3) = 10.

\end{examplebox}

\subsection{F.4.2 Cramer's Rule}\label{f.4.2-cramers-rule}

Cramer's rule solves a system of n equations in n unknowns by computing
n + 1 determinants. For the system AX = B, each unknown
x\textsubscript{k} = det(A\textsubscript{k}) / det(A), where
A\textsubscript{k} is the matrix A with its k-th column replaced by B.
While computationally expensive for large systems (O(n × n!) without
optimization), Cramer's rule is useful for hand calculations with 2 × 2
and 3 × 3 systems and provides theoretical insight into when solutions
exist and how they depend on the system parameters.

\begin{examplebox}

\textbf{Example F.4.2:} Use Cramer's rule to solve the two-mesh circuit
equations: 15I₁ − 10I₂ = 30 and −10I₁ + 30I₂ = 15.

\textbf{Solution:}\\
det(A) = (15)(30) − (−10)(−10) = 450 − 100 = 350.\\
For I₁: replace column 1 with {[}30, 15{]}\textsuperscript{T}. det(A₁) =
(30)(30) − (−10)(15) = 900 + 150 = 1050. I₁ = 1050/350 = 3.0 A.\\
For I₂: replace column 2 with {[}30, 15{]}\textsuperscript{T}. det(A₂) =
(15)(15) − (30)(−10) = 225 + 300 = 525. I₂ = 525/350 = 1.5 A.\\
Verification: 15(3) − 10(1.5) = 45 − 15 = 30 and −10(3) + 30(1.5) = −30
+ 45 = 15.

\end{examplebox}

\section{F.5 Applications in Electrical
Engineering}\label{f.5-applications-in-electrical-engineering}

\subsection{F.5.1 Nodal Analysis Matrix
Form}\label{f.5.1-nodal-analysis-matrix-form}

The nodal admittance equation YV = I is the standard matrix formulation
of nodal analysis. The admittance matrix Y is constructed by inspection:
diagonal element Y\textsubscript{kk} is the sum of all admittances
connected to node k, and off-diagonal element Y\textsubscript{kj} =
Y\textsubscript{jk} is the negative of the admittance between nodes k
and j. The voltage vector V contains the unknown node voltages, and the
current vector I contains the net current injected at each node from
independent current sources. For n non-reference nodes, Y is n × n, V is
n × 1, and I is n × 1.

\begin{examplebox}

\textbf{Example F.5.1:} A circuit has three nodes. A 2 A source feeds
into node 1, and a 1 A source feeds into node 3. Conductances are: G₁₂ =
0.5 S, G₁₃ = 0.2 S, G₂₃ = 0.1 S, with G₁₀ = 0.3 S (node 1 to ground).
Set up and solve YV = I.

\textbf{Solution:}\\
Y = {[}0.3 + 0.5 + 0.2, −0.5, −0.2; −0.5, 0.5 + 0.1, −0.1; −0.2, −0.1,
0.2 + 0.1{]} = {[}1.0, −0.5, −0.2; −0.5, 0.6, −0.1; −0.2, −0.1,
0.3{]}.\\
I = {[}2, 0, 1{]}\textsuperscript{T}.\\
Solving YV = I (by Gaussian elimination or matrix inverse): V₁ = 10.00
V, V₂ = 10.59 V, V₃ = 13.53 V.

\end{examplebox}

\subsection{F.5.2 Two-Port Network
Parameters}\label{f.5.2-two-port-network-parameters}

Two-port networks are characterized by 2 × 2 parameter matrices that
relate the port voltages and currents. The Z-parameters (impedance)
relate {[}V₁; V₂{]} = Z × {[}I₁; I₂{]}, the Y-parameters (admittance)
relate {[}I₁; I₂{]} = Y × {[}V₁; V₂{]}, and the ABCD parameters relate
{[}V₁; I₁{]} = {[}A, B; C, D{]} × {[}V₂; I₂{]}. Cascading two-port
networks is accomplished by multiplying their ABCD matrices: the overall
ABCD matrix of networks in cascade is the product of the individual
matrices, making matrix multiplication the natural operation for
analyzing transmission line sections, filter stages, and amplifier
chains.

\begin{examplebox}

\textbf{Example F.5.2:} Two transmission line sections have ABCD
matrices M₁ = {[}1, 50; 0, 1{]} and M₂ = {[}1, 0; 0.02, 1{]}. Find the
overall ABCD matrix of the cascade.

\textbf{Solution:}\\
M\textsubscript{total} = M₁ × M₂.\\
A = 1 × 1 + 50 × 0.02 = 1 + 1 = 2.\\
B = 1 × 0 + 50 × 1 = 50.\\
C = 0 × 1 + 1 × 0.02 = 0.02.\\
D = 0 × 0 + 1 × 1 = 1.\\
M\textsubscript{total} = {[}2, 50; 0.02, 1{]}.\\
Verification: det(M\textsubscript{total}) = 2 × 1 − 50 × 0.02 = 2 − 1 =
1, confirming a reciprocal network (det = 1 for lossless reciprocal
two-ports).

\end{examplebox}

\subsection{F.5.3 State-Space
Representation}\label{f.5.3-state-space-representation}

Linear time-invariant systems in control theory are described by the
state-space equations: x'(t) = Ax(t) + Bu(t) and y(t) = Cx(t) + Du(t),
where x is the state vector, u is the input vector, y is the output
vector, and A, B, C, D are constant matrices. The A matrix (state
matrix) determines the system dynamics --- its eigenvalues are the
system poles. The B matrix maps inputs to state derivatives, C maps
states to outputs, and D provides direct feedthrough. For an n-th order
system with p inputs and q outputs, A is n × n, B is n × p, C is q × n,
and D is q × p.

\begin{examplebox}

\textbf{Example F.5.3:} A series RLC circuit (R = 2 Ω, L = 1 H, C = 0.5
F) driven by voltage source u(t) has state variables x₁ = capacitor
voltage and x₂ = inductor current, with output y = capacitor voltage.
Write the state-space matrices.

\textbf{Solution:}\\
From circuit equations: dx₁/dt = (1/C)x₂ = 2x₂ and dx₂/dt = (1/L)(u −
Rx₂ − x₁) = −x₁ − 2x₂ + u.\\
Output: y = x₁.\\
Therefore: A = {[}0, 2; −1, −2{]}, B = {[}0; 1{]}, C = {[}1, 0{]}, D =
{[}0{]}.\\
The eigenvalues of A (system poles) are found from det(A − λI) = 0: λ² +
2λ + 2 = 0, giving λ = −1 ± j1, confirming an underdamped second-order
system with ω₀ = √2 rad/s and ζ = 1/√2 ≈ 0.707.

\end{examplebox}

\chapter{Dictionary of Terms}\label{dictionary-of-terms}

A reference glossary of technical terms, acronyms, and abbreviations
used throughout this book. Terms are listed alphabetically with the
chapter or appendix where they are primarily discussed indicated in
parentheses.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{802.1X} --- IEEE port-based network access control standard that
authenticates devices before granting network access using a three-party
model: supplicant (client), authenticator (switch/AP), and
authentication server (RADIUS). Supports EAP methods including EAP-TLS,
PEAP, and EAP-TTLS. (Ch. 15)

\textbf{Aberration (Optical)} --- Systematic deviation of light rays
from ideal focusing in a lens or mirror system. The five Seidel
aberrations are spherical aberration, coma, astigmatism, field
curvature, and distortion; chromatic aberration arises from
wavelength-dependent refraction. (Ch. 18)

\textbf{AC (Alternating Current)} --- Electric current that periodically
reverses direction, characterized by frequency (Hz) and amplitude.
Standard power frequencies are 60 Hz (North America) and 50 Hz (most
other regions). (Ch. 1, 7)

\textbf{Accelerometer} --- A sensor that measures acceleration along one
or more axes using a micromachined proof mass and capacitive or
piezoresistive detection. MEMS accelerometers are used in smartphones,
drones, automotive stability systems, and vibration analysis. (Ch. 11)

\textbf{Accuracy} --- The closeness of a measured value to the true
value of the quantity being measured, often expressed as a percentage of
full scale or reading. (Ch. 11)

\textbf{ACR (Attenuation-to-Crosstalk Ratio)} --- The difference between
NEXT and insertion loss in dB on a twisted-pair cable; a positive ACR
indicates the desired signal is stronger than crosstalk interference.
(Ch. 15)

\textbf{Adaptive Filter} --- A digital filter whose coefficients are
automatically adjusted to minimize an error signal, enabling operation
in environments with unknown or time-varying signal statistics.
Applications include noise cancellation, echo cancellation, and channel
equalization. (Ch. 8)

\textbf{ADC (Analog-to-Digital Converter)} --- A peripheral or circuit
that converts a continuous analog voltage to a discrete digital value,
characterized by resolution (bits), sampling rate, and reference
voltage. (Ch. 5, 11)

\textbf{Admittance (Y)} --- The reciprocal of impedance, Y = G + jB,
measured in siemens (S), where G is conductance and B is susceptance.
Used in nodal analysis of AC circuits. (Ch. 7, App. A)

\textbf{After-Tax Cash Flow (ATCF)} --- The net cash flow remaining
after income taxes, computed as ATCF = BTCF − (BTCF − D) × T, where BTCF
is before-tax cash flow, D is depreciation, and T is the tax rate. (Ch.
19)

\textbf{Aliasing} --- Distortion that occurs when a signal is sampled
below the Nyquist rate (less than twice the highest frequency), causing
high-frequency components to appear as false low-frequency artifacts.
(Ch. 2, 8)

\textbf{Allpass Filter} --- A filter with unity magnitude response at
all frequencies (\textbar H(e\textsuperscript{jω})\textbar{} = 1) but
frequency-dependent phase. Used for group delay equalization of IIR
filters and constructing complementary filter pairs. Zeros are placed at
reciprocal conjugate locations of the poles. (Ch. 8)

\textbf{AM (Amplitude Modulation)} --- A modulation technique that
encodes information by varying the amplitude of a carrier wave, used in
AM radio broadcasting. (Ch. 2)

\textbf{Ampacity} --- The maximum current a conductor can carry
continuously under specified conditions of use (ambient temperature,
insulation type, installation method) without exceeding its rated
temperature. (Ch. 1, 14)

\textbf{Ampere (A)} --- The SI base unit of electric current, defined as
the flow of one coulomb of charge per second. (App. D)

\textbf{Ampere's Law} --- A Maxwell equation relating the magnetic field
circulation around a closed path to the enclosed current: ∮B·dl =
μ₀I\textsubscript{enc}. (Ch. 9)

\textbf{Annual Worth (AW)} --- The equivalent uniform annual value of
all cash flows over a project's life, used to compare alternatives with
different service lives without requiring a least common multiple
calculation. (Ch. 19)

\textbf{Antenna} --- A transducer that converts guided electromagnetic
energy (in a transmission line or waveguide) to radiated electromagnetic
waves in free space, or vice versa. Characterized by gain, directivity,
bandwidth, and radiation pattern. (Ch. 9, 16)

\textbf{Antenna Gain} --- The ratio of radiation intensity in a given
direction to the intensity of an isotropic radiator with the same total
power, expressed in dBi. Gain = efficiency × directivity. (Ch. 9, 16)

\textbf{Anti-Islanding} --- A protection requirement for grid-tied
inverters mandating that the inverter cease energizing a local circuit
within 2 seconds whenever the utility grid goes offline, preventing
shock hazards for utility workers and unsynchronized reclosure damage.
Detection methods include passive (over/underfrequency,
over/undervoltage) and active (frequency shift, reactive power
injection) schemes. Required by IEEE 1547 and UL 1741. (Ch. 10)

\textbf{Anti-Windup} --- A control strategy that prevents the integral
term of a PID controller from accumulating error when the actuator is
saturated. Common methods include clamping (freezing the integrator) and
back-calculation (reducing the integral proportionally to saturation).
(Ch. 4)

\textbf{Arc Flash} --- An electrical explosion caused by current flowing
through ionized air between conductors, producing temperatures exceeding
20,000°C. Arc flash hazard analysis per IEEE 1584 calculates incident
energy to determine required PPE levels. (Ch. 1)

\textbf{Arc-Fault Circuit Interrupter (AFCI)} --- A circuit breaker or
receptacle that detects dangerous arcing signatures (series and parallel
arcs) and trips to prevent fires. Required by NEC 210.12 in most
dwelling unit branch circuits. Listed to UL 1699. (Ch. 14)

\textbf{Arithmetic Gradient} --- A cash flow pattern where amounts
increase by a constant dollar value G each period, with the present
worth factor (P/G, i, n) converting the gradient to present value. (Ch.
19)

\textbf{ARM Cortex-M} --- A family of 32-bit RISC processor cores
designed by ARM Holdings for embedded microcontroller applications, with
variants ranging from the low-power M0 to the high-performance M7. (Ch.
5)

\textbf{ASGI (Asynchronous Server Gateway Interface)} --- An extension
of the WSGI standard for asynchronous Python web applications,
supporting WebSockets, HTTP/2, and long-lived connections. Servers
include Uvicorn and Hypercorn. (Ch. 15)

\textbf{ASK (Amplitude Shift Keying)} --- A digital modulation technique
that encodes data by varying the amplitude of a carrier signal. Binary
ASK (on-off keying) transmits the carrier at full amplitude for a 1 and
zero amplitude for a 0. (Ch. 2)

\textbf{atan2(y, x)} --- The two-argument arctangent function that
returns the angle in all four quadrants (−180° to +180°) by using the
signs of both arguments, resolving the quadrant ambiguity of the
single-argument arctan function. (App. B)

\textbf{Augmentation (BESS)} --- The strategy of adding new battery
modules to an existing BESS installation to compensate for capacity fade
over time, maintaining the system's nameplate energy rating throughout
its contracted life. (Ch. 10)

\textbf{Autocorrelation} --- The correlation of a signal with a
time-shifted copy of itself, R\textsubscript{xx}(τ), revealing periodic
structure and signal power. Related to the power spectral density via
the Wiener-Khinchin theorem. (Ch. 8)

\textbf{Autotransformer} --- A transformer with a single winding tapped
at an intermediate point, where the primary and secondary circuits share
a common winding section. More compact and efficient than a two-winding
transformer when the voltage ratio is close to 1:1, but provides no
galvanic isolation. (Ch. 1)

\textbf{AVR} --- An 8-bit RISC microcontroller architecture originally
developed by Atmel (now Microchip), widely used in Arduino development
boards. (Ch. 5)

\textbf{AWG (American Wire Gauge)} --- A standardized wire sizing system
where smaller gauge numbers indicate larger conductor diameters. Common
sizes range from 14 AWG (residential wiring) to 4/0 AWG (large feeders).
(Ch. 14)

\textbf{Babinet's Principle} --- The radiation pattern of a slot antenna
is complementary to that of a dipole of the same dimensions, with
E-plane and H-plane interchanged. The slot and dipole impedances are
related by Z\textsubscript{slot} × Z\textsubscript{dipole} = η²/4, where
η = 377 Ω. (Ch. 16)

\textbf{Back EMF} --- The voltage generated by a rotating motor that
opposes the applied voltage, proportional to rotor speed. Also called
counter-electromotive force (CEMF). (Ch. 12)

\textbf{Balun} --- A transformer or network that converts between
balanced (equal and opposite signals, e.g., dipole antenna) and
unbalanced (single-ended, e.g., coaxial cable) transmission systems.
Common types include sleeve, folded, and ferrite-core baluns. (Ch. 16)

\textbf{Bandgap Energy} --- The energy difference between the valence
band and conduction band of a semiconductor material, determining its
electrical and optical properties. Silicon has a bandgap of 1.1 eV. (Ch.
3)

\textbf{Bandwidth} --- The range of frequencies over which a system,
signal, or medium operates effectively. In networking, often used
loosely to mean data transfer rate. (Ch. 2, 8, 15)

\textbf{Battery Energy Storage System (BESS)} --- A grid-scale or
commercial energy storage installation comprising battery modules, a
power conversion system (bidirectional inverter), battery management
system hierarchy, thermal management, and control systems. Used for peak
shaving, frequency regulation, renewable firming, and energy arbitrage.
(Ch. 10)

\textbf{Battery Management System (BMS)} --- An electronic system that
monitors and controls a rechargeable battery pack, managing cell
voltages, currents, temperatures, state of charge estimation, cell
balancing, and fault protection to ensure safe operation and maximize
battery life. (Ch. 10)

\textbf{Beamforming} --- A signal processing technique that uses an
antenna array to steer and shape the radiated beam by controlling the
amplitude and phase of each element. Analog beamforming uses RF phase
shifters; digital beamforming uses per-element DSP for simultaneous
multi-beam capability. (Ch. 16)

\textbf{Beamwidth} --- The angular width of an antenna's main lobe,
typically measured at the half-power (−3 dB) points (HPBW). Narrower
beamwidth indicates higher directivity. Approximated as HPBW ≈ 70λ/D for
aperture antennas. (Ch. 16)

\textbf{Bearing Fault Frequency} --- Characteristic vibration
frequencies generated by defects in rolling-element bearings. BPFO (ball
pass frequency outer race) and BPFI (ball pass frequency inner race)
depend on bearing geometry, number of rolling elements, and shaft speed.
Monitoring these frequencies with spectrum analysis enables predictive
maintenance before catastrophic failure. (Ch. 12)

\textbf{Benefit-Cost Ratio (B/C)} --- The ratio of a public project's
benefits to its costs, both expressed in present worth or annual worth;
a project is justified when B/C ≥ 1.0. (Ch. 19)

\textbf{BER (Bit Error Rate)} --- The ratio of incorrectly received bits
to the total number of bits transmitted, expressed as a probability
(e.g., 10⁻¹²). (Ch. 2, 15)

\textbf{BGP (Border Gateway Protocol)} --- The exterior gateway routing
protocol used between autonomous systems on the Internet, making routing
decisions based on path attributes and policy rules. (Ch. 15)

\textbf{Bilinear Transform} --- A mapping s = (2/T)(z − 1)/(z + 1) that
converts continuous-time transfer functions to discrete-time
equivalents, preserving stability by mapping the left half s-plane to
the interior of the unit circle. Introduces frequency warping corrected
by pre-warping critical frequencies. (Ch. 8)

\textbf{Binary} --- Base-2 number system using digits 0 and 1, the
fundamental representation of digital data. (Ch. 6)

\textbf{BJT (Bipolar Junction Transistor)} --- A three-terminal
semiconductor device (NPN or PNP) that uses both electron and hole
carriers for current amplification, controlled by base current. (Ch. 3)

\textbf{BLDC (Brushless DC Motor)} --- A DC motor that uses electronic
commutation (via Hall sensors or back-EMF sensing) instead of mechanical
brushes, providing higher efficiency, longer life, and lower
maintenance. (Ch. 12)

\textbf{Bode Plot} --- A pair of graphs showing the magnitude (in dB)
and phase (in degrees) of a system's frequency response as a function of
frequency on a logarithmic scale. (Ch. 4, 13)

\textbf{Bonding} --- The permanent joining of metallic parts to form an
electrically conductive path that ensures electrical continuity and the
capacity to safely conduct any fault current. (Ch. 14)

\textbf{Boolean Algebra} --- A mathematical system operating on binary
variables (0 and 1) using logical operations AND, OR, and NOT, forming
the theoretical foundation of digital logic circuits. (Ch. 6)

\textbf{Boost Converter} --- A step-up DC-DC switching converter where
the output voltage is greater than the input voltage, with
V\textsubscript{out} = V\textsubscript{in} / (1 − D). (Ch. 10)

\textbf{Bootloader} --- A small program in protected flash memory that
executes before the main application firmware, providing a mechanism for
updating firmware over UART, USB, CAN, or wirelessly (OTA) without a
debug probe. (Ch. 5)

\textbf{Breakeven Analysis} --- A technique that determines the critical
value of a parameter at which two alternatives are equally attractive or
a project's NPV equals zero. (Ch. 19)

\textbf{Brewster's Angle} --- The angle of incidence θ\textsubscript{B}
= arctan(n₂/n₁) at which reflected light is completely polarized
perpendicular to the plane of incidence, with zero p-polarization
reflection. (Ch. 18)

\textbf{Bridgeless PFC} --- A power factor correction topology that
eliminates the input diode bridge rectifier, reducing conduction losses
by one or two diode drops per half-cycle. The totem-pole bridgeless PFC
using GaN HEMTs is the dominant topology for high-efficiency (96\%+)
server and EV charger power supplies. (Ch. 10)

\textbf{Buck Converter} --- A step-down DC-DC switching converter where
the output voltage is less than the input voltage, with
V\textsubscript{out} = D × V\textsubscript{in}, where D is the duty
cycle. (Ch. 10)

\textbf{Bypass Diode (PV)} --- A diode placed in parallel with a group
of series-connected PV cells (typically 18--20 cells per diode) to
provide an alternate current path when those cells are shaded or
damaged. Without bypass diodes, one shaded cell can eliminate nearly all
output from its series string; with bypass diodes, the shaded cell group
is bypassed and the power loss is limited to the bypassed section.
Modern 60-cell modules include three bypass diodes in the junction box.
(Ch. 10)

\textbf{C-Rate} --- A measure of the rate at which a battery is charged
or discharged relative to its capacity. A 1C rate means the battery is
fully charged or discharged in one hour; 0.5C takes two hours; 2C takes
30 minutes. Higher C-rates increase stress and reduce cycle life. (Ch.
10)

\textbf{Calibration} --- The process of comparing an instrument's
measurements against a known standard and adjusting or documenting any
deviations to ensure accuracy. (Ch. 11)

\textbf{CAN Bus (Controller Area Network)} --- A robust serial
communication protocol developed for automotive applications, using
differential signaling and message-based arbitration to allow multiple
nodes on a shared bus. (Ch. 5)

\textbf{Capacitance (C)} --- The ability of a component or system to
store electric charge, defined as C = Q/V, measured in farads (F). (Ch.
7, 9)

\textbf{Capital Recovery Factor (A/P)} --- The compound interest factor
{[}i(1+i)ⁿ{]}/{[}(1+i)ⁿ−1{]} that converts a present value into an
equivalent series of uniform annual payments. (Ch. 19)

\textbf{Carrier Wave} --- A high-frequency sinusoidal signal used to
carry information through modulation (amplitude, frequency, or phase).
(Ch. 2)

\textbf{CC/CV (Constant-Current/Constant-Voltage)} --- The standard
charging algorithm for lithium-ion batteries. The charger first supplies
a fixed current (CC phase) until the cell reaches its cutoff voltage,
then holds that voltage constant (CV phase) while current tapers
exponentially. Charge terminates when the current drops below a
threshold (typically C/20 to C/50). (Ch. 10)

\textbf{CCD (Charge-Coupled Device)} --- An image sensor that
accumulates photogenerated charge in potential wells and transfers
packets sequentially to a single output amplifier, providing low noise
and high uniformity for scientific and medical imaging. (Ch. 18)

\textbf{CCS (Combined Charging System)} --- An EV DC fast-charging
standard that extends the SAE J1772 AC connector with two additional DC
pins, enabling charging at up to 350 kW. Uses PLC (Power Line
Communication) for high-level digital communication between vehicle and
charger. (Ch. 10)

\textbf{CDMA (Code Division Multiple Access)} --- A multiple access
technique where each user's signal is spread across a wide bandwidth
using a unique pseudo-random code, allowing simultaneous transmission in
the same frequency band. The processing gain provides interference
rejection. (Ch. 2)

\textbf{Cell Balancing} --- The process of equalizing charge levels
across series-connected battery cells to prevent capacity loss and
safety hazards from cell voltage divergence. Passive balancing
dissipates excess energy through resistors; active balancing transfers
energy between cells using capacitors, inductors, or transformers for
higher efficiency. (Ch. 10)

\textbf{Cepstrum} --- The inverse Fourier transform of the logarithm of
the magnitude spectrum, mapping a signal into the quefrency domain
(units of time). Separates slowly varying spectral envelope (low
quefrency) from fine harmonic structure (high quefrency). Mel-frequency
cepstral coefficients (MFCCs) derived from the cepstrum are the standard
feature representation for speech recognition and speaker
identification. (Ch. 8)

\textbf{CFAR (Constant False Alarm Rate)} --- A radar detection
technique that adapts the detection threshold to the local noise/clutter
environment by estimating noise power from reference cells surrounding
the cell under test, maintaining a constant false alarm probability.
(Ch. 17)

\textbf{CHAdeMO} --- A DC fast-charging standard for electric vehicles
developed in Japan, using CAN bus communication and supporting
bidirectional power flow (V2G). Capable of charging rates up to 400 kW.
Being superseded by CCS and NACS in most markets. (Ch. 10)

\textbf{Charge Termination} --- The criterion used to end a battery
charging cycle. For lithium-ion (CC/CV), charging terminates when the
taper current drops below C/20 to C/50. For NiMH, a −ΔV/Δt voltage drop
of 5--10 mV signals full charge. For lead-acid, termination is based on
return current dropping below a threshold during the absorption stage.
(Ch. 10)

\textbf{Chemical Sensor} --- A transducer that converts the
concentration of a chemical species into an electrical signal. Types
include pH electrodes (glass membrane, −59.16 mV/pH at 25°C),
conductivity cells (AC excitation, cell constant K\textsubscript{cell}),
dissolved oxygen sensors (electrochemical or optical luminescence
quenching), and gas detectors (catalytic bead, electrochemical, MOS,
NDIR). (Ch. 11)

\textbf{Chiplet} --- A small, modular die designed to be combined with
other chiplets in an advanced package using 2.5D (interposer) or 3D
(direct stacking) integration. Enables mixing process nodes and
functions (compute, I/O, memory) for cost and performance optimization.
(Ch. 3)

\textbf{CIDR (Classless Inter-Domain Routing)} --- An IP addressing
scheme (RFC 4632) that replaces the original classful system, using
variable-length prefix notation (e.g., /24) to specify the network/host
boundary at any bit position. A /n prefix contains
2\textsuperscript{(32−n)} addresses. CIDR enables route aggregation
(supernetting), where contiguous address blocks are advertised as a
single shorter prefix to reduce routing table size. (Ch. 15)

\textbf{Circuit Breaker} --- A switching device designed to
automatically interrupt fault currents and isolate faulted sections of
the power system, rated by voltage, continuous current, and interrupting
capacity. (Ch. 1, 14)

\textbf{Clutter (Radar)} --- Unwanted radar returns from the environment
(ground, sea, precipitation, birds) rather than the targets of interest.
Characterized by the normalized clutter coefficient σ⁰ (m²/m²). Sea
clutter exhibits non-Rayleigh statistics with heavy tails, requiring
specialized detection algorithms. (Ch. 17)

\textbf{CMOS (Complementary Metal-Oxide-Semiconductor)} --- A logic
family using complementary pairs of PMOS and NMOS transistors, offering
near-zero static power dissipation, high noise margins, and rail-to-rail
output swings. Dynamic power increases with switching frequency as P =
C\textsubscript{L} × V\textsubscript{DD}² × f.~(Ch. 3, 6)

\textbf{CMRR (Common-Mode Rejection Ratio)} --- The ratio of
differential gain to common-mode gain in an amplifier, expressed in dB.
A higher CMRR indicates better rejection of signals common to both
inputs. (Ch. 13)

\textbf{Coaxial Cable} --- A transmission line consisting of a center
conductor, dielectric insulator, conductive shield, and outer jacket.
Standard impedances are 50 Ω (RF/data) and 75 Ω (video/CATV). (Ch. 15)

\textbf{Coherent Optical Detection} --- A fiber-optic receiver technique
that mixes the incoming signal with a local oscillator laser to recover
both amplitude and phase, enabling advanced modulation formats (DP-QPSK,
DP-16QAM) and digital signal processing for dispersion compensation and
polarization demultiplexing. (Ch. 18)

\textbf{Combinational Circuit} --- A digital logic circuit whose output
depends only on the current combination of inputs, with no memory or
feedback (e.g., adders, multiplexers, decoders). (Ch. 6)

\textbf{Commutator} --- A mechanical rotary switch in a brushed DC motor
that reverses the current direction in the armature windings as the
rotor turns, maintaining continuous torque. (Ch. 12)

\textbf{Complex Conjugate} --- For a complex number z = a + jb, its
conjugate is z* = a − jb. Multiplying a complex number by its conjugate
yields a real number: z × z* = a² + b². (App. A)

\textbf{Complex Number} --- A number of the form z = a + jb, where a is
the real part, b is the imaginary part, and j = √(−1). Essential for AC
circuit analysis. (App. A)

\textbf{Complex Power (S)} --- The product of phasor voltage and
conjugate phasor current, S = P + jQ, where P is real power (watts) and
Q is reactive power (VAR). Measured in volt-amperes (VA). (App. A)

\textbf{Compound Interest} --- Interest calculated on both the original
principal and accumulated interest, producing exponential growth
described by F = P(1+i)ⁿ. (Ch. 19)

\textbf{Compressive Sensing} --- A signal acquisition framework that
recovers sparse signals from far fewer measurements than the Nyquist
rate requires, using random measurement matrices and ℓ₁-minimization or
greedy algorithms (OMP). Requires M ≥ C × K × log(N/K) measurements for
a K-sparse signal of length N. (Ch. 8)

\textbf{Conducted Emissions} --- Electromagnetic interference currents
that travel along power and signal cables, regulated from 150 kHz to 30
MHz by CISPR 32 and FCC Part 15. Suppressed using EMI line filters with
X-capacitors (differential mode), Y-capacitors (common mode), and
common-mode chokes. (Ch. 9)

\textbf{Conduit Fill} --- The percentage of a conduit's internal
cross-sectional area occupied by conductors, limited by NEC Chapter 9,
Table 1 to 53\% for one conductor, 31\% for two, and 40\% for three or
more, to prevent overheating and facilitate conductor pulling. (Ch. 14)

\textbf{Constellation Diagram} --- A graphical representation of a
digital modulation scheme in the I-Q (in-phase/quadrature) signal space,
where each point represents a unique symbol. Used to visualize decision
regions, assess signal quality, and compare modulation schemes (BPSK,
QPSK, 16-QAM, 64-QAM). (Ch. 2)

\textbf{Continuous Compounding} --- The theoretical limit of compound
interest as compounding periods approach infinity, with future value F =
Pe\^{}(rn) and effective rate i = e\^{}r − 1. (Ch. 19)

\textbf{Controllability} --- A property of a dynamic system indicating
whether it is possible to drive the system from any initial state to any
desired final state using the available control inputs. Determined by
the rank of the controllability matrix {[}B, AB, A²B, \ldots{]}. (Ch. 4)

\textbf{Convolution} --- A mathematical operation that relates the
output of an LTI system to its input and impulse response: y(t) = x(t) *
h(t). In the frequency domain, convolution becomes multiplication. (Ch.
8)

\textbf{Coriolis Flow Meter} --- A mass flow sensor that vibrates a tube
at its resonant frequency; the Coriolis force from flowing fluid
produces a phase shift between inlet and outlet proportional to mass
flow rate. Provides ±0.1\% accuracy and simultaneous density
measurement, making it the standard for hydrocarbon custody transfer.
(Ch. 11)

\textbf{Coulomb Counting} --- A state of charge estimation method that
integrates battery current over time (SOC = SOC₀ − ∫I·dt /
Q\textsubscript{rated}), providing real-time tracking but accumulating
drift error from current sensor offset, requiring periodic recalibration
via open-circuit voltage or Kalman filtering. (Ch. 10)

\textbf{Coulomb's Law} --- The fundamental electrostatic law giving the
force between two point charges: F = kq₁q₂/r², where k ≈ 8.99 × 10⁹
N·m²/C². (Ch. 9)

\textbf{Coulombic Efficiency} --- The ratio of charge extracted from a
battery during discharge to charge inserted during the preceding charge
cycle, expressed as a percentage. Healthy lithium-ion cells achieve
99.5--99.9\%; values below 99\% indicate accelerated side reactions (SEI
growth, lithium plating) and degradation. (Ch. 10)

\textbf{Counter} --- A sequential digital circuit that counts clock
pulses and outputs the count in binary, available in up, down, and
up/down configurations. (Ch. 6)

\textbf{Coupled Transmission Lines} --- Two or more transmission lines
in close proximity where electromagnetic fields interact, causing
crosstalk through capacitive and inductive coupling; characterized by
even-mode and odd-mode impedances. (Ch. 9)

\textbf{Coupling Coefficient (k)} --- A dimensionless parameter (0 ≤ k ≤
1) indicating how much magnetic flux links two coupled inductors: k =
M/√(L₁L₂). A value of k = 1 represents perfect coupling (ideal
transformer); practical power transformers achieve k ≈ 0.95--0.99. (Ch.
7)

\textbf{CPLD (Complex Programmable Logic Device)} --- A programmable
digital logic device with a simpler, more predictable timing structure
than an FPGA, suitable for glue logic and control applications. (Ch. 6)

\textbf{CRC (Cyclic Redundancy Check)} --- An error detection code based
on polynomial division in GF(2), used in Ethernet (CRC-32), USB, and
most digital communication protocols. Detects all burst errors of length
≤ r bits for an r-bit CRC. (Ch. 2)

\textbf{Critical Path} --- The longest combinational logic delay path
between any two flip-flops in a synchronous digital circuit, determining
the maximum clock frequency: f\textsubscript{max} = 1 /
(t\textsubscript{cq} + t\textsubscript{crit} + t\textsubscript{su}).
(Ch. 6)

\textbf{Cross-Correlation} --- A measure of similarity between two
signals as a function of a time shift, used in radar (range finding),
GPS (code acquisition), and system identification to detect time delays.
(Ch. 8)

\textbf{Crosstalk} --- Unwanted signal coupling between adjacent
conductors or circuits caused by mutual capacitance (electric field) and
mutual inductance (magnetic field). Measured as NEXT (near-end) and FEXT
(far-end). NEXT saturates for coupled lengths exceeding the critical
length; FEXT increases linearly with coupled length and vanishes in
homogeneous media (stripline). (Ch. 9, 15)

\textbf{CT (Current Transformer)} --- See \emph{Current Transformer
(CT)}.

\textbf{Current Mode Control (CMC)} --- A converter control method that
adds an inner loop sensing inductor current, with peak CMC terminating
the switch on-time when current reaches the error amplifier output.
Provides cycle-by-cycle current limiting and simplified compensation but
requires slope compensation above 50\% duty cycle. (Ch. 10)

\textbf{Current Sense Amplifier} --- A specialized differential
amplifier optimized for measuring voltage across low-value shunt
resistors (1--100 mΩ) in power lines. High-side types reject common-mode
voltages up to hundreds of volts while providing fixed gains (20--200
V/V) with sub-percent accuracy. (Ch. 13)

\textbf{Current Sensor} --- A device that measures electric current
non-invasively (Hall effect sensors, current transformers, Rogowski
coils) or with minimal insertion loss (shunt resistors). Hall sensors
measure AC and DC; CTs and Rogowski coils measure AC only. (Ch. 11)

\textbf{Current Transformer (CT)} --- A transformer-based current sensor
where the primary is the conductor being measured and the secondary
produces a proportional scaled-down current (e.g., 100:5 ratio). Used in
power metering and protective relaying. (Ch. 1, 11)

\textbf{Cycloconverter} --- A power electronics converter that directly
converts AC at one frequency to AC at a different (lower) frequency
without an intermediate DC link. (Ch. 10)

\textbf{Czochralski Method} --- The primary technique for growing
single-crystal silicon ingots by pulling a seed crystal from a crucible
of molten silicon while rotating, producing ingots up to 300 mm in
diameter for IC wafer fabrication. (Ch. 3)

\textbf{DAC (Digital-to-Analog Converter)} --- A circuit that converts a
digital value to a corresponding analog voltage or current, used in
signal generation and control systems. (Ch. 5, 11)

\textbf{Damping Ratio (ζ)} --- A dimensionless parameter describing how
oscillations in a second-order system decay: underdamped (ζ \textless{}
1), critically damped (ζ = 1), or overdamped (ζ \textgreater{} 1). (Ch.
4)

\textbf{DAQ (Data Acquisition System)} --- A system that converts
physical signals (temperature, pressure, voltage) to digital data
through sensors, signal conditioning, and ADCs for computer processing.
(Ch. 11)

\textbf{Data Association} --- The process of assigning radar detections
to existing tracks in a multi-target tracking system; algorithms include
nearest-neighbor, probabilistic data association (PDA), and joint
probabilistic data association (JPDA). (Ch. 17)

\textbf{Data Logger} --- A standalone or PC-based device that records
measurement data over time with timestamps for later retrieval and
analysis. Standalone loggers use battery power and onboard flash memory
for long-term field deployments; PC-based loggers offer higher channel
counts and real-time display. (Ch. 11)

\textbf{dB (Decibel)} --- A logarithmic unit expressing the ratio of two
power levels: dB = 10 log₁₀(P₂/P₁). For voltage ratios: dB = 20
log₁₀(V₂/V₁). (App. C)

\textbf{dBm} --- An absolute power level referenced to 1 milliwatt: dBm
= 10 log₁₀(P/1 mW). 0 dBm = 1 mW, +30 dBm = 1 W. (App. C)

\textbf{DC (Direct Current)} --- Electric current flowing in one
constant direction, produced by batteries, solar cells, and rectified AC
power supplies. (Ch. 7)

\textbf{DCT (Discrete Cosine Transform)} --- A transform that expresses
a data sequence as a sum of cosine functions, producing real-valued
coefficients with strong energy compaction. The foundation of lossy
compression in JPEG (images) and MDCT-based audio codecs (MP3, AAC).
(Ch. 8)

\textbf{Dead Zone} --- In OTDR testing, the minimum distance after a
reflective event before the next event can be detected. Event dead zone
is typically 0.8--3 m; attenuation dead zone is 5--20 m. (Ch. 15)

\textbf{Decimation} --- The process of reducing the sampling rate of a
discrete-time signal by a factor M, requiring an anti-aliasing lowpass
filter before discarding samples to prevent spectral aliasing. (Ch. 8)

\textbf{Declining Balance Depreciation} --- An accelerated depreciation
method that applies a fixed percentage rate to the current book value
each year, producing larger charges in early years. (Ch. 19)

\textbf{Decoder} --- A combinational logic circuit that converts an
n-bit binary input to one of 2ⁿ output lines, used for memory address
decoding and device selection. (Ch. 6)

\textbf{Defender} --- In replacement analysis, the currently owned asset
being evaluated for continued service versus replacement by a
challenger. (Ch. 19)

\textbf{Delta Connection (Δ)} --- A three-phase winding configuration
where phase windings are connected end-to-end in a closed triangle.
V\textsubscript{LL} = V\textsubscript{phase}, I\textsubscript{L} = √3 ×
I\textsubscript{phase}. No neutral point available. (Ch. 1)

\textbf{Demand Factor} --- The ratio of the maximum demand of a system
to the total connected load, expressed as a percentage. NEC Article 220
provides demand factors for general lighting (Table 220.42), cooking
equipment (Table 220.55), and other loads to reduce service and feeder
sizing from the sum of all connected loads. (Ch. 14)

\textbf{Dependent Source} --- A voltage or current source whose value is
controlled by a voltage or current elsewhere in the circuit. Four types
exist: VCVS, VCCS, CCVS, and CCCS. Used to model transistor small-signal
behavior and amplifier gain. (Ch. 7)

\textbf{Depletion Region} --- The charge-depleted zone at a PN junction
where mobile carriers have diffused away, leaving fixed ionized donor
and acceptor atoms that create an internal electric field opposing
further diffusion. Its width varies with applied voltage. (Ch. 3)

\textbf{Depreciation} --- The systematic allocation of an asset's cost
over its useful life for accounting and tax purposes, reducing taxable
income by a non-cash deduction. (Ch. 19)

\textbf{Depth of Discharge (DOD)} --- The percentage of a battery's
total capacity that has been discharged, where 80\% DOD means 80\% of
the energy has been used and 20\% remains. Deeper DOD per cycle
accelerates capacity degradation; most BESS installations operate at
80--90\% DOD. (Ch. 10)

\textbf{Determinant} --- A scalar value computed from a square matrix
that indicates whether the matrix is invertible (non-zero determinant)
and appears in Cramer's rule for solving linear systems. (App. F)

\textbf{DFT (Discrete Fourier Transform)} --- The Fourier transform
applied to a finite-length discrete-time signal, producing a discrete
frequency spectrum. Computed efficiently using the FFT algorithm. (Ch.
8)

\textbf{DHCP (Dynamic Host Configuration Protocol)} --- A network
protocol that automatically assigns IP addresses and other configuration
parameters to devices joining a network. (Ch. 15)

\textbf{Dielectric Constant (Relative Permittivity)} --- The ratio
ε\textsubscript{r} = ε/ε₀ that quantifies a material's ability to store
electric field energy relative to free space. Determines capacitance,
wave velocity, and characteristic impedance in dielectric-filled
structures. Common values: air ≈ 1, FR-4 ≈ 4.3, alumina ≈ 9, BaTiO₃ ≈
1000+. (Ch. 9)

\textbf{Differential Amplifier} --- An amplifier that produces an output
proportional to the difference between two input signals while rejecting
signals common to both inputs. (Ch. 13)

\textbf{Differential Escalation} --- The rate at which a specific cost
escalates above or below the general inflation rate, requiring separate
treatment in economic analysis. (Ch. 19)

\textbf{Diffraction} --- The bending and spreading of light waves as
they pass through apertures or around obstacles. For a circular aperture
of diameter D, the angular resolution limit (Rayleigh criterion) is θ =
1.22λ/D. (Ch. 18)

\textbf{Diffraction Grating} --- An optical element with many periodic
grooves that disperses light into its constituent wavelengths by
diffraction. The grating equation d sin(θ) = mλ determines diffraction
angles. Resolving power R = mN, where N is the number of grooves. Used
in spectrometers and DWDM demultiplexers. (Ch. 18)

\textbf{Diffusion Current} --- Current flow in a semiconductor caused by
carrier concentration gradients, where carriers move from regions of
high concentration to low concentration. Governed by Fick's law:
J\textsubscript{diff} = qD(dn/dx). (Ch. 3)

\textbf{Diode} --- A two-terminal semiconductor device that allows
current to flow primarily in one direction (forward bias), blocking
current in the reverse direction until breakdown voltage is reached.
(Ch. 3)

\textbf{Dipole Antenna} --- A fundamental antenna type consisting of two
collinear conductors, typically λ/2 in total length, producing an
omnidirectional radiation pattern in the azimuthal plane. Input
impedance is 73 + j42.5 Ω with gain of 2.15 dBi. (Ch. 9, 16)

\textbf{Direct Torque Control (DTC)} --- A motor control method that
directly controls stator flux and electromagnetic torque using
hysteresis comparators and an optimal switching table, without
coordinate transformations or a rotor position sensor. Achieves 1--2 ms
torque response, faster than FOC, but with variable switching frequency.
(Ch. 12)

\textbf{Directivity} --- The ratio of an antenna's maximum radiation
intensity to the average radiation intensity over all directions: D =
4πU\textsubscript{max}/P\textsubscript{rad}. Related to gain by G = ηD,
where η is radiation efficiency. (Ch. 16)

\textbf{DMA (Direct Memory Access)} --- A hardware peripheral that
transfers data between memory and peripherals without CPU involvement,
freeing the processor for other tasks and enabling high-throughput data
streaming with minimal overhead. (Ch. 5)

\textbf{DMM (Digital Multimeter)} --- A measuring instrument capable of
reading voltage (AC/DC), current (AC/DC), and resistance, with
additional functions such as continuity, diode test, and capacitance.
(Ch. 11)

\textbf{DNP3 (Distributed Network Protocol)} --- A SCADA communication
protocol widely used in North American electric utilities for polling
Remote Terminal Units (RTUs) over serial or TCP/IP links. Supports
unsolicited responses, time-stamped events, and secure authentication.
(Ch. 1)

\textbf{DNS (Domain Name System)} --- A hierarchical naming system that
translates human-readable domain names (e.g., example.com) to IP
addresses, typically using UDP port 53. (Ch. 15)

\textbf{Doping} --- The intentional introduction of impurity atoms into
a semiconductor to modify its electrical conductivity, creating N-type
(excess electrons) or P-type (excess holes) material. (Ch. 3)

\textbf{Doppler Shift (Radar)} --- The frequency change in a radar echo
caused by target motion: f\textsubscript{d} = 2v\textsubscript{r}/λ,
where v\textsubscript{r} is the radial velocity. Used for velocity
measurement and moving target indication. (Ch. 17)

\textbf{Drift Current} --- Current flow in a semiconductor caused by the
motion of charge carriers under an applied electric field. The drift
current density is J\textsubscript{drift} = qnμE, where μ is carrier
mobility. (Ch. 3)

\textbf{Duty Cycle (D)} --- The fraction of a switching period during
which the switch is in the ON state, expressed as a ratio (0 to 1) or
percentage. Controls the output voltage in DC-DC converters. (Ch. 10)

\textbf{DWDM (Dense Wavelength Division Multiplexing)} --- An optical
transport technology that transmits multiple data channels
simultaneously over a single fiber using closely spaced wavelengths
(typically 100 GHz or 50 GHz spacing) in the C-band (1530--1565 nm).
(Ch. 15)

\textbf{Economic Service Life (ESL)} --- The number of years of asset
retention that minimizes the equivalent uniform annual cost, balancing
decreasing capital recovery against increasing operating costs. (Ch. 19)

\textbf{Eddy Currents} --- Circulating currents induced in a conductor
by a time-varying magnetic field (Faraday's law). Cause I²R losses
proportional to f²B²t²/ρ in transformer and motor cores, mitigated by
laminations or high-resistivity ferrite. Deliberately exploited in
induction heating and eddy current NDT. (Ch. 9)

\textbf{EDFA (Erbium-Doped Fiber Amplifier)} --- An optical amplifier
that uses erbium-doped fiber pumped by a 980 nm or 1480 nm laser to
amplify signals in the C-band without optical-to-electrical conversion.
Provides 15--30 dB gain with 4--6 dB noise figure. (Ch. 15, 18)

\textbf{EDLC (Electrochemical Double-Layer Capacitor)} --- A
supercapacitor that stores energy electrostatically at the interface
between a high-surface-area carbon electrode (activated carbon,
1,000--3,000 m²/g) and an electrolyte. The electric double layer --- two
charge sheets separated by \textasciitilde0.3--1 nm --- yields
capacitances from a few farads to thousands of farads. Cell voltage is
limited to 2.5--2.7 V (organic electrolyte) or 1.0--1.2 V (aqueous).
Also called an ultracapacitor. (Ch. 10)

\textbf{EEPROM (Electrically Erasable Programmable Read-Only Memory)}
--- Non-volatile memory that can be electrically erased and reprogrammed
byte-by-byte, used for storing configuration data and calibration
values. (Ch. 5)

\textbf{Effective Interest Rate} --- The actual annual yield accounting
for compounding frequency, computed as i\_eff = (1 + r/m)\^{}m − 1 where
r is the nominal rate and m is the compounding periods per year. (Ch.
19)

\textbf{EGC (Equipment Grounding Conductor)} --- A conductor that
provides a low-impedance ground-fault return path from equipment
enclosures back to the electrical source, sized per NEC Table 250.122.
(Ch. 14)

\textbf{EIRP (Effective Isotropic Radiated Power)} --- The product of
transmit power and antenna gain: EIRP =
P\textsubscript{t}G\textsubscript{t}. Represents the equivalent power an
isotropic antenna would need to produce the same peak radiation
intensity. (Ch. 16)

\textbf{Electric Field (E)} --- A vector field representing the force
per unit positive charge at each point in space, measured in volts per
meter (V/m). (Ch. 9)

\textbf{Electric Potential (V)} --- The work per unit charge required to
move a test charge from infinity to a point in an electric field,
measured in volts. (Ch. 9)

\textbf{Electromagnetic Compatibility (EMC)} --- The ability of
electronic equipment to function satisfactorily in its electromagnetic
environment without introducing intolerable interference to other
devices. Addressed through shielding, filtering, grounding, and circuit
layout per FCC/CISPR/IEC standards. (Ch. 9)

\textbf{Electromagnetic Wave} --- A self-propagating wave of oscillating
electric and magnetic fields perpendicular to each other and to the
direction of propagation, traveling at the speed of light in vacuum.
(Ch. 9)

\textbf{Electrostatic Discharge (ESD)} --- The sudden transfer of charge
between objects at different electrostatic potentials, producing
nanosecond-scale current pulses that can damage semiconductor devices.
Standard test models include the Human Body Model (HBM, 100 pF/1.5 kΩ),
Charged Device Model (CDM), and Machine Model (MM). Protection uses TVS
diodes and on-chip clamp circuits. (Ch. 9)

\textbf{Encapsulation} --- The process of adding protocol headers and
trailers as data passes down through the OSI layers, with each layer
wrapping the data from the layer above. (Ch. 15)

\textbf{Encoder} --- A combinational logic circuit that converts 2ⁿ
input lines into an n-bit binary output code. A priority encoder
resolves multiple simultaneous inputs by encoding the highest-priority
active input. (Ch. 6)

\textbf{Engineering Notation} --- A form of scientific notation where
the exponent is restricted to multiples of 3, aligning with SI prefixes
(kilo, mega, giga, milli, micro, nano). (App. D)

\textbf{Entropy} --- In information theory, the average information
content per symbol emitted by a source: H(X) = −Σ p\textsubscript{i}
log₂(p\textsubscript{i}). Represents the theoretical minimum number of
bits per symbol for lossless compression. (Ch. 2)

\textbf{Equivalent Series Resistance (ESR)} --- The lumped resistive
component of a capacitor or supercapacitor equivalent circuit, combining
electrode contact resistance, electrolyte resistance, and
current-collector resistance. ESR limits peak power
(P\textsubscript{max} = V²/(4·ESR)), causes a voltage step at the start
of charge or discharge, and is measured in milliohms for supercapacitors
(1--50 mΩ) and microfarad capacitors. (Ch. 10)

\textbf{Equivalent Uniform Annual Cost (EUAC)} --- The annualized total
cost of owning and operating an asset, including capital recovery and
operating expenses, used in replacement and life cycle analysis. (Ch.
19)

\textbf{Ethernet} --- The dominant LAN technology standardized as IEEE
802.3, using CSMA/CD (historically) or full-duplex switching, with frame
sizes of 64--1,518 bytes and speeds from 10 Mbps to 400 Gbps. (Ch. 15)

\textbf{Euler's Formula} --- The mathematical identity
e\textsuperscript{jθ} = cos θ + j sin θ, which links exponential,
trigonometric, and complex number representations. Fundamental to phasor
analysis. (App. A)

\textbf{EUV Lithography (Extreme Ultraviolet)} --- A semiconductor
patterning technology using 13.5 nm wavelength light with reflective
optics, enabling single-exposure patterning of features below 40 nm.
Essential for 7 nm and smaller process nodes. (Ch. 3)

\textbf{EVSE (Electric Vehicle Supply Equipment)} --- The infrastructure
that delivers electrical energy to an electric vehicle, including the
connector, cable, control electronics, and pilot signal circuitry. Level
1 EVSE uses 120 V household outlets; Level 2 uses 208--240 V dedicated
circuits; DC fast chargers bypass the on-board charger entirely. (Ch.
10)

\textbf{Fade Margin} --- The additional signal level (in dB) included in
a link budget beyond the minimum required for reliable operation,
accounting for time-varying impairments such as multipath fading, rain
attenuation, and atmospheric variations. Typical values range from
10--30 dB depending on reliability requirements. (Ch. 2)

\textbf{Fan-Out} --- The maximum number of gate inputs that a single
logic gate output can drive while maintaining valid voltage levels.
Effectively unlimited for CMOS at low frequencies but limited by
capacitive loading at high frequencies. (Ch. 6)

\textbf{Farad (F)} --- The SI derived unit of capacitance. One farad is
the capacitance that stores one coulomb of charge at one volt. Practical
values range from picofarads (pF) to millifarads (mF). (App. D)

\textbf{Faradaic Charge Storage} --- Charge storage resulting from
reversible electrochemical reactions at or near an electrode surface,
including surface redox reactions, intercalation, and underpotential
deposition. Pseudocapacitors exploit Faradaic storage to achieve 2--5×
higher energy density than purely electrostatic EDLC, at the cost of
slightly reduced cycle life and slower response. (Ch. 10)

\textbf{Fast Charging} --- Charging a battery at rates above 1C,
generating significant I²R heat and risking lithium plating at low
temperatures. Requires active thermal management and charge acceptance
algorithms that adjust current based on cell temperature and anode
potential. (Ch. 10)

\textbf{FEC (Forward Error Correction)} --- A coding technique that adds
redundant data to transmitted messages, allowing the receiver to detect
and correct errors without retransmission. Common FEC overheads are
7--25\%. (Ch. 15)

\textbf{Feedback} --- The process of returning a portion of a system's
output to its input for comparison with a reference signal, forming the
basis of closed-loop control. (Ch. 4)

\textbf{Ferromagnetic} --- A class of materials (iron, nickel, cobalt,
and their alloys) with very high relative permeability (μᵣ
\textgreater\textgreater{} 1) that exhibit strong magnetization,
hysteresis, and magnetic saturation. Used in transformer cores,
inductors, and permanent magnets. (Ch. 9)

\textbf{FET (Field-Effect Transistor)} --- A voltage-controlled
semiconductor device where current flow between drain and source is
controlled by the electric field from a gate terminal. Includes JFET and
MOSFET types. (Ch. 3)

\textbf{FFT (Fast Fourier Transform)} --- An efficient algorithm for
computing the DFT with O(N log₂ N) complexity instead of O(N²), making
real-time spectral analysis practical. (Ch. 8)

\textbf{Fiber Laser} --- A laser using rare-earth-doped optical fiber
(ytterbium, erbium, thulium) as the gain medium, pumped by semiconductor
diodes. Offers excellent beam quality (M² ≈ 1), high efficiency
(30--50\%), and scalability to \textgreater100 kW CW power for
industrial cutting and welding. (Ch. 18)

\textbf{Fiber Optic Cable} --- A cable containing one or more glass or
plastic fibers that transmit data as pulses of light, offering high
bandwidth, low attenuation, EMI immunity, and electrical isolation. (Ch.
15)

\textbf{Field-Oriented Control (FOC)} --- An advanced motor control
technique that decouples the torque-producing (q-axis) and
flux-producing (d-axis) components of stator current in a rotating
reference frame aligned with the rotor flux, enabling independent torque
and flux control comparable to a separately excited DC motor. Also
called vector control. (Ch. 12)

\textbf{Fill Factor (FF)} --- A figure of merit for a PV cell or module
defined as FF = (V\textsubscript{mp} × I\textsubscript{mp}) /
(V\textsubscript{oc} × I\textsubscript{sc}), where (V\textsubscript{mp},
I\textsubscript{mp}) is the maximum power point and V\textsubscript{oc},
I\textsubscript{sc} are open-circuit voltage and short-circuit current.
FF measures the ``squareness'' of the I-V curve; commercial
monocrystalline silicon cells achieve FF = 0.75--0.85. Higher series
resistance and lower shunt resistance reduce FF. (Ch. 10)

\textbf{FinFET} --- A three-dimensional transistor structure where the
gate wraps around three sides of a tall, narrow silicon fin, providing
superior electrostatic control compared to planar MOSFETs. Used from 22
nm through 5 nm process nodes. (Ch. 3)

\textbf{FIR Filter (Finite Impulse Response)} --- A digital filter whose
impulse response has finite duration, implemented as a weighted sum of
delayed input samples. Always stable and can provide linear phase. (Ch.
8)

\textbf{Fixed-Point Arithmetic} --- A number representation using scaled
integers with an implied binary point (e.g., Q15 uses 16 bits for values
from -1.0 to +0.99997). Used in embedded DSP and FPGAs for digital
filter implementation, offering lower cost and power than floating-point
at the expense of limited dynamic range and susceptibility to
quantization effects. (Ch. 8)

\textbf{Flash Memory} --- Non-volatile semiconductor memory that can be
electrically erased and reprogrammed in blocks, used for program storage
in microcontrollers. (Ch. 5)

\textbf{FLC (Full-Load Current)} --- The current drawn by a motor
operating at its rated load, voltage, and frequency. NEC motor circuit
sizing is based on FLC table values, not nameplate current. (Ch. 12, 14)

\textbf{Flip-Flop} --- An edge-triggered bistable memory element that
captures and stores one bit of data on the active clock edge. Types
include D (data), JK, and T (toggle). (Ch. 6)

\textbf{Flux Weakening} --- A motor control technique that reduces rotor
flux above base speed to prevent voltage saturation of the inverter,
enabling constant-power operation at speeds beyond the motor's rated
speed. Implemented in FOC by injecting negative d-axis current. IPM
motors with high saliency ratios achieve the widest constant-power speed
ranges (3:1 to 5:1 typical for EV traction). (Ch. 12)

\textbf{FM (Frequency Modulation)} --- A modulation technique that
encodes information by varying the instantaneous frequency of a carrier
signal. FM provides superior noise immunity compared to AM by trading
bandwidth for SNR improvement. Used in FM radio broadcasting (88-108
MHz). (Ch. 2)

\textbf{FMCW (Frequency Modulated Continuous Wave)} --- A radar waveform
that sweeps the transmit frequency linearly over a bandwidth B,
measuring range from the beat frequency between transmitted and received
signals. Range resolution = c/(2B). Dominant technology for automotive
radar at 77 GHz. (Ch. 17)

\textbf{FOD (Foreign Object Detection)} --- A safety system in wireless
charging that detects metallic or living objects on the charging pad
that could absorb energy and overheat. Methods include auxiliary sensing
coils, quality factor monitoring, and thermal sensors. Required by SAE
J2954 and Qi standards. (Ch. 10)

\textbf{Fourier Series} --- The representation of a periodic signal as
an infinite sum of harmonically related sinusoidal components
(fundamental frequency plus integer multiples). (Ch. 8)

\textbf{Fourier Transform} --- A mathematical operation that decomposes
a continuous-time signal into its constituent frequencies, transforming
from the time domain to the frequency domain. (Ch. 8)

\textbf{FPGA (Field-Programmable Gate Array)} --- A reconfigurable
integrated circuit containing programmable logic blocks, interconnects,
and I/O blocks that can implement arbitrary digital logic designs after
manufacture. (Ch. 6)

\textbf{Free-Space Path Loss (FSPL)} --- The attenuation of radio waves
due to spreading over distance in free space: FSPL (dB) = 20
log₁₀(4πd/λ) = 20 log₁₀(d) + 20 log₁₀(f) + 32.44 (d in km, f in MHz).
(Ch. 2, 15)

\textbf{Frequency Counter} --- An instrument that measures signal
frequency by counting zero-crossings within a timed gate interval.
Reciprocal counters measure the period using a high-speed internal clock
for superior resolution at low frequencies. Accuracy depends on the
timebase reference: TCXO (\textasciitilde1 ppm), OCXO
(\textasciitilde0.01 ppm), or GPS-disciplined oscillator
(\textasciitilde10⁻¹² long-term). (Ch. 11)

\textbf{Frequency Regulation} --- A grid ancillary service in which a
BESS or generator adjusts its power output in response to system
frequency deviations to maintain the grid at its nominal frequency (50
or 60 Hz). Primary regulation uses droop control; secondary regulation
(AGC) restores frequency to the setpoint. (Ch. 10)

\textbf{Frequency Response} --- The characterization of a system's
output magnitude and phase as a function of input frequency, typically
displayed as a Bode plot. (Ch. 4, 8, 13)

\textbf{Fresnel Equations} --- The equations describing the reflection
and transmission coefficients of electromagnetic waves at the boundary
between two media as a function of incidence angle and polarization. At
normal incidence: Γ = (η₂ - η₁)/(η₂ + η₁). The reflection vanishes for
TM polarization at Brewster's angle. (Ch. 9)

\textbf{Friis Formula} --- The equation for calculating the overall
noise figure of cascaded stages: F\textsubscript{total} = F₁ + (F₂ −
1)/G₁ + (F₃ − 1)/(G₁G₂) + \ldots, showing that the first stage dominates
system noise performance when it has sufficient gain. (Ch. 2)

\textbf{FSK (Frequency Shift Keying)} --- A digital modulation technique
that encodes data by switching the carrier frequency between discrete
values. Provides constant-envelope signals robust against nonlinear
distortion. GMSK (Gaussian MSK) is used in GSM cellular. (Ch. 2)

\textbf{FSPL} --- See Free-Space Path Loss. (Ch. 2, 15)

\textbf{Fusion Splice} --- A permanent, low-loss joint between two
optical fibers made by melting and fusing the fiber ends together with
an electric arc. Typical loss: 0.02--0.10 dB. (Ch. 15)

\textbf{G/T (Gain-to-Noise Temperature Ratio)} --- The figure of merit
for a satellite or radio receiver system, equal to the antenna gain
divided by the system noise temperature (dB/K). Higher G/T indicates
better sensitivity. Determines the carrier-to-noise ratio independent of
bandwidth. (Ch. 2)

\textbf{GAA (Gate-All-Around)} --- A transistor architecture where the
gate completely surrounds the channel on all four sides using stacked
horizontal nanosheets, providing maximum electrostatic control. Adopted
at 3 nm and below, succeeding FinFET. (Ch. 3)

\textbf{GaAs (Gallium Arsenide)} --- A III-V compound semiconductor with
a bandgap of 1.42 eV, used for high-frequency amplifiers, RF circuits,
and optoelectronics. (Ch. 3)

\textbf{Gain Margin} --- The additional gain (in dB) that can be applied
to a control system before it becomes unstable, measured at the phase
crossover frequency where the phase angle equals −180°. Adequate
stability typically requires GM ≥ 6 dB. (Ch. 4)

\textbf{GaN (Gallium Nitride)} --- A wide-bandgap semiconductor (3.4 eV)
used in high-power, high-frequency power electronics and RF amplifiers
due to its high breakdown voltage and electron mobility. GaN HEMTs
enable MHz-range switching in compact adapters and chargers. (Ch. 3, 10)

\textbf{Gate Driver} --- An interface circuit that translates low-power
control signals into high-current pulses to rapidly charge and discharge
the gate capacitance of power MOSFETs and IGBTs. Bootstrap gate drivers
use a capacitor recharged during the low-side on-time to power the
high-side driver, while isolated gate drivers use transformer or
capacitive barriers to provide galvanic isolation and high dv/dt
common-mode rejection. (Ch. 10)

\textbf{Gaussian Elimination} --- An algorithm for solving systems of
linear equations by systematically reducing the augmented matrix to
row-echelon form through elementary row operations. (App. F)

\textbf{Geometric Gradient} --- A cash flow pattern where amounts
increase by a constant percentage g each period, modeling
inflation-driven cost escalation. (Ch. 19)

\textbf{GFCI (Ground Fault Circuit Interrupter)} --- A protective device
that detects leakage current (typically 5 mA) between hot and neutral
conductors and rapidly disconnects the circuit to prevent electric
shock. (Ch. 14)

\textbf{Goertzel Algorithm} --- An efficient O(N)-per-bin method for
computing the DFT at a single frequency, implemented as a second-order
IIR recursion. More efficient than a full FFT when fewer than log₂(2N)
frequency bins are needed. Primary application is DTMF tone detection in
telephony. (Ch. 8)

\textbf{GPIO (General Purpose Input/Output)} --- Configurable digital
pins on a microcontroller that can be individually set as inputs
(reading external signals) or outputs (driving external devices). (Ch.
5)

\textbf{GPR (Ground-Penetrating Radar)} --- A radar technique that
transmits UWB impulse waveforms into the ground to detect subsurface
interfaces and buried objects. Operates at 10 MHz--4 GHz, trading
penetration depth for resolution. Used for utility mapping, road
inspection, and archaeology. (Ch. 17)

\textbf{Grating Lobe} --- An unwanted secondary main beam in an antenna
array that appears when element spacing exceeds λ/(1 + \textbar sin
θ₀\textbar), where θ₀ is the scan angle from broadside. At
half-wavelength spacing, grating lobes are suppressed for all scan
angles. (Ch. 16)

\textbf{Ground Loop} --- A closed conductive path formed when two points
in a system are connected to ground through different paths, allowing
magnetically induced or ground-potential-difference currents to flow and
couple noise (typically 50/60 Hz hum) into signal circuits. Mitigated by
differential signaling, galvanic isolation, or single-point shield
grounding. (Ch. 9, 11)

\textbf{Grounding} --- The intentional connection of an electrical
system or equipment to the earth through a grounding electrode,
providing a reference potential and a fault current return path for
safety. (Ch. 14)

\textbf{GSU (Generator Step-Up Transformer)} --- A large power
transformer at a generating station that steps up generator voltage
(typically 11--25 kV) to transmission voltage (115--765 kV). (Ch. 1)

\textbf{Gyroscope (MEMS)} --- A sensor that measures angular velocity
using a vibrating structure and detecting Coriolis forces. Combined with
accelerometers in Inertial Measurement Units (IMUs) for motion tracking,
navigation, and stabilization. (Ch. 11)

\textbf{Hall Effect Sensor} --- A magnetic field sensor that produces a
voltage proportional to the perpendicular magnetic flux density through
a current-carrying semiconductor. Used for position sensing, current
measurement, and brushless motor commutation. (Ch. 11)

\textbf{Hazardous Location} --- An area where flammable gases, vapors,
dusts, or fibers may be present in sufficient quantity to create an
explosion risk. NEC Article 500 classifies by material type (Class I
gases, Class II dusts, Class III fibers), probability of presence
(Division 1 normal, Division 2 abnormal), and gas/dust group (A--G). The
IEC Zone system (Zones 0/1/2 for gases, Zones 20/21/22 for dusts)
provides an alternative classification accepted in NEC Article 505. (Ch.
14)

\textbf{Henry (H)} --- The SI derived unit of inductance. One henry is
the inductance that produces one volt of EMF when the current changes at
one ampere per second. (App. D)

\textbf{Hertz (Hz)} --- The SI derived unit of frequency, equal to one
cycle per second. (App. D)

\textbf{Hexadecimal} --- Base-16 number system using digits 0--9 and
letters A--F, providing a compact representation of binary data (each
hex digit = 4 bits). (Ch. 6)

\textbf{Hilbert Transform} --- An operation that shifts every frequency
component of a real signal by ±90°, producing the quadrature companion
signal. Combined with the original to form the analytic signal z(t) =
x(t) + jx̂(t), from which instantaneous envelope A(t) =
\textbar z(t)\textbar{} and instantaneous frequency can be extracted.
Used in AM/FM demodulation, vibration analysis, and single-sideband
modulation. (Ch. 8)

\textbf{HMI (Human-Machine Interface)} --- The operator console in a
SCADA system that displays real-time power system data (one-line
diagrams, alarm lists, trend charts) and provides controls for
supervisory commands such as opening breakers or adjusting transformer
taps. (Ch. 1)

\textbf{Hold Time (t\textsubscript{h})} --- The minimum time a data
input must remain stable after the active clock edge of a flip-flop to
ensure reliable capture. Violating hold time can cause metastability.
(Ch. 6)

\textbf{Horn Antenna} --- An aperture antenna formed by flaring the end
of a waveguide, providing moderate gain (10--25 dBi), wide bandwidth
(\textgreater{} 2:1), and predictable performance. Used as feeds for
parabolic reflectors, calibration standards, and EMC testing. (Ch. 16)

\textbf{HVDC (High-Voltage Direct Current)} --- A power transmission
technology that converts AC to DC for long-distance transmission and
back to AC at the receiving end. Preferred for submarine cables, very
long overhead lines (\textgreater600 km), and asynchronous system
interconnections. Uses LCC (thyristor) or VSC (IGBT) converter
technology. (Ch. 1)

\textbf{Hysteresis (Magnetic)} --- The phenomenon where the
magnetization of a ferromagnetic material depends on its history,
forming a B-H loop when the applied field is cycled. Characterized by
remanence B\textsubscript{r} (residual flux density) and coercivity
H\textsubscript{c} (field to demagnetize). (Ch. 9)

\textbf{I2C (Inter-Integrated Circuit)} --- A two-wire synchronous
serial communication bus (SDA for data, SCL for clock) supporting
multiple masters and slaves on the same bus with 7-bit or 10-bit
addressing. (Ch. 5)

\textbf{IDF (Intermediate Distribution Frame)} --- A floor-level
telecommunications room in a building's structured cabling system,
housing access-layer switches and patch panels that serve the work areas
on that floor. (Ch. 15)

\textbf{IE Efficiency Classes} --- International efficiency
classification for electric motors defined by IEC 60034-30-1: IE1
(standard), IE2 (high), IE3 (premium), IE4 (super-premium), and IE5
(ultra-premium). NEMA Premium aligns with IE3. Higher classes use more
copper and better steel to reduce losses. (Ch. 12)

\textbf{IEC 61850} --- An international standard for substation
automation that defines a common data model and communication services
for IEDs, including GOOSE (Generic Object Oriented Substation Event)
messaging for high-speed peer-to-peer tripping and interlocking with
latencies under 4 ms. (Ch. 1)

\textbf{IED (Intelligent Electronic Device)} --- A microprocessor-based
device in a substation (protective relay, meter, breaker controller)
that acquires data, communicates via protocols such as DNP3 or IEC
61850, and can execute local control logic. (Ch. 1)

\textbf{IGBT (Insulated Gate Bipolar Transistor)} --- A power
semiconductor switch that combines the voltage-controlled gate drive of
a MOSFET with the high-current, low-saturation-voltage characteristics
of a BJT. Used in motor drives and inverters. (Ch. 10)

\textbf{IIR Filter (Infinite Impulse Response)} --- A digital filter
that uses feedback (recursive computation), producing an impulse
response of theoretically infinite duration. More efficient than FIR for
the same frequency response but can be unstable. (Ch. 8)

\textbf{Imaginary Unit (j)} --- The square root of −1, denoted j in
electrical engineering (i in mathematics) to avoid confusion with
current. Forms the basis of complex number representation for AC
analysis. (App. A)

\textbf{Impedance (Z)} --- The total opposition to current flow in an AC
circuit, combining resistance and reactance as a complex quantity: Z = R
+ jX, measured in ohms (Ω). (Ch. 7, App. A)

\textbf{Impedance Matching Network} --- A circuit (L-network,
pi-network, T-network, or transformer) inserted between a source and
load to maximize power transfer by transforming the load impedance to
the complex conjugate of the source impedance; commonly designed using
Smith charts. (Ch. 9)

\textbf{Impulse Response} --- The output of a system when the input is a
Dirac delta function (unit impulse). For LTI systems, the impulse
response completely characterizes the system's behavior. (Ch. 4, 8)

\textbf{Incident Energy} --- The thermal energy per unit area (cal/cm²
or J/cm²) at a specific working distance from an arc flash, used to
determine the required PPE category per NFPA 70E and IEEE 1584. (Ch. 1)

\textbf{Incremental Rate of Return} --- The internal rate of return
earned on the additional investment required by a more expensive
alternative, used to compare mutually exclusive options. (Ch. 19)

\textbf{Inductance (L)} --- The property of a circuit element that
opposes changes in current by storing energy in a magnetic field. L =
NΦ/I, measured in henries (H). (Ch. 9)

\textbf{Induction Motor} --- An AC motor where the rotor current is
induced by the rotating magnetic field of the stator, causing the rotor
to turn at slightly less than synchronous speed (slip). The most common
industrial motor type. (Ch. 12)

\textbf{Instrumentation Amplifier} --- A precision differential
amplifier with very high input impedance, high CMRR, and adjustable gain
set by a single resistor. Typically implemented with three op-amps. (Ch.
13)

\textbf{Insulation Class} --- A thermal rating system for motor winding
insulation defining maximum allowable hot-spot temperature: Class B
(130°C), Class F (155°C), Class H (180°C). Insulation life approximately
halves for every 10°C above the rated temperature (Arrhenius/Montsinger
rule). (Ch. 12)

\textbf{Integrator} --- An op-amp circuit whose output is proportional
to the time integral of the input signal, implemented with a capacitor
in the feedback path: V\textsubscript{out} = −(1/RC) ∫
V\textsubscript{in} dt. (Ch. 13)

\textbf{Internal Rate of Return (IRR)} --- The interest rate at which a
project's net present value equals zero, representing the effective
yield of the investment; accepted when IRR exceeds the MARR. (Ch. 19)

\textbf{Interrupt} --- A hardware or software signal that causes a
processor to suspend its current execution, save context, and execute a
designated interrupt service routine (ISR). (Ch. 5)

\textbf{Inverse Z-Transform} --- The operation that recovers a
discrete-time sequence x{[}n{]} from its Z-transform X(z), typically
performed by partial fraction expansion of X(z)/z followed by table
lookup, or by long division (power series expansion) for direct
computation of output samples. (Ch. 8)

\textbf{Inverter} --- In power electronics, a circuit that converts DC
power to AC power. In digital logic, a NOT gate that outputs the
complement of its input. (Ch. 6, 10)

\textbf{Investment Tax Credit (ITC)} --- A dollar-for-dollar reduction
in tax liability based on a percentage of a qualifying investment,
commonly applied to renewable energy systems. (Ch. 19)

\textbf{Ion Implantation} --- The primary doping method in modern
semiconductor fabrication, accelerating dopant ions (boron, phosphorus,
arsenic) into the silicon substrate with precise control of dose
(atoms/cm²) and depth profile through acceleration energy. (Ch. 3)

\textbf{IP Address} --- A numerical label assigned to each device on a
network for identification and routing. IPv4 uses 32-bit addresses; IPv6
uses 128-bit addresses. (Ch. 15)

\textbf{IPv4} --- Internet Protocol version 4, using 32-bit addresses
written in dotted-decimal notation (e.g., 192.168.1.1), providing
approximately 4.3 billion unique addresses. (Ch. 15)

\textbf{IPv6} --- Internet Protocol version 6, using 128-bit addresses
written in colon-hexadecimal notation (e.g., 2001:db8::1), providing 3.4
× 10³⁸ addresses. (Ch. 15)

\textbf{Irradiance} --- The radiant power incident per unit area on a
surface, measured in W/m². Follows the inverse-square law for point
sources: E = I/r². (Ch. 18)

\textbf{JTAG (Joint Test Action Group)} --- A debug and boundary scan
interface (IEEE 1149.1) using four signal lines (TDI, TDO, TCK, TMS)
that provides real-time access to processor state, breakpoints, memory
inspection, and flash programming. (Ch. 5)

\textbf{Jury Stability Criterion} --- An algebraic test for
discrete-time system stability analogous to Routh-Hurwitz for
continuous-time systems. Constructs a triangular array from the
characteristic polynomial coefficients to determine whether all roots
lie inside the unit circle. For second-order systems, reduces to the
stability triangle conditions: 1 + a₁ + a₂ \textgreater{} 0, 1 − a₁ + a₂
\textgreater{} 0, \textbar a₂\textbar{} \textless{} 1. (Ch. 8)

\textbf{K-Factor Transformer} --- A transformer designed to withstand
the additional heating caused by harmonic currents from nonlinear loads.
The K-factor K = Σ(I\textsubscript{h}² × h²)/Σ(I\textsubscript{h}²)
quantifies harmonic heating; standard ratings are K-1, K-4, K-13, and
K-20. Features include oversized neutrals, reduced core flux density,
and transposed windings to minimize eddy current losses. (Ch. 14)

\textbf{Kalman Filter} --- An optimal recursive estimator for linear
systems with Gaussian noise that maintains a state estimate and
covariance, updating each with new measurements via a predict-correct
cycle. Used in radar target tracking, GPS navigation, IMU sensor fusion,
and battery state estimation. The extended Kalman filter (EKF) handles
nonlinear systems via Jacobian linearization. (Ch. 8, 17)

\textbf{Karnaugh Map (K-map)} --- A graphical method for simplifying
Boolean expressions by arranging truth table entries in a grid that
allows visual identification of adjacent minterms for grouping. (Ch. 6)

\textbf{KCL (Kirchhoff's Current Law)} --- The principle that the
algebraic sum of all currents entering and leaving any node in a circuit
equals zero. (Ch. 7)

\textbf{kcmil} --- Thousand circular mils, a unit of area for large
electrical conductors (formerly MCM). One kcmil equals the area of a
circle with a diameter of one mil (0.001 inch), multiplied by 1,000.
(Ch. 14)

\textbf{KVL (Kirchhoff's Voltage Law)} --- The principle that the
algebraic sum of all voltages around any closed loop in a circuit equals
zero. (Ch. 7)

\textbf{L-Network} --- A two-element impedance matching network using
one series and one shunt reactive component (inductor or capacitor) to
transform a load impedance to a desired source impedance. The matching Q
= √(R\textsubscript{high}/R\textsubscript{low} − 1) determines both the
element values and the matching bandwidth. (Ch. 9)

\textbf{LAG (Link Aggregation Group)} --- A technique (IEEE
802.3ad/802.1AX) that bundles multiple physical network links into a
single logical link to increase bandwidth and provide redundancy. (Ch.
15)

\textbf{Lag Compensator} --- A frequency-domain controller
G\textsubscript{c}(s) = K(s + z)/(s + p) with z \textgreater{} p that
boosts low-frequency gain to reduce steady-state error without
significantly affecting phase margin at the crossover frequency. (Ch. 4)

\textbf{Laplace Transform} --- An integral transform that converts a
time-domain function f(t) into a complex-frequency-domain function F(s),
where s = σ + jω. Enables algebraic analysis of differential equations
and transfer functions. (Ch. 4, 8)

\textbf{Laplace's Equation} --- The second-order PDE ∇²V = 0 governing
electric potential in charge-free regions. Combined with boundary
conditions, it uniquely determines the field distribution. Solved
analytically for simple geometries and numerically (FEM, FDM, BEM) for
complex structures like PCB traces, high-voltage bushings, and IC
interconnects. (Ch. 9)

\textbf{Laser} --- Light Amplification by Stimulated Emission of
Radiation. A device that produces coherent, monochromatic light through
stimulated emission in a gain medium within an optical resonator. Types
include gas (HeNe, CO₂), solid-state (Nd:YAG), semiconductor (laser
diodes), and fiber lasers. (Ch. 18)

\textbf{Latch} --- A level-sensitive bistable memory element that is
transparent (passes input to output) when the enable signal is active.
Simpler than a flip-flop but susceptible to timing hazards. (Ch. 6)

\textbf{Latency} --- The total time delay for data to travel from source
to destination, comprising propagation, serialization, processing, and
queuing delays. (Ch. 15)

\textbf{LCR Meter} --- An instrument that measures inductance (L),
capacitance (C), and resistance (R) of passive components by applying a
sinusoidal test signal and computing impedance Z = V/I. Also reports
dissipation factor (D), quality factor (Q), and ESR. Four-terminal
Kelvin sensing eliminates lead resistance errors for low-impedance
measurements. (Ch. 11)

\textbf{LDO (Low-Dropout Regulator)} --- A linear voltage regulator that
can operate with a very small input-to-output voltage differential
(100-300 mV), using a PMOS or PNP pass transistor. Preferred for
battery-powered and noise-sensitive applications. (Ch. 3)

\textbf{Lead Compensator} --- A frequency-domain controller
G\textsubscript{c}(s) = K(s + z)/(s + p) with p \textgreater{} z that
adds positive phase shift near the geometric mean frequency √(zp) to
increase phase margin and improve transient response. (Ch. 4)

\textbf{LED (Light-Emitting Diode)} --- A semiconductor diode that emits
photons when forward biased, with the emitted wavelength determined by
the bandgap of the semiconductor material. Used in indicators, displays,
and general illumination with efficacies up to 200 lm/W. (Ch. 3)

\textbf{Levelized Cost of Energy (LCOE)} --- The constant per-unit cost
of electricity that equates the present worth of all lifetime costs with
all lifetime energy production, expressed in \$/MWh. (Ch. 19)

\textbf{Levelized Cost of Storage (LCOS)} --- The constant per-unit cost
of energy delivered from a storage system over its lifetime, calculated
as LCOS = Total Lifetime Costs / Total Lifetime Energy Delivered,
expressed in \$/MWh. Accounts for capital cost, O\&M, degradation,
round-trip efficiency, and replacement costs. (Ch. 10)

\textbf{LiDAR (Light Detection and Ranging)} --- A remote sensing
technology that uses pulsed or FMCW laser light (typically 905 nm or
1550 nm) to measure range with centimeter-level accuracy, generating
dense 3D point clouds. Key technology for autonomous vehicles,
topographic mapping, and forestry. (Ch. 17)

\textbf{Life Cycle Cost (LCC)} --- The total present worth of all costs
associated with an asset over its entire life, including acquisition,
operation, maintenance, and disposal. (Ch. 19)

\textbf{Linear Motor} --- An electric motor that produces force and
motion in a straight line rather than rotation, created by ``unrolling''
a rotary motor stator into a flat or tubular geometry. Linear induction
motors (LIMs) produce a traveling magnetic field at synchronous velocity
v\textsubscript{s} = 2τ\textsubscript{p}f, while linear synchronous
motors (LSMs) use permanent magnets or electromagnets on the translator
for zero-backlash, sub-micron positioning. Applications include maglev
trains, semiconductor lithography stages, and baggage handling systems.
(Ch. 12)

\textbf{Linear Regulator} --- A voltage regulator that maintains a
stable output by dissipating excess voltage as heat across a series pass
element. Simple and low-noise but limited in efficiency to
V\textsubscript{out}/V\textsubscript{in}. Includes fixed (LM78xx) and
adjustable (LM317) types. (Ch. 3)

\textbf{Linearization} --- The process of correcting a nonlinear sensor
transfer characteristic to produce an output proportional to the
measured quantity. Methods include lookup tables with interpolation,
polynomial curve fitting (e.g., Steinhart-Hart equation for
thermistors), and analog hardware shaping circuits. (Ch. 11)

\textbf{Link Budget} --- An accounting of all gains and losses in a
communication link from transmitter to receiver, expressed in dB, used
to determine whether the received signal meets the minimum required
level. (Ch. 2, 15, App. C)

\textbf{LISN (Line Impedance Stabilization Network)} --- A measurement
device that presents a defined impedance (typically 50 Ω) to equipment
under test for conducted EMI testing, isolating the measurement from the
utility supply while coupling the device's conducted emissions to a
spectrum analyzer or EMI receiver per CISPR standards. (Ch. 10)

\textbf{Lithium Plating} --- The deposition of metallic lithium on the
surface of a battery anode when the charging rate exceeds the anode's
ability to intercalate lithium ions, particularly at low temperatures.
Permanently reduces capacity, increases internal resistance, and can
create dendrites that cause internal short circuits. (Ch. 10)

\textbf{Lithium-Ion Capacitor (LIC)} --- A hybrid energy storage device
combining a pre-lithiated graphite anode (battery-like intercalation)
with an activated carbon cathode (EDLC-like double-layer storage). The
asymmetric design raises the cell voltage to 2.2--3.8 V, achieving 3×
the energy density of a conventional EDLC while retaining much of its
peak-power advantage. Targets applications --- elevator energy recovery,
regenerative braking, industrial UPS --- that require more energy than
standard EDLC but more power than lithium-ion batteries. (Ch. 10)

\textbf{LLC Resonant Converter} --- An isolated DC-DC converter using a
resonant tank of two inductors and one capacitor to achieve zero-voltage
switching across the full load range. Widely used in server power
supplies, telecom rectifiers, and EV chargers for its high efficiency
(95--97\%). (Ch. 10)

\textbf{LMS (Least Mean Squares)} --- The most widely used adaptive
filtering algorithm, updating filter weights using stochastic gradient
descent: w{[}n+1{]} = w{[}n{]} + 2μe{[}n{]}x{[}n{]}. Simple, low
computational cost, with convergence controlled by the step size μ. (Ch.
8)

\textbf{Load Cell} --- A transducer that converts mechanical force or
weight into an electrical signal, typically using strain gauges arranged
in a Wheatstone bridge configuration. (Ch. 11)

\textbf{Load Flow (Power Flow)} --- The fundamental power system
analysis that determines steady-state voltage magnitudes and angles at
all buses and power flows through all branches, solved iteratively using
Newton-Raphson or Gauss-Seidel methods. (Ch. 1)

\textbf{Locked-Rotor Current} --- The current drawn by a motor at the
instant of starting when the rotor is stationary, typically 4--8 times
the full-load current. (Ch. 12, 14)

\textbf{Logarithmic Amplifier} --- An op-amp circuit that uses a BJT or
diode in the feedback path to produce an output proportional to the
logarithm of the input current or voltage. Provides a useful dynamic
range of 3--7 decades and outputs approximately 59.16 mV/decade (= 2.303
× V\textsubscript{T} = 2.303 × 25.69 mV) at 25°C before scaling. (Ch.
13)

\textbf{Logic Gate} --- A fundamental digital circuit that implements a
Boolean function (AND, OR, NOT, NAND, NOR, XOR, XNOR) with one or more
inputs and one output. (Ch. 6)

\textbf{Loss Tangent (tan δ)} --- The ratio of the imaginary to real
parts of complex permittivity (ε″/ε′), quantifying dielectric energy
dissipation in an alternating electric field. Low tan δ materials (PTFE
≈ 0.0002, Rogers ≈ 0.003) are preferred for RF circuits; FR-4 (tan δ ≈
0.02) is adequate below \textasciitilde1 GHz. (Ch. 9)

\textbf{LTI System (Linear Time-Invariant)} --- A system that obeys the
principles of superposition (linearity) and time-shift invariance,
allowing complete characterization by its impulse response or transfer
function. (Ch. 8)

\textbf{Luenberger Observer} --- A state estimator that reconstructs
unmeasured state variables from output measurements using the equation x̂̇
= Ax̂ + Bu + L(y − Cx̂), where L is the observer gain vector. Requires the
system to be observable. (Ch. 4)

\textbf{LVDT (Linear Variable Differential Transformer)} --- A position
sensor that uses electromagnetic coupling between a movable core and
three coils (one primary, two secondary) to produce an output voltage
proportional to core displacement. (Ch. 11)

\textbf{MAC Address} --- A 48-bit hardware address permanently assigned
to a network interface, written as six pairs of hexadecimal digits
(e.g., 00:1A:2B:3C:4D:5E). The first 24 bits are the OUI identifying the
manufacturer. (Ch. 15)

\textbf{MACRS} --- Modified Accelerated Cost Recovery System, the U.S.
tax depreciation method using prescribed recovery periods, declining
balance switching to straight-line, and a half-year convention. (Ch. 19)

\textbf{Magnetic Circuit} --- An analogy to electric circuits where
magnetic flux Φ (analogous to current) is driven by magnetomotive force
ℱ = NI (analogous to voltage) through reluctance ℛ = l/(μA) (analogous
to resistance). Used to design inductor and transformer cores, with air
gaps added to store energy, linearize inductance, and increase
saturation current. (Ch. 9)

\textbf{Magnetic Field (B)} --- A vector field representing the magnetic
influence on moving charges and magnetic materials, measured in tesla
(T) or gauss (1 T = 10,000 gauss). (Ch. 9)

\textbf{Matrix} --- A rectangular array of numbers arranged in rows and
columns, used to represent and solve systems of linear equations,
circuit analysis problems, and state-space models. (App. F)

\textbf{Matrix Converter} --- A direct AC-to-AC converter using a matrix
of bidirectional switches (9 switches for 3φ-to-3φ) to provide frequency
and voltage conversion without intermediate DC energy storage. Maximum
voltage ratio is √3/2 ≈ 0.866. Offers sinusoidal I/O, controllable power
factor, and four-quadrant operation. (Ch. 10)

\textbf{Matrix Inverse (A⁻¹)} --- The matrix satisfying A × A⁻¹ = I
(identity matrix). Exists only for square matrices with non-zero
determinant. Used in solving AX = B as X = A⁻¹B. (App. F)

\textbf{Maximum Power Point (MPP)} --- The operating point
(V\textsubscript{mp}, I\textsubscript{mp}) on a PV module's I-V curve
where the product P = V × I is maximized. The MPP shifts with irradiance
and temperature, requiring active maximum power point tracking (MPPT) to
harvest available energy efficiently. At STC, a 60-cell module typically
has V\textsubscript{mp} ≈ 30--38 V. (Ch. 10)

\textbf{Maximum Power Point Tracking (MPPT)} --- An algorithm
implemented in a DC-DC converter that continuously adjusts its duty
cycle to operate a PV array at its maximum power point as irradiance and
temperature change. Common algorithms include Perturb-and-Observe (P\&O)
and Incremental Conductance (InC). MPPT efficiency typically reaches
97--99.5\%. (Ch. 10)

\textbf{Maximum Power Transfer} --- The theorem stating that maximum
power is delivered to a load when the load impedance equals the complex
conjugate of the source impedance (or equals the source resistance for
resistive circuits). (Ch. 7)

\textbf{Maxwell's Equations} --- The four fundamental equations
governing all electromagnetic phenomena: Gauss's law for electricity,
Gauss's law for magnetism, Faraday's law of induction, and the
Ampere-Maxwell law. (Ch. 9)

\textbf{MDF (Main Distribution Frame)} --- The primary equipment room in
a building's structured cabling system, serving as the building entry
point for external services and housing core network switches. (Ch. 15)

\textbf{Mealy Machine} --- A finite state machine whose outputs depend
on both the current state and the current inputs, allowing faster
response than a Moore machine but with the potential for output glitches
during input transitions. (Ch. 6)

\textbf{Measurement Uncertainty} --- The quantitative expression of
doubt about a measurement result, evaluated using the GUM (Guide to the
Expression of Uncertainty in Measurement) framework. Type A uncertainty
is evaluated statistically from repeated measurements; Type B is
evaluated from calibration certificates, specifications, and engineering
judgment. Combined standard uncertainty is the RSS of all components;
expanded uncertainty U = k × u\textsubscript{c} (typically k = 2 for
95\% confidence). (Ch. 11)

\textbf{Mesh Analysis} --- A systematic circuit analysis method that
applies KVL around each independent loop (mesh) to establish equations
for the unknown mesh currents. (Ch. 7)

\textbf{Microcontroller} --- A single-chip computer integrating a CPU,
program memory (Flash), data memory (SRAM), and peripherals (GPIO,
timers, ADC, communication interfaces) for embedded applications. (Ch.
5)

\textbf{Microgrid} --- A local energy grid with defined electrical
boundaries that can connect to and disconnect from the main utility
grid, operating autonomously using local generation and storage. (Ch. 1)

\textbf{Microstrip} --- A planar transmission line consisting of a
signal trace on the top surface of a dielectric substrate with a ground
plane on the bottom, used for controlled-impedance interconnects on PCBs
at RF and high-speed digital frequencies. Characteristic impedance
depends on trace width, substrate height, and dielectric constant. (Ch.
9)

\textbf{MIMO (Multiple-Input Multiple-Output)} --- A wireless technique
using multiple antennas at both transmitter and receiver to increase
throughput and reliability through spatial multiplexing and diversity.
Capacity scales linearly with min(N\textsubscript{t},
N\textsubscript{r}) in rich scattering. Massive MIMO (64--256 elements)
is fundamental to 5G NR. (Ch. 2, 15, 16)

\textbf{Minimum Attractive Rate of Return (MARR)} --- The minimum return
a project must earn to be considered acceptable, typically set above the
cost of capital to account for risk and opportunity cost. (Ch. 19)

\textbf{MMF (Multimode Fiber)} --- Optical fiber with a 50 μm or 62.5 μm
core that supports multiple propagation modes. Bandwidth limited by
modal dispersion. OM3/OM4/OM5 grades support 10--100 Gbps over data
center distances. (Ch. 15)

\textbf{Mode-Locking} --- A laser technique that forces many
longitudinal cavity modes to oscillate in phase, producing a train of
ultrashort pulses (femtoseconds to picoseconds). Pulse width is
inversely proportional to laser bandwidth: τ ≈ 0.44/Δf. Enables peak
powers of gigawatts to petawatts (with CPA). (Ch. 18)

\textbf{Modified Internal Rate of Return (MIRR)} --- A rate of return
measure that resolves multiple-IRR ambiguity by separating the finance
rate for negative cash flows from the reinvestment rate for positive
cash flows. (Ch. 19)

\textbf{Modulation Index} --- The ratio of the modulating signal
amplitude to the carrier amplitude in AM systems; determines the depth
of modulation and sideband power. (Ch. 2)

\textbf{Monopole Antenna} --- A wire antenna consisting of a
quarter-wavelength element mounted perpendicular to a ground plane. Has
half the impedance of a dipole (≈ 36.5 Ω) and 3 dB higher gain (5.15
dBi) due to ground-plane image effect. (Ch. 16)

\textbf{Moore Machine} --- A finite state machine whose outputs depend
only on the current state, providing glitch-free synchronous outputs
that change only on clock edges. (Ch. 6)

\textbf{MOSFET (Metal-Oxide-Semiconductor FET)} --- A voltage-controlled
transistor widely used as a switch in power electronics, operating at
high switching frequencies with very low gate drive power. (Ch. 3, 10)

\textbf{MTI (Moving Target Indication)} --- A radar signal processing
technique that suppresses echoes from stationary clutter by exploiting
Doppler shift differences between moving targets and the fixed
background. Uses pulse-to-pulse cancellation or Doppler filter banks.
(Ch. 17)

\textbf{MTU (Maximum Transmission Unit)} --- The largest packet or frame
size (in bytes) that can be transmitted on a network segment without
fragmentation. Ethernet MTU is typically 1,500 bytes. (Ch. 15)

\textbf{Multilevel Inverter} --- A power converter topology that
synthesizes the output voltage using three or more discrete voltage
levels, reducing harmonic content and dv/dt stress compared to two-level
inverters. Main types: neutral-point-clamped (NPC), flying capacitor,
and cascaded H-bridge (CHB). Modular multilevel converters (MMC) are
used in HVDC systems. (Ch. 10)

\textbf{Multiphase Converter} --- A DC-DC converter topology using N
parallel phases with switching signals phase-shifted by 360°/N, reducing
input and output ripple by cancellation and increasing effective ripple
frequency to N × f\textsubscript{sw}. The standard architecture for
CPU/GPU voltage regulator modules (VRMs), typically using 6--16
interleaved buck phases with DCR current sensing and adaptive voltage
positioning. (Ch. 10)

\textbf{Multiple Feedback (MFB) Filter} --- A second-order active filter
topology using a single op-amp in an inverting configuration with two
feedback paths. Particularly effective for bandpass filters with a
single op-amp, and preferred over Sallen-Key at high Q values due to
lower sensitivity to op-amp gain-bandwidth limitations. (Ch. 13)

\textbf{Multiplexer (MUX)} --- A combinational logic circuit that
selects one of several input signals and forwards it to a single output,
based on select line values. (Ch. 6)

\textbf{Multirate Signal Processing} --- Techniques for changing the
sampling rate of a discrete-time signal through decimation (rate
reduction) and interpolation (rate increase), used in digital audio,
software-defined radio, and efficient filter implementations. (Ch. 8)

\textbf{Mutual Inductance (M)} --- The property of two coupled inductors
where a changing current in one induces a voltage in the other: V₂ =
M(dI₁/dt). Related to self-inductances by M = k√(L₁L₂), where k is the
coupling coefficient. (Ch. 7)

\textbf{NACS (North American Charging Standard)} --- An EV charging
connector standard (SAE J3400), originally Tesla's proprietary design,
supporting both AC and DC charging through a single compact connector
rated to 1 MW. Adopted by most major automakers for the North American
market. (Ch. 10)

\textbf{NAT (Network Address Translation)} --- A technique that maps
private (RFC 1918) IP addresses to public addresses at the network
boundary. Static NAT provides one-to-one mappings for servers; Port
Address Translation (PAT/overload) maps thousands of internal hosts to a
single public IP using unique source port numbers. Carrier-Grade NAT
(CGNAT) applies a second PAT layer at the ISP. NAT breaks end-to-end
connectivity and requires ALGs for protocols that embed addresses in
payloads. (Ch. 15)

\textbf{Natural Frequency (ω₀)} --- The frequency at which an undamped
second-order system oscillates freely, ω₀ = 1/√(LC) for an RLC circuit.
(Ch. 4, 7)

\textbf{Near-Field Region} --- The region surrounding an antenna where
the electromagnetic field stores energy reactively and does not behave
as a propagating wave. Extends to approximately r = 2D²/λ, beyond which
the far-field (Fraunhofer) region begins with 1/r power decay and a
stable radiation pattern. (Ch. 9, 16)

\textbf{NEC (National Electrical Code)} --- NFPA 70, the U.S. standard
for safe electrical installation practices, covering wiring methods,
conductor sizing, overcurrent protection, grounding, and equipment
installation. (Ch. 14)

\textbf{NERC CIP (Critical Infrastructure Protection)} --- A set of
mandatory cybersecurity standards issued by the North American Electric
Reliability Corporation for bulk electric system cyber assets, covering
electronic security perimeters, access control, security patching,
incident response, and configuration management. (Ch. 1)

\textbf{Net Present Value (NPV)} --- The sum of all cash flows
discounted to time zero at the MARR; a positive NPV indicates the
project earns more than the minimum required return. (Ch. 19)

\textbf{NEXT (Near-End Crosstalk)} --- Crosstalk measured at the same
end of a cable as the signal source, representing the worst-case
interference because the transmitted signal is at full strength. (Ch.
15)

\textbf{Nodal Analysis} --- A systematic circuit analysis method that
applies KCL at each node to establish equations for the unknown node
voltages, using a conductance (admittance) matrix. (Ch. 7, App. F)

\textbf{Noise Figure (NF)} --- A measure of how much a device degrades
the signal-to-noise ratio, defined as NF = 10
log₁₀(SNR\textsubscript{in}/SNR\textsubscript{out}) in dB. An ideal
noiseless device has NF = 0 dB. Related to equivalent noise temperature
by T\textsubscript{e} = T₀(F − 1). (Ch. 2)

\textbf{Noise Margin} --- The voltage difference between a logic gate's
guaranteed output level and the required input level of the receiving
gate. NM\textsubscript{H} = V\textsubscript{OH} − V\textsubscript{IH}
and NM\textsubscript{L} = V\textsubscript{IL} − V\textsubscript{OL}.
Higher noise margins provide greater immunity to electrical noise. (Ch.
6)

\textbf{Noise-Equivalent Power (NEP)} --- The optical power incident on
a photodetector that produces a signal-to-noise ratio of 1 in a 1 Hz
bandwidth, expressed in W/√Hz. Lower NEP indicates higher detector
sensitivity. Related to specific detectivity by D* = √A/NEP, where A is
the detector area. (Ch. 18)

\textbf{Nominal Interest Rate} --- The stated annual interest rate
before accounting for compounding frequency, equal to the periodic rate
times the number of compounding periods per year. (Ch. 19)

\textbf{Norton's Theorem} --- Any linear two-terminal circuit can be
replaced by an equivalent circuit consisting of a current source in
parallel with a resistance. I\textsubscript{N} =
V\textsubscript{Th}/R\textsubscript{Th}. (Ch. 7)

\textbf{Notch Filter (Band-Reject Filter)} --- A frequency-selective
circuit that strongly attenuates a narrow band of frequencies while
passing all others. The active Twin-T notch filter uses an RC Twin-T
network in an op-amp feedback loop with positive feedback to achieve
high Q (narrow rejection bandwidth), commonly used to remove 50/60 Hz
power-line hum from instrumentation signals. (Ch. 13)

\textbf{NRZ (Non-Return-to-Zero)} --- A binary line encoding where the
signal level is held constant for the entire bit period: one level for a
1, another for a 0. Simple but lacks inherent clock recovery. (Ch. 15)

\textbf{Numerical Aperture (NA)} --- A dimensionless number
characterizing the light-gathering ability of an optical fiber: NA =
√(n\textsubscript{core}² − n\textsubscript{clad}²). Determines the
maximum acceptance angle. (Ch. 15, 18)

\textbf{Nyquist Sampling Theorem} --- A bandlimited signal can be
perfectly reconstructed from its samples if the sampling rate is greater
than twice the highest frequency component: f\textsubscript{s}
\textgreater{} 2f\textsubscript{max}. (Ch. 2, 8)

\textbf{OBC (On-Board Charger)} --- An AC/DC converter integrated into
an electric vehicle that converts grid AC power to DC for battery
charging. Typically rated at 3.3--22 kW for Level 1/Level 2 charging,
using a two-stage architecture (PFC + isolated DC-DC). DC fast charging
bypasses the OBC entirely. (Ch. 10)

\textbf{Observability} --- A property of a dynamic system indicating
whether the internal states can be uniquely determined from measurements
of the output over a finite time interval. Determined by the rank of the
observability matrix {[}C; CA; CA²; \ldots{]}. (Ch. 4)

\textbf{OCPD (Overcurrent Protective Device)} --- A circuit breaker or
fuse designed to open a circuit when current exceeds a specified value,
protecting conductors and equipment from overloads and short circuits.
(Ch. 14)

\textbf{OFDM (Orthogonal Frequency Division Multiplexing)} --- A digital
multiplexing technique that distributes data across many closely-spaced
orthogonal subcarriers using the Inverse FFT. Provides robustness
against multipath fading. Used in Wi-Fi, LTE, 5G NR, and DVB-T. (Ch. 2)

\textbf{OFDMA (Orthogonal Frequency Division Multiple Access)} --- A
multi-user variant of OFDM that dynamically assigns subsets of
subcarriers (resource blocks) to different users based on channel
conditions. Used in LTE downlink, 5G NR, and Wi-Fi 6 (802.11ax). Enables
frequency-domain scheduling and multi-user diversity. (Ch. 2, 15)

\textbf{Ohm (Ω)} --- The SI derived unit of electrical resistance. One
ohm is the resistance that produces one volt of drop per ampere of
current: V = IR. (App. D)

\textbf{Ohm's Law} --- The fundamental circuit relationship V = I × R,
stating that voltage across a resistor is proportional to the current
through it. Extended to AC circuits as V = I × Z using complex
impedance. (Ch. 7)

\textbf{Op-Amp (Operational Amplifier)} --- A high-gain DC-coupled
differential voltage amplifier with very high input impedance and low
output impedance, used as a building block for analog circuits
(amplifiers, filters, comparators, oscillators). (Ch. 13)

\textbf{Optical Link Budget} --- An accounting of all optical gains and
losses in a fiber-optic or free-space link, verifying that received
power exceeds the receiver sensitivity plus a system margin (typically
3--6 dB). Loss contributions include fiber attenuation, connector and
splice losses, and passive component insertion losses. (Ch. 15, 18)

\textbf{OSI Model (Open Systems Interconnection)} --- A seven-layer
conceptual framework for network communication: Physical, Data Link,
Network, Transport, Session, Presentation, Application. (Ch. 15)

\textbf{OSNR (Optical Signal-to-Noise Ratio)} --- The ratio of signal
power to ASE noise power in a specified optical bandwidth (typically 0.1
nm), used to assess the quality of DWDM optical links. (Ch. 15)

\textbf{OSPF (Open Shortest Path First)} --- A link-state interior
gateway routing protocol that uses Dijkstra's algorithm to compute the
shortest path to each destination within an autonomous system. (Ch. 15)

\textbf{OTDR (Optical Time-Domain Reflectometer)} --- A fiber optic test
instrument that characterizes a fiber link by launching optical pulses
and analyzing the backscattered and reflected light to map events
(splices, connectors, breaks) and measure attenuation as a function of
distance. (Ch. 15)

\textbf{OUI (Organizationally Unique Identifier)} --- The first 24 bits
(3 bytes) of a MAC address, assigned by IEEE to identify the
manufacturer or organization that produced the network interface. (Ch.
15)

\textbf{Overcurrent Protection} --- The use of fuses or circuit breakers
to automatically disconnect a circuit when current exceeds safe levels,
preventing conductor overheating and equipment damage. (Ch. 14)

\textbf{Overshoot (Percent)} --- The amount by which a system's step
response exceeds its final steady-state value, expressed as a
percentage. For a second-order system: \%OS = 100 ×
e\textsuperscript{−ζπ/√(1−ζ²)}. (Ch. 4)

\textbf{PAM-4 (Pulse Amplitude Modulation, 4-level)} --- A signaling
method using four distinct amplitude levels to encode 2 bits per symbol,
used in 10GBASE-T Ethernet and 400G optical interfaces. (Ch. 15)

\textbf{Parabolic Reflector Antenna} --- A high-gain antenna using a
paraboloidal dish to focus electromagnetic waves to a focal point. Gain
= η(πD/λ)², where D is the dish diameter and η is aperture efficiency
(0.55--0.70). Used in satellite communications, radar, and radio
astronomy. (Ch. 16)

\textbf{Parametric Spectral Estimation} --- A class of PSD estimation
methods that fit a mathematical model (typically autoregressive) to
observed data, achieving higher frequency resolution than FFT-based
methods on short data records. Includes AR/Burg methods and subspace
methods (MUSIC, ESPRIT). (Ch. 8)

\textbf{Patch Antenna} --- A low-profile antenna fabricated on a printed
circuit board substrate, consisting of a conducting patch over a ground
plane. Typical gain is 6--9 dBi with narrow bandwidth (1--5\%). Widely
used in mobile devices, GPS, Wi-Fi, and phased arrays. (Ch. 16)

\textbf{Patch Panel} --- A passive (unpowered) device mounted in a rack
that provides a termination point for horizontal cabling, with IDC
punchdown connections on the back and RJ-45 jacks (or fiber adapters) on
the front. (Ch. 15)

\textbf{Peak Shaving} --- The use of energy storage or demand response
to reduce peak electrical demand, typically to lower demand charges on
commercial utility bills. A BESS discharges during peak periods and
recharges during off-peak hours. (Ch. 10)

\textbf{Perturb-and-Observe (P\&O)} --- The most widely deployed MPPT
algorithm for PV systems. The controller periodically perturbs the array
voltage by a small step ΔV, measures the resulting change in power ΔP,
and continues in the same direction if ΔP \textgreater{} 0 or reverses
if ΔP \textless{} 0. Simple to implement but produces steady-state
oscillation of amplitude ΔV around the MPP. (Ch. 10)

\textbf{Phase Margin} --- The amount of additional phase lag (in
degrees) at the gain crossover frequency that would make a control
system unstable. Adequate stability typically requires PM ≥ 30-60°. For
second-order systems, PM ≈ 100ζ for ζ \textless{} 0.7. (Ch. 4)

\textbf{Phasor} --- A complex number representing the amplitude and
phase of a steady-state sinusoidal signal, typically expressed in RMS
magnitude and phase angle: V = V\textsubscript{rms}∠θ. (App. A)

\textbf{Photodiode} --- A semiconductor device that converts incident
photons into electrical current through absorption in a reverse-biased
PN junction. PIN photodiodes have a wide intrinsic region for high-speed
response; avalanche photodiodes (APDs) provide internal gain through
impact ionization. (Ch. 18)

\textbf{Photolithography} --- The process of transferring circuit
patterns onto a semiconductor wafer by exposing light-sensitive
photoresist through a photomask, then developing the resist to create a
patterned etch mask. Resolution limited by CD\textsubscript{min} =
k₁λ/NA. (Ch. 3)

\textbf{Photovoltaic (PV) Cell} --- A semiconductor p-n junction device
that generates electricity from sunlight through the photovoltaic
effect. Incident photons generate electron-hole pairs that are separated
by the junction's built-in electric field, producing a photocurrent
proportional to irradiance. Key parameters are short-circuit current
I\textsubscript{sc}, open-circuit voltage V\textsubscript{oc}, fill
factor FF, and efficiency η. Commercial monocrystalline silicon cells
achieve 18--24\% efficiency at STC. (Ch. 10)

\textbf{PID Controller} --- A feedback controller that computes a
control signal as the sum of proportional, integral, and derivative
terms of the error signal, providing fast response with zero
steady-state error. (Ch. 4)

\textbf{PIN Photodiode} --- A semiconductor photodetector with a P-I-N
junction structure that converts incident light to electrical current.
Used in fiber optic receivers for its linear response and fast speed.
(Ch. 15)

\textbf{PLL (Phase-Locked Loop)} --- A clock generation circuit that
multiplies a reference frequency to produce a higher-frequency output
clock. In MCUs, the PLL multiplies the crystal oscillator frequency to
generate the system clock (e.g., 8 MHz × 21 = 168 MHz). (Ch. 5)

\textbf{PN Junction} --- The interface between P-type and N-type
semiconductor regions, forming the fundamental building block of diodes,
BJTs, and MOSFETs. Characterized by a depletion region, built-in
potential, and exponential I-V behavior under forward bias. (Ch. 3)

\textbf{Polar Form} --- A representation of a complex number as
magnitude and angle: z = r∠θ, where r = \textbar z\textbar{} and θ =
atan2(b, a). Convenient for multiplication and division. (App. A)

\textbf{Poles and Zeros} --- The values of the complex frequency
variable s (or z) that make a transfer function infinite (poles) or zero
(zeros). Pole locations determine system stability and transient
behavior. (Ch. 4, 8)

\textbf{Polyphase Filter} --- An efficient multirate filter structure
that decomposes an N-tap filter into M subfilters of N/M taps each,
operating at the lower sampling rate to avoid wasting computation on
samples that will be discarded (decimation) or on zero-valued inputs
(interpolation). Reduces computational cost by a factor of M. (Ch. 8)

\textbf{Power Analyzer} --- A precision instrument that simultaneously
samples voltage and current to compute real power, reactive power,
apparent power, power factor, and harmonic content for AC and DC
systems. Provides accurate measurements on non-sinusoidal waveforms from
motor drives, power supplies, and switching converters. (Ch. 11)

\textbf{Power Factor (PF)} --- The ratio of real power (W) to apparent
power (VA) in an AC circuit, equal to cos θ where θ is the phase angle
between voltage and current. PF = 1.0 is ideal. (Ch. 1)

\textbf{Power Factor Correction (PFC)} --- The practice of improving a
system's power factor toward unity. In power systems, achieved by adding
capacitors to offset inductive loads. In power electronics, active PFC
circuits (boost PFC) shape the input current to follow the voltage
waveform, achieving PF \textgreater{} 0.99 and meeting IEC 61000-3-2
harmonic limits. (Ch. 1, 10)

\textbf{Power MOSFET} --- A MOSFET designed for high-current,
high-voltage switching using a vertical device structure (VDMOS or
trench). Key parameters include R\textsubscript{DS(on)} (conduction
loss), gate charge Q\textsubscript{g} (switching speed), and body diode
characteristics. (Ch. 3, 10)

\textbf{Power over Ethernet (PoE)} --- A technology that delivers DC
power over twisted-pair Ethernet cabling alongside data, defined by IEEE
802.3af (15.4 W), 802.3at (30 W), and 802.3bt (60/90 W). Uses 48 VDC
nominal with classification handshake between PSE and PD. (Ch. 15)

\textbf{Power Spectral Density (PSD)} --- The distribution of signal
power across frequency, expressed in watts per hertz (W/Hz), obtained
from the Fourier transform of the autocorrelation function. (Ch. 8)

\textbf{Power Supply Rejection Ratio (PSRR)} --- A measure of how well
an op-amp rejects noise and ripple on its power supply rails, defined as
PSRR = ΔV\textsubscript{supply}/ΔV\textsubscript{OS}. Typical DC values
are 80--120 dB but degrade with frequency at -20 dB/decade. (Ch. 13)

\textbf{Power Supply Sequencing} --- The practice of enabling multiple
voltage rails in a specific order and timing to prevent latch-up,
excessive inrush, or damage to sensitive ICs during startup and
shutdown. Strategies include sequential (daisy-chained PG signals),
ratiometric (all rails ramp proportionally), and simultaneous. PMBus
provides digital control and telemetry for multi-rail power management.
(Ch. 10)

\textbf{Poynting Vector (S)} --- The cross product S = E × H,
representing the instantaneous electromagnetic power flow per unit area
(W/m²). The time-averaged Poynting vector S\textsubscript{avg} =
\textbar E₀\textbar²/(2η) gives the power density of a plane wave. Used
to calculate radiated power, radiation intensity, and RF safety exposure
limits. (Ch. 9)

\textbf{Precision} --- The repeatability of a measurement --- the degree
to which repeated measurements under identical conditions yield the same
result. High precision does not imply high accuracy. (Ch. 11)

\textbf{Precision Rectifier} --- An op-amp circuit (also called a
superdiode) that overcomes the forward voltage drop of a conventional
diode, enabling rectification of millivolt-level signals. The op-amp's
open-loop gain effectively reduces the diode threshold by a factor of
A\textsubscript{OL} (e.g., 0.6 V becomes 6 μV). Used for precision
AC-to-DC conversion, AM demodulation, and absolute value circuits. (Ch.
13)

\textbf{Precision Time Protocol (PTP)} --- IEEE 1588 protocol for
sub-microsecond clock synchronization over packet networks, using
hardware timestamping and boundary/transparent clocks to measure and
compensate for network delay. Often combined with SyncE for phase and
frequency synchronization in 5G and telecom. (Ch. 15)

\textbf{Present Worth Factor (P/F)} --- The compound interest factor
1/(1+i)ⁿ that converts a future value to its equivalent present value.
(Ch. 19)

\textbf{Prism} --- A transparent optical element with flat, polished
surfaces that refracts light; used to separate white light into its
constituent wavelengths (dispersion) or to redirect beams at specific
angles based on Snell's law and total internal reflection. (Ch. 18)

\textbf{Profitability Index} --- The ratio of a project's NPV to its
initial investment (PI = NPV/Investment), used to rank independent
projects for capital budgeting under budget constraints. (Ch. 19)

\textbf{Programmable Gain Amplifier (PGA)} --- An amplifier whose gain
can be changed dynamically via digital control (SPI/I²C), typically by
switching between laser-trimmed feedback resistors using an analog
multiplexer. Used between input multiplexers and ADCs in data
acquisition systems to maximize effective dynamic range by matching gain
to signal level. (Ch. 13)

\textbf{Propagation Delay} --- The time for a signal to travel through a
medium or circuit. In fiber optics: t = d × n/c.~In digital logic: the
time from an input change to the corresponding output change of a gate
(t\textsubscript{pHL}, t\textsubscript{pLH}), determining the critical
path and maximum clock frequency. (Ch. 6, 15)

\textbf{Protective Relay} --- An intelligent device that monitors
electrical quantities (current, voltage, impedance, frequency) via
instrument transformers and issues trip signals to circuit breakers when
abnormal conditions are detected. Types include overcurrent (50/51),
distance (21), differential (87), and directional (67). (Ch. 1)

\textbf{PSD} --- See Power Spectral Density. (Ch. 8)

\textbf{Pseudocapacitor} --- A supercapacitor electrode that stores
charge through reversible Faradaic reactions at the electrode surface
rather than purely electrostatic double-layer adsorption. Common
pseudocapacitive materials include RuO₂ (high performance, expensive),
MnO₂ (low cost), and conducting polymers (polyaniline, polypyrrole).
Achieves 2--5× higher energy density than EDLC at the cost of slightly
reduced cycle life. (Ch. 10)

\textbf{PSK (Phase Shift Keying)} --- A digital modulation technique
that encodes data in the phase of a carrier signal. BPSK uses two phases
(1 bit/symbol), QPSK uses four phases (2 bits/symbol). QPSK achieves the
same BER per bit as BPSK while doubling bandwidth efficiency. (Ch. 2)

\textbf{Pulse Compression} --- A radar technique that transmits a long,
coded waveform (LFM chirp or phase code) and compresses it in the
receiver to achieve the range resolution of a much shorter pulse while
maintaining the energy of the long pulse. Compression ratio =
time-bandwidth product Bτ. (Ch. 17)

\textbf{PWM (Pulse Width Modulation)} --- A technique for encoding an
analog signal level as the duty cycle of a digital pulse train, used in
motor control, power conversion, and DAC approximation. (Ch. 5, 10)

\textbf{Pyrometer} --- A non-contact temperature sensor that measures
thermal radiation emitted by an object's surface. Single-color
pyrometers require known emissivity, while two-color (ratio) pyrometers
compare intensity at two wavelengths to cancel emissivity dependence.
Ranges from −50°C to over 3000°C. (Ch. 11)

\textbf{Q-Factor (Quality Factor)} --- A dimensionless parameter
expressing the ratio of energy stored to energy dissipated per cycle in
a resonant circuit: Q = ω₀L/R (series RLC) or Q = R/(ω₀L) (parallel
RLC). Higher Q means narrower bandwidth and sharper resonance. (Ch. 7)

\textbf{QAM (Quadrature Amplitude Modulation)} --- A modulation scheme
that encodes data in both the amplitude and phase of a carrier, used in
Wi-Fi (up to 4096-QAM in Wi-Fi 7), cable modems, and coherent optical
transceivers. (Ch. 15)

\textbf{Quality of Service (QoS)} --- Network mechanisms that
differentiate traffic classes and provide preferential treatment through
classification/marking (DSCP, 802.1p), queuing/scheduling (strict
priority, WFQ, LLQ), and policing/shaping. Enables latency-sensitive
traffic (VoIP, video) to receive priority over best-effort traffic
during congestion. (Ch. 15)

\textbf{Quantization} --- The process of mapping continuous amplitude
values to a finite set of discrete levels in an ADC, introducing
quantization noise proportional to the step size. (Ch. 2, 11)

\textbf{QUIC} --- A transport-layer protocol built on UDP that provides
reliable, multiplexed, encrypted connections with 1-RTT (or 0-RTT
resumed) handshake latency. Eliminates TCP's head-of-line blocking
through independent streams, mandates TLS 1.3, supports connection
migration via Connection IDs, and serves as the transport for HTTP/3.
(Ch. 15)

\textbf{Radar} --- A system that uses transmitted electromagnetic waves
and their echoes to detect, locate, and measure the velocity of objects.
The received power follows an R⁴ range dependence for point targets.
(Ch. 17)

\textbf{Radar Clutter} --- Unwanted radar echoes from the environment
(ground, sea, rain, birds) that can mask target returns; characterized
by its reflectivity (σ⁰ for surface clutter) and mitigated using MTI
filtering, Doppler processing, and CFAR detection. (Ch. 17)

\textbf{Radar Cross Section (RCS)} --- A measure of a target's
reflectivity to radar: σ =
4πR²(P\textsubscript{reflected}/P\textsubscript{incident}), expressed in
m² or dBsm. Depends on target size, shape, material, and frequency.
Typical values: person \textasciitilde1 m², aircraft
\textasciitilde1--100 m², stealth aircraft \textasciitilde0.001--0.01
m². (Ch. 17)

\textbf{Radiation Pattern} --- A graphical representation of an
antenna's radiated power as a function of direction, showing the main
lobe, sidelobes, nulls, and back lobe. Characterized by beamwidth
(HPBW), sidelobe level, and front-to-back ratio. (Ch. 16)

\textbf{Ragone Plot} --- A log-log chart comparing energy storage
technologies by plotting specific power (W/kg) on the vertical axis
against specific energy (Wh/kg) on the horizontal axis. Each technology
occupies a characteristic region: conventional capacitors (extreme
power, minimal energy) → EDLC → pseudocapacitors/LIC → batteries → fuel
cells (high energy, low power). Used to select the appropriate storage
technology for a given application. (Ch. 10)

\textbf{Rail-to-Rail Op-Amp} --- An op-amp whose input common-mode range
and/or output swing extends to within millivolts of the supply rails
(V\textsubscript{CC} and V\textsubscript{EE}), maximizing usable signal
range in single-supply and low-voltage designs. RRIO (rail-to-rail input
and output) types use complementary input pairs and CMOS output stages.
(Ch. 13)

\textbf{Rayleigh Backscatter} --- Low-level continuous reflections of
light in an optical fiber caused by microscopic density variations in
the glass, used by OTDRs to measure fiber attenuation along the length.
(Ch. 15)

\textbf{Reactance (X)} --- The imaginary component of impedance,
representing opposition to AC current due to energy storage in inductors
(X\textsubscript{L} = ωL, positive) or capacitors (X\textsubscript{C} =
−1/ωC, negative). Measured in ohms. (Ch. 7)

\textbf{Reactive Power (Q)} --- The power that oscillates between source
and reactive elements (inductors and capacitors) without performing
useful work. Measured in volt-ampere reactive (VAR). (Ch. 1, 7)

\textbf{Real Power (P)} --- The average power consumed by resistive
elements and converted to useful work or heat, measured in watts (W). P
= VI cos θ. (Ch. 1, 7)

\textbf{Receiver Sensitivity} --- The minimum input signal power at
which a receiver can achieve the required performance (typically a
specified BER or SNR), determined by the noise floor, noise figure, and
required signal-to-noise ratio. (Ch. 2)

\textbf{Rectifier} --- A circuit that converts AC to DC using diodes.
Configurations include half-wave, full-wave center-tap, and bridge
rectifiers for single-phase, and six-pulse for three-phase. (Ch. 10)

\textbf{Recursive Least Squares (RLS)} --- An adaptive filtering
algorithm that minimizes the exponentially weighted sum of all past
squared errors, converging in approximately M iterations (filter order)
compared to hundreds for LMS. Uses a forgetting factor λ (0.95--1.0) and
costs O(M²) per sample. (Ch. 8)

\textbf{Reflection Coefficient (Γ)} --- The ratio of reflected wave
amplitude to incident wave amplitude at a discontinuity in a
transmission line: Γ = (Z\textsubscript{L} − Z₀)/(Z\textsubscript{L} +
Z₀). (Ch. 9)

\textbf{Refractive Index (n)} --- The ratio of the speed of light in
vacuum to its speed in a medium: n = c/v. Determines how light bends at
interfaces (Snell's law) and governs optical fiber waveguiding. Common
values: air ≈ 1.000, glass ≈ 1.5, silicon ≈ 3.5. (Ch. 18)

\textbf{Regenerative Braking} --- A technique in which a motor operates
as a generator during deceleration, converting kinetic energy back into
electrical energy. The recovered energy is either dissipated in a
braking resistor or returned to the supply through an active front-end
converter. (Ch. 12)

\textbf{Relaxation Oscillator} --- An oscillator that generates square
and triangular waves by alternately charging and discharging a capacitor
between two threshold voltages set by a Schmitt trigger. The frequency
is f = 1/(2RC × ln((1 + β)/(1 − β))), where β is the positive feedback
fraction. Used in function generators, PWM circuits, and clock sources.
(Ch. 13)

\textbf{Reluctance Motor} --- An AC motor that produces torque by
exploiting the tendency of a ferromagnetic rotor to align with the
stator magnetic field to minimize reluctance. Types include the switched
reluctance motor (SRM) with salient poles and the synchronous reluctance
motor (SynRM) with flux barriers in the rotor laminations. (Ch. 12)

\textbf{Replacement Analysis} --- The decision framework for determining
when to retire existing equipment and replace it with new equipment,
based on economic service life and annual cost comparison. (Ch. 19)

\textbf{Resolution} --- The smallest change in a measured quantity that
an instrument can detect and display, determined by the number of bits
(for digital instruments) or scale divisions (for analog instruments).
(Ch. 11)

\textbf{Resonance} --- The condition in an AC circuit where inductive
reactance equals capacitive reactance (X\textsubscript{L} =
X\textsubscript{C}), producing maximum current (series) or maximum
impedance (parallel) at the resonant frequency f₀ = 1/(2π√(LC)). (Ch. 7)

\textbf{Rise Time} --- The time for a system's step response to go from
10\% to 90\% of its final value. For a first-order system:
t\textsubscript{r} = 2.2τ. Inversely related to system bandwidth. (Ch.
4)

\textbf{RMS (Root-Mean-Square)} --- The effective value of an AC
waveform, equal to V\textsubscript{peak}/√2 for a sinusoid. The RMS
value produces the same heating effect as an equivalent DC value. (App.
A)

\textbf{Rogowski Coil} --- A flexible, air-core coil wrapped around a
conductor that outputs a voltage proportional to di/dt; integration
recovers the current waveform. Linear over enormous current ranges (no
magnetic saturation) and ideal for measuring transient and fault
currents. (Ch. 11)

\textbf{Root Locus} --- A graphical method showing how closed-loop poles
move in the s-plane as a parameter (typically loop gain K) varies from 0
to infinity. Branches start at open-loop poles and end at open-loop
zeros. (Ch. 4)

\textbf{Round-Trip Efficiency (RTE)} --- The ratio of energy delivered
by a storage system during discharge to the energy consumed during
charging, expressed as a percentage. For lithium-ion BESS, typical RTE
is 85--92\%, with losses occurring in the inverter, battery internal
resistance, and auxiliary systems. (Ch. 10)

\textbf{Router} --- A Layer 3 network device that forwards packets
between different IP networks based on destination IP address, using
routing tables populated by static configuration or dynamic routing
protocols (OSPF, BGP). (Ch. 15)

\textbf{Routh-Hurwitz Criterion} --- An algebraic stability test that
determines the number of right half-plane poles of a polynomial by
constructing a Routh array and counting sign changes in the first
column. Used to find the range of gain K for stability. (Ch. 4)

\textbf{RTD (Resistance Temperature Detector)} --- A temperature sensor
that measures temperature by correlating the resistance of a metallic
element (typically platinum, Pt100 or Pt1000) with temperature. More
accurate and stable than thermocouples. (Ch. 11)

\textbf{RTOS (Real-Time Operating System)} --- An operating system that
guarantees task execution within specified time constraints (deadlines),
providing deterministic scheduling, inter-task communication, and
resource management for embedded systems. (Ch. 5)

\textbf{RTU (Remote Terminal Unit)} --- A ruggedized
microprocessor-based device installed at a remote field site
(substation, pumping station) that acquires analog and digital
measurements from local instruments, executes supervisory commands from
the SCADA master station, and communicates via DNP3 or IEC 60870-5
protocols. (Ch. 1)

\textbf{SAE J1772} --- The SAE standard defining the Level 1 and Level 2
AC charging connector for electric vehicles in North America, including
the control pilot (CP) signal --- a 1 kHz PWM square wave whose duty
cycle communicates the maximum available current from the EVSE to the
vehicle. (Ch. 10)

\textbf{SAE J2954} --- The SAE standard for wireless (inductive) EV
charging at 85 kHz, defining power levels WPT1 (3.7 kW) through WPT4 (22
kW), ground clearance classes (100--250 mm), alignment tolerances, and
foreign object detection requirements. (Ch. 10)

\textbf{Sallen-Key Filter} --- A popular second-order active filter
topology using a single op-amp with positive feedback through a voltage
follower configuration. Available in low-pass, high-pass, and bandpass
forms. (Ch. 13)

\textbf{Salvage Value} --- The estimated market value of an asset at the
end of its useful life, subtracted from the cost basis when calculating
depreciation. (Ch. 19)

\textbf{Sampling Rate (f\textsubscript{s})} --- The number of samples
taken per second when converting an analog signal to digital form,
measured in samples per second (S/s) or hertz (Hz). (Ch. 2, 8, 11)

\textbf{SAR (Synthetic Aperture Radar)} --- A radar imaging technique
that achieves fine cross-range resolution by coherently processing
echoes collected as the radar platform moves, synthesizing a large
effective antenna aperture. Azimuth resolution = D/2 (antenna length /
2), independent of range. Used for satellite Earth observation and
military reconnaissance. (Ch. 17)

\textbf{SC-FDMA (Single Carrier Frequency Division Multiple Access)} ---
A DFT-precoded OFDM uplink access scheme used in LTE, producing a
single-carrier waveform with 2--4 dB lower peak-to-average power ratio
(PAPR) than OFDMA, improving mobile device power amplifier efficiency
and battery life. (Ch. 2)

\textbf{SCADA (Supervisory Control and Data Acquisition)} --- A
centralized system for real-time monitoring and control of
geographically distributed infrastructure (power grids, pipelines, water
systems). Collects measurements from RTUs/IEDs, displays data on HMI
screens, and relays operator commands to field devices. Modern SCADA
integrates with EMS for state estimation, AGC, and economic dispatch.
(Ch. 1)

\textbf{Schmitt Trigger} --- A comparator circuit with hysteresis (two
different threshold voltages for rising and falling inputs), providing
noise immunity and clean output transitions for noisy or slowly changing
signals. (Ch. 13)

\textbf{Schottky Diode} --- A diode using a metal-semiconductor junction
instead of a PN junction, providing lower forward voltage drop
(0.15-0.45 V), no reverse recovery time, and faster switching. Widely
used in high-frequency power supply rectification. (Ch. 3)

\textbf{SCPI (Standard Commands for Programmable Instruments)} --- A
standardized ASCII command syntax for controlling test instruments over
GPIB, USB-TMC, LAN/LXI, or serial interfaces. Commands follow a
hierarchical tree structure (e.g., \texttt{MEAS:VOLT:DC?}), enabling
manufacturer-independent instrument programming via VISA libraries and
languages such as Python (PyVISA), LabVIEW, and MATLAB. (Ch. 11)

\textbf{Self-Discharge} --- The gradual loss of stored charge in a
capacitor or battery without an external load, caused by leakage
currents through the dielectric or electrolyte. In supercapacitors,
self-discharge is governed by a parallel leakage resistance (100 kΩ--1
MΩ) and reduces the terminal voltage with a time constant of hours to
days --- far faster than batteries (weeks to months). (Ch. 10)

\textbf{Sensitivity Analysis} --- A technique that systematically varies
input parameters to determine how much the economic outcome changes,
identifying the most influential variables. (Ch. 19)

\textbf{Sensorless Motor Control} --- Control techniques that estimate
rotor position and speed without mechanical sensors (encoders,
resolvers). Methods include back-EMF estimation (voltage model
observers, sliding-mode observers, extended Kalman filters) for
medium/high-speed operation, and high-frequency injection (HFI)
exploiting rotor saliency for zero/low-speed operation. (Ch. 12)

\textbf{Sequential Circuit} --- A digital logic circuit whose output
depends on both the current inputs and the previous state (stored in
memory elements such as flip-flops or latches). (Ch. 6)

\textbf{Settling Time} --- The time for a system's step response to
reach and remain within a specified percentage (typically 2\% or 5\%) of
its final value. For a second-order system: t\textsubscript{s} ≈
4/(ζω\textsubscript{n}) for 2\% criterion. (Ch. 4)

\textbf{Setup Time (t\textsubscript{su})} --- The minimum time a data
input must be stable before the active clock edge of a flip-flop to
ensure reliable capture. Part of the critical path timing constraint
along with clock-to-Q delay. (Ch. 6)

\textbf{Shannon-Hartley Theorem} --- The theoretical maximum data rate
of a communication channel: C = B × log₂(1 + SNR), where B is bandwidth
in Hz and SNR is the linear signal-to-noise ratio. (Ch. 15)

\textbf{Shift Register} --- A sequential circuit consisting of cascaded
flip-flops that shifts stored data by one position per clock cycle. Used
for serial-to-parallel conversion, data buffering, and sequence
generation. (Ch. 6)

\textbf{Short-Circuit Current} --- The maximum current that can flow at
a given point in an electrical distribution system during a bolted
fault, determined by the source impedance (transformer, utility, and
conductor). NEC 110.9 requires overcurrent devices to have an
interrupting rating at least equal to the available short-circuit
current. (Ch. 14)

\textbf{SiC (Silicon Carbide)} --- A wide-bandgap semiconductor (3.26
eV) with 10× the critical electric field of silicon, enabling power
MOSFETs and Schottky diodes with dramatically lower on-resistance and
switching losses at 650 V--3.3 kV ratings. Used in EV inverters, solar
inverters, and fast chargers. (Ch. 3, 10)

\textbf{Siemens (S)} --- The SI derived unit of electrical conductance
(reciprocal of ohm). One siemens equals one ampere per volt. (App. D)

\textbf{Silicon (Si)} --- The most widely used semiconductor material,
with a bandgap of 1.1 eV, forming the basis of most diodes, transistors,
integrated circuits, and solar cells. (Ch. 3)

\textbf{Simple Interest} --- Interest calculated only on the original
principal, producing linear growth described by I = P × i × n.~(Ch. 19)

\textbf{Sinking Fund Factor (A/F)} --- The compound interest factor
i/{[}(1+i)ⁿ−1{]} that determines the uniform annual deposit needed to
accumulate a target future amount. (Ch. 19)

\textbf{Skin Effect} --- The tendency of AC current to concentrate near
the surface of a conductor at higher frequencies, increasing effective
resistance and attenuation. The skin depth δ = 1/√(πfμσ) decreases with
frequency. (Ch. 9, 15)

\textbf{Sleep Mode} --- A low-power operating state in a microcontroller
where the CPU is halted and selected peripherals and clocks are disabled
to reduce power consumption. Wake-up is triggered by interrupts, RTC
alarms, or external pin events. (Ch. 5)

\textbf{Slew Rate} --- The maximum rate of change of an op-amp's output
voltage, expressed in V/μs. Limits the maximum undistorted output
frequency for large-signal operation. (Ch. 13)

\textbf{Slip} --- The difference between synchronous speed and actual
rotor speed in an induction motor, expressed as a fraction: s =
(n\textsubscript{s} − n\textsubscript{r})/n\textsubscript{s}. Typical
full-load slip is 2--5\%. (Ch. 12)

\textbf{Slot Antenna} --- An antenna formed by cutting a narrow
rectangular opening in a conducting ground plane. By Babinet's
principle, a half-wave slot has a complementary radiation pattern to a
dipole. Cavity-backed slots eliminate backward radiation and are used
for flush-mounted aircraft and vehicle installations. (Ch. 16)

\textbf{SMF (Single-Mode Fiber)} --- Optical fiber with an 8--10 μm core
that supports only one propagation mode, eliminating modal dispersion.
Standard attenuation: 0.35 dB/km at 1310 nm, 0.20 dB/km at 1550 nm.
Supports transmission over 100+ km. (Ch. 15)

\textbf{Smith Chart} --- A graphical tool that maps complex impedance or
reflection coefficient onto a circular chart, enabling visual analysis
of transmission line matching, VSWR, and impedance transformation. (Ch.
9)

\textbf{Snell's Law} --- The law of refraction relating the angles of
incidence and transmission at an interface between two media: n₁ sin(θ₁)
= n₂ sin(θ₂), where n₁, n₂ are the refractive indices and θ₁, θ₂ are the
angles from the surface normal. (Ch. 18)

\textbf{SNMP (Simple Network Management Protocol)} --- A protocol for
monitoring and managing network devices (routers, switches, servers),
using UDP to exchange management information between agents and a
management station. (Ch. 15)

\textbf{SNR (Signal-to-Noise Ratio)} --- The ratio of desired signal
power to noise power, expressed in dB: SNR = 10
log₁₀(P\textsubscript{signal}/P\textsubscript{noise}). Higher SNR
indicates a cleaner signal. (Ch. 11, App. C)

\textbf{Socket} --- A software endpoint combining an IP address and port
number that provides the API for network communication. A TCP connection
is identified by a 4-tuple: (source IP, source port, destination IP,
destination port). (Ch. 15)

\textbf{Soft Start} --- A controlled startup technique in power
converters that gradually ramps the duty cycle or reference voltage over
a defined interval (typically 5--50 ms), limiting inrush current into
discharged output capacitors and preventing overcurrent trips during
power-on. Also used in motor starters to reduce starting current by
ramping applied voltage. (Ch. 10, 12)

\textbf{Software-Defined Networking (SDN)} --- A network architecture
that separates the control plane (routing decisions) from the data plane
(packet forwarding), centralizing network intelligence in a software
controller that programs forwarding devices via southbound APIs
(OpenFlow, gNMI). Enables programmatic network management, automation,
and policy enforcement through northbound REST/gRPC APIs. (Ch. 15)

\textbf{SONET (Synchronous Optical Networking)} --- A standardized TDM
transport protocol for fiber optic networks. The base rate STS-1 is
51.84 Mbps; higher rates include OC-3 (155 Mbps), OC-48 (2.5 Gbps), and
OC-192 (10 Gbps). (Ch. 2)

\textbf{Spanning Tree Protocol (STP)} --- IEEE 802.1D protocol that
prevents Layer 2 loops in networks with redundant switch links by
electing a root bridge and placing redundant ports in a blocking state
to form a loop-free tree topology. Rapid STP (802.1w) converges in 1--3
seconds vs 30--50 seconds for classic STP. Multiple STP (802.1s) maps
VLAN groups to separate spanning tree instances for per-VLAN load
balancing. (Ch. 15)

\textbf{Specific Energy} --- Energy stored per unit mass, expressed in
watt-hours per kilogram (Wh/kg) or joules per kilogram (J/kg). The key
figure of merit for comparing energy storage technologies: EDLC
supercapacitors 1--15 Wh/kg; Li-ion batteries 100--250 Wh/kg;
lithium-ion capacitors 10--30 Wh/kg. (Ch. 10)

\textbf{Specific Power} --- Peak power deliverable per unit mass,
expressed in watts per kilogram (W/kg). The key figure of merit for
high-rate applications: EDLC supercapacitors 500--10,000 W/kg; Li-ion
batteries 100--1,000 W/kg. Plotted against specific energy on a Ragone
plot to compare technologies. (Ch. 10)

\textbf{Spectral Leakage} --- The spreading of energy across frequency
bins in a DFT caused by analyzing a signal over a finite observation
window. Reduced by applying window functions (Hanning, Hamming,
Blackman). (Ch. 8)

\textbf{SPI (Serial Peripheral Interface)} --- A four-wire synchronous
serial communication protocol (MOSI, MISO, SCLK, CS) providing
full-duplex, high-speed data transfer between a master and one or more
slave devices. (Ch. 5)

\textbf{SRAM (Static Random-Access Memory)} --- Fast volatile memory
that retains data as long as power is supplied, without requiring
refresh cycles. Used for data memory (variables, stack) in
microcontrollers. (Ch. 5)

\textbf{Standard Test Conditions (STC)} --- The standardized reference
conditions under which PV cells and modules are rated: irradiance G =
1,000 W/m², cell temperature T = 25 °C, and AM 1.5 solar spectrum. PV
nameplate power (watts peak, W\textsubscript{p}) is always specified at
STC. Real-world output is typically 10--25\% lower due to elevated cell
temperatures and sub-STC irradiance. (Ch. 10)

\textbf{State Machine (Finite State Machine)} --- A sequential circuit
that transitions between a finite number of states based on current
state and inputs, producing outputs according to a defined mapping.
Moore machines have state-dependent outputs; Mealy machines have
state-and-input-dependent outputs. (Ch. 6)

\textbf{State of Charge (SOC)} --- The remaining capacity of a battery
expressed as a percentage of its rated capacity (0--100\%). Estimated
via coulomb counting, open-circuit voltage lookup, or model-based
methods such as extended Kalman filters. (Ch. 10)

\textbf{State of Health (SOH)} --- A measure of a battery's condition
relative to its original specifications, typically expressed as the
ratio of current maximum capacity to rated capacity. Decreases over time
due to calendar aging and cycle aging from SEI layer growth and lithium
plating. (Ch. 10)

\textbf{State-Space Representation} --- A mathematical model of a
dynamic system using first-order matrix differential equations: ẋ = Ax +
Bu, y = Cx + Du, where x is the state vector, u is input, and y is
output. (Ch. 4, App. F)

\textbf{Stepper Motor} --- A brushless DC motor that divides a full
rotation into a fixed number of equal steps, providing precise open-loop
position control without feedback sensors. Types include permanent
magnet, variable reluctance, and hybrid. (Ch. 12)

\textbf{Straight-Line Depreciation} --- The simplest depreciation
method, allocating equal annual charges of (P−S)/n over the asset's
useful life. (Ch. 19)

\textbf{Strain Gauge} --- A resistive sensor whose resistance changes
proportionally to mechanical deformation (strain), typically bonded to a
structure and measured in a Wheatstone bridge circuit. Gauge factor ≈ 2
for metallic foil gauges. (Ch. 11)

\textbf{Stripline} --- A transmission line structure consisting of a
flat conductor sandwiched between two ground planes with a dielectric
fill; provides inherent shielding and supports TEM propagation, commonly
used in multilayer PCBs and microwave circuits. (Ch. 9)

\textbf{Structured Cabling} --- A standardized approach to building
telecommunications infrastructure following TIA-568/ISO 11801,
organizing cables into horizontal runs (max 90 m), backbone links, and
equipment rooms (MDF/IDF). (Ch. 15)

\textbf{Subnet Mask} --- A 32-bit value that divides an IP address into
network and host portions. Written in dotted-decimal (e.g.,
255.255.255.0) or prefix notation (e.g., /24). (Ch. 15)

\textbf{Supercapacitor} --- An electrochemical energy storage device
occupying the performance space between conventional capacitors and
batteries, offering capacitances from a few farads to thousands of
farads, specific power of 500--10,000 W/kg, specific energy of 1--15
Wh/kg, and cycle lives exceeding 500,000 cycles. Charge storage is
primarily electrostatic (EDLC) or a combination of electrostatic and
Faradaic (pseudocapacitor). Energy stored: E = ½CV²; discharging to
V\textsubscript{max}/2 extracts exactly 75\% of stored energy. Also
called an ultracapacitor or EDLC. Applications include regenerative
braking, peak power buffering, UPS ride-through, and hybrid
battery-supercapacitor systems. (Ch. 10)

\textbf{Superposition} --- The principle that in a linear circuit with
multiple independent sources, the total response equals the algebraic
sum of responses due to each source acting individually (with others
deactivated). (Ch. 7)

\textbf{SWD (Serial Wire Debug)} --- An ARM-specific two-pin debug
interface (SWDIO and SWCLK) providing the same debug capabilities as
JTAG with fewer pins, used as the standard debug interface for Cortex-M
microcontrollers. (Ch. 5)

\textbf{Switch (Network)} --- A Layer 2 device that forwards Ethernet
frames between ports based on destination MAC addresses, using a MAC
address table (CAM table) for lookup. (Ch. 15)

\textbf{Symmetrical Components} --- A mathematical transformation that
decomposes unbalanced three-phase phasors into three balanced sets:
positive sequence (normal rotation), negative sequence (reverse
rotation), and zero sequence (in phase). Used to analyze unbalanced
faults. (Ch. 1)

\textbf{Synchronous Motor} --- An AC motor that runs at exactly
synchronous speed (n\textsubscript{s} = 120f/p RPM), with the rotor
locked to the rotating magnetic field. Requires excitation (DC field or
permanent magnets). (Ch. 12)

\textbf{Tap Rule} --- An NEC exception (240.21(B)) allowing conductors
smaller than the overcurrent device rating for limited lengths (10-foot
or 25-foot tap rules), provided specific conditions are met. (Ch. 14)

\textbf{Target Tracking} --- The process of estimating a radar target's
position, velocity, and trajectory over time using sequential
measurements; implemented with Kalman filters or alpha-beta trackers and
requiring data association in multi-target environments. (Ch. 17)

\textbf{TCAM (Ternary Content-Addressable Memory)} --- Specialized
memory in routers and switches that performs parallel lookups on all
entries simultaneously, enabling wire-speed forwarding table lookups
with ternary (0, 1, don't-care) matching. (Ch. 15)

\textbf{TCP (Transmission Control Protocol)} --- A connection-oriented,
reliable Layer 4 protocol that provides ordered delivery, flow control,
and congestion avoidance using sequence numbers, acknowledgments, and a
sliding window mechanism. (Ch. 15)

\textbf{TDM (Time Division Multiplexing)} --- A multiplexing technique
that assigns each signal a recurring time slot within a repeating frame,
allowing multiple signals to share a single channel. The T-carrier
(DS-1/T1: 1.544 Mbps) and SONET/SDH hierarchies are TDM systems. (Ch. 2)

\textbf{TDR (Time-Domain Reflectometry)} --- A measurement technique
that launches a fast step into a transmission line and analyzes the
reflected waveform to locate impedance discontinuities, faults, and
connector transitions. Each discontinuity appears as a step at a time
corresponding to twice the electrical distance; the characteristic
impedance at any point is Z = Z₀(1 + Γ)/(1 - Γ). (Ch. 9)

\textbf{THD (Total Harmonic Distortion)} --- A measure of waveform
distortion: THD = (√(Σ V\textsubscript{h}²))/V₁ × 100\%. IEEE 519 limits
voltage THD to 5\% at the point of common coupling for systems below 69
kV. (Ch. 1)

\textbf{Thermal Imaging Camera} --- An instrument that captures infrared
radiation emitted by objects to produce a two-dimensional temperature
map (thermogram). Uses cooled (InSb, HgCdTe) or uncooled
(microbolometer) detector arrays. Key parameter: NETD (Noise Equivalent
Temperature Difference), typically 20--50 mK. Requires surface
emissivity compensation for accurate temperature measurement. (Ch. 11)

\textbf{Thermal Interface Material (TIM)} --- A material placed between
a semiconductor package and heat sink to fill microscopic air gaps and
reduce thermal resistance. Types include thermal grease (1--5 W/m·K),
phase-change materials, thermal pads, and sintered silver (up to 250
W/m·K). (Ch. 10)

\textbf{Thermal Noise} --- Random electrical noise generated by the
thermal agitation of charge carriers in any conductor at a temperature
above absolute zero, also called Johnson-Nyquist noise. The noise power
is N = kTB, where k is Boltzmann's constant, T is temperature in kelvin,
and B is bandwidth in hertz. (Ch. 2)

\textbf{Thermal Runaway} --- An uncontrolled exothermic chain reaction
in a lithium-ion battery cell where internal temperature rises above
\textasciitilde130°C, causing separator melting, internal short circuit,
and potentially fire or explosion. BMS protection circuits monitor cell
voltages and temperatures to detect early signs and disconnect the pack.
(Ch. 10)

\textbf{Thermocouple} --- A temperature sensor formed by joining two
dissimilar metals, producing a voltage proportional to temperature
difference (Seebeck effect). Common types: J, K, T, E, N. (Ch. 11)

\textbf{Thin-Film Optical Coating} --- A multilayer stack of alternating
high-index and low-index dielectric materials (each a quarter-wave
optical thickness) deposited on optical surfaces to engineer spectral
reflectance and transmittance. Used to create anti-reflection coatings,
high-reflectivity mirrors (\textgreater{} 99.99\%), bandpass filters,
and dichroic beam splitters. (Ch. 18)

\textbf{Throughput} --- The actual rate of successful data delivery over
a network link, always less than the raw line rate due to protocol
overhead, retransmissions, and congestion. (Ch. 15)

\textbf{Thyristor (SCR)} --- A four-layer (PNPN) semiconductor device
that conducts when triggered by a gate pulse and continues conducting
until forward current drops below the holding current. Used in AC power
control and rectifier circuits. (Ch. 10)

\textbf{Thévenin's Theorem} --- Any linear two-terminal circuit can be
replaced by an equivalent circuit consisting of a voltage source
(V\textsubscript{Th}) in series with a resistance (R\textsubscript{Th}).
(Ch. 7)

\textbf{Time Constant (τ)} --- The time for an exponential response to
reach 63.2\% of its final value (charging) or decay to 36.8\%
(discharging). τ = RC for RC circuits, τ = L/R for RL circuits. (Ch. 7)

\textbf{Time Value of Money} --- The fundamental principle that a dollar
available today is worth more than a dollar received in the future due
to its earning potential through investment. (Ch. 19)

\textbf{TL431} --- A programmable precision shunt voltage regulator from
Texas Instruments, widely used as a voltage reference and error
amplifier in power supply feedback circuits. (Ch. 3)

\textbf{Torque} --- The rotational force produced by a motor, measured
in newton-meters (N·m). Related to power and speed by T = P / ω = P × 60
/ (2π × n). (Ch. 12)

\textbf{Total Internal Reflection} --- The complete reflection of light
at an interface when traveling from a denser to a less dense medium at
an angle exceeding the critical angle θ\textsubscript{c} =
arcsin(n₂/n₁). The fundamental waveguiding mechanism in optical fibers.
(Ch. 18)

\textbf{Transfer Function} --- The ratio of the Laplace transform of a
system's output to its input (assuming zero initial conditions): H(s) =
Y(s)/X(s). Characterizes the input-output behavior of an LTI system.
(Ch. 4, 8)

\textbf{Transfer Switch (ATS)} --- An automatic transfer switch that
monitors the normal power source and transfers the load to an alternate
source (generator) when the normal supply fails. Emergency systems (NEC
Article 700) require transfer within 10 seconds. Modern ATS units
include bypass isolation, programmable time delays, and in-phase
transition monitoring. (Ch. 14)

\textbf{Transformer} --- A static electromagnetic device that transfers
electrical energy between circuits through mutual induction, enabling
voltage step-up or step-down while maintaining approximately constant
power. (Ch. 1)

\textbf{Transient Response} --- The temporary circuit behavior that
occurs during the transition between steady states, governed by the
natural response of energy-storage elements (capacitors and inductors).
(Ch. 7)

\textbf{Transimpedance Amplifier (TIA)} --- An op-amp circuit that
converts an input current to an output voltage with gain
V\textsubscript{out} = -I\textsubscript{in} × R\textsubscript{f}. Used
with photodiodes, phototransistors, and current-output sensors. A
feedback capacitor C\textsubscript{f} is required for stability. (Ch.
13)

\textbf{Transmission Line} --- A pair of conductors designed to carry
electromagnetic signals from source to load with controlled impedance.
In power systems, high-voltage lines carrying bulk power over long
distances. (Ch. 1, 9, 15)

\textbf{Triplen Harmonics} --- Multiples of the third harmonic (3rd,
6th, 9th, 12th, 15th, \ldots) that are zero-sequence. In a balanced
three-phase system, even triplens cancel; odd triplens (3rd, 9th, 15th,
\ldots) are zero-sequence and additive in the neutral conductor of a
three-phase wye system. In systems with nonlinear loads, the neutral
current from triplens can exceed the phase current, requiring oversized
neutral conductors. (Ch. 14)

\textbf{Truth Table} --- A tabular representation of a Boolean function
showing the output value for every possible combination of input values.
(Ch. 6)

\textbf{TTL (Time to Live)} --- A field in the IP packet header that is
decremented by each router; when it reaches zero, the packet is
discarded. Prevents routing loops from causing packets to circulate
indefinitely. (Ch. 15)

\textbf{TTL (Transistor-Transistor Logic)} --- A logic family built from
bipolar junction transistors, historically dominant in digital design.
The 74LS series operates at 5 V with V\textsubscript{OH} = 2.7 V,
V\textsubscript{OL} = 0.5 V, and lower noise margins than CMOS. (Ch. 6)

\textbf{Twisted-Pair Cable} --- Copper cable consisting of insulated
conductor pairs twisted together to reduce electromagnetic interference
and crosstalk. Categories: Cat 5e (100 MHz), Cat 6 (250 MHz), Cat 6A
(500 MHz), Cat 8 (2 GHz). (Ch. 15)

\textbf{Two-Port Network} --- A circuit abstraction with four terminals
grouped into an input port and an output port, characterized by
parameter sets (Z, Y, h, ABCD) that relate port voltages and currents.
Used to model amplifiers, filters, transformers, and transmission line
segments. (Ch. 7)

\textbf{UART (Universal Asynchronous Receiver/Transmitter)} --- A
hardware peripheral for asynchronous serial communication using
start/stop bits for framing, configurable baud rate, and optional parity
for error detection. Common in embedded systems and RS-232 interfaces.
(Ch. 5)

\textbf{UDP (User Datagram Protocol)} --- A connectionless, unreliable
Layer 4 protocol with minimal overhead (8-byte header), used for
real-time applications (VoIP, video, gaming) and lightweight queries
(DNS, SNMP, NTP). (Ch. 15)

\textbf{Ultrafast Laser} --- A laser producing pulses with durations
from femtoseconds (10⁻¹⁵ s) to picoseconds (10⁻¹² s), enabling
applications in precision micromachining, nonlinear optics, and
time-resolved spectroscopy; mode-locked oscillators with chirped pulse
amplification (CPA) achieve peak powers exceeding terawatts. (Ch. 18)

\textbf{Units-of-Production Depreciation} --- A depreciation method that
allocates cost based on actual usage rather than time elapsed,
appropriate for assets whose wear is driven by usage. (Ch. 19)

\textbf{Universal Motor} --- A series-wound DC motor designed to operate
on both AC and DC supplies, achieving high speeds (up to 20,000--30,000
RPM) and high power-to-weight ratios. Commonly used in handheld power
tools, vacuum cleaners, and blenders, with speed controlled by triac
phase-angle controllers. (Ch. 12)

\textbf{USB (Universal Serial Bus)} --- A communication standard
providing data transfer and power delivery through a single cable, using
a host-device topology. Speeds range from Full Speed (12 Mbps) to
SuperSpeed (5-20 Gbps). Common device classes include CDC, HID, and MSC.
(Ch. 5, 15)

\textbf{Varactor Diode} --- A PN junction diode designed to exploit the
voltage-dependent depletion capacitance under reverse bias, used in
voltage-controlled oscillators (VCOs), tuning circuits, and frequency
multipliers. (Ch. 3)

\textbf{VCSEL (Vertical-Cavity Surface-Emitting Laser)} --- A
semiconductor laser that emits light perpendicular to the chip surface
at 850 nm, used as the standard optical source for multimode fiber links
due to low cost and high modulation speed. (Ch. 15, 18)

\textbf{Vector Network Analyzer (VNA)} --- An instrument that measures
the complex (magnitude and phase) S-parameters of RF/microwave devices,
characterizing reflection and transmission as a function of frequency.
Results are displayed as return loss, insertion loss, VSWR, Smith chart
impedance, and group delay. Requires SOLT or TRL calibration to remove
systematic errors. (Ch. 11)

\textbf{Vector Potential (A)} --- A vector field defined by B = ∇ × A,
providing an alternative formulation of Maxwell's equations that
simplifies radiation and antenna calculations. Combined with the scalar
potential φ (where E = −∇φ − ∂A/∂t), the retarded potentials give the
fields produced by arbitrary time-varying source distributions. (Ch. 9)

\textbf{VFD (Variable Frequency Drive)} --- A power electronics system
that controls AC motor speed by varying the frequency and voltage of the
power supplied to the motor. Consists of a rectifier, DC bus, and
inverter. PWM output causes reflected wave voltage doubling on long
cables and bearing currents from common-mode voltage; mitigation
includes dv/dt filters, sine-wave filters, insulated bearings, and shaft
grounding brushes. (Ch. 12)

\textbf{Virtual Ground} --- A node in an op-amp circuit (typically the
inverting input) that is held at ground potential by negative feedback,
without being directly connected to ground. (Ch. 13)

\textbf{VLAN (Virtual LAN)} --- A logical subdivision of a physical
network at Layer 2, implemented using IEEE 802.1Q tags (12-bit VLAN ID)
to isolate broadcast domains without separate physical infrastructure.
(Ch. 15)

\textbf{Volt (V)} --- The SI derived unit of electric potential
difference. One volt is the potential difference that drives one ampere
through one ohm of resistance. (App. D)

\textbf{Voltage Drop} --- The reduction in voltage along a conductor due
to its resistance (and reactance for AC), calculated as
V\textsubscript{drop} = I × Z × L. NEC recommends limiting voltage drop
to 3\% for branch circuits and 5\% total. (Ch. 14)

\textbf{Voltage Follower (Buffer)} --- A non-inverting op-amp
configuration with unity gain (A = 1) and very high input impedance,
used to isolate a high-impedance source from a low-impedance load. (Ch.
13)

\textbf{Voltage Mode Control} --- A power converter control strategy
where the duty cycle is determined by comparing the output voltage error
signal to a fixed-frequency sawtooth ramp; simpler than current mode
control but requires slope compensation at duty cycles above 50\% and
has slower transient response due to the output LC filter pole. (Ch. 10)

\textbf{Voltage Regulator} --- A circuit that maintains a constant
output voltage despite variations in input voltage or load current.
Types include linear regulators, switching regulators (buck, boost), and
shunt regulators (TL431). (Ch. 3)

\textbf{Voltage Sag} --- A temporary reduction in RMS voltage to between
10\% and 90\% of nominal lasting 0.5 cycles to 1 minute, typically
caused by faults on adjacent feeders or motor starting. The most common
power quality disturbance affecting industrial facilities. (Ch. 1)

\textbf{Voltage Transformer (VT)} --- An instrument transformer that
steps down high primary voltages to standardized secondary voltages
(typically 120 V) for metering and protective relaying. Also called a
potential transformer (PT). (Ch. 1)

\textbf{VSWR (Voltage Standing Wave Ratio)} --- A measure of impedance
mismatch on a transmission line: VSWR = (1 + \textbar Γ\textbar)/(1 −
\textbar Γ\textbar), where Γ is the reflection coefficient. VSWR = 1:1
is a perfect match; VSWR \textless{} 2:1 (return loss \textgreater{} 10
dB) is generally acceptable. (Ch. 16)

\textbf{VT} --- See Voltage Transformer. (Ch. 1)

\textbf{Watchdog Timer (WDT)} --- A safety peripheral that resets the
microcontroller if firmware fails to refresh it within a specified
timeout period, providing automatic recovery from software hangs and
fault conditions. Required by most safety-critical standards. (Ch. 5)

\textbf{Watt (W)} --- The SI derived unit of power, equal to one joule
per second. In electrical circuits, P = V × I (DC) or P =
V\textsubscript{rms} × I\textsubscript{rms} × cos θ (AC). (App. D)

\textbf{Watt-hour (Wh)} --- A unit of energy equal to one watt sustained
for one hour, or 3,600 joules. Commonly used for electrical energy
billing (kWh). (App. D)

\textbf{Waveguide} --- A hollow metallic structure (rectangular or
circular) that guides electromagnetic waves by confining them within
conducting walls. Operates above a cutoff frequency f\textsubscript{c}
determined by cross-sectional dimensions; preferred over coaxial cables
at microwave frequencies for lower loss and higher power handling. (Ch.
9)

\textbf{Wavelet Transform} --- A multi-resolution analysis that
decomposes a signal into scaled and translated wavelets, providing
adaptive time-frequency resolution (fine time resolution at high
frequencies, fine frequency resolution at low frequencies). The DWT uses
Mallat's filter bank algorithm for efficient computation. Used in
denoising, JPEG 2000 compression, and transient detection. (Ch. 8)

\textbf{Wheatstone Bridge} --- A four-resistor circuit that measures an
unknown resistance by adjusting known reference resistors until a null
detector reads zero, achieving sub-ppm accuracy. At balance,
R\textsubscript{x} = R₂ × R₃/R₁. Extended forms include the Kelvin
bridge (low resistance), Wien bridge (capacitance), Maxwell bridge
(inductance), and Schering bridge (high-voltage insulation). (Ch. 11)

\textbf{Wi-Fi} --- Wireless local-area networking technology based on
the IEEE 802.11 family of standards, operating in the 2.4 GHz, 5 GHz,
and 6 GHz unlicensed bands. Generations include Wi-Fi 4 (802.11n), Wi-Fi
5 (802.11ac), Wi-Fi 6/6E (802.11ax), and Wi-Fi 7 (802.11be). (Ch. 15)

\textbf{Wide-Bandgap Semiconductor} --- A semiconductor material with a
bandgap significantly larger than silicon's 1.12 eV, such as silicon
carbide (SiC, 3.26 eV) and gallium nitride (GaN, 3.4 eV); enables higher
blocking voltages, switching frequencies, and operating temperatures
with lower conduction and switching losses. (Ch. 10)

\textbf{Wien Bridge Oscillator} --- An op-amp sine wave oscillator using
a Wien network (series RC + parallel RC) in the positive feedback path,
oscillating at f₀ = 1/(2πRC) when the non-inverting amplifier gain
equals exactly 3. Amplitude stabilization (lamp, FET AGC) is required
for low-distortion output. (Ch. 13)

\textbf{Wiener Filter} --- The theoretically optimal linear filter that
minimizes mean squared error between its output and a desired signal. In
the frequency domain, H(f) =
S\textsubscript{xd}(f)/S\textsubscript{xx}(f). For additive noise with
signal and noise uncorrelated, simplifies to H(f) = SNR(f)/(1 + SNR(f)),
passing frequencies with high SNR and suppressing those with low SNR.
The LMS and RLS adaptive algorithms converge toward the Wiener solution
iteratively. (Ch. 8)

\textbf{Windowing} --- The application of a window function (Hanning,
Hamming, Blackman, Kaiser) to a finite-length signal before DFT
computation, reducing spectral leakage at the expense of frequency
resolution. (Ch. 8)

\textbf{Wireless Power Transfer (WPT)} --- The transmission of
electrical energy across an air gap using time-varying magnetic fields
between loosely coupled coils (coupling coefficient k = 0.1--0.6).
Series-series resonant compensation cancels reactive impedance to
maximize efficiency. Standards include Qi (consumer electronics, 5--15 W
at 110--205 kHz) and SAE J2954 (EV charging, 3.7--22 kW at 85 kHz). (Ch.
10)

\textbf{Wound-Rotor Motor} --- An induction motor with a three-phase
rotor winding connected to external circuits through slip rings,
allowing insertion of external resistance for torque-speed control.
Provides maximum torque at standstill for crane and hoist applications,
and enables slip-energy recovery (Scherbius drives). (Ch. 12)

\textbf{WPA3 (Wi-Fi Protected Access 3)} --- The current Wi-Fi security
standard, replacing WPA2. WPA3-Personal uses SAE (Simultaneous
Authentication of Equals) to resist offline dictionary attacks and
provide forward secrecy. WPA3-Enterprise mandates 192-bit cryptographic
strength with AES-256-GCM. (Ch. 15)

\textbf{WSGI (Web Server Gateway Interface)} --- A Python standard (PEP
3333) defining the interface between web servers and Python web
applications, enabling any WSGI-compliant application (Flask, Django) to
run on any WSGI-compliant server (Gunicorn, uWSGI). (Ch. 15)

\textbf{Wye Connection (Y)} --- A three-phase winding configuration
where one terminal of each phase is connected to a common neutral point.
V\textsubscript{LL} = √3 × V\textsubscript{LN}, I\textsubscript{L} =
I\textsubscript{phase}. Provides a neutral for grounding and
single-phase loads. (Ch. 1)

\textbf{Yagi-Uda Antenna} --- A directional wire antenna array with a
single driven element (dipole or folded dipole), a reflector element
(\textasciitilde5\% longer than λ/2), and one or more director elements
(\textasciitilde5--10\% shorter). Parasitic elements create forward gain
through mutual coupling. A 5-element Yagi achieves \textasciitilde10.5
dBi. (Ch. 16)

\textbf{Z-Transform} --- The discrete-time equivalent of the Laplace
transform, converting a discrete-time sequence x{[}n{]} to a function of
the complex variable z: X(z) = Σ x{[}n{]}z⁻ⁿ. Used for digital filter
analysis and design. (Ch. 8)

\textbf{Zener Diode} --- A specially designed diode intended to operate
in reverse breakdown at a precise voltage (the Zener voltage), providing
voltage regulation and voltage reference functions. (Ch. 3)

\textbf{Zero-Order Hold (ZOH)} --- A circuit that holds a sampled value
constant for one sample period T until the next sample arrives,
producing a staircase approximation of the continuous signal. Used in
digital control to interface discrete-time controllers with
continuous-time plants. (Ch. 4)

\textbf{Ziegler-Nichols Method} --- An empirical PID tuning procedure
using either the step response (dead time and time constant) or the
ultimate gain method (finding the gain K\textsubscript{u} and period
P\textsubscript{u} that produce sustained oscillations) to determine
initial K\textsubscript{p}, K\textsubscript{i}, and K\textsubscript{d}
values. (Ch. 4)

\textbf{ZVS (Zero-Voltage Switching)} --- A soft-switching technique
where a power transistor turns on only after its drain-source voltage
has been reduced to zero by resonant action, eliminating turn-on
switching losses and enabling higher switching frequencies with high
efficiency. (Ch. 10)

\end{document}
